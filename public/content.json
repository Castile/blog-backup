{"meta":{"title":"Castile","subtitle":"","description":"","author":"朱宏梁","url":"https://castile.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","text":"","path":"/404.html","date":"11-07","excerpt":""},{"title":"关于","text":"个人详细介绍","path":"about/index.html","date":"11-07","excerpt":""},{"title":"书单","text":"","path":"books/index.html","date":"11-07","excerpt":""},{"title":"分类","text":"","path":"categories/index.html","date":"11-07","excerpt":""},{"title":"Repositories","text":"","path":"repository/index.html","date":"11-07","excerpt":""},{"title":"link","text":"","path":"links/index.html","date":"02-11","excerpt":""},{"title":"标签","text":"","path":"tags/index.html","date":"11-07","excerpt":""}],"posts":[{"title":"领域驱动设计05-识别限界上下文","text":"Mike说： “限界上下文是领域驱动设计中最难解释的原则，但或许也是最重要的原则，可以说，没有限界上下文，就不能做领域驱动设计。在了解聚合根（Aggregate Root）、聚合（Aggregate）、实体（Entity）等概念之前，需要先了解限界上下文。” 如何在DDD中识别出正确的限界上下文？ 答： 凭经验 (正确的废话) 在《程序员的思维修炼》说道： 专家凭直觉工作，而不需要理由。 这说明了这是经验的积累，通过实践无数的项目得出的经验。 限界上下文就是“边界”，这与面向对象设计中的职责分配其实是同一道理。限界上下文的识别并不是一蹴而就的，需要演化和迭代。 通过从业务边界到工作边界再到应用边界这三个层次抽丝剥茧，分别以不同的视角、不同的角色协作来运用对应的设计原则，会是一个可行的识别限界上下文的过程方法 整体过程如下： 1、从业务边界识别限界上下文分析业务场景围绕着“领域”来开展： 明确系统问题也业务期望 和领域专家交流，梳理业务流程 识别参与者/业务活动/业务价值 在业务流程的基础上抽象业务场景 一个业务场景由多个业务活动组成 采用用例对场景进行分析，一个业务活动就是一个用例 业务流程是一个由多个用户角色参与的动态过程，而业务场景则是这些用户角色执行业务活动的静态上下文。从业务流程中抽象出来的业务场景可能是交叉重叠的。 例如，在针对一款文学阅读产品进行需求分析时，可以根据得到的业务流程划分不同的业务场景： 阅读作品 创作作品 支付 社交 消息通知 注册与登录 接下来，我们利用领域场景分析的用例分析方法剖析这些场景。我们往往通过参与者（Actor）来驱动对用例的识别，这些参与者恰好就是参与到场景业务活动的角色。根据用例描述出来的业务活动应该与统一语言一致，最好直接从统一语言中撷取。业务活动的描述应该精准地表达领域概念，且通过尽可能简洁的方式进行描述，通常格式为动宾形式。以阅读作品场景为例，可以包括如下业务活动： 查询作品 收藏作品 关注作者 浏览作品目录 阅读作品 标记作品内容 撰写读书笔记 评价作品 评价作者 分享选中的作品内容 分享作品链接 购买作品 一旦准确地用统一语言描述出这些业务活动，我们就可以从如下两个方面识别业务边界，进而提炼出初步的限界上下文： 语义相关性 功能相关性 1.1 语义相关性语义角度去分析业务活动的描述，倘若是相同的语义，可以作为归类的特征。 识别语义相关性的前提是准确地使用统一语言描述业务活动。在描述时，应尽量避免使用“管理（manage）”或“维护（maintain）”等过于抽象的词语。抽象的词语容易让我们忽视隐藏的领域语言，缺少对领域的精确表达。 在进行语义相关性判断时，还需要注意业务活动之间可能存在不同的语义相关性。 1.2 功能相关性从功能角度去分析业务活动是否彼此关联和依赖，倘若存在关联和依赖，可以作为归类的特征，这种关联性，代表了功能之间的相关性。倘若两个功能必须同时存在，又或者缺少一个功能，另一个功能是不完整的，则二者就是功能强相关的。 所谓“功能相关性”，指的就是职责的内聚性，强相关就等于高内聚。故而从这个角度看，功能相关性的判断标准恰好符合“高内聚、松耦合”的设计原则。 两个相关的功能未必一定属于同一个限界上下文。例如，购买作品与支付购买费用是功能相关的，且前者依赖于后者，但后者从领域知识的角度判断，却应该分配给支付上下文，我们非但不能将其紧耦合在一起，还应该竭尽所能降低二者之间的耦合度。 事实上，功能相关性往往会与上下文之间的协作关系有关。由于这种功能相关性恰恰对应了用例之间的包含与扩展关系，它们往往又可成为识别限界上下文边界的关键点。我在后面讲解上下文映射时还会详细阐释。 接下来就可以为业务领域进行命名了。 2、 从工作边界识别限界上下文如果说为限界上下文划分业务边界，更多的是从业务相关性（内聚）判断业务的归属，那么基于团队合作划分工作边界可以帮助我们确定限界上下文合理的工作粒度。 工作分配的基础在于“尽可能降低沟通成本”，遵循康威定律，沟通其实就是项目模块之间的依赖，这个过程同样不是一蹴而就的。康威认为： 在大多数情况下，最先产生的设计都不是最完美的，主导的系统设计理念可能需要更改。因此，组织的灵活性对于有效的设计有着举足轻重的作用，必须找到可以鼓励设计经理保持他们的组织精简与灵活的方法。 特性团队正是用来解决这一问题的。换言之，当我们发现团队规模越来越大，失去了组织精简与灵活的优势，实际上就是在传递限界上下文过大的信号。项目经理对此需要有清醒认识，当团队规模违背了 2PTs 时，就该坐下来讨论一下如何细分团队的问题了。因此，按照团队合作的角度划分限界上下文，其实是一个动态的过程、演进的过程。 如果我们从团队合作层面看待限界上下文，就从技术范畴上升到了管理范畴。Jurgen Appelo 在《管理 3.0：培养和提升敏捷领导力（Management 3.0: Leading Agile Developers，Developing Agile Leaders）》这本书中提到，一个高效的团队需要满足两点要求： 共同的目标 团队的边界 书中对边界的阐释，大致包括： 团队成员应对团队的边界形成共识，这就意味着团队成员需要了解自己负责的限界上下文边界，以及该限界上下文如何与外部的资源以及其他限界上下文进行通信。 团队的边界不能太封闭（拒绝外部输入），也不能太开放（失去内聚力），即所谓的“渗透性边界”，这种渗透性边界恰恰与“高内聚、松耦合”的设计原则完全契合。 针对这种“渗透性边界”，团队成员需要对自己负责开发的需求“抱有成见”，在识别限界上下文时，“任劳任怨”的好员工并不是真正的好员工。一个好的员工明确地知道团队的职责边界，他应该学会勇于承担属于团队边界内的需求开发任务，也要敢于推辞职责范围之外强加于他的需求。通过团队每个人的主观能动，就可以渐渐地形成在组织结构上的“自治单元”，进而催生出架构设计上的“自治单元”。同理，“任劳任怨”的好团队也不是真正的好团队，团队对自己的边界已经达成了共识，为什么还要违背这个共识去承接不属于自己边界内的工作呢？这并非团队之间的“恶性竞争”，也不是工作上的互相推诿；恰恰相反，这实际上是一种良好的合作，表面上维持了自己的利益，然而在一个组织下，如果每个团队都以这种方式维持自我利益，反而会形成一种“互利主义”。 这种“你给我搔背，我也替你抓抓痒”的互利主义最终会形成团队之间的良好协作。如果团队领导者与团队成员能够充分认识到这一点，就可以从团队层面思考限界上下文。此时，限界上下文就不仅仅是架构师局限于一孔之见去完成甄别，而是每个团队成员自发组织的内在驱动力。当每个人都在思考这项工作该不该我做时，变相地就是在思考职责的分配是否合理，限界上下文的划分是否合理。 3、 从应用边界识别限界上下文3.1 质量属性管理的目的在于打造高效的团队，但最后还是要落脚到技术实现上来，不懂业务分析的架构师不是一个好的程序员，而一个不懂得提前识别系统风险的程序员更不是一个好的架构师。站在技术层面上看待限界上下文，我们需要关注的其实是质量属性（Quality Attributes）。如果把关乎质量属性的问题都视为在将来可能会发生，其实就是“风险（Risk）”。 架构是什么？Martin Fowler 认为：架构是重要的东西，是不容易改变的决策。如果我们未曾预测到系统存在的风险，不幸它又发生了，带给系统架构的改变可能是灾难性的。利用限界上下文的边界，就可以将这种风险带来的影响控制在一个极小的范围，这也是前面提及的安全。为什么说限界上下文是领域驱动设计中最重要的元素，答案就在这里。 3.2 重用和变化无论是重用领域逻辑还是技术实现，都是在设计层面上我们必须考虑的因素，需求变化更是影响设计策略的关键因素。我在前面分析限界上下文的本质时，就提及一个限界上下文其实是一个“自治”的单元。基于自治的四个特征，我们也可以认为这个自治的单元其实就是逻辑重用和封装变化的设计单元。这时，对限界上下文边界的考虑，更多是出于技术设计因素，而非业务因素。 运用重用原则分离出来的限界上下文往往对应于子领域（Sub Domain），尤其作为支撑子领域。限界上下文对变化的应对，其实是“单一职责原则”的体现，即一个限界上下文不应该存在两个引起它变化的原因。 3.3 遗留系统自治原则的唯一例外是遗留系统，因为领域驱动设计建议的通常做法是将整个遗留系统视为一个限界上下文。那么，什么是遗留系统？根据维基百科的定义，它是一种旧的方法、旧的技术、旧的计算机系统或应用程序，这个定义并不能解释遗留系统的真相。我认为，系统之所以成为遗留系统，关键在于知识的缺乏。文档不够全面真实，掌握系统知识的团队成员泰半离开，系统的代码可能是一个大泥团。因此，我对遗留系统的定义是“一个还在运行和使用，但已步入软件生命衰老期的缺乏足够知识的软件系统”。 倘若运用领域驱动设计的系统要与这样一个遗留系统打交道，应该怎么办？窃以为，粗暴地将整个遗留系统包裹在一个限界上下文中，未免太理想化和简单化了。要点还是自治，这时候我们应该站在遗留系统的调用者来观察它，考虑如何与遗留系统集成，然后逐步对遗留系统进行抽取与迁移，形成自治的限界上下文。 在这个过程中，我们可以借鉴技术栈迁移中常常运用的“抽象分支（Branch By Abstraction）”手法。该手法会站在消费者（Consumer）一方观察遗留系统，找到需要替换的单元（组件）；然后对该组件进行抽象，从而将消费者与遗留系统中的实现解耦。最后，提供一个完全新的组件实现，在保留抽象层接口不变的情况下替换掉遗留系统的旧组件，达到技术栈迁移的目的： 如上图所示的抽象层，其实也称之为“防腐层（Anticorruption Layer）”，通过引入这么一个间接层来隔离与遗留系统之间的耦合。这个防腐层往往是作为下游限界上下文的一部分存在。若有必要，也可以单独为其创建一个独立的限界上下文。 4、 设计驱动力通过以上过程去识别限界上下文，仅仅是一种对领域问题域的静态划分，我们还缺少另外一个重要的关注点，即：限界上下文之间是如何协作的？倘若限界上下文识别不合理，协作就会变得更加困难，尤其当一个限界上下文对应一个微服务时，协作成本更会显著增加。反过来，当我们发现彼此协作存在问题时，说明限界上下文的划分出现了问题，这算是对识别限界上下文的一种验证方法。Eric Evans 将这种体现限界上下文协作方式的要素称之为“上下文映射（Context Map）”。","path":"2024/11/11/领域驱动设计05-识别限界上下文/","date":"11-11","excerpt":"","tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"限界上下文","slug":"限界上下文","permalink":"https://castile.github.io/tags/%E9%99%90%E7%95%8C%E4%B8%8A%E4%B8%8B%E6%96%87/"}]},{"title":"nebula图数据库","text":"图数据库概述图数据库是专门存储庞大的图形网络并从中检索信息的数据库。它可以将图中的数据高效存储为点（Vertex）和边（Edge），还可以将属性（Property）附加到点和边上。 图数据库适合存储大多数从现实抽象出的数据类型。世界上几乎所有领域的事物都有内在联系，像关系型数据库这样的建模系统会提取实体之间的关系，并将关系单独存储到表和列中，而实体的类型和属性存储在其他列甚至其他表中，这使得数据管理费时费力。 NebulaGraph 作为一个典型的图数据库，可以将丰富的关系通过边及其类型和属性自然地呈现。","path":"2024/11/07/nebula图数据库/","date":"11-07","excerpt":"","tags":[{"name":"nebula","slug":"nebula","permalink":"https://castile.github.io/tags/nebula/"},{"name":"图数据库","slug":"图数据库","permalink":"https://castile.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Java四大引用类型","text":"四大引用类型强引用被强引用关联的对象不会被回收。 使用 new 一个新对象的方式来创建强引用。 当内存不足。JVM开始垃圾回收，对于强引用的对象，就算是出现了OOM也不会对该对象进行回收，死都不收。 强引用是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还活着。垃圾收集器不会碰这种对象。Java中最常见的就是强引用，把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，他是不可能被垃圾回收机制回收的。即使该对象以后永远都不会被用到，jvm也不会回收。因此，强引用是造成Java内存泄露的主要原因之一。 对于一个普通对象，如果没有其他的引用关系，只要超过了引用的作用域或者显示的将强引用赋值为null，一般就认为就是可以被垃圾收集的了，当然具体回收时机还要看垃圾收集策略。 123456789101112131415161718192021222324package cn.hongliang.reference;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @Date 2020-08-26-20:10 */public class StrongReferenceDemo &#123; public static void main(String[] args) &#123; // 这样定义的默认是强引用 Object obj1 = new Object(); Object obj2 = obj1; // obj2引用赋值 obj1 = null;// 置为null System.gc(); // 并不会马上执行垃圾回收 执行System.gc()函数的作用只是提醒或告诉虚拟机，希望进行一次垃圾回收。 try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(obj2); &#125;&#125; java.lang.Object@1540e19d 软引用被软引用关联的对象只有在内存不够的情况下才会被回收。 使用 SoftReference 类来创建软引用。 软引用通常用在对内存才能敏感的程序中，比如高速缓存就有用到软引用，内存够的时候就保留，不够就回收。 先设置JVM参数： -Xmx20m， heap内存为20M 1234567891011121314151617181920212223242526272829package cn.hongliang.reference;import java.lang.ref.SoftReference;import java.util.Calendar;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @Date 2020-08-26-20:19 */public class SoftReferenceDemo &#123; public static void main(String[] args) &#123; SoftReference&lt;byte[] &gt; softReference = new SoftReference&lt;&gt;(new byte[1024*1224*10]); System.out.println(softReference.get()); System.gc(); try &#123; Thread.sleep(500); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; System.out.println(softReference.get()); byte[] a = new byte[1024*1024*10]; //再分配一个数组，heap将装不下，这时系统会进行垃圾回收，先回收一次，如果不够，就会把软引用回收 System.out.println(softReference.get()); // 回收 &#125;&#125; [B@1540e19d[B@1540e19dnull 假如有一个应用需要读取大量的本地图片，如果每一次读取图片都是从硬盘中读取则会严重影响性能；如果一次性全部加载到内存中又可能造成内存溢出。 此时可以使用软引用来解决这个问题。 设计思路： 用一个HashMap来保存图片的路径和相应图片对象的软引用之间的映射关系，在内存不足时候，JVM会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。 1Map&lt;String, SoftReference&lt;Bitmap&gt;&gt; imgCache = new HashMap&lt;&gt;(); 弱引用被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。 使用 WeakReference 类来创建弱引用。 1234567891011121314151617import java.lang.ref.WeakReference;/** * @author Hongliang Zhu * @Date 2020-08-26-20:38 */public class WeakRederenceDemo &#123; public static void main(String[] args) &#123; WeakReference&lt;M&gt; weakReference = new WeakReference&lt;&gt;(new M()); System.out.println(weakReference.get()); System.gc(); System.out.println(weakReference.get()); &#125;&#125; cn.hongliang.reference.M@1540e19dnullfinalize weakHashMap待补充… 虚引用又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 使用 PhantomReference 来创建虚引用。 顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。他不能单独使用，也不能通过他访问对象。虚引用必须和引用队列（ReferenceQueue）联合使用。 虚引用的主要作用是跟踪对象被垃圾回收的状态。仅仅是提供了一种确保对象被finalize以后做某些事情的机制。PhantomReference 的get方法总是返回null。因此无法访问对应的引用对象。其意义在于说明一个对象已经进入finalization阶段，可以被gc回收。用来实现比finalization机制更灵活的回收操作。 换句话说，设置虚引用关联的唯一目的就是在这个对象被收集器回收的时候收到一个系统通知或者后续添加进一步处理。java技术允许使用finalize方法在垃圾收集器将对象从内存中移除出去之前 做必要的清理工作。 实际上，这个和直接内存有关。虚引用的作用就是为了管理直接内存。 我们程序的内存通常是由JVM来管理的，垃圾回收器是工作在JVM里面，但是为了提高效率，比如说，当OS收到了网络发送来的数据，会通过OS的系统内核的方法将传来的数据放在OS的内存里面，如果Java程序要用的话，需要从OS的内存中copy过来，这样的效率太低了。所以在新版的JVM中提供了一个直接内存（DirectByteBuffer），他可以通过虚拟机的一个指针直接指向OS管理的内存中。可以直接访问操作系统的内存，这样就不需要copy一份了。 那么JVM怎么回收这部分系统内存呢？ 内部机制就是用的虚引用，虚引用new的时候，执指向一个对象，这个对象要回收的时候，会将其放入一个队列里面，相当于跟踪这个对象。主要分为两步，第一步将其放入队列，第二步是通过队列来进行回收的。需要回收的时候发起一个通知。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cn.hongliang.reference;import java.lang.ref.PhantomReference;import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.util.LinkedList;import java.util.List;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @Date 2020-08-26-20:53 */public class PhantomReferenceDemo &#123; private static final List&lt;Object&gt; list = new LinkedList&lt;&gt;(); private static final ReferenceQueue&lt;M&gt; queue = new ReferenceQueue&lt;&gt;(); public static void main(String[] args) &#123; PhantomReference&lt;M&gt; phantomReference = new PhantomReference&lt;&gt;(new M(), queue); System.out.println(phantomReference.get()); new Thread(()-&gt;&#123; while (true)&#123; list.add(new byte[1024*1024]); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); Thread.currentThread().interrupt(); &#125; System.out.println(phantomReference.get()); &#125; &#125;).start(); new Thread(()-&gt;&#123; while (true)&#123; Reference&lt;? extends M&gt; poll = queue.poll(); if(poll != null)&#123; System.out.println(&quot;虚引用被JVM回收了...&quot; + poll); &#125; &#125; &#125;).start(); &#125;&#125;","path":"2024/11/07/四大引用/","date":"11-07","excerpt":"","tags":[{"name":"Thread","slug":"Thread","permalink":"https://castile.github.io/tags/Thread/"},{"name":"多线程","slug":"多线程","permalink":"https://castile.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"设计模式-单例设计模式","text":"单例设计模式涉及到的知识点 类加载机制 字节码知识 jvm指令重排序 java序列化机制 定义及应用场景保证一个类只有一个实例，并且提供一个全局访问点 场景： 线程池、数据库连接池 单例设计模式八种方式 饿汉式**(静态常量)** 饿汉式（静态代码块） 懒汉式(线程不安全) 懒汉式(线程安全，同步方法) 懒汉式(线程安全，同步代码块) 双重检查 静态内部类 枚举 懒汉式使用的时候才开始初始化 123456789101112class LazySingleton&#123; private static LazySingleton instance = null; // 单例对象 private LazySingleton()&#123;&#125; // 私有化构造函数 // 静态工厂方法 public static LazySingleton getInstance()&#123; if(instance == null)&#123; instance = new LazySingleton(); &#125; &#125;&#125; 1.要想让一个类只能构建一个对象，自然不能让它随便去做new操作，因此Signleton的构造方法是私有的。 2.instance是Singleton类的静态成员，也是我们的单例对象。它的初始值可以写成Null，也可以写成new Singleton()。至于其中的区别后来会做解释。 3.getInstance是获取单例对象的方法。 如果单例初始值是null，还未构建，则构建单例对象并返回。这个写法属于单例模式当中的懒汉模式。 如果单例对象一开始就被new Singleton()主动构建，则不再需要判空操作，这种写法属于饿汉模式。 这两个名字很形象：饿汉主动找食物吃，懒汉躺在地上等着人喂 但是上面的代码并不安全，为啥？在多线程的环境下去创建会导致返回多个不同的实例对象 123456789101112131415161718192021222324252627282930313233343536public class SingletonTest &#123; public static void main(String[] args) &#123; /** * 模拟两个线程 */ new Thread(()-&gt;&#123; LazySingleton l1 = getInstance(); System.out.println(l1);&#125;).start(); new Thread(()-&gt;&#123; LazySingleton l1 = getInstance(); System.out.println(l1);&#125;).start(); &#125;&#125;class LazySingleton&#123; private static LazySingleton instance = null; // 单例对象 private LazySingleton()&#123;&#125; // 私有化构造函数 // 静态工厂方法 public static LazySingleton getInstance()&#123; if(instance == null)&#123; try &#123; TimeUnit.SECONDS.sleep(2); // 休眠2秒 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; instance = new LazySingleton(); &#125; return instance; &#125;&#125; cn.hongliang.singleton.LazySingleton@6afa9656cn.hongliang.singleton.LazySingleton@2b3351f2 可以看到创建了两个不同的实例对象，单例失效了！ 假设Singleton类刚刚被初始化，instance对象还是空，这时候两个线程同时访问getInstance方法： 因为Instance是空，所以两个线程同时通过了条件判断，开始执行new操作： 这样的话两个线程分别创建一个实例。 对于线程不安全的问题，我们很直观的就想到加锁，使用synchronized关键字，改写代码如下： 12345678910111213141516class LazySingleton&#123; private static LazySingleton instance = null; // 单例对象 private LazySingleton()&#123;&#125; // 私有化构造函数 // 静态工厂方法 public static LazySingleton getInstance()&#123; if(instance == null)&#123; synchronized (LazySingleton.class)&#123; // 注意，这里要锁类 if (instance == null)&#123; // 双重检测机制 instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 细节问题： 为了防止new Singleton被执行多次，因此在new操作之前加上Synchronized 同步锁，锁住整个类（注意，这里不能使用对象锁）。 因为锁实例是锁不到的，每个线程还是可以进来。 在拿到锁之后，进入到 Synchronized 临界区以后，还要再做一次判空。 因为如果一个线程已经创建了一个实例，下一个进程进来的时候也会执行一次new Singleton操作，这样又创建了两个对象，所以这里要加上双重检测机制。 但是上面的代码还是有漏洞， 这就涉及到了JVM 的指令重排序问题了。 指令重排序：JVM会根据cpu的执行情况，改变程序指令的执行顺序。我们创建一个对象的时候经历了很多步操作，1. 加载： 加载对应的二进制字节码文件，并且在方法区创建对应的数据结构，2. 连接： a. 验证 b.解析 c.初始化， 3. 初始化： 给静态属性赋值。 12345public class User &#123; public static void main(String[] args) &#123; User user = new User(); &#125;&#125; 反编译： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 Last modified 2020-8-8; size 435 bytes MD5 checksum 3b5f34a0e7b4eb8045214ecd6c8a007d Compiled from &quot;User.java&quot;public class cn.hongliang.singleton.User minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#19 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Class #20 // cn/hongliang/singleton/User #3 = Methodref #2.#19 // cn/hongliang/singleton/User.&quot;&lt;init&gt;&quot;:()V #4 = Class #21 // java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 LocalVariableTable #10 = Utf8 this #11 = Utf8 Lcn/hongliang/singleton/User; #12 = Utf8 main #13 = Utf8 ([Ljava/lang/String;)V #14 = Utf8 args #15 = Utf8 [Ljava/lang/String; #16 = Utf8 user #17 = Utf8 SourceFile #18 = Utf8 User.java #19 = NameAndType #5:#6 // &quot;&lt;init&gt;&quot;:()V #20 = Utf8 cn/hongliang/singleton/User #21 = Utf8 java/lang/Object&#123; public cn.hongliang.singleton.User(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 7: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcn/hongliang/singleton/User; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=2, args_size=1 0: new #2 // class cn/hongliang/singleton/User 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: return LineNumberTable: line 9: 0 line 10: 8 LocalVariableTable: Start Length Slot Name Signature 0 9 0 args [Ljava/lang/String; 8 1 1 user Lcn/hongliang/singleton/User;&#125;SourceFile: &quot;User.java&quot; 指向简单的一个new对象操作，会执行以下指令 123456memory =allocate(); //1：分配对象的内存空间 ctorInstance(memory); //2：初始化对象 instance =memory; //3：设置instance指向刚分配的内存地址 但是这几条指令不是一成不变的，有可能会经过JVM和CPU的优化，指令重排成下面的顺序： 12345memory =allocate(); //1：分配对象的内存空间 instance =memory; //3：设置instance指向刚分配的内存地址 ctorInstance(memory); //2：初始化对象 当执行到第二条的时候，对象已经创建了，但是对象没有完成初始化，是一个不完整的对象。而此时线程T2 抢占到了cpu，在第一个if判断语句，得到的结果是不为空，然后直接返回此对象。这样得到的是一个未经过初始化的一个对象，之后很可能会出现空指针异常。 解决方法是使用volatile关键字，次关键字可以禁止指令重排序。所以改进后的单例设计模式如下 12345678910111213141516class LazySingleton&#123; private static volatile LazySingleton instance = null; // 单例对象 private LazySingleton()&#123;&#125; // 私有化构造函数 // 静态工厂方法 public static LazySingleton getInstance()&#123; if(instance == null)&#123; synchronized (LazySingleton.class)&#123; // 注意，这里要锁类 if (instance == null)&#123; // 双重检测机制 instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 如此在线程T2看来，instance对象的引用要么指向null，要么指向一个初始化完毕的Instance，而不会出现某个中间态，保证了安全。 synchronized改为reentranlock如何写12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class LockSingleton &#123; private static volatile LockSingleton instance = null; private static Lock lock = new ReentrantLock(); private LockSingleton() &#123; &#125; public static LockSingleton getInstance()&#123; if(instance == null)&#123; lock.lock(); try &#123; if (instance == null)&#123; instance = new LockSingleton(); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; return instance; &#125; public static void main(String[] args) &#123; new Thread(()-&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; instance = getInstance(); System.out.println(instance); &#125;).start(); new Thread(()-&gt;&#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; instance = getInstance(); System.out.println(instance); &#125;).start(); &#125;&#125; 饿汉模式在类加载阶段就完成了实例化。通过类加载机制来保证线程安全 类加载有是三个步骤加载： 加载对应的二进制字节码文件，并且在方法区创建对应的数据结构 连接： a. 验证 b.解析 c.初始化 初始化： 给静态属性赋值 123456789101112public class HungarySingleton &#123; private static HungarySingleton instance = new HungarySingleton(); // 私有化构造方法 private HungarySingleton()&#123;&#125; // 公有的方法返回实例对象 public static HungarySingleton getInstance() &#123; return instance; &#125;&#125; 优点：这种写法比较简单，就是在类装载的时候就完成实例化。避免了线程同步问题。 缺点：在类装载的时候就完成实例化，没有达到 Lazy Loading 的效果。如果从始至终从未使用过这个实例，则会造成内存的浪费。 静态内部类1234567891011121314public class Singleton &#123; ///静态内部类 private static class InstanceHolder&#123; private final static Singleton INSTANCE = new Singleton(); &#125; // 私有化构造方法 private Singleton()&#123;&#125; public static Singleton getInstance() &#123; return InstanceHolder.INSTANCE; &#125;&#125; 从外部无法访问静态内部类InstanceHolder，只有当调用Singleton.getInstance方法的时候，才能得到单例对象INSTANCE。 INSTANCE对象初始化的时机并不是在单例类Singleton被加载的时候，而是在调用getInstance方法，使得静态内部类InstanceHolder被加载的时候。因此这种实现方式是利用classloader的加载机制来实现懒加载，并保证构建单例的线程安全。 可以看到，使用静态内部类的方法创建单例对象是很巧妙的，但是，和以上方法一样，都不能阻止使用反射机制来创建，也就是说，反射机制会打破上述单例模式。 来看看是怎么实现的。 反射打破单例12345678910111213141516public class RefectSingleton &#123; public static void main(String[] args) throws Exception &#123; // 首先获得构造器 Class&lt;?&gt; clazz = Class.forName(&quot;cn.hongliang.singleton.Singleton&quot;); Constructor&lt;?&gt; declaredConstructor = clazz.getDeclaredConstructor(); // 因为构造方法是private的， 所以设置暴力反射 declaredConstructor.setAccessible(true); // 创建对象 Singleton s1= (Singleton) declaredConstructor.newInstance(); Singleton s2= (Singleton) declaredConstructor.newInstance(); System.out.println(s1 == s2); System.out.println(s1.hashCode() == s2.hashCode()); &#125;&#125; falsefalse 可以看到创建的两个实例对象，所以破坏了单例。 接下来介绍一下使用枚举类的方法来创建单例对象，枚举的方式可以阻止反射。 枚举123public enum SingletonEnum &#123; INSTANCE;&#125; 这借助 JDK1.5 中添加的枚举来实现单例模式。不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象。 缺点就是并不是使用懒加载的方式实现的。 这种方式是 Effective Java 作者 Josh Bloch 提倡的方式. 如果使用反射来创建实例，会抛出异常。 1234567891011public class RefectSingleton &#123; public static void main(String[] args) throws Exception &#123; SingletonEnum singletonEnum1 = SingletonEnum.class.getDeclaredConstructor().newInstance(); SingletonEnum singletonEnum2 = SingletonEnum.class.getDeclaredConstructor().newInstance(); System.out.println(singletonEnum1 == singletonEnum2); &#125;&#125; Exception in thread “main” java.lang.NoSuchMethodException: cn.hongliang.singleton.SingletonEnum.&lt;init&gt;()at java.lang.Class.getConstructor0(Class.java:3082)at java.lang.Class.getDeclaredConstructor(Class.java:2178)at cn.hongliang.singleton.RefectSingleton.main(RefectSingleton.java:24) 刚刚说了枚举既可以防止反射创建单例也能够防止反序列化创建新的对象，我们继续看看什么是序列化。 序列化什么是序列化？序列化就是将java对象编码成二进制文件，课保存在磁盘中。 反序列化就是从文件中解码成一个对象。 怎么实现序列化java对象实现Serializable接口，通过ObjectOutputStream， ObjectInputputStream实现序列化和反序列化。 什么样的数据会序列化到文件中对象的默认序列化机制写入的内容是：对象的类，类签名，以及非瞬态（transit）和非静态字段的值，因为静态static的东西在方法区。 所以序列化的数据是在堆中的，将堆中数据的生命周期延长，持久化到文件，保存到磁盘中，文件扩展名是.object， 当我们以后想要使用这个类的时候就不需要new了，直接从文件中读取就行。 serialVersionUID SerializableUID号是根据类的特征和类的签名算出来的 ，主要用于判断是否为同一个版本的对象。如果没有加上serialVersionUID ，在反序列化之前更改了类的签名或者增加了一些字段，在反序列化的时候就报错。 12345678910111213141516171819202122232425public class User implements Serializable &#123; private String name;&#125;public class SeralizVersionIDTest &#123; public static void main(String[] args) throws Exception &#123; User user = new User(); // 序列化// ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;user&quot;));// oos.writeObject(user);// 反序列化 ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;user&quot;)); User user1 = (User) ois.readObject(); System.out.println(user1.toString());// oos.close(); ois.close(); &#125;&#125; 在反序列化之前，增加了一个属性 123456789public class User implements Serializable &#123; private String name; private int age; private int id;&#125; 反序列化之后报错 所以我们需要手动指定一个serialVersionUID ，就可以正常反序列化了。 静态变量的序列化我们在User类中加上一个静态变量 1public static int i = 100; 然后在序列化之后，将变量i修改成99， 通过反序列化之后i的值应该是多少呢？ 1234567891011121314151617public class SeralizVersionIDTest &#123; public static void main(String[] args) throws Exception &#123; User user = new User(); // 序列化 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;user&quot;)); oos.writeObject(user); User.i = 99; // 序列化之后改变值// 反序列化 ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;user&quot;)); User user1 = (User) ois.readObject(); System.out.println(user1.i); oos.close(); ois.close(); &#125;&#125; 99 这说明了序列化不对静态变量序列化。我们总说是对象序列化，但是i数据属于类变量，所以不会序列化静态变量。 不想要序列化？transit那么对于非静态变量就可以序列化，但是可不可以选择不序列化呢？ 当然，那就是transit关键字 Transient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。 父类的序列化考虑这种情况，子类实现了Serializable接口，父类没有实现Serializable接口。看看序列化与反序列化的时候会出现什么情况。 123456789101112public class Father &#123; public int money; public Father(int money) &#123; this.money = 100; &#125; public Father()&#123;&#125; // 默认的构造函数， 不加报错&#125;class Son extends Father implements Serializable &#123; public static final long serialVersionUID = 1L; private int a = 9;&#125; 12345678910111213141516public class SeralizVersionIDTest &#123; public static void main(String[] args) throws Exception &#123; Son son = new Son(); // 序列化 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;son&quot;)); oos.writeObject(son);// 反序列化 ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;son&quot;)); Son s = (Son) ois.readObject(); System.out.println(s.money); // 父亲那里继承下来的钱 oos.close(); ois.close(); &#125;&#125; 0 反序列化子类需要创建父类，调用父类默认的无参构造方法。 所以除了可以用tansit关键字修饰不想被序列化的属性之外，还可以将不想序列化的属性放入父类中，子类实现Serializable接口， 父类不实现。 单例解决序列化的问题言归正传！！！！！！！！！！！！回到单例设计模式 下面以饿汉模式举例， 实现Serializable接口，看看序列化的问题 123456789101112public class HungarySingleton implements Serializable &#123; private static HungarySingleton instance = new HungarySingleton(); // 私有化构造方法 private HungarySingleton()&#123;&#125; // 公有的方法返回实例对象 public static HungarySingleton getInstance() &#123; return instance; &#125;&#125; 序列化测试 123456789101112public class SerializableTest &#123; public static void main(String[] args) throws Exception &#123; HungarySingleton instance = HungarySingleton.getInstance(); // 序列化 ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;instance&quot;)); oos.writeObject(instance); // 反序列化 ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;instance&quot;)); HungarySingleton instance1 = (HungarySingleton) ois.readObject(); System.out.println(instance1 == instance); &#125;&#125; false 可以发现返回的是两个对象，也就是说，序列化破坏了我们的单例模式！ 那怎么解决呢？ 使用 readResolve() 12345678910111213141516public class HungarySingleton implements Serializable &#123; public static final long serialVersioUID = 1L; private static HungarySingleton instance = new HungarySingleton(); // 私有化构造方法 private HungarySingleton()&#123;&#125; // 公有的方法返回实例对象 public static HungarySingleton getInstance() &#123; return instance; &#125; private Object readResolve() &#123; return instance; &#125;&#125; 似乎是加了readResolve()方法后反序列化做的是浅拷贝,也就是拷贝的是之前对象的指针,指的还是原先的对象， 而不加默认是深拷贝?直接开辟新空间, 地址自然就不一样了. 如果使用枚举的话，可以解决序列化的问题。 使用枚举实现的单例模式，不但可以防止利用反射强行构建单例对象，而且可以在枚举类对象被反序列化的时候，保证反序列的返回结果是同一对象。","path":"2024/11/07/单例设计模式/","date":"11-07","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"初探ThreadLocal","text":"ThreadLocal当调用theadlocal的set的方法的时候， set方法的源码 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); // 获取当前的线程 ThreadLocalMap map = getMap(t); // 获取当前线程的ThreadLocalMap： threadlocals if (map != null) map.set(this, value); // 往map里面put值，key为threadlocal对象，value是threadlocal里面的值 else createMap(t, value); &#125; 进一步看一下getMap里面的内容 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; 在Thread类里面 1ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocalMap底层是一个Map结构。在ThreadLocal里面的一个静态内部类，ThreadLocalMap里面又包含一个Entry的静态内部类，是一个k-v键值对的结构，key为threadlocal对象，value是里面的值。还继承了WeakReference， 所以这个Entry是一个弱引用对象，当垃圾收集器看到他的时候会直接回收。 1234567891011121314151617181920212223static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; /** * The initial capacity -- MUST be a power of two. */ private static final int INITIAL_CAPACITY = 16; /** * The table, resized as necessary. * table.length MUST always be a power of two. */ private Entry[] table;&#125; 当我们new了一个threadlocal对象，调用set方法的时候，先拿到 当前的线程的ThreadLocalMap threadlocals， 这是一个Map结构，key为threadlocal对象，value是threadlocal对象里面的值，key是通过一个弱引用指向threadlocal对象的。如下图所示。 为什么是弱引用呢？ 假如这是个强引用，当tl的引用置为null的时候，key的引用不为null，还指向了threadlocal对象，所以这时threadlocal将不会被回收，就可能发生内存泄漏。如果是弱引用的话，当JVM虚拟机运行gc的时候，发现threadlocal是一个弱引用，则直接将其回收，这样就可以解决内存泄漏问题。 还有一个问题，假如，这时候key为null了，要想通过get方法获得value的话是不可能获取到的，这个value对象的值怎么释放呢？所以，这也会产生内存泄漏 的情况，良好的编程习惯是将这一条记录remove掉，这样就防止了value这部分的内存泄漏。 假如使用的线程池，如果不清理掉旧的记录，当线程复用的时候，会导致数据混乱。所以，线程池的底层源码就是每次开启一个线程的时候都会将当前线程的ThreadLocalMap置为null。 ThreadLocal的使用场景spring关于事务的管理 mybatis中分页的处理。","path":"2024/11/07/theadlocal/","date":"11-07","excerpt":"","tags":[{"name":"Thread","slug":"Thread","permalink":"https://castile.github.io/tags/Thread/"},{"name":"多线程","slug":"多线程","permalink":"https://castile.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"Java中的各种锁机制","text":"Java中的各种锁机制图片来自于美团技术团队java主流锁 一、公平锁和非公平锁公平锁​ 是指多个线程按照申请锁的顺序来获取锁，类似排队打饭，先来后到 非公平锁​ 是指在多线程获取锁的顺序并不是按照申请锁的顺序, 有可能后申请的线程比先申请的线程优先获取到锁, 在高并发的情况下, 有可能造成优先级反转或者饥饿现象。 公平锁/非公平锁区别 并发包ReentrantLock的创建可以指定构造函数的boolean类型来得到公平锁或者非公平锁 （默认是非公平锁） 1234567 public ReentrantLock() &#123; sync = new NonfairSync(); &#125;public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; 公平锁： Thread acquire a fair lock in the order in which they requested it 公平锁就是很公平，在并发环境下，每个线程获取锁时会先查看此锁维护的等待队列，如果为空，或者当前线程时等待队列的第一个，就占有锁，否则就会被加入到等待队列中，以后会按照FIFO的规则从队列中取到自己。 非公平锁： 非公平锁比较粗鲁， 上来就直接尝试占有锁，如果尝试失败，就在采用类似公平锁那种方式。 ReentrantLock而言，通过构造函数指定该锁是否是公平锁。默认是非公平锁，非公平锁的优点在于吞吐量比公平锁大。 对于synchronized而言 也是一种非公平锁。 下面是ReentrantLock的公平锁和非公平锁源码 公平锁加锁： 123456789101112131415161718192021protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; // 判断线程是不是同步队列中的第一个 compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 非公平锁： 12345678910111213141516171819final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; 源代码对比，我们可以明显的看出公平锁与非公平锁的lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。 12345678910public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。 综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。 二、可重入锁也称为递归锁。指的是同一线程外层函数获得锁之后，内层的方法仍然可以获得该锁的代码。在同一个线程的外层方法获取锁的时候，在进入内层方法会自动获取锁。也就是说，线程可以进入任何一个它已经拥有锁的同步代码。 其最大的作用就是可以避免死锁。 synchronized接下来证明synchronized是可重入锁 123456789101112131415161718192021222324252627package cn.hongliang.lock;import java.util.concurrent.locks.ReentrantLock;class Phone&#123; public synchronized void sendMsg()&#123; System.out.println(Thread.currentThread().getId()+&quot;\\t invoke sendMsg&quot;); sendEmail(); &#125; public synchronized void sendEmail()&#123; System.out.println(Thread.currentThread().getId()+&quot;\\t $$$$$$$$$$$$$$$ invoke sendEmail&quot;); &#125;&#125;public class LockDemo1 &#123; public static void main(String[] args) &#123; Phone phone = new Phone(); new Thread(()-&gt;&#123; phone.sendMsg(); &#125;, &quot;t1&quot;).start(); new Thread(()-&gt;&#123; phone.sendMsg(); &#125;, &quot;t2&quot;).start(); &#125;&#125; 11 invoke sendMsg11 $$$$$$$$$$$$$$$ invoke sendEmail12 invoke sendMsg12 $$$$$$$$$$$$$$$ invoke sendEmail 可以看到getID()返回的是同一个线程。 ReentrantLock下面再看看ReentrantLock是不是也是可重入的 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cn.hongliang.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class Phone implements Runnable&#123; private Lock lock = new ReentrantLock(); @Override public void run() &#123; get(); &#125; private void get()&#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() +&quot;\\t invoke get()&quot;); set(); &#125;finally &#123; lock.unlock(); &#125; &#125; private void set() &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread().getName() +&quot;\\t invoke set()&quot;); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125;public class LockDemo1 &#123; public static void main(String[] args) throws InterruptedException &#123; Phone phone = new Phone(); Thread t3 = new Thread(phone, &quot;t3&quot;); Thread t4 = new Thread(phone, &quot;t4&quot;); t3.start(); t4.start(); &#125;&#125; t3 invoke get()t3 invoke set()t4 invoke get()t4 invoke set() Synchronized与ReentrantLock的区别 原始构成： Synchronized是关键字，属于JVM层面的。monitorenter和monitorexit指令完成。 monitorenter 底层是通过monitor对象来完成的，其实wait/notify等方法也是依赖monitor对象 只有在同步块或者方法中才能调用wait/notify等方法。 而ReentrantLock是具体类，是api层面的锁。 使用方法： Synchronized 不需要手动释放锁，当Synchronized代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock则需要用户手动释放，如果没有手动释放，就有可能导致死锁现象。lock和unlock方法配合try/finally语句块来完成。 等待是否可以中断 Synchronized 不可中断，除非抛出异常或正常运行完成。 ReentrantLock是可以中断的。1. 通过设置超时方法 trylock(long timeout, TimeUint unit) 2. lockInterruptibly() 放入代码块中，调用interrupt可中断。 加锁是否公平 Synchronized是非公平锁 ReentrantLock两者都可以，默认是非公平锁，构造方法可以传入boolean值，true为公平锁，false为非公平锁 锁绑定多个条件 Synchronized没有，只能随机唤醒一个或者全部唤醒 ReentrantLock可以实现精确唤醒 三、自旋锁spinlock是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU 自旋锁的好处： 循环比较直到获取成功为止，没有类似的wait的阻塞 实现一个自旋锁通过CAS操作完成自旋锁，A线程先进来调用mylock方法自己持有锁5秒钟，B随后进来后发现当有线程持有锁，不是null， 所以只能自旋等待，直到A释放锁后B随后抢到。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package cn.hongliang.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;/** * @author Hongliang Zhu * @Date 2020-08-23-17:32 * * 实现一个自旋锁 */public class SpinLock &#123; // 原子引用线程 AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); public void mylock()&#123; Thread thread = Thread.currentThread(); //当前进来的线程 System.out.println(Thread.currentThread().getName() +&quot; 进来了...&quot;); while(!atomicReference.compareAndSet(null, thread))&#123; // spin &#125; &#125; public void unlock()&#123; Thread thread = Thread.currentThread(); //当前进来的线程 atomicReference.compareAndSet(thread, null); System.out.println(Thread.currentThread().getName() +&quot; 释放锁&quot;); &#125; public static void main(String[] args) &#123; SpinLock lock = new SpinLock(); new Thread(()-&gt;&#123; // 获取锁 lock.mylock(); // 休眠 try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 释放锁 lock.unlock(); &#125;, &quot;AAA&quot;).start(); new Thread(() -&gt; &#123; lock.mylock(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; lock.unlock(); &#125;, &quot;BBB&quot;).start(); &#125;&#125; mylock（)方法利用的CAS，当第一个线程A获取锁的时候，能够成功获取到，不会进入while循环，如果此时线程A没有释放锁，另一个线程B又来获取锁，此时由于不满足CAS，所以就会进入while循环，不断判断是否满足CAS，直到A线程调用unlock方法释放了该锁。 自旋锁存在的问题 如果某个线程持有锁的时间过长，就会导致其它等待获取锁的线程进入循环等待，消耗CPU。使用不当会造成CPU使用率极高。 上面Java实现的自旋锁不是公平的，即无法满足等待时间最长的线程优先获取锁。不公平的锁就会存在“线程饥饿”问题。 自旋锁的优点 自旋锁不会使线程状态发生切换，一直处于用户态，即线程一直都是active的；不会使线程进入阻塞状态，减少了不必要的上下文切换，执行速度快 非自旋锁在获取不到锁的时候会进入阻塞状态，从而进入内核态，当获取到锁的时候需要从内核态恢复，需要线程上下文切换。 （线程被阻塞后便进入内核（Linux）调度状态，这个会导致系统在用户态与内核态之间来回切换，严重影响锁的性能） 可重入的自旋锁和不可重入的自旋锁我们再来看一下我们实现的自旋锁 12345678910111213141516171819public class SpinLock &#123; // 原子引用线程 AtomicReference&lt;Thread&gt; atomicReference = new AtomicReference&lt;&gt;(); public void mylock()&#123; Thread thread = Thread.currentThread(); //当前进来的线程 System.out.println(Thread.currentThread().getName() +&quot; 进来了...&quot;); while(!atomicReference.compareAndSet(null, thread))&#123; // spin &#125; &#125; public void unlock()&#123; Thread thread = Thread.currentThread(); //当前进来的线程 atomicReference.compareAndSet(thread, null); System.out.println(Thread.currentThread().getName() +&quot; 释放锁&quot;); &#125;&#125; 可以发现我们上面的自旋锁不支持可重入，即当一个线程第一次已经获取到了该锁，在锁释放之前又一次重新希望获取该锁，第二次就不能成功获取到。由于不满足CAS，所以第二次获取会进入while循环等待，而如果是可重入锁，第二次也是应该能够成功获取到的。 而且，即使第二次能够成功获取，那么当第一次释放锁的时候，第二次获取到的锁也会被释放，而这是不合理的。为了实现可重入锁，我们需要引入一个计数器，用来记录获取锁的线程数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package cn.hongliang.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;import java.util.concurrent.atomic.AtomicMarkableReference;import java.util.concurrent.atomic.AtomicReference;/** * @author Hongliang Zhu * @Date 2020-08-25-15:55 * * 可重入的自旋锁 */public class ReentrantSpinLock &#123; AtomicReference&lt;Thread&gt; threadAtomicReference = new AtomicReference&lt;&gt;();// private int count; // 计数器 private AtomicInteger count = new AtomicInteger(); public void lock()&#123; Thread thread = Thread.currentThread(); if(threadAtomicReference.get() == thread)&#123; // 如果当前线程已经获取到了该锁，计数器加1 ，然后直接返回// count.incrementAndGet(); System.out.println(Thread.currentThread().getName() +&quot; 已经获取了该锁,目前count值为&quot;+ count.getAndIncrement()+&quot;，计数器为&quot;+ count.get()); return; &#125; // 如果没有获取，则通过CAS自旋 System.out.println(Thread.currentThread().getName() +&quot; 开始获取锁，进来了...&quot;+count.get()); while (!threadAtomicReference.compareAndSet(null, thread))&#123; // Do nothing &#125; &#125; public void unlock()&#123; Thread thread = Thread.currentThread(); if(threadAtomicReference.get() == thread)&#123; if(count.get() &gt; 0)&#123;// count.decrementAndGet(); // 如果当前线程获取了锁，则通过count--来模拟释放一次锁 System.out.println(Thread.currentThread().getName() +&quot; count为&quot;+ count.getAndDecrement()+&quot;，继续释放...&quot;+ count.get()); &#125;else&#123; System.out.println(Thread.currentThread().getName() +&quot; 释放了全部锁...&quot; + count.get()); // count == 0 ， 可以将锁释放， 保证获取锁的次数与释放锁的次数一致 threadAtomicReference.compareAndSet(thread, null); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantSpinLock spinLock = new ReentrantSpinLock(); new Thread(()-&gt;&#123; spinLock.lock(); try&#123; spinLock.lock(); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; spinLock.unlock(); &#125; &#125;catch (Exception e)&#123; System.out.println(&quot;异常&quot;); &#125;finally &#123; spinLock.unlock(); &#125; &#125;,&quot;AAA&quot;).start(); new Thread(() -&gt; &#123; spinLock.lock(); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; spinLock.unlock(); &#125;, &quot;BBB&quot;).start(); &#125;&#125; AAA 开始获取锁，进来了…0AAA 已经获取了该锁,目前count值为0，计数器为1BBB 开始获取锁，进来了…1AAA count为1，继续释放…0AAA 释放了全部锁…0BBB 释放了全部锁…0 这样可以重入 自旋锁的变种：TicketLockTicketLock主要解决的是公平性的问题。 思路：每当有线程获取锁的时候，就给该线程分配一个递增的id，我们称之为排队号，同时，锁对应一个服务号，每当有线程释放锁，服务号就会递增，此时如果服务号与某个线程排队号一致，那么该线程就获得锁，由于排队号是递增的，所以就保证了最先请求获取锁的线程可以最先获取到锁，就实现了公平性。 可以想象成银行办理业务排队，排队的每一个顾客都代表一个需要请求锁的线程，而银行服务窗口表示锁，每当有窗口服务完成就把自己的服务号加一，此时在排队的所有顾客中，只有自己的排队号与服务号一致的才可以得到服务。 123456789101112131415161718192021222324252627public class TicketLockV2 &#123; /** * 服务号 */ private AtomicInteger serviceNum = new AtomicInteger(); /** * 排队号 */ private AtomicInteger ticketNum = new AtomicInteger(); /** * 新增一个ThreadLocal，用于存储每个线程的排队号 */ private ThreadLocal&lt;Integer&gt; ticketNumHolder = new ThreadLocal&lt;Integer&gt;(); public void lock() &#123; int currentTicketNum = ticketNum.incrementAndGet(); // 获取锁的时候，将当前线程的排队号保存起来 ticketNumHolder.set(currentTicketNum); while (currentTicketNum != serviceNum.get()) &#123; // Do nothing &#125; &#125; public void unlock() &#123; // 释放锁，从ThreadLocal中获取当前线程的排队号 Integer currentTickNum = ticketNumHolder.get(); serviceNum.compareAndSet(currentTickNum, currentTickNum + 1); &#125;&#125; 上面的实现方式是将每个线程的排队号放到了ThreadLocal中。 TicketLock存在的问题: 多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。 下面介绍的CLHLock就是解决这个问题的。 自旋锁的变种CLHLockCLH锁是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋，获得锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;/** * CLH的发明人是：Craig，Landin and Hagersten。 * 代码来源：http://ifeve.com/java_lock_see2/ */public class CLHLock &#123; /** * 定义一个节点，默认的lock状态为true */ public static class CLHNode &#123; private volatile boolean isLocked = true; &#125; /** * 尾部节点,只用一个节点即可 */ private volatile CLHNode tail; private static final ThreadLocal&lt;CLHNode&gt; LOCAL = new ThreadLocal&lt;CLHNode&gt;(); private static final AtomicReferenceFieldUpdater&lt;CLHLock, CLHNode&gt; UPDATER = AtomicReferenceFieldUpdater.newUpdater(CLHLock.class, CLHNode.class, &quot;tail&quot;); public void lock() &#123; // 新建节点并将节点与当前线程保存起来 CLHNode node = new CLHNode(); LOCAL.set(node); // 将新建的节点设置为尾部节点，并返回旧的节点（原子操作），这里旧的节点实际上就是当前节点的前驱节点 CLHNode preNode = UPDATER.getAndSet(this, node); if (preNode != null) &#123; // 前驱节点不为null表示当锁被其他线程占用，通过不断轮询判断前驱节点的锁标志位等待前驱节点释放锁 while (preNode.isLocked) &#123; &#125; preNode = null; LOCAL.set(node); &#125; // 如果不存在前驱节点，表示该锁没有被其他线程占用，则当前线程获得锁 &#125; public void unlock() &#123; // 获取当前线程对应的节点 CLHNode node = LOCAL.get(); // 如果tail节点等于node，则将tail节点更新为null，同时将node的lock状态职位false，表示当前线程释放了锁 if (!UPDATER.compareAndSet(this, node, null)) &#123; node.isLocked = false; &#125; node = null; &#125;&#125; 四、独占锁（写锁）/共享锁(读锁) /互斥锁独占锁： 指该锁一次只能被一个线程锁持有。ReentrantLock和Synchronized都是独占锁 共享锁： 该锁可以被多个线程锁共享 对ReentrantReadWriteLock其读锁是共享的，写锁是独占的。 读锁的共享锁可以保证并发读是高效的，读写、写写、写读的过程是互斥的。 独享锁与共享锁是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 分布式缓存我们使用读写锁实现一个分布式缓存，要求写时独占，原子的，读操作可以共享。 先来看没有加锁的时候，会发生什么状况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package cn.hongliang.lock;import java.util.HashMap;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @Date 2020-08-23-23:05 * * 读写锁实践： 手写一个 缓存 * */class MyCache&#123; HashMap&lt;String, Object&gt; cache = new HashMap&lt;&gt;(); public void put(String key, Object value)&#123; System.out.println(Thread.currentThread().getName() + &quot;\\t 开始写入&quot; + key); // 模拟网络延迟 try &#123; TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cache.put(key, value); System.out.println(Thread.currentThread().getName() + &quot;\\t 写入完成&quot;); &#125; public Object get(String key)&#123; System.out.println(Thread.currentThread().getName() + &quot;\\t 开始读取&quot;); // 模拟网络延迟 try &#123; TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Object value = cache.get(key); System.out.println(Thread.currentThread().getName() + &quot;\\t 读取完成：&quot;+ value); return value; &#125;&#125;public class readwriteLockDemo &#123; public static void main(String[] args) &#123; // 线程操作资源类 MyCache cache = new MyCache(); // 模拟5个线程写，5个线程读 for (int i = 1; i &lt;= 5; i++) &#123; final int tmp = i; new Thread(()-&gt;&#123; cache.put(tmp+&quot;&quot;, tmp+&quot;&quot;); &#125;, String.valueOf(i)).start(); &#125; for (int i = 1; i &lt;= 5; i++) &#123; final int tmp = i; new Thread(()-&gt;&#123; cache.get(tmp+&quot;&quot;); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; 1 开始写入12 开始写入23 开始写入34 开始写入45 开始写入51 开始读取2 开始读取3 开始读取4 开始读取5 开始读取5 写入完成1 读取完成：null4 写入完成3 写入完成2 写入完成1 写入完成2 读取完成：23 读取完成：34 读取完成：45 读取完成：5 可以发现，写操作被读操作中断了，而且还读到了一个null值。这是并发问题。 我们要实现写操作是原子的，应该为独占锁，读取操作是各个线程所共享的。可以使用JUC下面的ReentrantReadWriteLock， 称为读写锁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package cn.hongliang.lock;import java.util.HashMap;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * @author Hongliang Zhu * @Date 2020-08-23-23:05 * * 读写锁实践： 手写一个 缓存 * */class MyCache&#123; HashMap&lt;String, Object&gt; cache = new HashMap&lt;&gt;(); ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); public void put(String key, Object value)&#123; // 使用写锁 lock.writeLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + &quot;\\t 开始写入&quot; + key); // 模拟网络延迟 try &#123; TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; cache.put(key, value); System.out.println(Thread.currentThread().getName() + &quot;\\t 写入完成&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放锁 lock.writeLock().unlock(); &#125; &#125; public Object get(String key)&#123; // 加读锁 lock.readLock().lock(); try &#123; System.out.println(Thread.currentThread().getName() + &quot;\\t 开始读取&quot;); // 模拟网络延迟 try &#123; TimeUnit.MILLISECONDS.sleep(300); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Object value = cache.get(key); System.out.println(Thread.currentThread().getName() + &quot;\\t 读取完成：&quot;+ value); return value; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.readLock().unlock(); &#125; return null; &#125;&#125;public class readwriteLockDemo &#123; public static void main(String[] args) &#123; // 线程操作资源类 MyCache cache = new MyCache(); // 模拟5个线程写，5个线程读 for (int i = 1; i &lt;= 5; i++) &#123; final int tmp = i; new Thread(()-&gt;&#123; cache.put(tmp+&quot;&quot;, tmp+&quot;&quot;); &#125;, String.valueOf(i)).start(); &#125; for (int i = 1; i &lt;= 5; i++) &#123; final int tmp = i; new Thread(()-&gt;&#123; cache.get(tmp+&quot;&quot;); &#125;, String.valueOf(i)).start(); &#125; &#125;&#125; 1 开始写入11 写入完成2 开始写入22 写入完成3 开始写入33 写入完成4 开始写入44 写入完成5 开始写入55 写入完成1 开始读取2 开始读取4 开始读取5 开始读取3 开始读取5 读取完成：52 读取完成：24 读取完成：43 读取完成：31 读取完成：1 可以清楚看到，写操作是配对完成的，中间没有打断。读操作是并发的，可以无序。 深入理解ReentrantReadWriteLock读写锁 读锁 写锁 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 123abstract static class Sync extends AbstractQueuedSynchronizer &#123; ...&#125; 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。 在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。 在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示： 来看看写锁的加锁源码 12345678910111213141516171819protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); // 取到当前锁的个数 int w = exclusiveCount(c); // 取写锁的个数w if (c != 0) &#123; // 如果已经有线程持有了锁(c!=0) // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 如果写线程数（w）为0（换言之存在读锁） 或者持有锁的线程不是当前线程就返回失败 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 如果当且写线程数为0，并且当前线程需要阻塞那么就返回失败；或者如果通过CAS增加写线程数失败也返回失败。 return false; setExclusiveOwnerThread(current); // 如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者 return true;&#125; 这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount©; ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。 在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁(c!=0)，则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。 如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。 如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。 如果c=0,w=0或者c&gt;0,w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！ tryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。 因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。 接着是读锁的代码： 123456789101112131415161718192021222324252627protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; // 如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; if (r == 0) &#123; firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。 五、乐观锁和悲观锁悲观锁顾名思义，很悲观，每次去拿数据的时候都担心别人回来修改数据，所以会加锁，其他线程需要这个资源的话只能被阻塞。直到释放锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁很乐观，总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 两种锁的适用场景乐观锁适用于多读的场景，可以提高吞吐量。但是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。 乐观锁的实现方法乐观锁一般会使用版本号机制或CAS（Compare-and-Swap，即比较并替换）算法实现。 版本号机制般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 50（50（100-$50 ）。 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 20（20（100-$20 ）。 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。 这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 CAS即 compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 CAS 底层实现原理？通过自旋锁+UNSafe类 12345 // setup to use Unsafe.compareAndSwapInt for updatesprivate static final Unsafe unsafe = Unsafe.getUnsafe();public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; UnSafe是CAS的核心类。由于Java 方法无法直接访问底层 ，需要通过本地(native)方法来访问， UnSafe可以直接操作特的内存数据。UnSafe类在于sun.misc包中，其内部方法操作可以像C的指针一样直接操作内存，因为Java中CAS操作的助兴依赖于UNSafe类的方法。Unsafe它提供了硬件级别的原子操作。注意UnSafe类中所有的方法都是native修饰的,也就是说UnSafe类中的方法都是直接调用操作底层资源执行响应的任务。 变量ValueOffset，便是该变量在内存中的偏移地址，因为UnSafe就是根据内存偏移地址获取数据的。 AtomicReference原子引用AtomicReference是作用是对”对象”进行原子操作。提供了一种读和写都是原子性的对象引用变量。原子意味着多个线程试图改变同一个AtomicReference(例如比较和交换操作)将不会使得AtomicReference处于不一致的状态。 AtomicReference和AtomicInteger非常类似，不同之处就在于AtomicInteger是对整数的封装，底层采用的是compareAndSwapInt实现CAS，比较的是数值是否相等，而AtomicReference则对应普通的对象引用，底层使用的是compareAndSwapObject实现CAS，比较的是两个对象的地址是否相等。也就是它可以保证你在修改对象引用时的线程安全性。 乐观锁的缺点1. ABA 问题如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？ 很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package cn.hongliang.lock;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicReference;import java.util.concurrent.atomic.AtomicStampedReference;/** * @author Hongliang Zhu * @Date 2020-08-25-16:33 * * CAS 的 ABA问题 */public class ABADemo &#123; private static AtomicReference&lt;Integer&gt; atomicReference = new AtomicReference&lt;&gt;(100); private static AtomicStampedReference&lt;Integer&gt; stampedReference = new AtomicStampedReference&lt;&gt;(100, 1); public static void main(String[] args) &#123; System.out.println(&quot;===以下是ABA问题的产生===&quot;); new Thread(() -&gt; &#123; atomicReference.compareAndSet(100, 101); atomicReference.compareAndSet(101, 100); &#125;, &quot;t1&quot;).start(); new Thread(() -&gt; &#123; //先暂停1秒 保证完成ABA try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(atomicReference.compareAndSet(100, 2019) + &quot;\\t&quot; + atomicReference.get()); &#125;, &quot;t2&quot;).start(); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;===以下是ABA问题的解决===&quot;); new Thread(() -&gt; &#123; int stamp = stampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot;\\t 第1次版本号&quot; + stamp + &quot;\\t值是&quot; + stampedReference.getReference()); //暂停1秒钟t3线程 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; stampedReference.compareAndSet(100, 101, stampedReference.getStamp(), stampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + &quot;\\t 第2次版本号&quot; + stampedReference.getStamp() + &quot;\\t值是&quot; + stampedReference.getReference()); stampedReference.compareAndSet(101, 100, stampedReference.getStamp(), stampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + &quot;\\t 第3次版本号&quot; + stampedReference.getStamp() + &quot;\\t值是&quot; + stampedReference.getReference()); &#125;, &quot;t3&quot;).start(); new Thread(() -&gt; &#123; int stamp = stampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + &quot;\\t 第1次版本号&quot; + stamp + &quot;\\t值是&quot; + stampedReference.getReference()); //保证线程3完成1次ABA try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean result = stampedReference.compareAndSet(100, 2019, stamp, stamp + 1); System.out.println(Thread.currentThread().getName() + &quot;\\t 修改成功否&quot; + result + &quot;\\t最新版本号&quot; + stampedReference.getStamp()); System.out.println(&quot;最新的值\\t&quot; + stampedReference.getReference()); &#125;, &quot;t4&quot;).start(); &#125;&#125; ===以下是ABA问题的产生===true 2019===以下是ABA问题的解决===t3 第1次版本号1 值是100t4 第1次版本号1 值是100t3 第2次版本号2 值是101t3 第3次版本号3 值是100t4 修改成功否false 最新版本号3最新的值 100 2. 循环时间长开销大自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline），使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3. 只能保证一个共享变量的原子操作CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作。所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。 CAS与synchronized的使用情景简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。 补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 六、无锁VS偏向锁VS轻量级锁VS重量级锁先了解几个概念，对象、对象头、Monitor Mark Word默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。 Klass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 Monitor： Monitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。 Monitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。 synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。 所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。 通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点： 无锁无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。 无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。 偏向锁偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。 在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。 当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。 偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。 偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。 轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。 如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。 若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。 重量级锁升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。 七、锁膨胀锁膨胀的过程： 轻量级锁获取锁过程 在线程进入同步方法、同步块的时候，如果同步对象锁状态为无锁状态(锁标志位为”01”状态，是否为偏向锁为”0”)，虚拟机首先将在当前线程的栈帧中建立一个名为锁记录(Lock Recored)的空间，用于储存锁对象目前的Mark Word的拷贝(官方把这份拷贝加了个Displaced前缀，即Displaced Mark Word)。 将对象头的Mark Word拷贝到线程的锁记录(Lock Recored)中。 拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针。如果这个更新成功了，则执行步骤4，否则执行步骤5。 更新成功，这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位将转变为”00”，即表示此对象处于轻量级锁的状态。。 更新失败，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，可以直接进入同步块继续执行，否则说明这个锁对象已经被其其它线程抢占了。进行自旋执行步骤3，如果自旋结束仍然没有获得锁，轻量级锁就需要膨胀为重量级锁，锁标志位状态值变为”10”，Mark Word中储存就是指向monitor对象的指针，当前线程以及后面等待锁的线程也要进入阻塞状态。 轻量级释放锁的过程 使用CAS操作将对象当前的Mark Word和线程中复制的Displaced Mark Word替换回来(依据Mark Word中锁记录指针是否还指向本线程的锁记录)，如果替换成功，则执行步骤2，否则执行步骤3。 如果替换成功，整个同步过程就完成了，恢复到无锁的状态(01)。 如果替换失败，说明有其他线程尝试获取该锁(此时锁已膨胀)，那就要在释放锁的同时，唤醒被挂起的线程。 偏向锁获取锁的过程获取锁的过程： 检查Mark Word是否为可偏向锁的状态，即是否偏向锁即为1即表示支持可偏向锁，否则为0表示不支持可偏向锁。 如果是可偏向锁，则**检查Mark Word储存的线程ID是否为当前线程ID**，如果是则执行同步块，否则执行步骤3。 如果检查到Mark Word的ID不是本线程的ID，则通过CAS操作去修改线程ID修改成本线程的ID，如果修改成功则执行同步代码块，否则执行步骤4。 当拥有该锁的线程到达安全点之后，挂起这个线程，升级为轻量级锁。 偏向锁释放锁的过程锁释放的过程： 有其他线程来获取这个锁，偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。 等待全局安全点(在这个是时间点上没有字节码正在执行)。 暂停拥有偏向锁的线程，检查持有偏向锁的线程是否活着，如果不处于活动状态，则将对象头设置为无锁状态，否则设置为被锁定状态。如果锁对象处于无锁状态，则恢复到无锁状态(01)，以允许其他线程竞争，如果锁对象处于锁定状态，则挂起持有偏向锁的线程，并将对象头Mark Word的锁记录指针改成当前线程的锁记录，锁**升级为轻量级锁状态(00)**。 锁升级过程 八、 AQSAQS 介绍AQS：AbstractQueneSynchronizer抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包 AQS的核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。 用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。 注意：AQS是自旋锁：在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功 实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物 AQS原理 AQS维护了一个volatile int state和一个FIFO线程等待队列，多线程争用资源被阻塞的时候就会进入这个队列。state就是共享资源，其访问方式有如下三种： getState(); setState(); compareAndSetState(); AQS 定义了两种资源共享方式： 1.Exclusive：独占，只有一个线程能执行，如ReentrantLock2.Share：共享，多个线程可以同时执行，如Semaphore、CountDownLatch、ReadWriteLock，CyclicBarrier 不同的自定义的同步器争用共享资源的方式也不同。 AQS底层使用了模板方法模式： 同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放） 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。这和我们以往通过实现接口的方式有很大区别，这是模板方法模式很经典的一个运用。 自定义同步器在实现的时候只需要实现共享资源state的获取和释放方式即可，至于具体线程等待队列的维护，AQS已经在顶层实现好了。自定义同步器实现的时候主要实现下面几种方法： isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。 tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。 tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。 tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源 tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。 以ReentrantLock为例（可重入独占式锁）：state初始化为0，表示未锁定状态，A线程lock()时，会调用tryAcquire()独占锁并将state+1。之后其他线程再想tryAcquire的时候就会失败，直到A线程unlock（）到state=0为止，其他线程才有机会获取该锁。A释放锁之前，自己也是可以重复获取此锁（state累加），这就是可重入的概念。注意：获取多少次锁就要释放多少次锁，保证state是能回到零态的。 以CountDownLatch为例，任务分N个子线程去执行，state就初始化 为N，N个线程并行执行，每个线程执行完之后countDown() 一次，state就会CAS减一。当N子线程全部执行完毕，state=0，会unpark()主调用线程，主调用线程就会从await()函数返回，继续之后的动作。 一般来说，自定义同步器要么是独占方式，要么是共享方式，他们也只需实现tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared中的一种即可。但AQS也支持自定义同步器同时实现独占和共享两种方式，如ReentrantReadWriteLock。在acquire() 、acquireShared()两种方式下，线程在等待队列中都是忽略中断的，acquireInterruptibly()/acquireSharedInterruptibly()是支持响应中断的。 AQS的简单应用Mutex：不可重入互斥锁，锁资源（state）只有两种状态：0：未被锁定；1：锁定。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Mutex implements Lock, java.io.Serializable &#123; // 自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 判断是否锁定状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 尝试获取资源，立即返回。成功则返回true，否则false。 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // 这里限定只能为1个量 if (compareAndSetState(0, 1)) &#123;//state为0才设置为1，不可重入！ setExclusiveOwnerThread(Thread.currentThread());//设置为当前线程独占资源 return true; &#125; return false; &#125; // 尝试释放资源，立即返回。成功则为true，否则false。 protected boolean tryRelease(int releases) &#123; assert releases == 1; // 限定为1个量 if (getState() == 0)//既然来释放，那肯定就是已占有状态了。只是为了保险，多层判断！ throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0);//释放资源，放弃占有状态 return true; &#125; &#125; // 真正同步类的实现都依赖继承于AQS的自定义同步器！ private final Sync sync = new Sync(); //lock&lt;--&gt;acquire。两者语义一样：获取资源，即便等待，直到成功才返回。 public void lock() &#123; sync.acquire(1); &#125; //tryLock&lt;--&gt;tryAcquire。两者语义一样：尝试获取资源，要求立即返回。成功则为true，失败则为false。 public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; //unlock&lt;--&gt;release。两者语文一样：释放资源。 public void unlock() &#123; sync.release(1); &#125; //锁是否占有状态 public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125;&#125; 同步类在实现时一般都将自定义同步器（sync）定义为内部类，供自己使用；而同步类自己（Mutex）则实现某个接口，对外服务。 九、 参考 不可不说的Java“锁”事 《深入理解Java虚拟机》 《Java并发编程之美》 深入分析synchronized原理和锁膨胀过程(二) https://blog.csdn.net/mulinsen77/article/details/84583716","path":"2024/11/07/java锁机制/","date":"11-07","excerpt":"","tags":[{"name":"多线程","slug":"多线程","permalink":"https://castile.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"锁","slug":"锁","permalink":"https://castile.github.io/tags/%E9%94%81/"}]},{"title":"从网络到IO多路复用","text":"基于linux操作系统tcpdump strace man nc curl nginx 开篇-基础知识准备tcp、ip协议层 。 TCP： 面向连接的可靠的传输协议， 需要进行3次握手建立连接。 四次挥手断开连接 软件分层结构，每个层有做自己的事情，解耦合。 在linux上执行命令访问www.baidu.com 1exec 6&lt;&gt; /dev/tcp/www.baidu.com/80 exec: 将一个程序覆盖当前进程，即将此程序压栈，如果程序执行完是退出，则会让内核触发，将整个进程销毁，断开连接 6: 文件描述符，可以自己定义 &lt;&gt;: 重定向操作符， 表示输入输出 /dev/tcp/www.baidu.com/80 ： 虚拟文件系统 0 输入流 1 正确输出流 2 报错输出 当前bash里面多了一个6号文件描述符，指向了一个socket， /dev/tcp/www.baidu.com/80为特殊目录，触发一个内核机制，让bash发起了对百度socket的连接 。 与百度建立了socket连接后怎么获取百度的主页呢？socket建立表示TCP连接已经建立了，然后应该使用协议来进行交互。是应用层的操作，所以我们需要发送HTTP协议请求头 http协议请求头 12345echo -e &quot;GET / HTTP/1.0\\n&quot; -e使得bash能识别换行符# 将请求头发送到百度服务器echo -e &quot;GET/HTTP/1.0\\n&quot; 1&gt;&amp;8 # 1 是输出，表示将输出重定向到 6中， 如果重定向后面是一个文件描述符的话，需要加一个 &amp; # 读取响应信息cat 0&lt;&amp;8 使用工具抓包使用tcpdump工具 安装：yum install tcpdump 查看网卡 ifconfig 看一下tcpdump如何使用： tcpdump –help 1tcpdump -nn -i ens33 port 80 # 监听80端口的时间 在网卡 ens33 上 目前还没有，是一个阻塞状态 然后我们去访问一下百度 curl ， 重开一个ssh 在刚刚的侦听界面上： 分析一下, 先看建立连接，也就是前三行 1234567891011121311:55:43.617175 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [S], seq 3681486933, win 29200, options [mss 1460,sackOK,TS val 41257007 ecr 0,nop,wscale 7], length 0表示本机给百度发送了一个 seq ，后面的数字表示序列号。 S 表示 sync11:55:43.845875 IP 104.193.88.77.80 &gt; 192.168.145.130.51914: Flags [S.], seq 1297381438, ack 3681486934, win 64240, options [mss 1460], length 0接着百度给本机发送 了一个 sync+ ack的包。11:55:43.845926 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [.], ack 1, win 29200, length 0然后本地给百度回复了一个 ack 确认 以上就是TCP建立连接的三次握手过程，完成建立后，双方开辟资源。 接着看中间几行表示本机与百度进行数据传输的过程 123456789101112131415161718192011:55:43.846291 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [P.], seq 1:78, ack 1, win 29200, length 77: HTTP: GET / HTTP/1.1本机给百度发送了一个数据包 长度为77 协议HTTP/1.1 以GET的方式请求11:55:43.846412 IP 104.193.88.77.80 &gt; 192.168.145.130.51914: Flags [.], ack 78, win 64240, length 0百度给本就回复一个确认 ack， 因为是可靠传输11:55:44.386992 IP 104.193.88.77.80 &gt; 192.168.145.130.51914: Flags [P.], seq 1:2782, ack 78, win 64240, length 2781: HTTP: HTTP/1.1 200 OK接着是百度个本机返回单的响应数据 长度为2781 状态码 200 表示成功上面两个都是百度发出的，最后有一个P表示，数据发送完了，不要存储在缓存中了，请马上告知应用程序去处理。11:55:44.387030 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [.], ack 2782, win 33580, length 0本机给百发送ack确认，表示已经收到 发送完数据之后，接着是断开连接，也就是四次挥手的过程 123456789101112131415161711:55:44.387247 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [F.], seq 78, ack 2782, win 33580, length 0本机需要断开连接 fin11:55:44.387563 IP 104.193.88.77.80 &gt; 192.168.145.130.51914: Flags [.], ack 79, win 64239, length 0百度返回给客户端一个ack，表示知道了你要断开连接。但是这时还没有完全断开，是一个半关闭的转态。11:55:45.280826 IP 104.193.88.77.80 &gt; 192.168.145.130.51914: Flags [FP.], seq 2782, ack 79, win 64239, length 0百度的服务器也要断开连接了，给本机发送了一个fin11:55:45.280853 IP 192.168.145.130.51914 &gt; 104.193.88.77.80: Flags [.], ack 2783, win 33580, length 0本机知道了，然后断开 通过以上分析，我们以及知道从客户端发起请求建立连接到传输数据再到四次挥手断开连接的全过程。这一整个过程应该是一个完整的粒度，不应该被拆散。 比如，我们做负载均衡的时候，客户端给一个服务器发送了一个建立连接的请求数据包sync， 然后这个服务器返回一个sync+ack给客户端，客户端还需要发送一个ack给服务器，但是由于有多台服务器，负载均衡会选择一个最佳的服务器，可能会出现这样的一种情况，就是客户端的ack发送给了另外一台服务器，而原来的这个服务器一直没有收到客户端的ack，所以这个连接就建立不起来。这就是粒度被拆散了。 这个粒度不能被我们以后所学的技术所拆散的！！！这是一个大前提。 NetCat nc是netcat工具的命令，是一个很好用的网络工具。比如，可以用来端口扫描，文件传输等网络功能。 在 网络工具中有“瑞士军刀”美誉的NetCat， 在我们用了N年了至今仍是爱不释手。 安装1yum install nc 参数 监听端口12nc -l 8080 # 开启服务端nc localhost 8080 # 开启客户端 他们之间就建立了连接，可以相互发送数据 查看他们的进程 1ps -ef | grep nc 然后我们用上面的提到的，在 /proc/进程id/fd 目录下面下有进程描述符： 12cd proc/102514/fdll strace yum install strace 用来跟踪程序的运行以及系统调用 123mkdir xxoo # 创建一个新文件夹，用来存放程序运行的跟踪文件cd xxootrace -ff -o out nc -l 8080 # 跟踪这个程序 然后在xxoo目录下有一个文件 out-4781 , 后面的id表示nc的进程id 打开这个文件： 查看select的作用： man 2 select select是一个多路复用器，会阻塞 使用 tail命令去动态查看文件的变化 1tail -f out.4781 打开一个客户端 nv localhost 8080 发送一些信息 write(1, “zhuhongliang\\n”, 13) = 13 表示在 文件描述符1 写入 。1代表标准写 看一下recvfrom 的功能：从一个socket接受数据data，返回数据的字节数 系统调用system callread、write、 socket、 bind、listen、accept 上述系统方法的实现是在linux kernel里面的实现的。kernel只会对应用程序暴露上述方法的调用，所以程序会对系统内核发起系统调用。 BIO如果程想使用内核完成网络通信的话，这时候会发生哪些事情呢？ 看看下面的过程 首先服务端系统调用kernel，socket获取服务端的文件描述符 5，然后使用bind将文件描述符与端口8080进行绑定，之后监听看有没有连接。 这时候，一个客户端也进行系统调用，经过三次握手之后连接了服务端，服务端系统调用accept， 建立连接 。客户端的文件描述符加入是fd 4 。 然后调用read 读操作，传入客户端的文件描述符4 。但是这个客户端没有发送数据，所以这个read现在被阻塞住了。 此时又有一个客户端来连接 建立完连接后，这时候不会给他分配文件描述符，因为程序已经被阻塞住了，只能运行到accept这个阶段，如果客户端有超时响应的话，会报超时连接错误。 这是整个IO 发展历程中的第一个时期：BIO，即阻塞IO。 那么，我们怎么解决这个问题呢？ 可以开辟一个线程。 一旦出现了一个连接，就分配一个文件描述符，然后开辟一个线程。 如果有线程来read了，就启动线程，否则阻塞。上述就是多线程模型。 这样已经解决服务端无法处理多个客户端连接请求的问题了，但这种多线程模型有什么缺点或者说弊端呢？ 思考一下如果有100000个客户端，那么是不是要与100000个线程的开辟？？？ 这就开销太大了吧。 我们首先看一下java程序在linux 系统中是如何调用的 写一个简单的java程序 使用是strace 追踪系统调用 1strace -ff -o xxoo java Hello 可以看到，这样一个简单的java程序并不是只开辟了一个线程。打开113151 发现调用了113152线程， 并且使用的系统调用clone 那 我们的主线程是哪个，主线程应该是打印Hello world的那个线程吧 1grep &quot;Hello world&quot; ./* 看到了write系统调用了吗。这是在113152线程中。 我们可以得出一个结论，线程的创建是通过调用内核的clone系统调用来实现的，主线程都需要clone，然后如果有成千上万个线程的话，就要进行成千上万次系统调用，这个开销很非常大的。因为调用内核不是直接就调用的，需要发生软中断，而且CPU也要切换状态。 NIO在BIO时期这一切万恶之源都是由于系统调用会有阻塞的情况发生，如果一个客户端没有发送数据，就会阻塞。虽然多线程模型可以处理多个客户端的情况，但是由于开销大，系统调用此时多，比较慢。 那么能不能只创建一个线程就可以处理多个客户端呢？ 我们看看socket： man 2 socket SOCK_NONBLOCK : Set the O_NONBLOCK file status flag on the new open file description. Using this flag saves extra calls to fcntl(2) to achieve the same result 可以使用非阻塞，fcntl来指定非阻塞的文件描述符 ==所以，内核需要发生变化== 下面的模型非阻塞的NIO （NON- Block IO） 在客户端只需要写一个死循环，然后有一个客户端的文件描述符解accept，如果没有数据传输，就报错，然后程序可以继续执行。这样的模型也有弊端。 试想一下，如果有10000个客户端，一次循环就进行10000次系统调用，那么如果只有第10000个客户端有数据传输，那这样的开销会很大。 有没有什么解决方法呢？ 如果能把多次系统调用变成一次系统调用那就好啦！！！ 怎么做？==内核又需要变化了== select上面我们提到了select。看看select ： man 2 select select() and pselect() allow a program to monitor multiple file descriptors, waiting until one or more of the file descriptors become “ready” for some class of I/O operation (e.g., input possible). A file descriptor is considered ready if it is possible to perform the corresponding I/O operation (e.g., read(2)) without blocking. select()和pselect()允许程序监视多个文件描述符，直到其中一个或多个文件描述符为某些类型的I/O操作(例如，输入)“准备好”。如果文件描述符可以不阻塞地执行相应的I/O操作(如read(2))，则认为它已经准备好了。 下面是使用了select或者poll的模型 将各个客户端的文件描述符给select，然后select会去主动遍历每一个文件描述符，哪个有数据输出就返回哪个文件描述符，然后通过系统调用read去读取。这样的话就只用以一次系统调用就把需要read的文件描述符选择出来了，比上面的需要非常多的系统调用模型更加优秀。另外，select是系统调用，会主动遍历每一个文件操作符，时间复杂度为O(N)。 这还没有完，这种模型还没有很优美，虽然减少了系统调用，但是select里面的轮询还是O(N)的，这该怎么改进呢？ epoll终于来了！！！ epoll讲epoll之前先来看看nginx，看看nginx怎么工作的。 首先需要安装nginx： https://blog.csdn.net/qq_37345604/article/details/90034424 12345678wget http://nginx.org/download/nginx-1.9.9.tar.gz tar -zxvf nginx-1.9.9.tar.gzcd nginx目录./configure make make install 运行nginx在 usr/local/nginx/sbin 目录下 我们来看看nginx有多少个线程，不出意外的话，应该是两个，一个是master，一个是worker。 1strace -ff -o out ./nginx 我们看看对应的out下有多少文件 可以看到有3635、3636、3637三个进程，不应该是两个吗？？？ 我们来看看3635这个进程： 这个进程只是启动进程，最后是退出了的，它clone了3636进程， 然后3636进程clone了3637进程，如下图。 所以他们是父子关系。 3635–&gt; 3636 –&gt; 3637。 因为3636是master进程，可以看到他其实没有做什么事情， 就是将3637 worker进程clone出来了。 其实一开始文件描述符是在3635进程，也就是启动线程就去确定了，通过clone将文件描述符带给3636进程， 3636又带去3637进程 再看看3637进程 文件描述符6 放进了8 里面，8 是上面的epoll_create创建出来的。 那么epoll_create 是干嘛的，运行命令 man 2 epoll_create 查看系统调用 epoll_create() returns a file descriptor referring to the new epoll instance. This file descriptor is used for all the subsequent calls to the epoll interface. When no longer required, the file descriptor returned by epoll_create() should be closed by using close(2). When all file descriptors referring to an epoll instance have been closed, the kernel destroys the instance and releases the associated resources for reuse. epoll_create()返回引用新epoll实例的文件描述符。此文件描述符用于随后对epoll接口的所有调用。当不再需要时，应该使用close(2)关闭epoll_create()返回的文件描述符。当引用epoll实例的所有文件描述符都被关闭时，内核会销毁该实例并释放相关的资源以供重用。 其实系统调用epoll_create() 在内核中开辟一个空间， 使用文件描述符指向这个空间。然后通过epoll_ctl(8, 6) 将文件描述符6放进 8里面。然后epoll_wait(8, 等待， 开始阻塞。 epoll_wait会返回有数据输出的文件描述符数量。 The epoll_wait() system call waits for events on the epoll(7) instance referred to by the file descriptor epfd. The memory area pointed to by events will contain the events that will be available for the caller. Up to maxevents are returned by epoll_wait(). The maxevents argument must be greater than zero. The timeout argument specifies the minimum number of milliseconds that epoll_wait() will block. (This interval will be rounded up to the system clock granularity, and kernel scheduling delays mean that the blocking interval may overrun by a small amount.) Specifying a timeout of -1 causes epoll_wait() to block indefinitely, while specifying a timeout equal to zero cause epoll_wait() to return immediately, even if no events are available. RETURN VALUE( 返回值 ) When successful, epoll_wait() returns the number of file descriptors ready for the requested I/O, or zero if no file descriptor became ready during the requested timeout milliseconds. When an error occurs, epoll_wait() returns -1 and errno is set appropriately. epoll_wait()系统调用等待文件描述符epfd引用的epoll(7)实例上的事件。事件指向的内存区域将包含调用者可用的事件。epoll_wait()返回最多maxevents。maxevents参数必须大于零。 超时参数指定epoll_wait()将阻塞的最小毫秒数。(这个时间间隔将被舍入到系统时钟粒度，内核调度延迟意味着阻塞时间间隔可能会超出一小部分。)将超时指定为-1将导致epoll_wait()无限期阻塞，而将超时指定为0将导致epoll_wait()立即返回，即使没有可用的事件。 成功时，epoll_wait()返回为请求的I/O准备好的文件描述符的数量，如果在请求的超时毫秒期间没有文件描述符准备好，则返回0。当发生错误时，epoll_wait()返回-1,errno被适当地设置。 我们来模拟一下访问，目前3637进程是阻塞的，因为没有客户端来连接。 使用tail命令去查看动态的文件变化 使用curl来模拟访问 1curl localhost 80 out文件的变化 主要看看这几句 123456789101112131415161718192021222324252627282930313233343536accept4(6, &#123;sa_family=AF_INET, sin_port=htons(34306), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, [110-&gt;16], SOCK_NONBLOCK) = 3一个客户端请求后，首先系统调用accept(6, ...)，6是服务端的文件描述符，客户端的文件描述符是3epoll_ctl(8, EPOLL_CTL_ADD, 3, &#123;EPOLLIN|EPOLLRDHUP|EPOLLET, &#123;u32=4200120752, u64=139994364166576&#125;&#125;) = 0 紧接着 将3放进8 里面去，这时候还没有客户端的数据流出epoll_wait(8, [&#123;EPOLLIN, &#123;u32=4200120752, u64=139994364166576&#125;&#125;], 512, 60000) = 1epoll_wait 去监听8 里面的文件描述符的 数据到达事件recvfrom(3, &quot;GET / HTTP/1.1\\r\\nUser-Agent: curl&quot;..., 1024, 0, NULL, NULL) = 73有事件到达了， 收到的数据是从文件描述3发来的stat(&quot;/usr/local/nginx/html/index.html&quot;, &#123;st_mode=S_IFREG|0644, st_size=612, ...&#125;) = 0判断是请求主页的open(&quot;/usr/local/nginx/html/index.html&quot;, O_RDONLY|O_NONBLOCK) = 10打开主页的文件， 文件描述符是10fstat(10, &#123;st_mode=S_IFREG|0644, st_size=612, ...&#125;) = 0查看文件描述符10 的状态writev(3, [&#123;iov_base=&quot;HTTP/1.1 200 OK\\r\\nServer: nginx/1&quot;..., iov_len=237&#125;], 1) = 237返回给文件描述符3 的数据，给3写入sendfile(3, 10, [0] =&gt; [612], 612) = 612发送数据 将10 发送给3 write(4, &quot;127.0.0.1 - - [02/Aug/2020:22:01&quot;..., 86) = 86写的时间close(10) = 0关闭文件描述符10setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0recvfrom(3, &quot;&quot;, 1024, 0, NULL, NULL) = 0close(3) # 连接断开就会关闭文件描述符3 我们也可以使用nc 来模拟多个客户端： 12nc localhost 80 # 客户端1nc localhost 80 # 客户端2 这是out文件的变化，可以看到有两个文件描述符加入8 中 所以，所有的连接只需要通过epoll_ctl（8， ）放入8一次，未来就连续调用epoll_wait来监听那个文件描述符有数据到达， 对于文件描述符6来说，等待的是accept事件，对于3、10 等其他的客户端的文件描述符是等待read，一旦监听到了，就将这个文件描述符放入一个集合中。 这样的模型不像select会一次将10000个文件描述符拷贝给内核，内核开辟了一个空间，来了一个客户端就通过epoll_ctl将文件描述符放入到指定的区域里面，只要连接不断开，那么可以通过epoll_wait获取到客户端的所有事件。 内核是被动的，中断的事件会让8 里面的文件描述符进入到右边的返回区，然后主程序就是一个epol_wait死循环，一直判断返回区里面有没有事件。 零拷贝： sendFile系统调用 直接内存 附：发展历程图示 参考资料 https://cyc2018.github.io/CS-Notes/#/notes/Socket","path":"2024/11/07/io复用/","date":"11-07","excerpt":"","tags":[{"name":"io","slug":"io","permalink":"https://castile.github.io/tags/io/"}]},{"title":"Java专题之Socket编程","text":"一、 概述Java 中的网络支持： InetAddress：用于表示网络上的硬件资源，即 IP 地址； URL：统一资源定位符； Sockets：使用 TCP 协议实现网络通信； Datagram：使用 UDP 协议实现网络通信。 二、 InetAddress 没有公有的构造函数，只能通过静态方法来创建实例。 1234567891011121314151617181920212223242526import java.net.InetAddress;import java.net.UnknownHostException;/** * IP InetAddress * @author Hongliang Zhu * @create 2020-02-19 21:50 */public class IPTest &#123; public static void main(String[] args) throws UnknownHostException &#123; InetAddress address = InetAddress.getLocalHost(); // 192.168.145.1 System.out.println(address.getHostAddress()); System.out.println(address.getHostName()); // zhuhongliang // 根据域名得到InetAddress //根据域名得到InetAddress对象 address = InetAddress.getByName(&quot;www.163.com&quot;); System.out.println(address.getHostAddress());//返回 163服务器的ip:183.216.182.9 System.out.println(address.getHostName()); //输出：www.163.com //根据ip得到InetAddress对象 address = InetAddress.getByName(&quot;183.216.182.7&quot;); System.out.println(address.getHostAddress()); //返回 163服务器的ip:61.135.253.15 System.out.println(address.getHostName());//输出ip而不是域名。如果这个IP地 址不存在或DNS 服务器不允许进行IP地址和域名的映射，getHostName方法就直接返回这个IP地址。 &#125;&#125; 端口ip地址用来标识一台计算机，端口用来区分不同的程序。 常用的命令： 查看所有端口： netstat -ano 查看指定端口： netstat -ano | findstr “5023” 查看指定进程： tasklist | findstr “5032” 查看具体程序： 使用任务管理器查看pid 123456//包含端口InetSocketAddress socketAddress = new InetSocketAddress(&quot;127.0.0.1&quot;,8080); //指定了端口InetSocketAddress socketAddress2 = new InetSocketAddress(&quot;localhost&quot;,9000);System.out.println(socketAddress.getHostName()); // 127.0.0.1System.out.println(socketAddress2.getAddress()); // localhost/127.0.0.1System.out.println(socketAddress.getPort()); // 8080 三、 URLURL（Uniform Resource Locator）： 统一资源定位符 ， 由4部分组成：协议 、存放资源的主机域名、端口号和资源文件名。 如： http://www.www.baidu.com:9090/index.html URL是指向互联网“资源”的指针。资源可以是简单的文件或目录，也可以是对更为复杂的对象的引用，例如对数据库或搜索引 擎的查询。 互联网的三大基石： html， http， url URI（Universal Resource Identifier）： 统一资源标志符，用来标识抽象或者物理资源的一个紧凑字符串。 URN（Universal Resource Name）：统一资源名称， 通过特定命名空间中的唯一名称或ID来标识资源。 12345678910111213141516171819202122232425import java.net.MalformedURLException;import java.net.URL;/** * URL: 统一资源定位符 区分资源 * * * @author Hongliang Zhu * @create 2020-02-19 22:52 */public class URLTest &#123; public static void main(String[] args) throws MalformedURLException &#123; URL url = new URL(&quot;http://www.baidu.com:9090/index.html?uname=zhu&amp;age=18#a&quot;); // 获取四个值 System.out.println(&quot;协议：&quot;+ url.getProtocol()); System.out.println(&quot;域名|ip： &quot;+ url.getHost()); System.out.println(&quot;请求的资源1：&quot;+ url.getFile()); System.out.println(&quot;请求的资源2： &quot;+ url.getPath()); //参数 System.out.println(&quot;参数：&quot;+ url.getQuery()); // 锚点 System.out.println(&quot;锚点： &quot;+ url.getRef()); &#125;&#125; 协议：http域名|ip： www.baidu.com请求的资源1：/index.html?uname=zhu&amp;age=18请求的资源2： /index.html参数：uname=zhu&amp;age=18锚点： a 爬虫原理使用url来下载资源 12345678910111213141516171819202122232425import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.net.URL;/** * URL下载资源 爬虫原理 * @author Hongliang Zhu * @create 2020-02-20 10:35 */public class SpyderTest &#123; public static void main(String[] args) throws IOException &#123; URL url = new URL(&quot;https://www.jd.com&quot;);// URL url = new URL(&quot;https://www.dianping.com&quot;); //不是所有的网站都可以爬 InputStream is = url.openStream(); // BufferedReader br = new BufferedReader(new InputStreamReader(is, &quot;utf8&quot;)); String msg = null; while(null != (msg=br.readLine()))&#123; System.out.println(msg); &#125; br.close(); &#125;&#125; 对于不能直接通过URL来获取资源的，可以通过浏览器请求方式来获取： 1234567891011121314151617181920212223import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.HttpURLConnection;import java.net.URL;/** *爬虫原理 : 模拟浏览器访问 * @author Hongliang Zhu * @create 2020-02-20 10:35 */public class SpyderTest2 &#123; public static void main(String[] args) throws IOException &#123; URL url = new URL(&quot;https://www.dianping.com&quot;); HttpURLConnection conn = (HttpURLConnection)url.openConnection(); conn.setRequestMethod(&quot;GET&quot;); conn.setRequestProperty(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Safari/537.36&quot;); BufferedReader br = new BufferedReader(new InputStreamReader(conn.getInputStream(), &quot;utf8&quot;)); String msg = null; while (null != (msg = br.readLine()))&#123; System.out.println(msg); &#125; &#125;&#125; 四、 传输协议TCP&amp;UDPTCP传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 套接字Socket​ 我们开发的网络应用程序位于应用层，TCP和UDP属于传输层协议，在应用层如何使用传输层 的服务呢？在应用层和传输层之间，则是使用套接字来进行分离。 ​ 套接字就像是传输层为应用层开的一个小口，应用程序通过这个小口向远程发送数据，或者 接收远程发来的数据；而这个小口以内，也就是数据进入这个口之后，或者数据从这个口出来之前，是不知道也不需要知道的，也不会关心它如何传输，这属于网络其它层次的工作。 ​ Socket实际是网络传输层供给应用层的编程接口。传输层则在网络层的基础上提供进 程到进程问的逻辑通道，而应用层的进程则利用传输层向另一台主机的某一进程通 信。Socket就是应用层与传输层之间的桥梁 。 ​ 使用Socket编程可以开发客户机和服务器应用程序，可以在本地网络上进行通信，也 可通过Internet在全球范围内通信。 生活案例1： ​ 如果你想写封邮件发给远方的朋友，如何写信、将信 打包，属于应用层。信怎么写，怎么打包完全由我们做主；​ 而当我们将信投入邮筒时，邮筒的那个口就是套接字， 在进入套接字之后，就是传输层、网络层等（邮局、公路交管或者航线等）其它层次的工作了。我们从来不会去关心信是如何从西安发往北京的，我们只知道 写好了投入邮筒就OK了。 生活案例2: 如果你想发货给国外，你只要把 货物放入集装箱，然后交给码头就可以了。发送什么货物，货物如何打包, 完全有你做主。 码头就是套接字，剩下的事情就 交给港口和货运公司处理就行了，具体细节我们无需了解。 ​ 五、 UDP编程Datagram DatagramSocket：通信类 : 用于发送或者接受数据包的套接字 DatagramPacket：数据包类 使用基于UDP协议的Socket网络编程实现 ： ​ 不需要利用IO流实现数据的传输。 每个数据发送单元被统一封装成数据包的方式，发送方将数据包发送到网络中，数据包在网络中去寻找他的目的地。 UDP编程 ： 一切转换成字节数组 接收端： 1.使用DatagramSocket 指定端口 创建接收端 2.指定容器， 封装DatagramPacket包 3.阻塞式接受包裹receive（DatagramPacket p） 4.分析数据 byte[] getData() getLength() 5.释放资源 发送端 1.使用DatagramSocket 指定端口 创建发送端 2.准备数据 ==》 一定要转成字节数组 3.封装 DatagramPacket包，需要指定目的地 + 端口 4.发送包裹 send( DatagramPacket p） 5.释放资源 123456789101112131415161718192021222324252627282930313233343536import java.net.DatagramPacket;import java.net.DatagramSocket;/** * 接受端： * 1. 使用DatagramSocket 指定端口 创建接收端 * 2. 指定容器， 封装DatagramPacket包 * 3. 阻塞式接受包裹receive（DatagramPacket p） * 4. 分析数据 * byte[] getData() * getLength() * 5. 释放资源 * @author Hongliang Zhu* @create 2020-02-20 11:51*/public class UDPServer &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;接收端启动中...&quot;); // 1. 使用DatagramSocket 指定端口 创建接收端 DatagramSocket server = new DatagramSocket(8888); // 2. 指定容器， 封装DatagramPacket包 byte[] contiainer = new byte[1024*60]; DatagramPacket packet = new DatagramPacket(contiainer, 0, contiainer.length); // 3. 阻塞式接受包裹receive（DatagramPacket p） server.receive(packet); // 4. 分析数据 byte[] datas = packet.getData(); int len = packet.getLength(); System.out.println(new String(datas, 0, len)); // 5. 释放资源 server.close(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetSocketAddress;/** * 发送端： * 1. 使用DatagramSocket 指定端口 创建发送端 * 2. 准备数据 一定转成字节数组 * 3. 封装DatagramPacket包，需要指定目的地 * 4. 发送包裹send( DatagramPacket p） * 5. 释放资源 * @author Hongliang Zhu * @create 2020-02-20 17:10 */public class UPDCilent &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;发送方启动中...&quot;); // 1. 使用DatagramSocket 指定端口 创建发送端 DatagramSocket client = new DatagramSocket(9999); //2. 准备数据 一定转成字节数组 String data = &quot;Hello world&quot;; byte[] datas = data.getBytes(); //3. 封装DatagramPacket包，需要指定目的地 DatagramPacket packet = new DatagramPacket(datas, 0, datas.length, new InetSocketAddress(&quot;localhost&quot;, 8888)); // 4. 发送包裹send( DatagramPacket p） client.send(packet); // 5. 释放资源 client.close();// &#125;&#125; UDP编程： 传输基本数据类型和引用服务端（接收端）： 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.io.BufferedInputStream;import java.io.ByteArrayInputStream;import java.io.ObjectInputStream;import java.net.DatagramPacket;import java.net.DatagramSocket;/** * 接受端： 基本数据类型和引用 * 1. 使用DatagramSocket 指定端口 创建接收端 * 2. 指定容器， 封装DatagramPacket包 * 3. 阻塞式接受包裹receive（DatagramPacket p） * 4. 分析数据 * 5. 释放资源 * @author Hongliang Zhu * @create 2020-02-20 19:13 */public class UDPTypeServer &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;传输基本数据类型==&gt;接收端启动中。。。。&quot;); DatagramSocket server = new DatagramSocket(9898); byte[] datas = new byte[1024*90]; DatagramPacket packet = new DatagramPacket(datas, 0, datas.length); server.receive(packet); byte[] data = packet.getData(); int len = packet.getLength(); ObjectInputStream dis = new ObjectInputStream(new BufferedInputStream(new ByteArrayInputStream(data))); // 按照顺序读取 String msg = dis.readUTF(); // 读取 boolean flag = dis.readBoolean(); int a = dis.readInt(); Object o = dis.readObject(); System.out.println(len); System.out.println(a+&quot;=&gt;&quot;+msg+&quot;--&gt;&quot;+flag);// o.toString(); if(o instanceof Employee)&#123; Employee e = (Employee)o; e.toString(); System.out.println(&quot;的确是马云&quot;); System.out.println(e.getName() +&quot;:&quot;+ e.getMoney()); &#125; server.close(); &#125;&#125; 客户端（发送端）： 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.BufferedOutputStream;import java.io.ByteArrayOutputStream;import java.io.ObjectOutputStream;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetSocketAddress;/** * 发送端： 基本数据类型和引用 * 1. 使用DatagramSocket 指定端口 创建发送端 * 2. 准备数据 一定转成字节数组 * 3. 封装DatagramPacket包，需要指定目的地 * 4. 发送包裹send( DatagramPacket p） * 5. 释放资源 * @author Hongliang Zhu * @create 2020-02-20 17:10 */public class UPDTypeCilent &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;传输基本数据类型==&gt;发送方启动中...&quot;); // 1. 使用DatagramSocket 指定端口 创建发送端 DatagramSocket client = new DatagramSocket(9999); //2. 准备数据 一定转成字节数组 ByteArrayOutputStream bao = new ByteArrayOutputStream(); ObjectOutputStream dos = new ObjectOutputStream(new BufferedOutputStream(bao)); dos.writeUTF(&quot;Hello world!&quot;); dos.writeBoolean(true); dos.writeInt(99); // 对象 Employee e = new Employee(&quot;马云&quot;, 900000); dos.writeObject(e); dos.flush(); byte[] datas = bao.toByteArray(); //3. 封装DatagramPacket包，需要指定目的地 DatagramPacket packet = new DatagramPacket(datas, 0, datas.length, new InetSocketAddress(&quot;localhost&quot;, 9898)); // 4. 发送包裹send( DatagramPacket p） client.send(packet); // 5. 释放资源 client.close(); &#125;&#125; 传输基本数据类型==&gt;发送方启动中… 6699=&gt;Hello world!–&gt;true的确是马云null:900000.0 UDP编程： 传输文件123456789101112131415161718192021222324252627282930313233343536373839404142import java.io.*;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetSocketAddress;/** * 发送端： 发送文件 * 1. 使用DatagramSocket 指定端口 创建发送端 * 2. 准备数据 一定转成字节数组 * 3. 封装DatagramPacket包，需要指定目的地 * 4. 发送包裹send( DatagramPacket p） * 5. 释放资源 * @author Hongliang Zhu * @create 2020-02-20 17:10 */public class UPDFileCilent &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;文件 ==&gt; 发送方启动中...&quot;); // 1. 使用DatagramSocket 指定端口 创建发送端 DatagramSocket client = new DatagramSocket(9999); //2. 准备数据 一定转成字节数组 InputStream is = new FileInputStream(&quot;./socket/socket.png&quot;); // 注意图片不能太大，否则会报异常 BufferedInputStream bi = new BufferedInputStream(is); ByteArrayOutputStream os = new ByteArrayOutputStream(); byte[] data = new byte[1024*60]; int len; while ( -1 != (len = is.read(data,0, data.length)))&#123; os.write(data, 0, len); os.flush(); &#125; byte[] datas = os.toByteArray(); //3. 封装DatagramPacket包，需要指定目的地 DatagramPacket packet = new DatagramPacket(datas, 0, datas.length, new InetSocketAddress(&quot;localhost&quot;, 8888)); // 4. 发送包裹send( DatagramPacket p） client.send(packet); // 5. 释放资源 client.close(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.BufferedOutputStream;import java.io.FileOutputStream;import java.io.InputStream;import java.io.OutputStream;import java.net.DatagramPacket;import java.net.DatagramSocket;/** * 接受端： * 1. 使用DatagramSocket 指定端口 创建接收端 * 2. 指定容器， 封装DatagramPacket包 * 3. 阻塞式接受包裹receive（DatagramPacket p） * 4. 分析数据 * byte[] getData() * getLength() * 5. 释放资源 * @author Hongliang Zhu* @create 2020-02-20 11:51*/public class UDPFileServer &#123; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;接收端启动中...&quot;); // 1. 使用DatagramSocket 指定端口 创建接收端 DatagramSocket server = new DatagramSocket(8888); // 2. 指定容器， 封装DatagramPacket包 byte[] contiainer = new byte[1024*60]; DatagramPacket packet = new DatagramPacket(contiainer, 0, contiainer.length); // 3. 阻塞式接受包裹receive（DatagramPacket p） server.receive(packet); // 4. 分析数据 byte[] datas = packet.getData(); int len = packet.getLength();// System.out.println(new String(datas, 0, len)); BufferedOutputStream os =new BufferedOutputStream(new FileOutputStream(&quot;./socket/copy.png&quot;)); //接受数据 os.write(datas, 0, datas.length); os.flush(); // 5. 释放资源 server.close(); &#125;&#125; UDP案例： 多线程实现在线咨询发送端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.InetSocketAddress;import java.net.SocketException;/** * 发送端： 使用面向对象封装 * @author Hongliang Zhu * @create 2020-02-21 10:53 */public class talkSend implements Runnable &#123; private DatagramSocket client ; // 发送端套接字 private BufferedReader reader; // 读取数据 private String toIP; // 发送到服务端的IP private int toPort; // 服务端的端口 public talkSend(int port, String toIP, int toPort) &#123; this.toIP = toIP; this.toPort = toPort; try &#123; this.client = new DatagramSocket(port); reader = new BufferedReader(new InputStreamReader(System.in)); &#125; catch (SocketException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; while (true)&#123; String msg = null; try &#123; msg = reader.readLine(); byte[] datas = msg.getBytes(); DatagramPacket packet = new DatagramPacket(datas, 0, datas.length, new InetSocketAddress(this.toIP, this.toPort)); client.send(packet); // 发送 if(&quot;bye&quot;.equals(msg))&#123; break; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; client.close(); &#125;&#125; 接收端1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.IOException;import java.net.DatagramPacket;import java.net.DatagramSocket;import java.net.SocketException;/** * 接收端 * @author Hongliang Zhu * @create 2020-02-21 11:08 */public class talkRecieve implements Runnable&#123; private DatagramSocket server; public talkRecieve(int port) &#123; try &#123; this.server = new DatagramSocket(port); &#125; catch (SocketException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; while (true)&#123; byte[] data = new byte[1024*60]; DatagramPacket packet = new DatagramPacket(data,0, data.length); try &#123; server.receive(packet); byte[] datas = packet.getData(); String msg = new String(datas); System.out.println(msg); if (&quot;bye&quot;.equals(msg))&#123; break; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; server.close(); &#125;&#125; 创建学生端： 1234567891011/** * 学生端： 加入多线程，实现在线交流 * @author Hongliang Zhu * @create 2020-02-21 11:25 */public class TalkStudent &#123; public static void main(String[] args) &#123; new Thread(new talkSend(8989, &quot;localhost&quot;, 9999)).start(); new Thread(new talkRecieve(10024)).start(); &#125;&#125; 创建教师端： 1234567891011/** * 教室端： 加入多线程，实现在线交流 * @author Hongliang Zhu * @create 2020-02-21 11:25 */public class TalkTeacher &#123; public static void main(String[] args) &#123; new Thread(new talkRecieve(9999)).start(); // 接受信息 new Thread(new talkSend(10025, &quot;localhost&quot;, 10024)).start(); &#125;&#125; 六、 TCP 编程TCP协议基于请求-响应模式， 在网络通讯中，第一次主动发起通讯的程序被称作客户端(Client)程序，第一次通讯中等待连接的程序被称作服务器端 (Server)程序。利用IO流实现数据的传输。 TCP通信原理 服务器创建ServerSocket，在指定端口监听并并处理请求。 客户端创建Socket，向服务器发送请求。 完成网络登录功能使用基于TCP协议的Socket网络编程实现。 单向：客户端向服务器端发送字符串，服务器获取字符串并输出双向：服务器端给出客户端反馈，客户端得到反馈并输出对象：客户端向服务器端发送User对象，服务器端获取对象并输出多线程：服务器接收多个客户端的请求，并给出反馈每个客户请求开启一个线程 服务端： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.io.*;import java.net.ServerSocket;import java.net.Socket;/** * TCP单向： 服务端 * @author Hongliang Zhu * @create 2020-02-21 13:28 */public class TCPServer &#123; public static void main(String[] args) throws IOException &#123; System.out.println(&quot;-----------服务端--------------&quot;); ServerSocket server = new ServerSocket(9696); Socket cilent = server.accept(); // 监听连接请求， 返回对应的客户端 System.out.println(&quot;建立了一个连接&quot;); InputStream is = cilent.getInputStream(); DataInputStream dis = new DataInputStream(is); // 读取 String uname = null; String upwd = null; String msg = dis.readUTF(); String []datas = msg.split(&quot;&amp;&quot;); for(String s: datas)&#123; String[] info = s.split(&quot;=&quot;); if(&quot;uname&quot;.equals(info[0]))&#123; System.out.println(&quot;您的用户名为：&quot;+ info[1]); uname = info[1]; &#125; if(&quot;upwd&quot;.equals(info[0]))&#123; System.out.println(&quot;您的密码为：&quot;+ info[1]); upwd = info[1]; &#125; &#125; //判断：返回给客户端的信息 String back = null; DataOutputStream dos = new DataOutputStream(cilent.getOutputStream()); if(&quot;zhuhongliang&quot;.equals(uname) &amp;&amp; &quot;123456&quot;.equals(upwd))&#123; back = &quot;登录成功， 欢迎回来&quot;; &#125;else&#123; back = &quot;用户名或者密码错误！&quot;; &#125; dos.writeUTF(back); dos.flush(); // 关闭资源 dos.close(); dis.close(); cilent.close(); &#125;&#125; 客户端 123456789101112131415161718192021222324252627282930313233343536import java.io.*;import java.net.Socket;/** * TCp 客户端 * @author Hongliang Zhu * @create 2020-02-21 13:34 */public class TCPClient &#123; public static void main(String[] args) throws IOException &#123; System.out.println(&quot;--------------客户端---------------&quot;); Socket client = new Socket(&quot;localhost&quot;, 9696); //服务器的ip和端口 // 操作： 输入输出流 String uname; String upwd; BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); System.out.println(&quot;请输入用户名：&quot;); uname = br.readLine(); System.out.println(&quot;请输入密码：&quot;); upwd = br.readLine(); String msg = &quot;uname=&quot;+ uname +&quot;&amp;&quot;+&quot;upwd=&quot;+upwd; // 写出 DataOutputStream dos = new DataOutputStream(client.getOutputStream()); dos.writeUTF(msg); dos.flush(); //接收服务端返回的结果 DataInputStream dis = new DataInputStream(client.getInputStream()); String res = dis.readUTF(); System.out.println(res); dos.close(); br.close(); client.close(); &#125;&#125; 文件上传1234567891011121314151617181920212223242526import java.io.*;import java.net.Socket;/** * TCp 客户端 文件上传 * @author Hongliang Zhu * @create 2020-02-21 13:34 */public class FileClient &#123; public static void main(String[] args) throws IOException &#123; System.out.println(&quot;--------------客户端---------------&quot;); Socket client = new Socket(&quot;localhost&quot;, 9696); //服务器的ip和端口 // 操作： 输入输出流 // 文件拷贝 InputStream is = new BufferedInputStream(new FileInputStream(&quot;./io/io.png&quot;)); OutputStream os = new BufferedOutputStream(client.getOutputStream()); byte[] buff = new byte[1024]; int len = -1; while (-1 != (len = is.read(buff)))&#123; os.write(buff,0, len); &#125; os.flush(); os.close(); is.close(); client.close(); &#125;&#125; 12345678910111213141516171819202122232425262728import java.io.*;import java.net.ServerSocket;import java.net.Socket;/** * TCP:服务端 保存文件 * @author Hongliang Zhu * @create 2020-02-21 13:28 */public class FileServer &#123; public static void main(String[] args) throws IOException &#123; System.out.println(&quot;-----------服务端--------------&quot;); ServerSocket server = new ServerSocket(9696); Socket cilent = server.accept(); // 监听连接请求， 返回对应的客户端 System.out.println(&quot;建立了一个连接&quot;); // 接受数据 InputStream is = new BufferedInputStream(cilent.getInputStream()); OutputStream os = new BufferedOutputStream(new FileOutputStream(new File(&quot;./socket/tcp.png&quot;))); byte[] buff = new byte[1024]; int len = -1; while (-1 != (len = is.read(buff)))&#123; os.write(buff,0, len); &#125; os.flush(); is.close(); os.close(); cilent.close(); &#125;&#125; 多用户登录服务端： 使用了多线程实现多个用户同时处理，将对接管道封装 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import java.io.DataInputStream;import java.io.DataOutputStream;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;/** * TCP多用户登录： 服务端 多线程处理 面向对象高度封装！ * @author Hongliang Zhu * @create 2020-02-21 13:28 */public class TCPMutiServer &#123; // main方法 public static void main(String[] args) throws IOException &#123; System.out.println(&quot;-----------服务端--------------&quot;); ServerSocket server = new ServerSocket(9696); boolean isRuning = true; while (isRuning)&#123; Socket cilent = server.accept(); // 监听连接请求， 返回对应的客户端 System.out.println(&quot;建立了一个连接&quot;); new Thread(new Channel(cilent)).start(); &#125; &#125; // 封装管道 里面有输入流和输出流 ，使用多线程可以服务多个客户端 static class Channel implements Runnable&#123; private Socket client; // 客户端 private DataInputStream dis; // 输入流 ==&gt; 用于客户端请求服务端的信息 private DataOutputStream dos; // 输出流 ==&gt; 服务端给客户端的响应信息 public Channel(Socket client)&#123; this.client = client; try &#123; dis = new DataInputStream(this.client.getInputStream()); // 获取客户端输入 dos = new DataOutputStream(this.client.getOutputStream()); // 给客户端的响应 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 接收数据 public String recieve()&#123; String msg = &quot;&quot;; try &#123; msg = dis.readUTF(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return msg; &#125; //发送给客户端数据 private void send(String msg)&#123; try &#123; dos.writeUTF(msg); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; // 关闭资源 private void release()&#123; try &#123; if (null != dos) dos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; if (null != dis) dis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; try &#123; if (null != client) client.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; // 读取读取 String msg = recieve(); String uname = null; String upwd = null; String []datas = msg.split(&quot;&amp;&quot;); for(String s: datas)&#123; String[] info = s.split(&quot;=&quot;); if(&quot;uname&quot;.equals(info[0]))&#123; System.out.println(&quot;您的用户名为：&quot;+ info[1]); uname = info[1]; &#125; if(&quot;upwd&quot;.equals(info[0]))&#123; System.out.println(&quot;您的密码为：&quot;+ info[1]); upwd = info[1]; &#125; &#125; //判断：返回给客户端的信息 String back = null; if(&quot;zhuhongliang&quot;.equals(uname) &amp;&amp; &quot;123456&quot;.equals(upwd))&#123; back = &quot;登录成功， 欢迎回来&quot;; &#125;else&#123; back = &quot;用户名或者密码错误！&quot;; &#125; send(back); // 发送给客户端 release(); // 释放资源 &#125; &#125;&#125; 客户端： 对发送和接受高度封装： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485import java.io.*;import java.net.Socket;/** * 多用户登录： 面向对象思维高度封装！ * @author Hongliang Zhu * @create 2020年2月21日23:57:11 */public class TCPMultiClient &#123; public static void main(String[] args) throws IOException &#123; System.out.println(&quot;--------------客户端---------------&quot;); Socket client = new Socket(&quot;localhost&quot;, 9696); //服务器的ip和端口 // 操作： 输入输出流 new Send(client).send(); //接收 new Recieve(client).recieve(); &#125; // 发送给服务器 static class Send&#123; private Socket client; private BufferedReader br; private DataOutputStream dos; String msg = &quot;&quot;; public Send(Socket client)&#123; this.client = client; try &#123; br = new BufferedReader(new InputStreamReader(System.in)); dos = new DataOutputStream(client.getOutputStream()); msg = init(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private String init()&#123; String uname = &quot;&quot;; String upwd = &quot;&quot;; try &#123; System.out.println(&quot;请输入用户名：&quot;); uname = br.readLine(); System.out.println(&quot;请输入密码：&quot;); upwd = br.readLine(); return &quot;uname=&quot;+ uname +&quot;&amp;&quot;+&quot;upwd=&quot;+upwd; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return &quot;&quot;; &#125; private void send()&#123; // 写出 try &#123; dos.writeUTF(msg); dos.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 接收服务器的返回消息 static class Recieve&#123; private Socket client; private DataInputStream dis; public Recieve(Socket client) &#123; this.client = client; try &#123; dis = new DataInputStream(client.getInputStream()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void recieve()&#123; try &#123; String res = dis.readUTF(); System.out.println(res); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 七、 实例： 手写在线聊天室1. 服务器功能：相当于消息的中转站（转发器） 1.可以同时处理多个客户端的请求。 2.当一个用户进入群聊的时候，会给群聊中所有的用户群发一条系统消息，提示所有用户有人进来了群聊当中。 3.当一个用户成功进入群聊的时候， 服务器会发送一条问候语给当前客户。 4.当一个用户离开群聊的时候，会给群聊中所有的用户群发一条系统消息，提示所有用户xxx离开了群聊。 5.一个用户发送的消息可以给群聊中的所有用户发送。 6.可以对指定的用户私聊，消息只对指定的用户看见。格式： @xxx：message 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133package chatVersion;import java.io.DataInputStream;import java.io.DataOutputStream;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;import java.util.concurrent.CopyOnWriteArrayList;import javax.management.relation.Relation;import javax.print.attribute.standard.MediaSize.Other;/** * 在线聊天室： 群聊版本 * @author ZHLAS * */public class Chat &#123; static CopyOnWriteArrayList&lt;Channel&gt; all = new CopyOnWriteArrayList&lt;&gt;(); public static void main(String[] args) throws IOException &#123; System.out.println(&quot;-------------服务器启动中------------------&quot;); ServerSocket server = new ServerSocket(8888); // 等待连接 while(true)&#123; Socket client = server.accept(); System.out.println(&quot;建立一个连接&quot;); Channel c = new Channel(client); all.add(c); // 加入一个客户端 new Thread(c).start(); // 开始服务 &#125; &#125; //一个Channel代表一个客户端 static class Channel implements Runnable&#123; private Socket client; private DataInputStream dis = null; private DataOutputStream dos = null; private boolean isRuning = true; private String name; //当前客户端的名字 // public Channel(Socket client) &#123; this.client = client; try&#123; dis = new DataInputStream(client.getInputStream()); dos= new DataOutputStream(client.getOutputStream()); //欢迎您的到来 this.name = recieve(); ///接收到客户端的名字 this.send(&quot;欢迎您来到聊天室！&quot;); // 发送给对应客户端的欢迎词 sendOthers(this.name+ &quot;加入了群聊...&quot;, true); //告诉大家谁加入了群聊 &#125;catch(Exception e)&#123; relese(); &#125; &#125; // 服务器接收到客户端发送的数据 private String recieve() &#123; String msg = &quot;&quot;; try &#123; msg = dis.readUTF(); &#125; catch (IOException e) &#123; relese(); &#125; return msg; &#125; // 服务器给客户点发送数据 private void send(String msg) &#123; try &#123; dos.writeUTF(msg); &#125; catch (IOException e) &#123; relese(); &#125; &#125; /** * 群发 ： 获取自己的消息， 发送给别人 * 私聊： 约定数据格式 ： @xxx:msg * @param msg */ private void sendOthers(String msg, boolean isSys) &#123; boolean isPrivate = msg.startsWith(&quot;@&quot;); //私聊 if(isPrivate)&#123; //私聊 int idx = msg.indexOf(&quot;:&quot;); //冒号的位置 // 获取目标和数据 String targetName = msg.substring(1, idx); msg = msg.substring(idx+1); // 遍历客户，找到指定目标 for(Channel target : all)&#123; if(target.name.equals(targetName))&#123; target.send(this.name +&quot;悄悄地对你说： &quot;+msg); &#125; &#125; &#125;else&#123; // 遍历容器 for(Channel c: all)&#123; if(this == c)&#123; //自己 continue; &#125;else&#123; if(!isSys) c.send(this.name+&quot;对所有人说： &quot;+msg); else c.send(msg); &#125; &#125; &#125; &#125; //释放资源 private void relese()&#123; this.isRuning = false; Release.reslese(dos, dis, client); // 移除容器的客户端 all.remove(this); sendOthers(this.name+&quot;离开了群聊...&quot;, true); &#125; public void run() &#123; String msg =&quot;&quot;; while(isRuning)&#123; // 接收数据 msg = recieve(); // 发送数据 if(!&quot;&quot;.equals(msg))&#123;// send(msg); sendOthers(msg, false); // 群聊 &#125; &#125; &#125; &#125;&#125; 2. 客户端功能： 1.发送消息给服务器 2.从服务器那边接收消息 12345678910111213141516171819202122232425262728293031package chatVersion;import java.io.BufferedReader;import java.io.DataInputStream;import java.io.DataOutputStream;import java.io.IOException;import java.io.InputStreamReader;import java.net.Socket;import java.net.UnknownHostException;import java.nio.Buffer;import org.omg.CosNaming.NamingContextExtPackage.StringNameHelper;/** * 在线聊天室：客户端 * 目标：群聊 * * @author ZHLAS * */public class Client &#123; public static void main(String[] args) throws UnknownHostException, IOException &#123; System.out.println(&quot;-------------客户端--------------&quot;); BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); System.out.println(&quot;请输入你的姓名：&quot;); String name = br.readLine(); Socket client = new Socket(&quot;localhost&quot;, 8888); // 建立连接 new Thread(new Send(client, name)).start(); // 发送 new Thread(new Recieve(client)).start(); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package chatVersion;import java.io.BufferedReader;import java.io.DataOutputStream;import java.io.IOException;import java.io.InputStreamReader;import java.net.Socket;/** * * 发送端 * @author ZHLAS * */public class Send implements Runnable&#123; private Socket client; // 准备数据 private BufferedReader br; private DataOutputStream dos; private boolean isRuning = true; private String name; public Send(Socket client, String name) &#123; this.client = client; br = new BufferedReader(new InputStreamReader(System.in)); this.name = name; try &#123; dos = new DataOutputStream(client.getOutputStream()); send(name); // 把客户端的名称发送给服务器 &#125; catch (IOException e) &#123; this.isRuning = false; Release.reslese(dos, br, client); &#125; &#125; private void send(String msg) &#123; try &#123; // 写出 dos.writeUTF(msg); dos.flush(); &#125; catch (IOException e) &#123; this.isRuning = false; Release.reslese(dos, br); &#125; &#125; @Override public void run() &#123; while(isRuning)&#123; String msg = &quot;&quot;; try &#123; msg = br.readLine(); &#125; catch (IOException e) &#123; this.isRuning = false; Release.reslese(br); &#125; send(msg); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package chatVersion;import java.io.DataInputStream;import java.io.IOException;import java.net.Socket;/** * 接收端 * @author ZHLAS * */public class Recieve implements Runnable&#123; private Socket client; private DataInputStream dis; private boolean isRuning = true; public Recieve(Socket client) &#123; this.client = client; try &#123; dis = new DataInputStream(client.getInputStream()); &#125; catch (IOException e) &#123; this.isRuning = false; Release.reslese(dis, client); &#125; &#125; private String recieve() &#123; String msg =&quot;&quot;; try &#123; msg = dis.readUTF(); &#125; catch (IOException e) &#123; Release.reslese(dis); &#125; return msg; &#125; @Override public void run() &#123; while(isRuning)&#123; String msg = recieve(); if(!&quot;&quot;.equals(msg)) System.out.println(msg); &#125; &#125;&#125; 3. 释放资源12345678910111213141516171819202122package chatVersion;import java.io.Closeable;import java.io.IOException;public class Release &#123; public static void reslese(Closeable... targets)&#123; for(Closeable target: targets)&#123; if(target != null)&#123; try &#123; target.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 4. 运行效果","path":"2024/11/07/Java专题之Socket编程/","date":"11-07","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"MySQL实战45讲精华","text":"01 一条SQL查询语句是如何执行的见 https://castile.github.io/2021/07/23/mysql%E8%AF%AD%E5%8F%A5%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/ 02 日志系统：一条SQL更新语句是如何执行的更新语句： update T set c=c+1 where ID=2; redo logredo log使用WAL技术（Write-Ahead Logging），也就是先写日志再写磁盘。 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做 write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。 binlog与redo log的区别： redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。 更新语句执行流程图： 注意，这里使用了两阶段提交。是因为要保证 数据库的状态和用它的日志恢复出来的库的一致。 03 事务隔离隔离性与隔离级别ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）。 SQL 标准的事务隔离级别包括： 读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable ）。 读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。 读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。 可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。 串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。 事务隔离的实现在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。 当没有事务再需要用到这些回滚日志时，回滚日志会被删除，因此尽量不要使用长事务。 由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间 查询事务 可以在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。 1select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60 如何避免长事务对业务的影响？首先，从应用开发端来看： 确认是否使用了 set autocommit=0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin/commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。 其次，从数据库端来看： 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill； Percona 的 pt-kill 这个工具不错，推荐使用； 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题； 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。 04 深入浅出索引（上） 索引的出现其实就是为了提高数据查询的效率，就像书的目录一样 索引的常见模型常见的有哈希表、有序数组和搜索树。 哈希索引： 通过hash函数计算key所在的位置从而找到value，冲突后后面挂了一条链表。 哈希表这种结构适用于只有等值查询的场景 ， 区间查询需要遍历全部，查询很慢。 有序数组： 有序数组在等值查询和范围查询场景中的性能就都非常优秀 ， 但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。 所以，有序数组索引只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。 二叉搜索树 ： O(log(N)) 的查询复杂度 ， 新的时间复杂度也是 O(log(N))。 InnoDB 的索引模型 在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表 nnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的， 每一个索引在 InnoDB 里面对应一棵 B+ 树。 B+ 树能够很好地配合磁盘的读写特性，减少单次查询的磁盘访问次数 建表语句： 12345create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB; 表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)， 根据叶子节点的内容，索引类型分为主键索引和非主键索引 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index） 基于主键索引和普通索引的查询有什么区别？ 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树； 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。 也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。 索引如何维护插入数据的时候就需要维护索引B+树，可能会涉及到页分裂、合并操作。 *哪些场景下应该使用自增主键，而哪些场景下不应该？ 自增主键： 插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值； 每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂 有的 业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。 除了考虑性能外，我们还可以从存储空间的角度来看， 主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小 “尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。 05 深入浅出索引（下）语句： 12345678create table T (ID int primary key,k int NOT NULL DEFAULT 0, s varchar(16) NOT NULL DEFAULT &#x27;&#x27;,index k(k))engine=InnoDB; insert into T values(100,1, &#x27;aa&#x27;),(200,2,&#x27;bb&#x27;),(300,3,&#x27;cc&#x27;),(500,5,&#x27;ee&#x27;),(600,6,&#x27;ff&#x27;),(700,7,&#x27;gg&#x27;); 执行select * from T where k between 3 and 5，需要执行几次树的搜索操作，会扫描多少行？ 在 k 索引树上找到 k=3 的记录，取得 ID = 300； 再到 ID 索引树查到 ID=300 对应的 R3； 在 k 索引树取下一个值 k=5，取得 ID=500； 再回到 ID 索引树查到 ID=500 对应的 R4； 在 k 索引树取下一个值 k=6，不满足条件，循环结束。 可以看到，这个查询过程读了 k 索引树的 3 条记录（步骤 1、3 和 5），回表了两次（步骤 2 和 4）。 覆盖索引 如果执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。 由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。 最左前缀原则 B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。 用（name，age）这个联合索引来分析。 索引项是按照索引定义里面出现的字段顺序排序的。 当你的逻辑需求是查到所有名字是“张三”的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果. 如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止 这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。 在建立联合索引的时候，如何安排索引内的字段顺序? 这里我们的评估标准是，索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。 索引下推最左前缀可以用于在索引中定位记录，那些不符合最左前缀的部分，会怎么样呢？ 市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的： 1select * from tuser where name like &#x27;张 %&#x27; and age=10 and ismale=1; 搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3， 后面只能从ID3开始回表操作，找出数据行再比较字段值。 在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 InnoDB 在 (name,age) 索引内部就判断了 age 是否等于 10，对于不等于 10 的记录，直接判断并跳过。在我们的这个例子中，只需要对 ID4、ID5 这两条记录回表取数据判断，就只需要回表 2 次 06 全局锁和表锁 根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类 全局锁全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。 全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。 全库备份的方式 1、 Flush tables with read lock (FTWRL) 2、使用可重复读的事务隔离级别。 逻辑备份工具是 mysqldump。 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。 但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎。 3、 全库只读，为什么不使用 set global readonly=true 的方式呢？但是建议使用FTWRL，原因如下： 一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。 二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。 表级锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。 表锁的语法是 lock tables … read/write。 可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。 另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。 当要对表做结构变更操作的时候，加 MDL 写锁。 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。 事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放。 如何安全地给小表加字段？ 1、 我们要解决长事务，事务不提交，就会一直占着 MDL 锁。 如果你要做 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务。 如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，你该怎么做呢？ 在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。 12ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 07 行锁功过：怎么减少行锁对性能的影响？行锁就是针对数据表中行记录的锁。这很好理解，比如事务 A 更新了一行，而这时候事务 B 也要更新同一行，则必须等事务 A 的操作完成后才能进行更新。 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 因此， 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。 死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。 事务 A 在等待事务 B 释放 id=2 的行锁，而事务 B 在等待事务 A 释放 id=1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略： 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。默认是50s 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。 那种好用呢？ 如果采用第一种，使用默认值的话，出现了死锁要等待50s才能超时退出，对于在线服务来说是无法接受的。但是如果值设置成1s，太短，会出现误伤。 采用第二种的话，如果客户端并发更新1000次，死锁检查就要执行100w次（每个线程都需要循环判断1000次，所以是10的6次方），那么死锁检测就需要大量的cpu， 你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。 解决方法： 1、 确保这个业务一定不会出现死锁，可以临时把死锁检测关掉 ： innodb_deadlock_detect = off 2、 控制并发度 ： 对于相同行的更新，在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。 3、 冗余行设计： 减少冲突概率，减少锁等待次数，也就减少了死锁检测的CPU消耗。 如果你要删除一个表里面的前 10000 行数据，有以下三种方法可以做到： 第一种，直接执行 delete from T limit 10000; 第二种，在一个连接中循环执行 20 次 delete from T limit 500; 第三种，在 20 个连接中同时执行 delete from T limit 500。 你会选择哪一种方法呢？为什么呢？ 第二种好一点。 第一种方式： 单个语句占用时间长，锁的时间也比较长；而且大事务还会导致主从延迟。 第三种方式 ： 会人为造成锁冲突 08 事务到底是隔离的还是不隔离的？“快照”在 MVCC 里是怎么工作的？ 可重复读隔离级别： 一个事务在启动的时候看到的数据，在整个事务过程中看到的数据是一致的。 在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。 快照的实现每个事务有一个唯一的事务 ID，叫作 transaction id，且是严格递增的。 每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。也就是说数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。 虚线框里是同一行数据的 4 个版本，当前最新版本是 V4，k 的值是 22，它是被 transaction id 为 25 的事务更新的，因此它的 row trx_id 也是 25。 三个虚线箭头，就是 undo log(回滚日志)；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。 InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。 数组里面事务 ID 的最小值记为低水位，当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。 而数据版本的可见性规则，就是基于数据的 row trx_id 和这个一致性视图的对比结果得到的。 对于当前事务的启动瞬间来说，一个数据版本的 row trx_id，有以下几种可能： 如果落在绿色部分，表示这个版本是已提交的事务或者是当前事务自己生成的，这个数据是可见的； 如果落在红色部分，表示这个版本是由将来启动的事务生成的，是肯定不可见的； 如果落在黄色部分，那就包括两种情况： a. 若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见； b. 若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。 InnoDB 利用了“所有数据都有多个版本”的这个特性，实现了“秒级创建快照”的能力。 事务的可重复读的能力是怎么实现的可重复读的核心就是一致性读（consistent read）；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。 而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是： 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图； 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 举例说明123456mysql&gt; CREATE TABLE `t` ( `id` int(11) NOT NULL, `k` int(11) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(id, k) values(1,1),(2,2); 可重复读隔离级别下 这里，我们不妨做如下假设： 事务 A 开始前，系统里面只有一个活跃事务 ID 是 99； 事务 A、B、C 的版本号分别是 100、101、102，且当前系统里只有这四个事务； 三个事务开始前，(1,1）这一行数据的 row trx_id 是 90。 这样，事务 A 的视图数组就是 [99,100], 事务 B 的视图数组是 [99,100,101], 事务 C 的视图数组是 [99,100,101,102]。 事务 A 查询语句的读数据流程是这样的： 找到 (1,3) 的时候，判断出 row trx_id=101，比高水位大，处于红色区域，不可见； 接着，找到上一个历史版本，一看 row trx_id=102，比高水位大，处于红色区域，不可见； 再往前找，终于找到了（1,1)，它的 row trx_id=90，比低水位小，处于绿色区域，可见。 总结就是：一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况： 版本未提交，不可见； 版本已提交，但是是在视图创建后提交的，不可见； 版本已提交，而且是在视图创建前提交的，可见。 更新逻辑 用到了这样一条规则：更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。 因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。 所以，在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。 两阶段锁 事务 C 不是马上提交的，而是变成了下面的事务 C’，会怎么样呢？ 更新后并没有马上提交，在它提交前，事务 B 的更新语句先发起了。 事务 C’没提交，也就是说 (1,2) 这个版本上的写锁还没释放。而事务 B 是当前读，必须要读最新版本，而且必须加锁，因此就被锁住了，必须等到事务 C’释放这个锁，才能继续它的当前读。 本地验证结果也符合预期： 读提交隔离级别下的情况 在读提交隔离级别下，事务 A 和事务 B 的查询语句查到的 k，分别应该是多少呢？ 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。 “start transaction with consistent snapshot; ”的意思是从这个语句开始，创建一个持续整个事务的一致性快照。所以，在读提交隔离级别下，这个用法就没意义了，等效于普通的 start transaction。 事务 A 的查询语句的视图数组是在执行这个语句的时候创建的，时序上 (1,2)、(1,3) 的生成时间都在创建这个视图数组的时刻之前。但是，在这个时刻： (1,3) 还没提交，属于情况 1，不可见； (1,2) 提交了，属于情况 3，可见。 所以，这时候事务 A 查询语句返回的是 k=2。 显然地，事务 B 查询结果 k=3。 09 普通索引和唯一索引，应该怎么选择？假设有以下索引组织结构： 从这两种索引对查询语句和更新语句的性能影响来进行分析 查询过程执行查询的语句是 select id from T where k=5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录。 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。 这个不同带来的性能差距会有多少呢？答案是，微乎其微。 因为 InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。 更新过程 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。 虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上 将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。 merge的时机： 1、 访问这个数据页 2、数据库正常关闭时 什么条件下可以使用 change buffer对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束，这样就必须要将数据页读入内存中才能判断，这就没必要使用change buffer 实际上也只有普通索引可以使用。 change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 25的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 25%。 如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。 这个记录要更新的目标页在内存中 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。 普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间 这个记录要更新的目标页不在内存中 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束； 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。 change buffer 的使用场景change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。 普通索引的所有场景，使用` change buffer 都可以起到加速作用吗？ 因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。 1、 对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。 2、假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer ，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。 索引选择和实践1、 查询上无差别，考虑更新性能选择普通索引 2、数据量大的表更新，选择普通索引 3、机械硬盘时，尽量使用普通索引，然后把 change buffer 尽量开大 change buffer 和 redo log1insert into t(id,k) values(id1,k1),(id2,k2); 我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图所示是带 change buffer 的更新状态图。 它涉及了四个部分：内存、redo log（ib_log_fileX）、 数据表空间（t.ibd）、系统表空间（ibdata1）。 这条更新语句做了如下的操作（按照图中的数字顺序）： Page 1 在内存中，直接更新内存； Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息 将上述两个动作记入 redo log 中（图中 3 和 4）。 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。 现在要执行 select * from t where k in (k1, k2)。 如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了 1、 读 Page 1 的时候，直接从内存返回 2、要读 Page 2 的时候，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。 可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。 redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。 10 MySQL为什么有时候会选错索引？选择索引是优化器的工作， 而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。 1、 索引的区分度 ，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。 基数是通过采样统计的方法。 2、 索引统计信息不准确导致的问题，可以用 analyze table 来解决。 可以用来重新统计索引信息 。 索引选择异常和处理1、 采用 force index 强行选择一个索引 2、 可以考虑修改语句，引导 MySQL 使用我们期望的索引 3、 新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引 11 怎么给字符串字段加索引？","path":"2024/06/05/MySQL实战45讲精华/","date":"06-05","excerpt":"","tags":[{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"函数式编程","text":"一. 道之伊始宇宙初开之际，混沌之气笼罩着整个宇宙，一切模糊不清。 然后，盘古开天，女娲造人：日月乃出、星辰乃现，山川蜿蜒、江河奔流、生灵万物，欣欣向荣。此日月、星辰、山川、江河、生灵万物，谓之【对象】，皆随时间而化。 然而：日月之行、星汉灿烂、山川起伏、湖海汇聚，冥冥中有至理藏其中。名曰【道】，乃万物遵循之规律，亦谓之【函数】，它无问东西，亘古不变 作为设计宇宙洪荒的程序员 造日月、筑山川、划江河、开湖海、演化生灵万物、令其生生不息，则必用面向【对象】之手段 若定规则、求本源、追纯粹，论不变，则当选【函数】编程之思想 下面就让我们从【函数】开始。 什么是函数什么是函数呢？函数即规则 数学上： 例如： INPUT f(x) OUTPUT 1 ? 1 2 ? 4 3 ? 9 4 ? 16 5 ? 25 … … … $f(x) = x^2$ 是一种规律， input 按照此规律变化为 output 很多规律已经由人揭示，例如 $e = m \\cdot c^2$ 程序设计中更可以自己去制定规律，一旦成为规则的制定者，你就是神 大道无情无情何为无情： 只要输入相同，无论多少次调用，无论什么时间调用，输出相同。 佛祖成道例如 12345678910111213141516171819202122public class TestMutable &#123; public static void main(String[] args) &#123; System.out.println(pray(&quot;张三&quot;)); System.out.println(pray(&quot;张三&quot;)); System.out.println(pray(&quot;张三&quot;)); &#125; static class Buddha &#123; String name; public Buddha(String name) &#123; this.name = name; &#125; &#125; static Buddha buddha = new Buddha(&quot;佛祖&quot;); static String pray(String person) &#123; return (person + &quot;向[&quot; + buddha.name + &quot;]虔诚祈祷&quot;); &#125;&#125; 以上 pray 的执行结果，除了参数变化外，希望函数的执行规则永远不变 123张三向[佛祖]虔诚祈祷张三向[佛祖]虔诚祈祷张三向[佛祖]虔诚祈祷 然而，由于设计上的缺陷，函数引用了外界可变的数据，如果这么使用 12buddha.name = &quot;魔王&quot;;System.out.println(pray(&quot;张三&quot;)); 结果就会是 1张三向[魔王]虔诚祈祷 问题出在哪儿呢？函数的目的是除了参数能变化，其它部分都要不变，这样才能成为规则的一部分。佛祖要成为规则的一部分，也要保持不变 改正方法 1234567static class Buddha &#123; final String name; public Buddha(String name) &#123; this.name = name; &#125;&#125; 或 1record Buddha(String name) &#123; &#125; 不是说函数不能引用外界的数据，而是它引用的数据必须也能作为规则的一部分 让佛祖不变，佛祖才能成为规则 函数与方法方法本质上也是函数。不过方法绑定在对象之上，它是对象个人法则 函数是 函数（对象数据，其它参数） 而方法是 对象数据.方法（其它参数） 不变的好处只有不变，才能在滚滚时间洪流中屹立不倒，成为规则的一部分。 多线程编程中，不变意味着线程安全 合格的函数无状态大道无形函数化对象函数本无形，也就是它代表的规则：位置固定、不能传播。 若要有形，让函数的规则能够传播，需要将函数化为对象。 12345public class MyClass &#123; static int add(int a, int b) &#123; return a + b; &#125;&#125; 与 12345interface Lambda &#123; int calculate(int a, int b);&#125;Lambda add = (a, b) -&gt; a + b; // 它已经变成了一个 lambda 对象 区别在哪？ 前者是纯粹的一条两数加法规则，它的位置是固定的，要使用它，需要通过 MyClass.add 找到它，然后执行 而后者（add 对象）就像长了腿，它的位置是可以变化的，想去哪里就去哪里，哪里要用到这条加法规则，把它传递过去 接口的目的是为了将来用它来执行函数对象，此接口中只能有一个方法定义 函数化为对象做个比喻 之前是大家要统一去西天取经 现在是每个菩萨、罗汉拿着经书，入世传经 例如 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Test &#123; interface Lambda &#123; int calculate(int a, int b); &#125; static class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket ss = new ServerSocket(8080); System.out.println(&quot;server start...&quot;); while (true) &#123; Socket s = ss.accept(); Thread.ofVirtual().start(() -&gt; &#123; try &#123; ObjectInputStream is = new ObjectInputStream(s.getInputStream()); Lambda lambda = (Lambda) is.readObject(); int a = ThreadLocalRandom.current().nextInt(10); int b = ThreadLocalRandom.current().nextInt(10); System.out.printf(&quot;%s %d op %d = %d%n&quot;, s.getRemoteSocketAddress().toString(), a, b, lambda.calculate(a, b)); &#125; catch (IOException | ClassNotFoundException e) &#123; throw new RuntimeException(e); &#125; &#125;); &#125; &#125; &#125; static class Client1 &#123; public static void main(String[] args) throws IOException &#123; try(Socket s = new Socket(&quot;127.0.0.1&quot;, 8080))&#123; Lambda lambda = (Lambda &amp; Serializable) (a, b) -&gt; a + b; ObjectOutputStream os = new ObjectOutputStream(s.getOutputStream()); os.writeObject(lambda); os.flush(); &#125; &#125; &#125; static class Client2 &#123; public static void main(String[] args) throws IOException &#123; try(Socket s = new Socket(&quot;127.0.0.1&quot;, 8080))&#123; Lambda lambda = (Lambda &amp; Serializable) (a, b) -&gt; a - b; ObjectOutputStream os = new ObjectOutputStream(s.getOutputStream()); os.writeObject(lambda); os.flush(); &#125; &#125; &#125; static class Client3 &#123; public static void main(String[] args) throws IOException &#123; try(Socket s = new Socket(&quot;127.0.0.1&quot;, 8080))&#123; Lambda lambda = (Lambda &amp; Serializable) (a, b) -&gt; a * b; ObjectOutputStream os = new ObjectOutputStream(s.getOutputStream()); os.writeObject(lambda); os.flush(); &#125; &#125; &#125;&#125; 上面的例子做了一些简单的扩展，可以看到不同的客户端可以上传自己的计算规则 P.S. 大部分文献都说 lambda 是匿名函数，但我觉得需要在这个说法上进行补充 至少在 java 里，虽然 lambda 表达式本身不需要起名字，但不得提供一个对应接口嘛 行为参数化已知学生类定义如下 1234567891011121314151617181920212223242526272829303132static class Student &#123; private String name; private int age; private String sex; public Student(String name, int age, String sex) &#123; this.name = name; this.age = age; this.sex = sex; &#125; public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125; public String getSex() &#123; return sex; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &quot;, sex=&#x27;&quot; + sex + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 针对一组学生集合，筛选出男学生，下面的代码实现如何，评价一下 1234567891011121314151617181920public static void main(String[] args) &#123; List&lt;Student&gt; students = List.of( new Student(&quot;张无忌&quot;, 18, &quot;男&quot;), new Student(&quot;杨不悔&quot;, 16, &quot;女&quot;), new Student(&quot;周芷若&quot;, 19, &quot;女&quot;), new Student(&quot;宋青书&quot;, 20, &quot;男&quot;) ); System.out.println(filter(students)); // 能得到 张无忌，宋青书&#125;static List&lt;Student&gt; filter(List&lt;Student&gt; students) &#123; List&lt;Student&gt; result = new ArrayList&lt;&gt;(); for (Student student : students) &#123; if (student.sex.equals(&quot;男&quot;)) &#123; result.add(student); &#125; &#125; return result;&#125; 如果需求再变动一下，要求找到 18 岁以下的学生，上面代码显然不能用了，改动方法如下 1234567891011static List&lt;Student&gt; filter(List&lt;Student&gt; students) &#123; List&lt;Student&gt; result = new ArrayList&lt;&gt;(); for (Student student : students) &#123; if (student.age &lt;= 18) &#123; result.add(student); &#125; &#125; return result;&#125;System.out.println(filter(students)); // 能得到 张无忌，杨不悔 那么需求如果再要变动，找18岁以下男学生，怎么改？显然上述做法并不太好… 更希望一个方法能处理各种情况，仔细观察以上两个方法，找不同。 不同在于筛选条件部分： 1student.sex.equals(&quot;男&quot;) 和 1student.age &lt;= 18 既然它们就是不同，那么能否把它作为参数传递进来，这样处理起来不就一致了吗？ 123456789static List&lt;Student&gt; filter(List&lt;Student&gt; students, ???) &#123; List&lt;Student&gt; result = new ArrayList&lt;&gt;(); for (Student student : students) &#123; if (???) &#123; result.add(student); &#125; &#125; return result;&#125; 它俩要判断的逻辑不同，那这两处不同的逻辑必然要用函数来表示，将来这两个函数都需要用到 student 对象来判断，都应该返回一个 boolean 结果，怎么描述函数的长相呢？ 123interface Lambda &#123; boolean test(Student student);&#125; 方法可以统一成下述代码 123456789static List&lt;Student&gt; filter(List&lt;Student&gt; students, Lambda lambda) &#123; List&lt;Student&gt; result = new ArrayList&lt;&gt;(); for (Student student : students) &#123; if (lambda.test(student)) &#123; result.add(student); &#125; &#125; return result;&#125; 好，最后怎么给它传递不同实现呢？ 1filter(students, student -&gt; student.sex.equals(&quot;男&quot;)); 以及 1filter(students, student -&gt; student.age &lt;= 18); 还有新需求也能满足 1filter(students, student -&gt; student.sex.equals(&quot;男&quot;) &amp;&amp; student.age &lt;= 18); 这样就实现了以不变应万变，而变换即是一个个函数对象，也可以称之为行为参数化 延迟执行在记录日志时，假设日志级别是 INFO，debug 方法会遇到下面的问题： 本不需要记录日志，但 expensive 方法仍被执行了 1234567891011static Logger logger = LogManager.getLogger();public static void main(String[] args) &#123; System.out.println(logger.getLevel()); logger.debug(&quot;&#123;&#125;&quot;, expensive());&#125;static String expensive() &#123; System.out.println(&quot;执行耗时操作&quot;); return &quot;结果&quot;;&#125; 改进方法1： 12if(logger.isDebugEnabled()) logger.debug(&quot;&#123;&#125;&quot;, expensive()); 显然这么做，很多类似代码都要加上这样 if 判断，很不优雅 改进方法2： 在 debug 方法外再套一个新方法，内部逻辑大概是这样： 12345public void debug(final String msg, final Supplier&lt;?&gt; lambda) &#123; if (this.isDebugEnabled()) &#123; this.debug(msg, lambda.get()); &#125;&#125; 调用时这样： 1logger.debug(&quot;&#123;&#125;&quot;, () -&gt; expensive()); expensive() 变成了不是立刻执行，在未来 if 条件成立时才执行 函数对象的不同类型12345Comparator&lt;Student&gt; c = (Student s1, Student s2) -&gt; Integer.compare(s1.age, s2.age); BiFunction&lt;Student, Student, Integer&gt; f = (Student s1, Student s2) -&gt; Integer.compare(s1.age, s2.age); 二. 函数编程语法表现形式在 Java 语言中，lambda 对象有两种形式：lambda 表达式与方法引用 lambda 对象的类型是由它的行为决定的，如果有一些 lambda 对象，它们的入参类型、返回值类型都一致，那么它们可以看作是同一类的 lambda 对象，它们的类型，用函数式接口来表示 函数类型练习：将 lambda 对象分类，见 PPT 函数接口的命名规律 带有 Unary 是一元的意思，表示一个参数 带有 Bi 或 Binary 是二元的意思，表示两个参数 Ternary 三元 Quatenary 四元 … 方法引用也是类似，入参类型、返回值类型都一致的话，可以看作同一类的对象，也是用函数式接口表示 六种方法引用1）类名::静态方法名如何理解： 函数对象的逻辑部分是：调用此静态方法 因此这个静态方法需要什么参数，函数对象也提供相应的参数即可 123456789101112131415161718192021public class Type2Test &#123; public static void main(String[] args) &#123; /* 需求：挑选出所有男性学生 */ Stream.of( new Student(&quot;张无忌&quot;, &quot;男&quot;), new Student(&quot;周芷若&quot;, &quot;女&quot;), new Student(&quot;宋青书&quot;, &quot;男&quot;) ) .filter(Type2Test::isMale) .forEach(student -&gt; System.out.println(student)); &#125; static boolean isMale(Student student) &#123; return student.sex.equals(&quot;男&quot;); &#125; record Student(String name, String sex) &#123; &#125;&#125; filter 这个高阶函数接收的函数类型（Predicate）是：一个 T 类型的入参，一个 boolean 的返回值 因此我们只需要给它提供一个相符合的 lambda 对象即可 isMale 这个静态方法有入参 Student 对应 T，有返回值 boolean 也能对应上，所以可以直接使用 输出 12Student[name=张无忌, sex=男]Student[name=宋青书, sex=男] 2）类名::非静态方法名如何理解： 函数对象的逻辑部分是：调用此非静态方法 因此这个函数对象需要提供一个额外的对象参数，以便能够调用此非静态方法 非静态方法的剩余参数，与函数对象的剩余参数一一对应 例1： 12345678910111213141516171819202122232425public class Type3Test &#123; public static void main(String[] args) &#123; highOrder(Student::hello); &#125; static void highOrder(Type3 lambda) &#123; System.out.println(lambda.transfer(new Student(&quot;张三&quot;), &quot;你好&quot;)); &#125; interface Type3 &#123; String transfer(Student stu, String message); &#125; static class Student &#123; String name; public Student(String name) &#123; this.name = name; &#125; public String hello(String message) &#123; return this.name + &quot; say: &quot; + message; &#125; &#125;&#125; 上例中函数类型的 参数1 对应着 hello 方法所属类型 Student 参数2 对应着 hello 方法自己的参数 String 返回值对应着 hello 方法自己的返回值 String 输出 1张三 say: 你好 例2：改写之前根据性别过滤的需求 1234567891011121314151617181920public class Type2Test &#123; public static void main(String[] args) &#123; /* 需求：挑选出所有男性学生 */ Stream.of( new Student(&quot;张无忌&quot;, &quot;男&quot;), new Student(&quot;周芷若&quot;, &quot;女&quot;), new Student(&quot;宋青书&quot;, &quot;男&quot;) ) .filter(Student::isMale) .forEach(student -&gt; System.out.println(student)); &#125; record Student(String name, String sex) &#123; boolean isMale() &#123; return this.sex.equals(&quot;男&quot;); &#125; &#125;&#125; filter 这个高阶函数接收的函数类型（Predicate）是：一个 T 类型的入参，一个 boolean 的返回值 因此我们只需要给它提供一个相符合的 lambda 对象即可 它的入参1 T 对应着 isMale 非静态方法的所属类型 Student 它没有其它参数，isMale 方法也没有参数 返回值都是 boolean 输出 12Student[name=张无忌, sex=男]Student[name=宋青书, sex=男] 例3：将学生对象仅保留学生的姓名 1234567891011121314151617public class Type2Test &#123; public static void main(String[] args) &#123; Stream.of( new Student(&quot;张无忌&quot;, &quot;男&quot;), new Student(&quot;周芷若&quot;, &quot;女&quot;), new Student(&quot;宋青书&quot;, &quot;男&quot;) ) .map(Student::name) .forEach(student -&gt; System.out.println(student)); &#125; record Student(String name, String sex) &#123; boolean isMale() &#123; return this.sex.equals(&quot;男&quot;); &#125; &#125;&#125; map 这个高阶函数接收的函数类型是（Function）是：一个 T 类型的参数，一个 R 类型的返回值 它的入参1 T 对应着 name 非静态方法的所属类型 Student 它没有剩余参数，name 方法也没有参数 它的返回值 R 对应着 name 方法的返回值 String 输出 123张无忌周芷若宋青书 3）对象::非静态方法名如何理解： 函数对象的逻辑部分是：调用此非静态方法 因为对象已提供，所以不必作为函数对象参数的一部分 非静态方法的剩余参数，与函数对象的剩余参数一一对应 12345678910111213141516171819202122232425262728public class Type4Test &#123; public static void main(String[] args) &#123; Util util = new Util(); // 对象 Stream.of( new Student(&quot;张无忌&quot;, &quot;男&quot;), new Student(&quot;周芷若&quot;, &quot;女&quot;), new Student(&quot;宋青书&quot;, &quot;男&quot;) ) .filter(util::isMale) .map(util::getName) .forEach(student -&gt; System.out.println(student)); &#125; record Student(String name, String sex) &#123; boolean isMale() &#123; return this.sex.equals(&quot;男&quot;); &#125; &#125; static class Util &#123; boolean isMale(Student student) &#123; return student.sex.equals(&quot;男&quot;); &#125; String getName(Student student) &#123; return student.name(); &#125; &#125;&#125; 其实较为典型的一个应用就是 System.out 对象中的非静态方法，最后的输出可以修改为 1.forEach(System.out::println); 这是因为 forEach 这个高阶函数接收的函数类型（Consumer）是一个 T 类型参数，void 无返回值 而 System.out 对象中有非静态方法 void println(Object x) 与之一致，因此可以将此方法化为 lambda 对象给 forEach 使用 4）类名::new对于构造方法，也有专门的语法把它们转换为 lambda 对象 函数类型应满足 参数部分与构造方法参数一致 返回值类型与构造方法所在类一致 例如： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Type5Test &#123; static class Student &#123; private final String name; private final int age; public Student() &#123; this.name = &quot;某人&quot;; this.age = 18; &#125; public Student(String name) &#123; this.name = name; this.age = 18; &#125; public Student(String name, int age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return &quot;Student&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &#x27;&#125;&#x27;; &#125; &#125; interface Type51 &#123; Student create(); &#125; interface Type52 &#123; Student create(String name); &#125; interface Type53 &#123; Student create(String name, int age); &#125; public static void main(String[] args) &#123; hiOrder((Type51) Student::new); hiOrder((Type52) Student::new); hiOrder((Type53) Student::new); &#125; static void hiOrder(Type51 creator) &#123; System.out.println(creator.create()); &#125; static void hiOrder(Type52 creator) &#123; System.out.println(creator.create(&quot;张三&quot;)); &#125; static void hiOrder(Type53 creator) &#123; System.out.println(creator.create(&quot;李四&quot;, 20)); &#125;&#125; 5）this::非静态方法名算是形式2的特例，只能用在类内部 123456789101112131415161718192021222324252627282930public class Type6Test &#123; public static void main(String[] args) &#123; Util util = new UtilExt(); util.hiOrder(Stream.of( new Student(&quot;张无忌&quot;, &quot;男&quot;), new Student(&quot;周芷若&quot;, &quot;女&quot;), new Student(&quot;宋青书&quot;, &quot;男&quot;) )); &#125; record Student(String name, String sex) &#123; &#125; static class Util &#123; boolean isMale(Student student) &#123; return student.sex.equals(&quot;男&quot;); &#125; boolean isFemale(Student student) &#123; return student.sex.equals(&quot;女&quot;); &#125; void hiOrder(Stream&lt;Student&gt; stream) &#123; stream .filter(this::isMale) .forEach(System.out::println); &#125; &#125;&#125; 6）super::非静态方法名算是形式2的特例，只能用在类内部（用在要用 super 区分重载方法时） 123456789101112public class Type6Test &#123; //... static class UtilExt extends Util &#123; void hiOrder(Stream&lt;Student&gt; stream) &#123; stream .filter(super::isFemale) .forEach(System.out::println); &#125; &#125;&#125; 7）特例函数接口和方法引用之间，可以差一个返回值，例如 123456789101112131415public class ExceptionTest &#123; public static void main(String[] args) &#123; Runnable task1 = ExceptionTest::print1; Runnable task2 = ExceptionTest::print2; &#125; static void print1() &#123; System.out.println(&quot;task1 running...&quot;); &#125; static int print2() &#123; System.out.println(&quot;task2 running...&quot;); return 1; &#125;&#125; 可以看到 Runnable 接口不需要返回值，而实际的函数对象多出的返回值也不影响使用 闭包（Closure）何为闭包，闭包就是函数对象与外界变量绑定在一起，形成的整体。例如 123456789101112131415public class ClosureTest1 &#123; interface Lambda &#123; int add(int y); &#125; public static void main(String[] args) &#123; int x = 10; highOrder(y -&gt; x + y); &#125; static void highOrder(Lambda lambda) &#123; System.out.println(lambda.add(20)); &#125;&#125; 代码中的 $y \\rightarrow x + y$ 和 $x = 10$，就形成了一个闭包 可以想象成，函数对象有个背包，背包里可以装变量随身携带，将来函数对象甭管传递到多远的地方，包里总装着个 $x = 10$ 有个限制，局部变量 x 必须是 final 或 effective final 的，effective final 意思就是，虽然没有用 final 修饰，但就像是用 final 修饰了一样，不能重新赋值，否则就语法错误。 意味着闭包变量，在装进包里的那一刻，就不能变化了 道理也简单，为了保证函数的不变性，防止破坏成道 闭包是一种给函数执行提供数据的手段，函数执行既可以使用函数入参，还可以使用闭包变量 例 1234567891011121314151617181920public class ClosureTest2 &#123; // 闭包作用：给函数对象提供参数以外的数据 public static void main(String[] args) throws IOException &#123; // 创建 10 个任务对象，并且每个任务对象给一个任务编号 List&lt;Runnable&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; int k = i + 1; Runnable task = () -&gt; System.out.println(Thread.currentThread()+&quot;:执行任务&quot; + k); list.add(task); &#125; ExecutorService service = Executors.newVirtualThreadPerTaskExecutor(); for (Runnable task : list) &#123; service.submit(task); &#125; System.in.read(); &#125;&#125; 柯里化（Carrying）柯里化的作用是让函数对象分步执行（本质上是利用多个函数对象和闭包） 例如： 12345678910111213141516171819public class Carrying1Test &#123; public static void main(String[] args) &#123; highOrder(a -&gt; b -&gt; a + b); &#125; static void highOrder(Step1 step1) &#123; Step2 step2 = step1.exec(10); System.out.println(step2.exec(20)); System.out.println(step2.exec(50)); &#125; interface Step1 &#123; Step2 exec(int a); &#125; interface Step2 &#123; int exec(int b); &#125;&#125; 代码中 $a \\rightarrow …$ 是第一个函数对象，它的返回结果 $b \\rightarrow …$ 是第二个函数对象 后者与前面的参数 a 构成了闭包 step1.exec(10) 确定了 a 的值是 10，返回第二个函数对象 step2，a 被放入了 step2 对象的背包记下来了 step2.exec(20) 确定了 b 的值是 20，此时可以执行 a + b 的操作，得到结果 30 step2.exec(50) 分析过程类似 高阶函数（Higher-Order Functions）1) 内循环不想写集合便利代码 不知道那种遍历效率高 对集合的元素只读 2) 遍历二叉树3) 简单流1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.castile.functional.hiorder;import java.util.ArrayList;import java.util.Arrays;import java.util.Collection;import java.util.List;import java.util.function.Consumer;import java.util.function.Function;import java.util.function.Predicate;/** * @description: * @author: Castile * @create: 2024-04-17 20:15 * @Version 1.0 **/public class SimpleStream&lt;T&gt; &#123; private Collection&lt;T&gt; collection; public static void main(String[] args) &#123; List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8); SimpleStream.of(list) .filter(x -&gt; (x &amp; 1) == 1) .map(x -&gt; x * x) .forEach(System.out::println); &#125; public void forEach(Consumer&lt;T&gt; consumer) &#123; for (T t : collection) &#123; consumer.accept(t); &#125; &#125; public SimpleStream&lt;T&gt; filter(Predicate&lt;T&gt; predicate) &#123; ArrayList&lt;T&gt; list = new ArrayList&lt;&gt;(); for (T t : collection) &#123; if (predicate.test(t)) &#123; list.add(t); &#125; &#125; return new SimpleStream&lt;&gt;(list); &#125; public &lt;U&gt; SimpleStream&lt;U&gt; map(Function&lt;T, U&gt; function) &#123; ArrayList&lt;U&gt; list = new ArrayList&lt;&gt;(); for (T t : collection) &#123; list.add(function.apply(t)); &#125; return new SimpleStream&lt;&gt;(list); &#125; public static &lt;T&gt; SimpleStream&lt;T&gt; of(Collection&lt;T&gt; collection) &#123; return new SimpleStream&lt;&gt;(collection); &#125; private SimpleStream(Collection&lt;T&gt; collection) &#123; this.collection = collection; &#125;&#125; 4) 简单流-化简1234567public T reduce(T init, BinaryOperator&lt;T&gt; operator) &#123; T p = init; for (T t : collection) &#123; p = operator.apply(p, t); &#125; return p; &#125; 5) 简单流-收集综合练习✅❌ 1）判断语法正确性1234567interface Lambda1 &#123; int op(int a, int b);&#125;interface Lambda2 &#123; void op(Object obj);&#125; Lambda1 lambda = a, b -&gt; a - b ❌ Lambda1 lambda = (c, d) -&gt; c * d ✅ Lambda1 lambda = (int a, b) -&gt; a + b ❌ Lambda2 lambda = Object a -&gt; System.out.println(a) ❌ 2）写出等价的 lambda 表达式12345678910111213141516171819202122232425262728static class Student &#123; private String name; public Student(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Student student = (Student) o; return Objects.equals(name, student.name); &#125; @Override public int hashCode() &#123; return Objects.hash(name); &#125;&#125; Math::random ()-&gt;Math.random() Math::sqrt (double number)-&gt;Math.sqrt(number) Student::getName (Student stu)-&gt;stu.getName() Student::setName (Student stu, String newName) -&gt; stu.setName(newName) Student::hashCode (Student stu) -&gt; stu.hashCode() Student::equals (Student stu, Object o) -&gt; stu.equals(o) 假设已有对象 Student stu = new Student(&quot;张三&quot;); stu::getName ()-&gt;stu.getName() stu::setName (String newName)-&gt;stu.setName(newName) Student::new (String name)-&gt;new Student(name) 3）使用函数接口解决问题把下列方法中，可能存在变化的部分，抽象为函数对象，从外界传递进来 12345678910static List&lt;Integer&gt; filter(List&lt;Integer&gt; list) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (Integer number : list) &#123; // 筛选：判断是否是偶数，但以后可能改变判断规则 if((number &amp; 1) == 0) &#123; result.add(number); &#125; &#125; return result;&#125; 12345678static List&lt;String&gt; map(List&lt;Integer&gt; list) &#123; List&lt;String&gt; result = new ArrayList&lt;&gt;(); for (Integer number : list) &#123; // 转换：将数字转为字符串，但以后可能改变转换规则 result.add(String.valueOf(number)); &#125; return result;&#125; 123456static void consume(List&lt;Integer&gt; list) &#123; for (Integer number : list) &#123; // 消费：打印，但以后可能改变消费规则 System.out.println(number); &#125;&#125; 12345678static List&lt;Integer&gt; supply(int count) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; count; i++) &#123; // 生成：随机数，但以后可能改变生成规则 result.add(ThreadLocalRandom.current().nextInt()); &#125; return result;&#125; 4）写出等价的方法引用1Function&lt;String, Integer&gt; lambda = (String s) -&gt; Integer.parseInt(s); 1BiPredicate&lt;List&lt;String&gt;, String&gt; lambda = (list, element) -&gt; list.contains(element); 1BiPredicate&lt;Student, Object&gt; lambda = (stu, obj) -&gt; stu.equals(obj); 1Predicate&lt;File&gt; lambda = (file) -&gt; file.exists(); 123Runtime runtime = Runtime.getRuntime();Supplier&lt;Long&gt; lambda = () -&gt; runtime.freeMemory(); 5）补充代码1record Color(Integer red, Integer green, Integer blue) &#123; &#125; 如果想用 Color::new 来构造 Color 对象，还应当补充哪些代码 6）实现需求1234567891011121314record Student(String name, int age) &#123; &#125;static void highOrder(Predicate&lt;Student&gt; predicate) &#123; List&lt;Student&gt; list = List.of( new Student(&quot;张三&quot;, 18), new Student(&quot;张三&quot;, 17), new Student(&quot;张三&quot;, 20) ); for (Student stu : list) &#123; if (predicate.test(stu)) &#123; System.out.println(&quot;通过测试&quot;); &#125; &#125;&#125; 传入参数时，分别用 类名::静态方法名 类名::非静态方法名 来表示【学生年龄大于等于18】的条件 三. Stream API过滤12345678910record Fruit(String cname, String name, String category, String color) &#123; &#125;Stream.of( new Fruit(&quot;草莓&quot;, &quot;Strawberry&quot;, &quot;浆果&quot;, &quot;红色&quot;), new Fruit(&quot;桑葚&quot;, &quot;Mulberry&quot;, &quot;浆果&quot;, &quot;紫色&quot;), new Fruit(&quot;杨梅&quot;, &quot;Waxberry&quot;, &quot;浆果&quot;, &quot;红色&quot;), new Fruit(&quot;核桃&quot;, &quot;Walnut&quot;, &quot;坚果&quot;, &quot;棕色&quot;), new Fruit(&quot;草莓&quot;, &quot;Peanut&quot;, &quot;坚果&quot;, &quot;棕色&quot;), new Fruit(&quot;蓝莓&quot;, &quot;Blueberry&quot;, &quot;浆果&quot;, &quot;蓝色&quot;)) 找到所有浆果 1.filter(f -&gt; f.category.equals(&quot;浆果&quot;)) 找到蓝色的浆果 方法1： 1.filter(f -&gt; f.category().equals(&quot;浆果&quot;) &amp;&amp; f.color().equals(&quot;蓝色&quot;)) 方法2：让每个 lambda 只做一件事，两次 filter 相对于并且关系 12.filter(f -&gt; f.category.equals(&quot;浆果&quot;)).filter(f -&gt; f.color().equals(&quot;蓝色&quot;)) 方法3：让每个 lambda 只做一件事，不过比方法2强的地方可以 or，and，nagate 运算 1.filter(((Predicate&lt;Fruit&gt;) f -&gt; f.category.equals(&quot;浆果&quot;)).and(f -&gt; f.color().equals(&quot;蓝色&quot;))) 映射 1.map(f -&gt; f.cname() + &quot;酱&quot;) 降维例1 1234567891011121314Stream.of( List.of( new Fruit(&quot;草莓&quot;, &quot;Strawberry&quot;, &quot;浆果&quot;, &quot;红色&quot;), new Fruit(&quot;桑葚&quot;, &quot;Mulberry&quot;, &quot;浆果&quot;, &quot;紫色&quot;), new Fruit(&quot;杨梅&quot;, &quot;Waxberry&quot;, &quot;浆果&quot;, &quot;红色&quot;), new Fruit(&quot;蓝莓&quot;, &quot;Blueberry&quot;, &quot;浆果&quot;, &quot;蓝色&quot;) ), List.of( new Fruit(&quot;核桃&quot;, &quot;Walnut&quot;, &quot;坚果&quot;, &quot;棕色&quot;), new Fruit(&quot;草莓&quot;, &quot;Peanut&quot;, &quot;坚果&quot;, &quot;棕色&quot;) )) .flatMap(Collection::stream) 这样把坚果和浆果两个集合变成了含六个元素的水果流 例2： 123456789101112Stream.of( new Order(1, List.of( new Item(6499, 1, &quot;HUAWEI MateBook 14s&quot;), new Item(6999, 1, &quot;HUAWEI Mate 60 Pro&quot;), new Item(1488, 1, &quot;HUAWEI WATCH GT 4&quot;) )), new Order(1, List.of( new Item(8999, 1, &quot;Apple MacBook Air 13&quot;), new Item(7999, 1, &quot;Apple iPhone 15 Pro&quot;), new Item(2999, 1, &quot;Apple Watch Series 9&quot;) ))) 想逐一处理每个订单中的商品 1.flatMap(order -&gt; order.items().stream()) 这样把一个有两个元素的订单流，变成了一个有六个元素的商品流 构建根据已有的数组构建流 1Arrays.stream(array) 根据已有的 Collection 构建流（包括 List，Set 等） 1List.of(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;).stream() 把一个对象变成流 1Stream.of(&quot;d&quot;) 把多个对象变成流 1Stream.of(&quot;x&quot;, &quot;y&quot;) 拼接两个流拼接 1Stream.concat(Stream.of(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;), Stream.of(&quot;d&quot;)) 截取123Stream.concat(Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), Stream.of(&quot;d&quot;)) .skip(1) .limit(2) skip 是跳过几个元素 limit 是限制处理的元素个数 dropWhile 是 drop 流中元素，直到条件不成立，留下剩余元素 takeWhile 是 take 流中元素，直到条件不成立，舍弃剩余元素 生成生成从 0 ~ 9 的数字 1IntStream.range(0, 10) 或者 1IntStream.rangeClosed(0, 9) 如果想订制，可以用 iterate 方法，例如下面生成奇数序列 1IntStream.iterate(1, x -&gt; x + 2) 参数1 是初始值 参数2 是一个特殊 Function，即参数类型与返回值相同，它会根据上一个元素 x 的值计算出当前元素 需要用 limit 限制元素个数 也可以用 iterate 的重载方法 1IntStream.iterate(1, x -&gt; x &lt; 10, x -&gt; x + 2) 参数1 是初始值 参数2 用来限制元素个数，一旦不满足此条件，流就结束 参数3 相当于上个方法的参数2 iterate 的特点是根据上一个元素计算当前元素，如果不需要依赖上一个元素，可以改用 generate 方法 例如下面是生成 5 个随机 int 1Stream.generate(()-&gt; ThreadLocalRandom.current().nextInt()).limit(5) 不过如果只是生成随机数的话，有更简单的办法 1ThreadLocalRandom.current().ints(5) 如果要指定上下限，例如下面是生成从 0~9 的100个随机数 1ThreadLocalRandom.current().ints(100, 0, 10) 查找与判断下面的代码找到流中任意（Any）一个偶数 123456int[] array = &#123;1, 3, 5, 4, 7, 6, 9&#125;;Arrays.stream(array) .filter(x -&gt; (x &amp; 1) == 0) .findAny() .ifPresent(System.out::println); 注意 findAny 返回的是 OptionalInt 对象，因为可能流中不存在偶数 对于 OptionalInt 对象，一般需要用 ifPresent 或 orElse（提供默认值）来处理 与 findAny 比较类似的是 firstFirst，它俩的区别 findAny 是找在流中任意位置的元素，不需要考虑顺序，对于上例返回 6 也是可以的 findFirst 是找第一个出现在元素，需要考虑顺序，对于上例只能返回 4 findAny 在顺序流中与 findFirst 表现相同，区别在于并行流下会更快 判断流中是否存在任意一个偶数 1Arrays.stream(array).anyMatch(x -&gt; (x &amp; 1) == 0) 它返回的是 boolean 值，可以直接用来判断 判断流是否全部是偶数 1Arrays.stream(array).allMatch(x -&gt; (x &amp; 1) == 0) 同样，它返回的是 boolean 值，可以直接用来判断 判断流是否全部不是偶数 1Arrays.stream(array).noneMatch(x -&gt; (x &amp; 1) == 0) noneMatch 与 allMatch 含义恰好相反 排序与去重已知有数据 12345678910111213record Hero(String name, int strength) &#123; &#125;Stream.of( new Hero(&quot;独孤求败&quot;, 100), new Hero(&quot;令狐冲&quot;, 90), new Hero(&quot;风清扬&quot;, 98), new Hero(&quot;东方不败&quot;, 98), new Hero(&quot;方证&quot;, 92), new Hero(&quot;任我行&quot;, 92), new Hero(&quot;冲虚&quot;, 90), new Hero(&quot;向问天&quot;, 88), new Hero(&quot;不戒&quot;, 88)) 要求，首先按 strength 武力排序（逆序），武力相同的，按姓名长度排序（正序） 仅用 lambda 来解 1234.sorted((a,b)-&gt; &#123; int res = Integer.compare(b.strength(), a.strength()); return (res == 0) ? Integer.compare(a.nameLength(), b.nameLength()) : res; &#125;) 方法引用改写 12345.sorted( Comparator.comparingInt(Hero::strength) .reversed() .thenComparingInt(Hero::nameLength)) 其中： comparingInt 接收一个 key 提取器（说明按对象中哪部分来比较），返回一个比较器 reversed 返回一个顺序相反的比较器 thenComparingInt 接收一个 key 提取器，返回一个新比较器，新比较器在原有比较器结果相等时执行新的比较逻辑 增加一个辅助方法 12345record Hero(String name, int strength) &#123; int nameLength() &#123; return this.name.length(); &#125;&#125; 原理： 12345678.sorted((e, f) -&gt; &#123; int res = ((Comparator&lt;Hero&gt;) (c, d) -&gt; ((Comparator&lt;Hero&gt;) (a, b) -&gt; Integer.compare(a.strength(), b.strength())) .compare(d, c)) .compare(e, f); return (res == 0) ? Integer.compare(e.nameLength(), f.nameLength()) : res;&#125;) 如果不好看，改成下面的代码 12345678910111213141516.sorted(step3(step2(step1())))static Comparator&lt;Hero&gt; step1() &#123; return (a, b) -&gt; Integer.compare(a.strength(), b.strength());&#125;static Comparator&lt;Hero&gt; step2(Comparator&lt;Hero&gt; step1) &#123; return (c, d) -&gt; step1.compare(d, c);&#125;static Comparator&lt;Hero&gt; step3(Comparator&lt;Hero&gt; step2) &#123; return (e, f) -&gt; &#123; int res = step2.compare(e, f); return (res == 0) ? Integer.compare(e.nameLength(), f.nameLength()) : res; &#125;;&#125; 化简reduce(init, (p,x) -&gt; r) init 代表初始值 (p,x) -&gt; r 是一个 BinaryOperator，作用是根据上次化简结果 p 和当前元素 x，得到本次化简结果 r 这样两两化简，可以将流中的所有元素合并成一个结果 收集collect( supplier, accumulator, combiner) supplier 是描述如何创建收集容器 c ：()-&gt; c accumulator 是描述如何向容器 c 添加元素 x：(c, x) -&gt; void combiner 是描述如何合并两个容器：(c1, c2) -&gt; void 串行流下不需要合并容器 并行流如果用的是并发容器，也不需要合并 收集器Collectors 类中提供了很多现成的收集器，详情见网页 下游收集器做 groupingBy 分组收集时，组内可能需要进一步的数据收集，称为下游收集器，详情见网页 基本流基本类型流指 IntStream、LongStream 和 DoubleStream，它们在做数值计算时有更好的性能。 转换成基本流 mapToInt mapToLong mapToDouble flatMapToInt flatMapToLong flatMapToDouble mapMultiToInt mapMultiToLong mapMultiToDouble 基本流转对象流 mapToObj boxed 特性 一次使用：流只能使用一次（终结方法只能调用一次） 两类操作： 中间操作，lazy 懒惰的 终结操作，eager 迫切的 并行123456789101112131415161718192021Stream.of(1, 2, 3, 4) .parallel() .collect(Collector.of( () -&gt; &#123; System.out.printf(&quot;%-12s %s%n&quot;,simple(),&quot;create&quot;); return new ArrayList&lt;Integer&gt;(); &#125;, (list, x) -&gt; &#123; List&lt;Integer&gt; old = new ArrayList&lt;&gt;(list); list.add(x); System.out.printf(&quot;%-12s %s.add(%d)=&gt;%s%n&quot;,simple(), old, x, list); &#125;, (list1, list2) -&gt; &#123; List&lt;Integer&gt; old = new ArrayList&lt;&gt;(list1); list1.addAll(list2); System.out.printf(&quot;%-12s %s.add(%s)=&gt;%s%n&quot;, simple(),old, list2, list1); return list1; &#125;, list -&gt; list, Collector.Characteristics.IDENTITY_FINISH )); 效率1) 数组求和其中 primitive 用 loop 循环对 int 求和 intStream 用 IntStream 对 int 求和 boxed 用 loop 循环对 Integer 求和 stream 用 Stream 对 Integer 求和 元素个数 100 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T01Sum.primitive avgt 5 25.424 ± 0.782 ns/op T01Sum.intStream avgt 5 47.482 ± 1.145 ns/op T01Sum.boxed avgt 5 72.457 ± 4.136 ns/op T01Sum.stream avgt 5 465.141 ± 4.891 ns/op 元素个数 1000 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T01Sum.primitive avgt 5 270.556 ± 1.277 ns/op T01Sum.intStream avgt 5 292.467 ± 10.987 ns/op T01Sum.boxed avgt 5 583.929 ± 57.338 ns/op T01Sum.stream avgt 5 5948.294 ± 2209.211 ns/op 元素个数 10000 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T01Sum.primitive avgt 5 2681.651 ± 12.614 ns/op T01Sum.intStream avgt 5 2718.408 ± 52.418 ns/op T01Sum.boxed avgt 5 6391.285 ± 358.154 ns/op T01Sum.stream avgt 5 44414.884 ± 3213.055 ns/op 结论： 做数值计算，优先挑选基本流（IntStream 等）在数据量较大时，它的性能已经非常接近普通 for 循环 做数值计算，应当避免普通流（Stream）性能与其它几种相比，慢一个数量级 2) 求最大值其中（原始数据都是 int，没有包装类） custom 自定义多线程并行求最大值 parallel 并行流求最大值 sequence 串行流求最大值 primitive loop 循环求最大值 元素个数 100 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T02Parallel.custom avgt 5 39619.796 ± 1263.036 ns/op T02Parallel.parallel avgt 5 6754.239 ± 79.894 ns/op T02Parallel.primitive avgt 5 29.538 ± 3.056 ns/op T02Parallel.sequence avgt 5 80.170 ± 1.940 ns/op 元素个数 10000 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T02Parallel.custom avgt 5 41656.093 ± 1537.237 ns/op T02Parallel.parallel avgt 5 11218.573 ± 1994.863 ns/op T02Parallel.primitive avgt 5 2217.562 ± 80.981 ns/op T02Parallel.sequence avgt 5 5682.482 ± 264.645 ns/op 元素个数 1000000 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units T02Parallel.custom avgt 5 194984.564 ± 25794.484 ns/op T02Parallel.parallel avgt 5 298940.794 ± 31944.959 ns/op T02Parallel.primitive avgt 5 325178.873 ± 81314.981 ns/op T02Parallel.sequence avgt 5 618274.062 ± 5867.812 ns/op 结论： 并行流相对自己用多线程实现分而治之更简洁 并行流只有在数据量非常大时，才能充分发力，数据量少，还不如用串行流 3) 并行(发)收集元素个数 100 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units loop1 avgt 5 1312.389 ± 90.683 ns/op loop2 avgt 5 1776.391 ± 255.271 ns/op sequence avgt 5 1727.739 ± 28.821 ns/op parallelNoConcurrent avgt 5 27654.004 ± 496.970 ns/op parallelConcurrent avgt 5 16320.113 ± 344.766 ns/op 元素个数 10000 Benchmark Mode Cnt Score (ns/op) Error (ns/op) Units loop1 avgt 5 211526.546 ± 13549.703 ns/op loop2 avgt 5 203794.146 ± 3525.972 ns/op sequence avgt 5 237688.651 ± 7593.483 ns/op parallelNoConcurrent avgt 5 527203.976 ± 3496.107 ns/op parallelConcurrent avgt 5 369630.728 ± 20549.731 ns/op 元素个数 1000000 Benchmark Mode Cnt Score (ms/op) Error (ms/op) Units loop1 avgt 5 69.154 ± 3.456 ms/op loop2 avgt 5 83.815 ± 2.307 ms/op sequence avgt 5 103.585 ± 0.834 ns/op parallelNoConcurrent avgt 5 167.032 ± 15.406 ms/op parallelConcurrent avgt 5 52.326 ± 1.501 ms/op 结论： sequence 是一个容器单线程收集，数据量少时性能占优 parallelNoConcurrent 是多个容器多线程并行收集，时间应该花费在合并容器上，性能最差 parallelConcurrent 是一个容器多线程并发收集，在数据量大时性能较优 4）MethodHandle 性能正常方法调用、反射、MethodHandle、Lambda 的性能对比 Benchmark Mode Cnt Score Error Units Sample2.lambda thrpt 5 389307532.881 ± 332213073.039 ops/s Sample2.method thrpt 5 157556577.611 ± 4048306.620 ops/s Sample2.origin thrpt 5 413287866.949 ± 65182730.966 ops/s Sample2.reflection thrpt 5 91640751.456 ± 37969233.369 ops/s 综合练习 将 filter 的课堂例题修改为方法引用方式实现 takeWhile 与 filter 的区别 三级排序 包含 null 值的排序 二维流扁平映射 三维流扁平映射 用 stream 打印九九乘法表 用 stream 生成斐波那契数列的前 10 项 123Stream.iterate(new int[]&#123;1, 1&#125;, x -&gt; new int[]&#123;x[1], x[0] + x[1]&#125;) .map(x -&gt; x[0]) .limit(10) 自定义 Collector 求平均 四. 实际应用数据统计分析1）每月的销售量结果应为 1234567891011121970-01 订单数13072020-01 订单数142702020-02 订单数179952020-03 订单数186882020-04 订单数118682020-05 订单数403342020-06 订单数413642020-07 订单数764182020-08 订单数1000072020-09 订单数704842020-10 订单数1040632020-11 订单数66060 其中 1970-01 应该是数据的问题 1234567lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; YearMonth.from(formatter.parse(a[TIME])), TreeMap::new, counting())) .forEach((k, v) -&gt; &#123; System.out.println(k + &quot; 订单数 &quot; + v); &#125;); 2）销量最高的月份结果应为 1234567891011121970-01 订单数13072020-01 订单数142702020-02 订单数179952020-03 订单数186882020-04 订单数118682020-05 订单数403342020-06 订单数413642020-07 订单数764182020-08 订单数1000072020-09 订单数704842020-10 订单数104063 *2020-11 订单数66060 12345678lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; YearMonth.from(formatter.parse(a[TIME])), counting())) .entrySet() .stream() .max(Comparator.comparingLong(Map.Entry::getValue)) // 也可以用 Map.Entry.comparingByValue() .orElse(null); 3）求销量最高的商品结果应为 11515966223517846928=2746 1234567lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; a[PRODUCT_ID], counting())) .entrySet() .stream() .max(Comparator.comparingLong(Map.Entry::getValue)) .orElse(null); 4）下单最多的前10用户结果应为 123456789101.515915625512423e+18 订单数10921.5159156255121183e+18 订单数10731.515915625512378e+18 订单数10401.515915625512377e+18 订单数10281.5159156255136955e+18 订单数10021.515915625512422e+18 订单数9571.515915625513446e+18 订单数9571.515915625513447e+18 订单数9281.515915625514598e+18 订单数8851.5159156255147195e+18 订单数869 123456789lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; a[USER_ID], counting())) .entrySet() .stream() .sorted(Map.Entry.&lt;String, Long&gt;comparingByValue().reversed()) .limit(10).forEach(e -&gt; &#123; System.out.println(e.getKey() + &quot; 订单数 &quot; + e.getValue()); &#125;); 或者 123456789101112131415161718192021222324252627282930static class MyQueue&lt;E&gt; extends PriorityQueue&lt;E&gt; &#123; private int max; public MyQueue(Comparator&lt;? super E&gt; comparator, int max) &#123; super(comparator); this.max = max; &#125; @Override public boolean offer(E e) &#123; boolean r = super.offer(e); if (this.size() &gt; max) &#123; this.poll(); &#125; return r; &#125;&#125;lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; a[USER_ID], counting())) .entrySet() .stream() .parallel() .collect( () -&gt; new MyQueue&lt;&gt;(Map.Entry.comparingByValue(), 10), MyQueue::offer, AbstractQueue::addAll ); 5.1）每个地区下单最多的用户结果应为： 1234567891011上海=Optional[1.5159156255127636e+18=634]广东=Optional[1.515915625512377e+18=1028]天津=Optional[1.5159156255120858e+18=530]四川=Optional[1.5159156255121551e+18=572]浙江=Optional[1.5159156255121183e+18=564]重庆=Optional[1.515915625512764e+18=632]湖北=Optional[1.5159156255121183e+18=509]湖南=Optional[1.5159156255120548e+18=545]江苏=Optional[1.5159156255122386e+18=551]海南=Optional[1.5159156255121178e+18=556]北京=Optional[1.5159156255128172e+18=584] 12345678910lines.skip(1) .map(line -&gt; line.split(&quot;,&quot;)) .collect(groupingBy(array -&gt; array[USER_REGION], groupingBy(array -&gt; array[USER_ID], counting()))) .entrySet().stream() .map(e -&gt; Map.entry( e.getKey(), e.getValue().entrySet().stream().max(Map.Entry.comparingByValue()) )) .forEach(System.out::println); 5.2）每个地区下单最多的前3用户结果应为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455上海--------------------------1.5159156255127636e+18=6341.515915625512118e+18=5831.515915625512422e+18=561广东--------------------------1.515915625512377e+18=10281.5159156255121544e+18=5721.5159156255120845e+18=571天津--------------------------1.5159156255120858e+18=5301.5159156255122383e+18=5041.5159156255123333e+18=481四川--------------------------1.5159156255121551e+18=5721.5159156255123768e+18=5681.515915625512055e+18=552浙江--------------------------1.5159156255121183e+18=5641.515915625513058e+18=5201.515915625512423e+18=513重庆--------------------------1.515915625512764e+18=6321.5159156255121188e+18=5721.515915625512085e+18=562湖北--------------------------1.5159156255121183e+18=5091.515915625512818e+18=5081.5159156255148017e+18=386湖南--------------------------1.5159156255120548e+18=5451.5159156255120855e+18=5431.5159156255134449e+18=511江苏--------------------------1.5159156255122386e+18=5511.5159156255122842e+18=5411.5159156255120842e+18=499海南--------------------------1.5159156255121178e+18=5561.5159156255128174e+18=5471.5159156255122022e+18=545北京--------------------------1.5159156255128172e+18=5841.515915625512423e+18=5791.5159156255123786e+18=558 12345678910111213141516171819202122232425lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .collect(groupingBy(a -&gt; a[USER_REGION], groupingBy(a -&gt; a[USER_ID], counting()))) /*.forEach((k,v)-&gt;&#123; System.out.println(k); System.out.println(&quot;---------------&quot;); v.forEach((x,y)-&gt;&#123; System.out.println(x + &quot;:&quot; + y); &#125;); &#125;);*/ .entrySet() .stream() .map(e -&gt; Map.entry( e.getKey(), e.getValue().entrySet().stream() .sorted(Map.Entry.&lt;String, Long&gt;comparingByValue().reversed()) .limit(3) .toList() ) ).forEach(e -&gt; &#123; System.out.println(e.getKey()); System.out.println(&quot;--------------------------&quot;); e.getValue().forEach(System.out::println); &#125;); 6.1）按类别统计销量结果应为 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123accessories.bag 订单数 3063accessories.umbrella 订单数 33apparel.costume 订单数 2apparel.glove 订单数 1942apparel.shirt 订单数 235apparel.shoes 订单数 2apparel.sock 订单数 21apparel.trousers 订单数 99apparel.tshirt 订单数 372appliances.environment.air_conditioner 订单数 7379appliances.environment.air_heater 订单数 2599appliances.environment.climate 订单数 101appliances.environment.fan 订单数 3855appliances.environment.vacuum 订单数 15971appliances.environment.water_heater 订单数 3644appliances.iron 订单数 8249appliances.ironing_board 订单数 2128appliances.kitchen.blender 订单数 8672appliances.kitchen.coffee_grinder 订单数 811appliances.kitchen.coffee_machine 订单数 1250appliances.kitchen.dishwasher 订单数 2663appliances.kitchen.fryer 订单数 97appliances.kitchen.grill 订单数 1579appliances.kitchen.hood 订单数 9045appliances.kitchen.juicer 订单数 1187appliances.kitchen.kettle 订单数 12740appliances.kitchen.meat_grinder 订单数 4520appliances.kitchen.microwave 订单数 7615appliances.kitchen.mixer 订单数 2610appliances.kitchen.oven 订单数 4000appliances.kitchen.refrigerators 订单数 20259appliances.kitchen.steam_cooker 订单数 464appliances.kitchen.toster 订单数 1381appliances.kitchen.washer 订单数 14563appliances.personal.hair_cutter 订单数 2716appliances.personal.massager 订单数 1724appliances.personal.scales 订单数 6727appliances.sewing_machine 订单数 1576appliances.steam_cleaner 订单数 119auto.accessories.alarm 订单数 252auto.accessories.anti_freeze 订单数 109auto.accessories.compressor 订单数 276auto.accessories.player 订单数 117auto.accessories.radar 订单数 80auto.accessories.videoregister 订单数 533computers.components.cdrw 订单数 158computers.components.cooler 订单数 3377computers.components.cpu 订单数 4147computers.components.hdd 订单数 5054computers.components.memory 订单数 1597computers.components.motherboard 订单数 860computers.components.power_supply 订单数 986computers.components.sound_card 订单数 26computers.components.videocards 订单数 1190computers.desktop 订单数 1041computers.ebooks 订单数 397computers.gaming 订单数 164computers.network.router 订单数 6473computers.notebook 订单数 25866computers.peripherals.camera 订单数 1041computers.peripherals.joystick 订单数 1192computers.peripherals.keyboard 订单数 3803computers.peripherals.monitor 订单数 3272computers.peripherals.mouse 订单数 12664computers.peripherals.printer 订单数 3458computers.peripherals.scanner 订单数 74construction.components.faucet 订单数 133construction.tools.drill 订单数 622construction.tools.generator 订单数 46construction.tools.heater 订单数 348construction.tools.light 订单数 10construction.tools.pump 订单数 65construction.tools.saw 订单数 169construction.tools.screw 订单数 2408construction.tools.welding 订单数 183country_yard.cultivator 订单数 33country_yard.lawn_mower 订单数 111country_yard.watering 订单数 5country_yard.weather_station 订单数 53electronics.audio.acoustic 订单数 438electronics.audio.dictaphone 订单数 12electronics.audio.headphone 订单数 20084electronics.audio.microphone 订单数 1062electronics.audio.subwoofer 订单数 70electronics.calculator 订单数 35electronics.camera.photo 订单数 348electronics.camera.video 订单数 133electronics.clocks 订单数 6474electronics.smartphone 订单数 102365electronics.tablet 订单数 6395electronics.telephone 订单数 2437electronics.video.projector 订单数 114electronics.video.tv 订单数 17618furniture.bathroom.bath 订单数 232furniture.bathroom.toilet 订单数 44furniture.bedroom.bed 订单数 451furniture.bedroom.blanket 订单数 68furniture.bedroom.pillow 订单数 1882furniture.kitchen.chair 订单数 3084furniture.kitchen.table 订单数 11260furniture.living_room.cabinet 订单数 3117furniture.living_room.chair 订单数 1439furniture.living_room.shelving 订单数 2572furniture.living_room.sofa 订单数 401furniture.universal.light 订单数 22kids.bottles 订单数 63kids.carriage 订单数 41kids.dolls 订单数 379kids.fmcg.diapers 订单数 11kids.skates 订单数 1159kids.swing 订单数 8kids.toys 订单数 643medicine.tools.tonometer 订单数 1106sport.bicycle 订单数 569sport.diving 订单数 10sport.ski 订单数 17sport.snowboard 订单数 3sport.tennis 订单数 87sport.trainer 订单数 210stationery.battery 订单数 5210stationery.cartrige 订单数 2473stationery.paper 订单数 1085stationery.stapler 订单数 97 1234567lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .filter(a -&gt; !a[CATEGORY_CODE].isEmpty()) .collect(groupingBy(a -&gt; a[CATEGORY_CODE], TreeMap::new, counting())) .forEach((k, v) -&gt; &#123; System.out.println(k + &quot; 订单数 &quot; + v); &#125;); 6.2）按一级类别统计销量结果应为 12345678910111213accessories 订单数 3096apparel 订单数 2673appliances 订单数 150244auto 订单数 1367computers 订单数 76840construction 订单数 3984country_yard 订单数 202electronics 订单数 157585furniture 订单数 24572kids 订单数 2304medicine 订单数 1106sport 订单数 896stationery 订单数 8865 1234567lines.skip(1) .map(l -&gt; l.split(&quot;,&quot;)) .filter(a -&gt; !a[CATEGORY_CODE].isEmpty()) .collect(groupingBy(TestData::firstCategory, TreeMap::new, counting())) .forEach((k, v) -&gt; &#123; System.out.println(k + &quot; 订单数 &quot; + v); &#125;); 12345static String firstCategory(String[] a) &#123; String category = a[CATEGORY_CODE]; int dot = category.indexOf(&quot;.&quot;); return category.substring(0, dot);&#125; 7）按价格区间统计销量 p &lt;100 100&lt;= p &lt;500 500&lt;=p&lt;1000 1000&lt;=p 结果应为 1234[0,100)=291624[1000,∞)=14514[500,1000)=52857[100,500)=203863 1234567891011121314151617static String priceRange(Double price) &#123; if (price &lt; 100) &#123; return &quot;[0,100)&quot;; &#125; else if (price &gt;= 100 &amp;&amp; price &lt; 500) &#123; return &quot;[100,500)&quot;; &#125; else if (price &gt;= 500 &amp;&amp; price &lt; 1000) &#123; return &quot;[500,1000)&quot;; &#125; else &#123; return &quot;[1000,∞)&quot;; &#125;&#125;lines.skip(1) .map(line -&gt; line.split(&quot;,&quot;)) .map(array -&gt; Double.parseDouble(array[PRICE])) .collect(groupingBy(TestData::priceRange, counting())) 8）不同年龄段女性所下不同类别订单 a &lt; 18 18 &lt;= a &lt; 30 30 &lt;= a &lt; 50 50 &lt;= a 1234567891011121314151617181920[0,18) accessories 81[0,18) apparel 60[0,18) appliances 4326[0,18) computers 1984...[18,30) accessories 491[18,30) apparel 488[18,30) appliances 25240[18,30) computers 13076...[30,50) accessories 890[30,50) apparel 893[30,50) appliances 42755[30,50) computers 21490...[50,∞) accessories 41[50,∞) apparel 41[50,∞) appliances 2255[50,∞) computers 1109... 12345678910111213141516171819static String ageRange(String[] array) &#123; int age = Double.valueOf(array[USER_AGE]).intValue(); if (age &lt; 18) &#123; return &quot;[0,18)&quot;; &#125; else if (age &lt; 30) &#123; return &quot;[18,30)&quot;; &#125; else if (age &lt; 50) &#123; return &quot;[30,50)&quot;; &#125; else &#123; return &quot;[50,∞)&quot;; &#125;&#125;lines.skip(1) .map(line -&gt; line.split(&quot;,&quot;)) .filter(array -&gt; !array[CATEGORY_CODE].isEmpty()) .filter(array -&gt; array[USER_SEX].equals(&quot;女&quot;)) .collect(groupingBy(TestData::ageRange, groupingBy(TestData::firstCategory, TreeMap::new, counting()))) 异步处理例子 1: 使用ExecutorService 123456789101112131415161718192021static Logger logger = LoggerFactory.getLogger(&quot;Test&quot;);public static void main(String[] args) &#123; try (ExecutorService service = Executors.newFixedThreadPool(2)) &#123; logger.info(&quot;开始统计&quot;); service.submit(() -&gt; monthlySalesReport(map-&gt;map.entrySet().forEach(e-&gt;logger.info(e.toString())))); logger.info(&quot;执行其它操作&quot;); &#125;&#125;private static void monthlySalesReport(Consumer&lt;Map&lt;YearMonth, Long&gt;&gt; consumer) &#123; try (Stream&lt;String&gt; lines = Files.lines(Path.of(&quot;./data.txt&quot;))) &#123; Map&lt;YearMonth, Long&gt; collect = lines.skip(1) .map(line -&gt; line.split(&quot;,&quot;)) .collect(groupingBy(array -&gt; YearMonth.from(formatter.parse(array[TIME])), TreeMap::new, counting())); consumer.accept(collect); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125;&#125; 例子 2: 使用CompletableFuture 123456789101112131415161718192021static Logger logger = LoggerFactory.getLogger(&quot;Test&quot;);public static void main(String[] args) throws InterruptedException &#123; logger.info(&quot;开始统计&quot;); CompletableFuture .supplyAsync(() -&gt; monthlySalesReport()) .thenAccept(map -&gt; map.entrySet().forEach(e -&gt; logger.info(e.toString()))); logger.info(&quot;执行其它操作&quot;); Thread.sleep(10000);&#125;private static Map&lt;YearMonth, Long&gt; monthlySalesReport() &#123; try (Stream&lt;String&gt; lines = Files.lines(Path.of(&quot;./data.txt&quot;))) &#123; Map&lt;YearMonth, Long&gt; collect = lines.skip(1) .map(line -&gt; line.split(&quot;,&quot;)) .collect(groupingBy(array -&gt; YearMonth.from(formatter.parse(array[TIME])), TreeMap::new, counting())); return collect; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125;&#125; 框架设计 什么是框架？ 半成品软件，帮助开发者快速构建应用程序 框架提供的都是固定不变的、已知的、可以重用的代码 而那些每个应用不同的业务逻辑，变化的、未知的部分，则在框架外由开发者自己实现 将未知交给子类Spring 延迟创建 bean 1234567891011classDiagramclass DefaultSingletonBeanRegistry &#123; - singletonObjects: Map + getSingleton(name, factory)&#125;class AbstractAutowireCapableBeanFactory &#123; # createBean(name, definition, args)&#125;DefaultSingletonBeanRegistry &lt;|-- AbstractAutowireCapableBeanFactory Spring 中的很多类有非常复杂的继承关系，并且它们分工明确，你做什么，我做什么，职责是划分好的。例如： DefaultSingletonBeanRegistry 是父类，它有个职责是缓存单例 bean，用下面方法实现 1public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; factory) 但如何创建 bean，这个父类是不知道的，创建 bean 是子类 AbstractAutowireCapableBeanFactory 的职责 123Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; ...&#125; 父类中 getSingleton 的内部就要使用 singletonFactory 函数对象来获得创建好的对象 123456789public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; ... Object singletonObject = this.singletonObjects.get(beanName); if(singletonObject == null) &#123; ... singletonObject = singletonFactory.getObject(); addSingleton(beanName, singletonObject); &#125;&#125; 最后子类创建单例 bean 时，会把 ObjectFactory 这个函数对象传进去 创建其它 scope bean，不需要用 getSingleton 缓存 12345678910protected &lt;T&gt; T doGetBean(...) &#123; ... if (mbd.isSingleton()) &#123; sharedInstance = getSingleton(beanName, () -&gt; &#123; ... return createBean(beanName, mbd, args); &#125;); &#125; ...&#125; 将未知交给用户JdbcTemplate 123456789101112131415create table student ( id int primary key auto_increment, name varchar(16), sex char(1));insert into student values (1, &#x27;赵一伤&#x27;, &#x27;男&#x27;), (2, &#x27;钱二败&#x27;, &#x27;男&#x27;), (3, &#x27;孙三毁&#x27;, &#x27;男&#x27;), (4, &#x27;李四摧&#x27;, &#x27;男&#x27;), (5, &#x27;周五输&#x27;, &#x27;男&#x27;), (6, &#x27;吴六破&#x27;, &#x27;男&#x27;), (7, &#x27;郑七灭&#x27;, &#x27;男&#x27;), (8, &#x27;王八衰&#x27;, &#x27;男&#x27;); spring 中 JdbcTemplate 代码 123456789101112131415161718192021public class TestJdbc &#123; public static void main(String[] args) &#123; HikariDataSource dataSource = new HikariDataSource(); dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/test&quot;); dataSource.setUsername(&quot;root&quot;); dataSource.setPassword(&quot;root&quot;); JdbcTemplate template = new JdbcTemplate(dataSource); String sql = &quot;select id,name,sex from student&quot;; template.query(sql, (rs, index) -&gt; &#123; int id = rs.getInt(&quot;id&quot;); String name = rs.getString(&quot;name&quot;); String sex = rs.getString(&quot;sex&quot;); return new Student(id, name, sex); &#125;).forEach(System.out::println); &#125; record Student(int id, String name, String sex) &#123; &#125;&#125; 对 query 来讲，建立数据库连接，创建 Statement 对象，执行查询这些步骤都是固定的 而结果要如何用 java 对象封装，这对框架代码是未知的，用 RowMapper 接口代表，将来它的 lambda 实现将结果转换成需要的 java 对象 ApplicationListener 12345678910111213141516171819202122232425262728293031public class MyEvent extends ApplicationEvent &#123; public MyEvent(Object source) &#123; super(source); &#125;&#125;@SpringBootApplicationpublic class TestExtend &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(TestExtend.class, args); context.publishEvent(new MyEvent(&quot;context&quot;)); &#125; @Bean public ApplicationListener&lt;MyEvent&gt; myListener() &#123; return (event -&gt; System.out.println(&quot;收到事件:&quot; + event)); &#125; @RestController static class MyController &#123; @Autowired private ApplicationContext context; @GetMapping(&quot;/hello&quot;) public String hello() &#123; context.publishEvent(new MyEvent(&quot;controller&quot;)); return &quot;hello&quot;; &#125; &#125;&#125; 对 spring 来讲，它并不知道如何处理事件 因此可以提供一个类型为 ApplicationListener 的 lambda 对象 延迟拼接条件Mybatis-Plus 123456789101112131415161718@SpringBootApplication@MapperScanpublic class TestMyBatisPlus &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(TestMyBatisPlus.class, args); StudentMapper mapper = context.getBean(StudentMapper.class); test(mapper, List.of(&quot;赵一伤&quot;)); &#125; static void test(StudentMapper mapper, List&lt;String&gt; names) &#123; LambdaQueryWrapper&lt;Student&gt; query = new LambdaQueryWrapper&lt;&gt;(); query.in(!names.isEmpty(), Student::getName, names); System.out.println(mapper.selectList(query)); &#125;&#125; 比较典型的用法有两处： 第一，在调用 in 等方法添加条件时，第一个参数是 boolean 为 true 才会拼接 SQL 条件，否则不拼接 如何实现的呢？用 DoSomething 类型的 lambda 对象来延迟拼接操作 1234567891011@FunctionalInterfacepublic interface DoSomething &#123; void doIt();&#125;protected final Children maybeDo(boolean condition, DoSomething something) &#123; if (condition) &#123; something.doIt(); &#125; return typedThis;&#125; 然而，它在实现 ()-&gt;appendSqlSegments(...) 拼接时，是不断修改一个 expression 状态变量，为函数编程所不齿 偏门用法第二，如果用 LambdaQueryWrapper 拼接 sql 条件时，为了取得列名，采用了这个办法 1Student::getName 它要做的事很简单，但内部实现却比较复杂 必须用 Student::getName 方法引用，而不能用其它 Lambda 对象 它会实现 Serializable 接口，序列化时会把它变成 SerializedLambda 想办法拿到 SerializedLambda 对象（反射调用 writeReplace） 通过 SerializedLambda 能够获得它对应的实际方法，也就是 String getName() 和所在类 Student 再通过方法名推导得到属性名（去掉 is，get）即 name 所在类 Student 知道了，属性名 name 也有了，就可以进一步确定列名 属性上的 @TableField 指定的列名优先 没有 @TableField，把属性名当作列名 P.S. 不是很喜欢这种做法，比较恶心 但它确实是想做这么一件事：在代码中全面使用 java 的字段名，避免出现数据库的列名 1234567891011121314151617181920public static void main(String[] args) throws Exception &#123;// Type1 lambda = (Type1 &amp; Serializable) (a, b) -&gt; a + b; Type2 lambda = (Type2 &amp; Serializable) Student::getName; // 将 lambda 对象序列化 Method writeReplace = lambda.getClass().getDeclaredMethod(&quot;writeReplace&quot;); SerializedLambda serializedLambda = (SerializedLambda) writeReplace.invoke(lambda); // 得到 lambda 对象使用类、所属类和实现方法名 System.out.println(serializedLambda.getCapturingClass()); System.out.println(serializedLambda.getImplClass()); System.out.println(serializedLambda.getImplMethodName());&#125;interface Type2 &#123; String get(Student student);&#125;interface Type1 &#123; int add(int a, int b);&#125; 并行计算统计页面的访问次数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ParallelTest &#123; static Pattern reg = Pattern.compile(&quot;(\\\\S+) - \\\\[(.+)] (.+) (.+)&quot;); private static final int FILES = 100; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; for (int i = 0; i &lt; 5; i++) &#123; sequence(); &#125; &#125; private static void sequence() throws InterruptedException, ExecutionException &#123; long start = System.currentTimeMillis(); Map&lt;String, Long&gt; m0 = new HashMap&lt;&gt;(); for (int i = 0; i &lt; FILES; i++) &#123; Map&lt;String, Long&gt; mi = one(i); m0 = Stream.of(m0, mi) .flatMap(m -&gt; m.entrySet().stream()) .collect(toMap(Map.Entry::getKey, Map.Entry::getValue, Long::sum)); &#125; long sum = 0; for (Map.Entry&lt;String, Long&gt; e : m0.entrySet()) &#123;// System.out.println(e); sum += e.getValue(); &#125; System.out.println(sum); System.out.println(&quot;cost: &quot; + (System.currentTimeMillis() - start)); &#125; private static Map&lt;String, Long&gt; one(int i) &#123; try (Stream&lt;String&gt; lines = Files.lines(Path.of(String.format(&quot;web_server_access_%d.log&quot;, i)))) &#123; return lines// .limit(10) .map(reg::matcher) .filter(Matcher::find) .map(matcher -&gt; matcher.group(3)) .collect(groupingBy(identity(), counting())); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; &#125; private static void parallel() throws InterruptedException, ExecutionException &#123; long start = System.currentTimeMillis(); List&lt;CompletableFuture&lt;Map&lt;String, Long&gt;&gt;&gt; futures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; FILES; i++) &#123; int k = i; CompletableFuture&lt;Map&lt;String, Long&gt;&gt; future = CompletableFuture.supplyAsync(() -&gt; one(k)); futures.add(future); &#125; CompletableFuture&lt;Map&lt;String, Long&gt;&gt; f0 = futures.getFirst(); for (int i = 1; i &lt; futures.size(); i++) &#123; f0 = f0.thenCombine(futures.get(i), (m1, m2) -&gt; Stream.of(m1, m2) .flatMap(m -&gt; m.entrySet().stream()) .collect(toMap(Map.Entry::getKey, Map.Entry::getValue, Long::sum)) ); &#125; Map&lt;String, Long&gt; map = f0.get(); long sum = 0; for (Map.Entry&lt;String, Long&gt; e : map.entrySet()) &#123;// System.out.println(e); sum += e.getValue(); &#125; System.out.println(sum); System.out.println(&quot;cost: &quot; + (System.currentTimeMillis() - start)); &#125;&#125; UI 事件12345678910111213141516public class TestUIEvent &#123; public static void main(String[] args) &#123; JFrame frame = new JFrame(&quot;Lambda Example&quot;); JButton button = new JButton(&quot;Click me&quot;); // 使用Lambda表达式定义按钮的点击事件处理程序 button.addActionListener(e -&gt; &#123; System.out.println(&quot;Button clicked!&quot;); &#125;); frame.add(button); frame.setSize(300, 200); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setVisible(true); &#125;&#125; 五. 实现原理lambda 原理以下面代码为例 123456789public class TestLambda &#123; public static void main(String[] args) &#123; test((a, b) -&gt; a + b); &#125; static void test(BinaryOperator&lt;Integer&gt; lambda) &#123; System.out.println(lambda.apply(1, 2)); &#125;&#125; 执行结果 13 第一步，生成静态方法如何证明？用反射 123for (Method method : TestLambda.class.getDeclaredMethods()) &#123; System.out.println(method);&#125; 输出为（去掉了包名，容易阅读） 123public static void TestLambda.main(java.lang.String[])static void TestLambda.test(BinaryOperator)private static java.lang.Integer TestLambda.lambda$main$0(Integer,Integer) 可以看到除了我们自己写的 main 和 test 以外，多出一个名为 lambda$main$0 的方法 这个方法是在编译期间由编译器生成的方法，是 synthetic（合成）方法 它的参数、内容就是 lambda 表达式提供的参数和内容，如下面代码片段所示 123private static Integer lambda$main$0(Integer a, Integer b) &#123; return a + b;&#125; 第二步，生成实现类字节码如果是我自己造一个对象包含此方法，可以这么做 先创建一个类 1234567final class LambdaObject implements BinaryOperator&lt;Integer&gt; &#123; @Override public Integer apply(Integer a, Integer b) &#123; return TestLambda.lambda$main$0(a, b); &#125;&#125; 将来使用时，创建对象 1test(new LambdaObject()); 只不过，jvm 是在运行期间造出的这个类以及对象而已，要想查看这个类 在 jdk 21 中运行时添加虚拟机参数 1-Djdk.invoke.LambdaMetafactory.dumpProxyClassFiles 早期 jdk 添加的参数是（没有去进行版本比对了） 1-Djdk.internal.lambda.dumpProxyClasses 若想实现在运行期间生成上述 class 字节码，有两种手段 一是动态代理，jdk 并没有采用这种办法来生成 Lambda 类 二是用 LambdaMetaFactory，它配合 MethodHandle API 在执行时更具性能优势 1234567891011121314151617181920212223242526272829public class TestLambda1 &#123; public static void main(String[] args) throws Throwable &#123; test((a, b) -&gt; a + b); MethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType factoryType = MethodType.methodType(BinaryOperator.class); MethodType interfaceMethodType = MethodType.methodType(Object.class, Object.class, Object.class); MethodType implementsMethodType = MethodType.methodType(Integer.class, Integer.class, Integer.class); MethodHandle implementsMethod = lookup.findStatic(TestLambda1.class, &quot;lambda$main$1&quot;, implementsMethodType); MethodType lambdaType = MethodType.methodType(Integer.class, Integer.class, Integer.class); CallSite callSite = LambdaMetafactory.metafactory(lookup, &quot;apply&quot;, factoryType, interfaceMethodType, implementsMethod, lambdaType); BinaryOperator&lt;Integer&gt; lambda = (BinaryOperator) callSite.getTarget().invoke(); test(lambda); &#125; static Integer lambda$main$1(Integer a, Integer b) &#123; return a + b; &#125; static void test(BinaryOperator&lt;Integer&gt; lambda) &#123; System.out.println(lambda.apply(1, 2)); &#125;&#125; 其中 “apply” 是接口方法名 factoryType 是工厂方法长相 interfaceMethodType 是接口方法长相 implementsMethod 是实现方法 implementsMethodType 是实现方法长相 lambdaType 是实际函数对象长相 callSite.getTarget() 实际是调用实现类的构造方法对应的 mh，最后 invoke 返回函数对象 方法引用原理12345678910111213141516171819202122public class TestLambda3 &#123; public static void main(String[] args) throws Throwable &#123; test(String::toLowerCase); MethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType factoryType = MethodType.methodType(Function.class); MethodType interfaceMethodType = MethodType.methodType(Object.class, Object.class); MethodHandle implementsMethod = lookup.findVirtual(String.class, &quot;toLowerCase&quot;, MethodType.methodType(String.class)); MethodType lambdaType = MethodType.methodType(String.class, String.class); CallSite callSite = LambdaMetafactory.metafactory(lookup, &quot;apply&quot;, factoryType, interfaceMethodType, implementsMethod, lambdaType); Function&lt;String, String&gt; lambda = (Function&lt;String, String&gt;) callSite.getTarget().invoke(); System.out.println(lambda.apply(&quot;Tom&quot;)); &#125; static void test(Function&lt;String,String&gt; lambda) &#123; System.out.println(lambda.apply(&quot;Tom&quot;)); &#125;&#125; 闭包原理捕获基本类型变量 123456int c = 10;test((a, b) -&gt; a + b + c);static void test(BinaryOperator&lt;Integer&gt; lambda) &#123; System.out.println(lambda.apply(1, 2));&#125; 生成一个带 3 个参数的方法，但它和 BinaryOperator 还差一个 int 参数 123static Integer lambda$main$1(int c, Integer a, Integer b) &#123; return a + b + c;&#125; 123456789101112131415161718192021222324252627282930public class TestLambda2 &#123; public static void main(String[] args) throws Throwable &#123;// int c = 10;// test((a, b) -&gt; a + b + c); MethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType factoryType = MethodType.methodType(BinaryOperator.class, int.class); MethodType interfaceMethodType = MethodType.methodType(Object.class, Object.class, Object.class); MethodType implementsMethodType = MethodType.methodType(Integer.class, int.class, Integer.class, Integer.class); MethodHandle implementsMethod = lookup.findStatic(TestLambda2.class, &quot;lambda$main$1&quot;, implementsMethodType); MethodType lambdaType = MethodType.methodType(Integer.class, Integer.class, Integer.class); CallSite callSite = LambdaMetafactory.metafactory(lookup, &quot;apply&quot;, factoryType, interfaceMethodType, implementsMethod, lambdaType); BinaryOperator&lt;Integer&gt; lambda = (BinaryOperator) callSite.getTarget().invoke(10); test(lambda); &#125; static Integer lambda$main$1(int c, Integer a, Integer b) &#123; return a + b + c; &#125; static void test(BinaryOperator&lt;Integer&gt; lambda) &#123; System.out.println(lambda.apply(1, 2)); &#125;&#125; 不同之处 factoryType，除了原本的接口类型之外，多了实现方法第一个参数的类型 产生 lambda 对象的时候，通过 invoke 把这个参数的实际值传进去 这样产生的 LambdaType 就是这样，并且生成 Lambda 对象时，c 的值被固定为 10 1234567891011final class LambdaType implements BinaryOperator &#123; private final int c; private TestLambda2$$Lambda(int c) &#123; this.c = c; &#125; public Object apply(Object a, Object b) &#123; return TestLambda2.lambda$main$1(this.c, (Integer)a, (Integer)b); &#125;&#125; 捕获引用类型变量 12345678910111213141516171819202122232425262728293031323334353637public class TestLambda4 &#123; static class MyRef &#123; int age; public MyRef(int age) &#123; this.age = age; &#125; &#125; public static void main(String[] args) throws Throwable &#123; /*MyRef ref = new MyRef(10); test((a, b) -&gt; a + b + ref.age);*/ MethodHandles.Lookup lookup = MethodHandles.lookup(); MethodType factoryType = MethodType.methodType(BinaryOperator.class, MyRef.class); MethodType interfaceMethodType = MethodType.methodType(Object.class, Object.class, Object.class); MethodType implementsMethodType = MethodType.methodType(Integer.class, MyRef.class, Integer.class, Integer.class); MethodHandle implementsMethod = lookup.findStatic(TestLambda4.class, &quot;lambda$main$1&quot;, implementsMethodType); MethodType lambdaType = MethodType.methodType(Integer.class, Integer.class, Integer.class); CallSite callSite = LambdaMetafactory.metafactory(lookup, &quot;apply&quot;, factoryType, interfaceMethodType, implementsMethod, lambdaType); BinaryOperator&lt;Integer&gt; lambda = (BinaryOperator) callSite.getTarget().bindTo(new MyRef(20)).invoke(); test(lambda); &#125; static Integer lambda$main$1(MyRef c, Integer a, Integer b) &#123; return a + b + c.age; &#125; static void test(BinaryOperator&lt;Integer&gt; lambda) &#123; System.out.println(lambda.apply(1, 2)); &#125;&#125; 与捕获基本类型变量类似，不过 除了 1callSite.getTarget().invoke(new MyRef(20)); 还可以 1callSite.getTarget().bindTo(new MyRef(20)).invoke(); Stream 构建自定义可切分迭代器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class TestSpliterator &#123; static class MySpliterator&lt;T&gt; implements Spliterator&lt;T&gt; &#123; T[] array; int begin; int end; public MySpliterator(T[] array, int begin, int end) &#123; this.array = array; this.begin = begin; this.end = end; &#125; @Override public boolean tryAdvance(Consumer&lt;? super T&gt; action) &#123; if (begin &gt; end) &#123; return false; &#125; action.accept(array[begin++]); return true; &#125; @Override public Spliterator&lt;T&gt; trySplit() &#123; if (estimateSize() &gt; 5) &#123; int mid = (begin + end) &gt;&gt;&gt; 1; MySpliterator&lt;T&gt; res = new MySpliterator&lt;&gt;(array, begin, mid); System.out.println(Thread.currentThread().getName() + &quot;=&gt;&quot; + res); begin = mid + 1; return res; &#125; return null; &#125; @Override public String toString() &#123; return Arrays.toString(Arrays.copyOfRange(array, begin, end + 1)); &#125; @Override public long estimateSize() &#123; return end - begin + 1; &#125; @Override public int characteristics() &#123; return Spliterator.SUBSIZED | Spliterator.ORDERED; &#125; &#125; public static void main(String[] args) &#123; Integer[] all = new Integer[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 10&#125;; MySpliterator&lt;Integer&gt; spliterator = new MySpliterator&lt;&gt;(all, 0, 9); StreamSupport.stream(spliterator, false) .parallel() .forEach(x -&gt; System.out.println(Thread.currentThread().getName() + &quot;:&quot; + x)); &#125;&#125; 练习：按每次切分固定大小来实现","path":"2024/04/19/函数式编程/","date":"04-19","excerpt":"","tags":[{"name":"函数式编程","slug":"函数式编程","permalink":"https://castile.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"Lambda","slug":"Lambda","permalink":"https://castile.github.io/tags/Lambda/"},{"name":"纯函数","slug":"纯函数","permalink":"https://castile.github.io/tags/%E7%BA%AF%E5%87%BD%E6%95%B0/"}]},{"title":"使用InvokeScriptedProcessor处理Record","text":"InvokeScriptedProcessor模板(一个更快的ExecuteScript)原文地址：https://funnifi.blogspot.com/2017/06/invokescriptedprocessor-template-faster.html 对于Apache Nifi中的快速，简单且小的脚本任务，ExecuteScript通常比InvokescriptedProcessor更好，因为很少有样板代码，关系和属性已经定义和支持，并且某些与Nifi API相关的对象（例如ProcessSession，ProcessContext和ComponentLog）已经被绑定到脚本引擎，作为脚本可以轻松使用的变量。 然而，一个权衡是性能;在ExecuteScript中，每次onTrigger被执行时，脚本都会被 evaluated 。对于InvokeScriptedProcessor，只要脚本(或任何InvokeScriptedProcessor属性)没有改变，脚本化的Processor实例就由处理器维护，当NiFi框架调用onTrigger()等父方法时，它的方法就会被简单地调用。 为了获得两者的最佳效果，我将InvokeScriptedProcessor实例放在一起，该实例的配置方式与ExecuteScript相同。提供了“成功”和“失败”的关系，API对象是可用的，如果您只是将您的ExecuteScript代码粘贴到下面脚本中的相同位置，它将表现得像一个性能更高的ExecuteScript实例。代码如下： 1234567891011121314151617181920212223242526272829303132333435////////////////////////////////////////////////////////////// imports go here////////////////////////////////////////////////////////////class E&#123; void executeScript(session, context, log, REL_SUCCESS, REL_FAILURE) &#123; //////////////////////////////////////////////////////////// // your code goes here //////////////////////////////////////////////////////////// &#125;&#125;class GroovyProcessor implements Processor &#123; def REL_SUCCESS = new Relationship.Builder().name(&quot;success&quot;).description(&#x27;FlowFiles that were successfully processed are routed here&#x27;).build() def REL_FAILURE = new Relationship.Builder().name(&quot;failure&quot;).description(&#x27;FlowFiles that were not successfully processed are routed here&#x27;).build() def ComponentLog log def e = new E() void initialize(ProcessorInitializationContext context) &#123; log = context.logger &#125; Set&lt;Relationship&gt; getRelationships() &#123; return [REL_FAILURE, REL_SUCCESS] as Set &#125; Collection&lt;ValidationResult&gt; validate(ValidationContext context) &#123; null &#125; PropertyDescriptor getPropertyDescriptor(String name) &#123; null &#125; void onPropertyModified(PropertyDescriptor descriptor, String oldValue, String newValue) &#123; &#125; List&lt;PropertyDescriptor&gt; getPropertyDescriptors() &#123; null &#125; String getIdentifier() &#123; null &#125; void onTrigger(ProcessContext context, ProcessSessionFactory sessionFactory) throws ProcessException &#123; def session = sessionFactory.createSession() try &#123; e.executeScript(session, context, log, REL_SUCCESS, REL_FAILURE) session.commit() &#125; catch (final Throwable t) &#123; log.error(&#x27;&#123;&#125; failed to process due to &#123;&#125;; rolling back session&#x27;, [this, t] as Object[]) session.rollback(true) throw t&#125;&#125;&#125;processor = new GroovyProcessor() InvokeScriptedProcessor模板(使用Jython) 我在Groovy中提供了一个模板，该模板将允许NIFI用户将其ExecuteScript Groovy脚本移植到更快的InvokescriptedProcessor（ISP）处理器中。ISP比ExecuteScript更快，因为仅当代码或其他配置更改时才重新加载脚本，而executeScript每次调用处理器时都会评估脚本。 自从那篇文章以来，我已经收到了使用Jython编写的ISP模板的几个请求（例如此请求），因此使用Jython脚本执行的用户可以从ISP性能提升中受益。 123456789101112131415161718192021222324252627282930313233343536373839404142#////////////////////////////////////////////////////////////#// imports go here#////////////////////////////////////////////////////////////from org.apache.nifi.processor import Processor,Relationshipfrom java.lang import Throwableclass E(): def __init__(self): pass def executeScript(self,session, context, log, REL_SUCCESS, REL_FAILURE): log.warn(&quot;=====Hello========&quot;)#end classclass JythonProcessor(Processor): REL_SUCCESS = Relationship.Builder().name(&quot;success&quot;).description(&#x27;FlowFiles that were successfully processed are routed here&#x27;).build() REL_FAILURE = Relationship.Builder().name(&quot;failure&quot;).description(&#x27;FlowFiles that were not successfully processed are routed here&#x27;).build() log = None e = E() def initialize(self,context): self.log = context.logger def getRelationships(self): return set([self.REL_SUCCESS, self.REL_FAILURE]) def validate(self,context): pass def onPropertyModified(self,descriptor, oldValue, newValue): pass def getPropertyDescriptors(self): return [] def getIdentifier(self): return None def onTrigger(self,context, sessionFactory): session = sessionFactory.createSession() try: self.e.executeScript(session, context, self.log, self.REL_SUCCESS, self.REL_FAILURE) session.commit() except Throwable, t: self.log.error(&#x27;&#123;&#125; failed to process due to &#123;&#125;; rolling back session&#x27;, [self, t]) session.rollback(true) raise t#end classprocessor = JythonProcessor() 可复用的脚本我们可以使用动态属性(在开发人员指南和之前的文章中有解释)，因为它们作为变量传递给ExecuteScript。然而，处理器的用户必须知道要添加和填充哪些属性，并且没有好的方法将这些信息传递给用户(至少使用ExecuteScript是这样)。 但是，IndokescriptedProcessor可让您提供完整处理器实例的脚本实现。这意味着您可以定义自己的属性和关系，以及对它们的文档和验证。您的脚本可以提供功能，取决于处理器用户配置处理器的方式，而无需与脚本进行交互！ 一个带有单个InvokescriptedProcessor（包含工作脚本）的模板可以拖到画布上，基本上就像将自定义处理器拖到画布上一样！当用户打开对话框时，他们会看到您添加的属性/关系，并且将像普通的属性一样（脚本语言，body等）进行验证。 脚本化的处理器只需要实现processor接口，该接口又扩展了AbstractConfigurableComponent。Groovy的基本框架是这样的:一个类包含一组被覆盖的接口方法 1234567891011121314151617181920212223242526272829303132class MyProcessor implements Processor &#123; @Override void initialize(ProcessorInitializationContext context) &#123; &#125; @Override Set&lt;Relationship&gt; getRelationships() &#123; return [] as Set &#125; @Override void onTrigger(ProcessContext context, ProcessSessionFactory sessionFactory) throws ProcessException &#123; // do stuff &#125; @Override Collection&lt;ValidationResult&gt; validate(ValidationContext context) &#123; return null &#125; @Override PropertyDescriptor getPropertyDescriptor(String name) &#123; return null &#125; @Override void onPropertyModified(PropertyDescriptor descriptor, String oldValue, String newValue) &#123; &#125; @Override List&lt;PropertyDescriptor&gt; getPropertyDescriptors() &#123; return [] as List &#125; @Override String getIdentifier() &#123; return &#x27;MyProcessor-InvokeScriptedProcessor&#x27; &#125;&#125;processor = new MyProcessor() 请注意，类必须实现处理器并声明一个名为“Processor”的变量，该变量包含类的实例。这是InvokescriptedProcessor所要求的约定。 重要的是：尽管您可能会在NIFI代码中找到许多处理器扩展AbstractProcessor或AbstrackSessionFactoryProcessor，但是如果它扩展了这些类之一，则您的脚本很可能无法正常工作。这是由于这些类的validation() 方法被声明为最终，并且基本实现将期望一组受支持的属性描述符包括Invokescriptedprocessor（例如脚本文件），但仅使用列表来使用该列表您的脚本处理器提供。可能会有一个黑客解决这个问题，但即使可能，也不值得。 继续前进，假设我们要创建一个可重复使用的脚本处理器，该处理器工作于GenerateFlowFile，但允许用户提供流量文件的内容以及其“文件名”属性的值。此外，也许内容可以包括Nifi Expression语言（EL）构造，例如$ {hostName（）}。由于内容可能具有类似EL语句的内容，但是用户可能不希望对其进行评估，因此我们应该让用户决定是否在写入流文件之前评估EL语句的内容。最后，这是一个“生成”处理器，因此我们只需要“成功”关系。“失败”在这里没有真正的意义。话虽如此，捕获您的代码可以投掷的所有异常将很重要；在ProcessException并重新启动中包装每个，以便该框架可以正确处理。 添加“成功”关系并将其返回（在集合中）中的 getRealationships() 添加一个“文件内容”属性以包含流量文件的预期内容（可能包括EL） 添加一个“评估内容中的表达式”属性，以指示是否评估EL的内容 添加一个可选的“文件名”属性，以覆盖默认的“文件名”属性。 触发处理器时，创建一个流文件，写入内容（可能在评估EL之后），并可能设置文件名属性 下面是一个Groovy语言的代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class GenerateFlowFileWithContent implements Processor &#123; def REL_SUCCESS = new Relationship.Builder() .name(&#x27;success&#x27;) .description(&#x27;The flow file with the specified content and/or filename was successfully transferred&#x27;) .build(); def CONTENT = new PropertyDescriptor.Builder() .name(&#x27;File Content&#x27;).description(&#x27;The content for the generated flow file&#x27;) .required(false).expressionLanguageSupported(true).addValidator(Validator.VALID).build() def CONTENT_HAS_EL = new PropertyDescriptor.Builder() .name(&#x27;Evaluate Expressions in Content&#x27;).description(&#x27;Whether to evaluate NiFi Expression Language constructs within the content&#x27;) .required(true).allowableValues(&#x27;true&#x27;,&#x27;false&#x27;).defaultValue(&#x27;false&#x27;).build() def FILENAME = new PropertyDescriptor.Builder() .name(&#x27;Filename&#x27;).description(&#x27;The name of the flow file to be stored in the filename attribute&#x27;) .required(false).expressionLanguageSupported(true).addValidator(StandardValidators.NON_EMPTY_VALIDATOR).build() @Override void initialize(ProcessorInitializationContext context) &#123; &#125; @Override Set&lt;Relationship&gt; getRelationships() &#123; return [REL_SUCCESS] as Set &#125; @Override void onTrigger(ProcessContext context, ProcessSessionFactory sessionFactory) throws ProcessException &#123; try &#123; def session = sessionFactory.createSession() def flowFile = session.create() def hasEL = context.getProperty(CONTENT_HAS_EL).asBoolean() def contentProp = context.getProperty(CONTENT) def content = (hasEL ? contentProp.evaluateAttributeExpressions().value : contentProp.value) ?: &#x27;&#x27; def filename = context.getProperty(FILENAME)?.evaluateAttributeExpressions()?.getValue() flowFile = session.write(flowFile, &#123; outStream -&gt; outStream.write(content.getBytes(&quot;UTF-8&quot;)) &#125; as OutputStreamCallback) if(filename != null) &#123; flowFile = session.putAttribute(flowFile, &#x27;filename&#x27;, filename) &#125; // transfer session.transfer(flowFile, REL_SUCCESS) session.commit() &#125; catch(e) &#123; throw new ProcessException(e) &#125; &#125; @Override Collection&lt;ValidationResult&gt; validate(ValidationContext context) &#123; return null &#125; @Override PropertyDescriptor getPropertyDescriptor(String name) &#123; switch(name) &#123; case &#x27;File Content&#x27;: return CONTENT case &#x27;Evaluate Expressions in Content&#x27;: return CONTENT_HAS_EL case &#x27;Filename&#x27;: return FILENAME default: return null &#125; &#125; @Override void onPropertyModified(PropertyDescriptor descriptor, String oldValue, String newValue) &#123; &#125; @Override List&lt;PropertyDescriptor&gt;&gt; getPropertyDescriptors() &#123; return [CONTENT, CONTENT_HAS_EL, FILENAME] as List &#125; @Override String getIdentifier() &#123; return &#x27;GenerateFlowFile-InvokeScriptedProcessor&#x27; &#125; &#125;processor = new GenerateFlowFileWithContent() 将其输入到InvokeScriptedProcessor的脚本主体中，语言设置为Groovy，然后应用(通过单击对话框上的Apply)，那么当重新打开对话框时，您应该看到关系设置为“success”，属性添加到配置对话框中。 此时，您可以将单个处理器保存为模板，称其为“生成FlowFileWithContent”之类的东西。现在，它是一个基本上可以作为处理器重复使用的模板。尝试将其拖到画布上并输入一些值，然后将其接线到其他处理器（例如Putfile）（查看它是否有效）： 希望这说明了InvokescriptedProcessor的功能和灵活性，以及如何使用自定义逻辑来创建可重复使用的处理器模板，而无需构建和部署NAR。 最合适的方法可能是使用InvoKescriptedProcessor，因为您可以添加更复杂的属性（指定控制器服务，例如），而不是用户。 - 定义的executeScript属性。 话虽如此，对于任何基于记录的脚本处理器，您都需要大量的设置代码，并且在如何处理记录的情况下，有最佳练习，即您在创建RecordSetWriter之前处理第一个记录，以防万一您的自定义处理器代码需要更新RecordSetWriter将使用的架构。下面的 Groovy 示例改编自 AbstractRecordProcessor ，这是标准NAR中所有记录处理器的共同基类。请注意，要处理第一个和其余记录的两个注释部分，这些是您将自定义代码处理记录的地方。最好是在脚本处理器中添加私有方法，然后将其调用一次以获取第一个记录，然后再次在循环中（这就是AbstractRecordProcessor所做的） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import org.apache.nifi.flowfile.attributes.CoreAttributesimport org.apache.nifi.processor.AbstractProcessorimport org.apache.nifi.processor.ProcessContextimport org.apache.nifi.processor.ProcessSessionimport org.apache.nifi.processor.Relationshipimport org.apache.nifi.processor.io.StreamCallbackimport org.apache.nifi.serialization.*import org.apache.nifi.serialization.record.*import org.apache.nifi.schema.access.SchemaNotFoundExceptionimport java.util.concurrent.atomic.AtomicIntegerclass MyRecordProcessor extends AbstractProcessor &#123; // Properties static final PropertyDescriptor RECORD_READER = new PropertyDescriptor.Builder() .name(&quot;record-reader&quot;) .displayName(&quot;Record Reader&quot;) .description(&quot;Specifies the Controller Service to use for reading incoming data&quot;) .identifiesControllerService(RecordReaderFactory.class) .required(true) .build() static final PropertyDescriptor RECORD_WRITER = new PropertyDescriptor.Builder() .name(&quot;record-writer&quot;) .displayName(&quot;Record Writer&quot;) .description(&quot;Specifies the Controller Service to use for writing out the records&quot;) .identifiesControllerService(RecordSetWriterFactory.class) .required(true) .build() def REL_SUCCESS = new Relationship.Builder().name(&quot;success&quot;).description(&#x27;FlowFiles that were successfully processed are routed here&#x27;).build() def REL_FAILURE = new Relationship.Builder().name(&quot;failure&quot;).description(&#x27;FlowFiles are routed here if an error occurs during processing&#x27;).build() @Override protected List&lt;PropertyDescriptor&gt; getSupportedPropertyDescriptors() &#123; def properties = [] as ArrayList properties.add(RECORD_READER) properties.add(RECORD_WRITER) properties &#125; @Override Set&lt;Relationship&gt; getRelationships() &#123; [REL_SUCCESS, REL_FAILURE] as Set&lt;Relationship&gt; &#125; @Override void onTrigger(ProcessContext context, ProcessSession session) &#123; def flowFile = session.get() if (!flowFile) return def readerFactory = context.getProperty(RECORD_READER).asControllerService(RecordReaderFactory) def writerFactory = context.getProperty(RECORD_WRITER).asControllerService(RecordSetWriterFactory) final Map&lt;String, String&gt; attributes = new HashMap&lt;&gt;() final AtomicInteger recordCount = new AtomicInteger() final FlowFile original = flowFile final Map&lt;String, String&gt; originalAttributes = flowFile.attributes try &#123; flowFile = session.write(flowFile, &#123; inStream, outStream -&gt; def reader = readerFactory.createRecordReader(originalAttributes, inStream, getLogger()) try &#123; // Get the first record and process it before we create the Record Writer. // We do this so that if the Processor updates the Record&#x27;s schema, we can provide // an updated schema to the Record Writer. If there are no records, then we can // simply create the Writer with the Reader&#x27;s schema and begin &amp; end the RecordSet def firstRecord = reader.nextRecord() if (!firstRecord) &#123; def writeSchema = writerFactory.getSchema(originalAttributes, reader.schema) def writer = writerFactory.createWriter(getLogger(), writeSchema, outStream) try &#123; writer.beginRecordSet() def writeResult = writer.finishRecordSet() attributes[&#x27;record.count&#x27;] = String.valueOf(writeResult.recordCount) attributes[CoreAttributes.MIME_TYPE.key()] = writer.mimeType attributes.putAll(writeResult.attributes) recordCount.set(writeResult.recordCount) &#125; finally &#123; writer.close() &#125; return &#125; ///////////////////////////////////////// // TODO process first record ///////////////////////////////////////// def writeSchema = writerFactory.getSchema(originalAttributes, firstRecord.schema) def writer = writerFactory.createWriter(getLogger(), writeSchema, outStream) try &#123; writer.beginRecordSet() writer.write(firstRecord) def record while (record = reader.nextRecord()) &#123; ////////////////////////////////////////// // TODO process next record ////////////////////////////////////////// writer.write(processed) &#125; def writeResult = writer.finishRecordSet() attributes.put(&#x27;record.count&#x27;, String.valueOf(writeResult.recordCount)) attributes.put(CoreAttributes.MIME_TYPE.key(), writer.mimeType) attributes.putAll(writeResult.attributes) recordCount.set(writeResult.recordCount) &#125; finally &#123; writer.close() &#125; &#125; catch (final SchemaNotFoundException e) &#123; throw new ProcessException(e.localizedMessage, e) &#125; catch (final MalformedRecordException e) &#123; throw new ProcessException(&#x27;Could not parse incoming data&#x27;, e) &#125; finally &#123; reader.close() &#125; &#125; as StreamCallback) &#125; catch (final Exception e) &#123; getLogger().error(&#x27;Failed to process &#123;&#125;; will route to failure&#x27;, [flowFile, e] as Object[]) session.transfer(flowFile, REL_FAILURE); return; &#125; flowFile = session.putAllAttributes(flowFile, attributes) recordCount.get() ? session.transfer(flowFile, REL_SUCCESS) : session.remove(flowFile) def count = recordCount.get() session.adjustCounter(&#x27;Records Processed&#x27;, count, false) getLogger().info(&#x27;Successfully converted &#123;&#125; records for &#123;&#125;&#x27;, [count, flowFile] as Object[]) &#125;&#125;processor = new MyRecordProcessor() 在session.write（）streamCallback内部，我们首先检查是否有任何记录，如果没有任何记录）并写出一个 zero-record 的flowfile。 在那之后，是时候与其他人分开处理第一个记录了。这是因为读者和/或自定义处理器代码可能会从读者的架构中更改作者的架构。例如，在架构推理期间，发生这种情况是自NIFI 1.9.0以来的读者的功能。 然后编写了第一个记录，其余记录的过程仍在继续。最后，填充了基于标准的记录的属性，然后更新流量文件并传输。上面的脚本还包括出现问题时的错误处理。","path":"2024/03/18/使用InvokeScriptedProcessor处理Record/","date":"03-18","excerpt":"","tags":[{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"}]},{"title":"一些有意思的关于NiFi的Blog汇总","text":"NiFi/HDF Dataflow Optimization (Part 1 of 2)NiFi/HDF Dataflow Optimization (Part 2 of 2) 怎么预防系统或者Processor过载运行 使用connection中背压控制 结合ControRate处理器 理解Processors所需的资源 数据流优化的另一个方面是了解每个处理器所需的资源。这将允许更好的数据流执行。例如，CompressContent处理器将使用1个CPU/并发任务，因此，如果该处理器具有4个并发任务，并且队列中有4个文件，则该处理器将使用4个CPU，直到文件被压缩为止。对于小型文件，这比处理大型文件少于资源瓶颈。一个很好的例子是，将中小型，中和大文件都从单独的流路路径沿着3个不同的压缩处理器流动，每个流程都有自己的并发任务数量。在下面的示例中，所有三个CompressContent处理器都有一个并发任务。 该图提供了优化吞吐量的一个很好的例子。每个CompressContent处理器的“ Tasks/Time”清楚地表明，随着文件的增加，压缩较大文件所需的时间呈指数较大。这提供了更好地利用CPU处理最多文件数量，而不是让任意的大文件放慢整个流程。这不是在文档中明确指出的，而是通过压缩NIFI内部或外部文件的唯一方法是使用每个文件使用要在完成操作的系统上使用CPU使用CPU。 请注意，处理器的某些文档指出了当特定处理器具有应意识到的行为时。例如，MemgeContent处理器的文档具有以下行：建议仅使用单个传入连接配置处理器，因为不会从不同连接的FlowFiles创建一组FlowFiles。 FlowFiles的大小和遍历各种数据流路径的流档数量将对某些处理器产生不同的影响。学习阅读有关处理器的信息可以帮助您确定何时何地应用一些或全部讨论的优化策略。 NIFI如何帮助您找到可以优化的位置/如何优化？ 每个处理器提供了大量信息，可以帮助DFM确定故障点在流动中的位置；请参阅下面的描述： In: 根据滑动5分钟的窗口，处理器从其传入连接的队列中取出的数据量。该值表示为 / 其中是已从队列中提取的流file的数量，而是这些FlowFiles内容的总大小。在此示例中，处理器已从输入队列中取出1270个flowfile，总共12.4兆字节（MB）。 Read/Write: 处理器已从磁盘读取并写入磁盘的flowfile内容的总大小。这提供了有关此处理器所需的I/O性能的有价值的信息。有些处理器只能在不编写任何内容的情况下读取数据，而有些则不会读取数据，而只会写数据。其他人则既不读取也不会写数据，而某些处理器则将读取和写入数据。在此示例中，我们看到在过去的五分钟内，该处理器读取了12.4 MB的flowfile，并且还写了12.4 MB。这就是我们期望的，因为该处理器只是将流file的内容复制到磁盘上。 Out： 处理器已转移到其出站连接的数据量。这不包括处理器删除自身的flowfiles，也不包括与自动终止的连接路由的流文件。就像上面的“ In”指标一样，此值表示为 / ，其中是已将其传输到出站连接的flowfile的数量，是这些FlowFiles内容的总大小。在此示例中，所有文件都写入磁盘，并且连接被自动终止，因此没有将文件移出到下游连接。 Tasks/Time： 反映了在过去5分钟内完成运行的任务数量以及这些任务完成的总时间。您可能有1个线程，一个任务需要20分钟才能完成。完成后，将在接下来的5分钟内添加到此累积报告中。时间的格式为&lt; hour&gt;：&lt; minute &gt;：&lt; second &gt;。请注意，所花费的时间可能超过五分钟，因为许多任务可以并行执行。例如，如果安排处理器运行60个并发任务，并且这些任务中的每一个都需要一秒钟才能完成，则所有60个任务可能会在一秒钟内完成。但是，在这种情况下，我们将看到时间指标表明它花了60秒，而不是1秒。 利用处理器提供的信息，读取/写入的数量以及每个任务的任务/时间来查找图表上的“热点”。例如，如果大量任务运行，但是通过处理器传递的数据量较低，则处理器可能被配置为过于频繁或同时执行的任务过多。对于处理器，至少需要更仔细的外观。一个完成任务很少的处理器以及较高的任务时间表明该处理器是CPU密集的。如果数据流量很高，并且处理器显示大量的已完成线程和高任务时间，则可以通过增加处理器调度的运行持续时间（Run Duration）来提高性能。 产生了背压 如果在数据始终始终积压的流程中存在连接，则如果处理数据的任何延迟是不可接受的，则可能是一个关注点。但是，只需在以上的情况下向处理器添加更多并发任务，就可以在图表的另一部分中导致线程饥饿（下面更详细地介绍）。再次在这里，DFM必须注意了解为什么数据在图中的此特定点备份。它只是可以是一个非常密集的处理器，并且在整个图中只有如此多的CPU可使用。这些文件可能对系统非常大，并且可能需要每个文件的读取和写入，这是昂贵的操作。如果资源不是问题，请添加更多的并发任务，看看是否解决了积压的问题。如果资源是问题，则必须重新设计流量以更好地利用可用的内容，否则必须将工作负载分配到多个系统上，这意味着群集两个或多个系统以减少任何一个系统的负载。文件可能是积压的，因为对其进行处理的处理器是I/O密集型。处理器统计信息应显示。检查磁盘；我是/o还是接近100％？添加更多线程不会更快地处理文件，而是会导致线程饥饿。 NiFi线程饥饿 优化的另一个方面是如何配置处理器，使其在流的一个区域占用太多可用资源，然后在流的另一个区域耗尽线程。 假设有一个处理器是CPU和磁盘密集型，需要10个并行的任务来维持日常操作流量。然后对图进行修改以添加需要系统资源的其他数据流。将附加数据流添加到图表后，注意到具有10个并发任务的处理器无法跟上数据速率。因此，将另外5个并发任务添加到处理器中。然后，图上的另一个流开始备份数据，然后将其他并发任务添加到该流程中，依此类推……很快，已将太多并发任务添加到了图中，以至于数据流实际上永远不会获得线程，系统花费了确定哪个处理器应该获得线程的所有资源，但永远不会允许完成任务，并且系统陷入了此周期。 为了防止这种情况发生在数据流程中，每次更新或添加图表之后，DFM应检查系统资源利用率的当前级别。如果更新或添加后，数据开始在以前未看到的流程的点上积压，则更改以某种方式不堪重负，并建议关闭添加的流量，直到它可以确定哪个系统资源正在过度使用。另一个解决方案是通过集群系统将流量平衡在两个或多个系统上。 集群 即使在优化的数据流中，物理资源耗尽也可以而且确实发生。当这种情况发生时，最好的方法是将数据负载分散在NIFI群集中的多个NIFI实例上。 NIFI管理员或DataFlow Manager（DFM）可能会发现，在单个服务器上使用NIFI的一个实例不足以处理其拥有的数据量。因此，一种解决方案是在多个单独的NIFI服务器上运行相同的数据流。但是，这会引起管理问题，因为每次DFM都想更改或更新数据流，它们必须在每个服务器上进行更改，然后单独监视每个服务器。通过聚类NIFI服务器，可以使增加的处理能力以及单个接口进行通过，以使数据流更改并监视数据流。聚类允许DFM仅进行每个更改一次，然后将更改复制到集群的所有节点。通过单个接口，DFM还可以监视所有节点的健康和状态 NIFI集群的设计是一个简单的主/从模型，其中有一个或一个或多个从属。在NIFI群集中，我们将主人称为NIFI群集管理器（NCM），而奴隶称为节点。尽管该模型是主和从属的模型，但如果NCM死亡，则指示节点继续操作，因为它们是为了确保数据流保持生存。NCM的缺失仅表示新节点不能连接群集，并且在恢复NCM之前，不会发生群集流量变化。","path":"2024/03/18/一些有意思的关于NiFi的Blog汇总/","date":"03-18","excerpt":"","tags":[{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"}]},{"title":"NiFi自定义扩展文档","text":"一、 NiFi组件NiFi提供了几个扩展点，使开发人员能够向应用程序添加功能以满足他们的需求。下面的列表提供了最常见扩展点的高级描述 1. Processor处理器接口是NiFi公开对FlowFiles、其属性和内容的访问的机制。处理器是用于组成NiFi数据流的基本元素。该接口用于完成以下所有任务 创建FlowFiles 读取FlowFile内容 写FlowFile内容 读FlowFile属性 更新FlowFile属性 摄取数据 输出数据 路由数据 提取数据 修改数据 2. ReportingTask ReportingTask接口允许将指标、监控信息和内部NiFi状态发布到外部端点，如日志文件、电子邮件和远程web服务。 3. ParameterProviderParameterProvider接口允许外部源提供参数。提供的参数仍然存储在参数上下文中，但是这种机制允许在外部提供和管理它们。 4. ControllerService 在单个JVM中，ControllerService提供跨处理器、其他ControllerServices、参数提供者和reportingtask的共享状态和功能。一个示例用例可能包括将非常大的数据集加载到内存中。通过在ControllerService中执行这项工作，数据可以加载一次，并通过该服务向所有处理器公开，而不是要求许多不同的处理器自己加载数据集。 5. FlowFilePrioritizerFlowFilePrioritizer接口提供了一种机制，通过该机制可以对队列中的FlowFiles进行优先级排序或排序，以便FlowFiles可以按照最有效的顺序处理特定用例。 6. AuthorityProvider AuthorityProvider负责确定应该授予给定用户哪些特权和角色(如果有的话) 二、 Processor API处理器是NiFi中使用最广泛的组件。处理器是唯一被赋予创建、删除、修改或检查FlowFiles(数据和属性)权限的组件。所有的处理器都是使用Java的ServiceLoader机制加载和实例化的。 虽然Processor是一个可以直接实现的接口，但是这样做是非常罕见的，因为org.apache.nifi.processor.AbstractProcessor是几乎所有Processor实现的基类。 AbstractProcessor类提供了大量的功能，这使得开发Processor的任务变得更加容易和方便。在本文的范围内，我们将主要关注处理Processor API时的AbstractProcessor类。 NiFi是一个高度并发的框架。这意味着所有扩展都必须是线程安全的。如果不熟悉用Java编写并发软件，强烈建议您熟悉Java并发原则。 为了理解Processor API，我们必须首先理解几个支持类和接口。 FlowFile FlowFile是一个逻辑概念，它将一段数据与一组关于该数据的属性相关联。这些属性包括FlowFile的唯一标识符，以及它的名称、大小和任何其他特定于流的值。虽然FlowFile的内容和属性可以改变，但FlowFile对象是不可变的。对FlowFile的修改可以通过ProcessSession实现。 FlowFiles的核心属性定义在org.apache.nifi.flowfile.attributes.CoreAttributes enum中。 Filename (filename): FlowFile的文件名。文件名不应包含任何目录结构 UUID (uuid):分配给该FlowFile的通用唯一标识符，用于将该FlowFile与系统中的其他FlowFile区分开来。 路径(path): FlowFile的路径是指FlowFile所属的相对目录，不包含文件名。 绝对路径( absolute.path ): FlowFile的绝对路径是指FlowFile所属的绝对目录，不包含文件名。 优先级( priority ):表示FlowFile优先级的数值。 MIME Type ( mime.type ):这个流文件的MIME类型。 丢弃原因( discard.reason ):指定FlowFile被丢弃的原因。 替代标识符( alternate.identifier ):指示FlowFile的UUID之外的标识符，已知该标识符引用该FlowFile。 其他的公共属性： 虽然这些属性不是CoreAttributes枚举的成员，但它们实际上是整个系统的标准，并且可以在大多数FlowFiles中找到。 文件大小(fileSize): FlowFile内容的大小，单位为字节。 输入日期(entryDate): FlowFile进入系统(即创建)的日期和时间。此属性的值是一个数字，表示从1970年1月1日午夜(UTC)开始的毫秒数。 血统开始日期(lineageStartDate):任何时候，一个FlowFile被克隆，合并，或者分割，这将导致一个“子”FlowFile被创建。当这些子代被克隆、合并或分裂时，一个祖先链就建立起来了。该值表示最早的祖先进入系统的日期和时间。考虑这个问题的另一种方式是，该属性表示FlowFile通过系统的延迟。取值为数字，表示从1970年1月1日午夜(UTC)开始的毫秒数。 ProcessSessionProcessSession(通常简称为“会话”)提供了一种机制，通过该机制可以创建、销毁、检查、克隆FlowFiles，并将其传输到其他处理器。此外，ProcessSession提供了通过添加或删除属性或修改FlowFile的内容来创建修改版本的FlowFiles的机制。ProcessSession还公开了一种发出出处事件（ Provenance Events ）的机制，该机制提供了跟踪FlowFile沿袭和历史的能力。 在对一个或多个FlowFiles执行操作后，ProcessSession可以提交或回滚。 ProcessContextProcessContext提供了处理器和框架之间的桥梁。它提供有关处理器当前如何配置的信息，并允许处理器执行特定于框架的任务， 比如释放自己的资源，这样框架就可以在不消耗不必要资源的情况下调度其他处理器运行。 PropertyDescriptorPropertyDescriptor定义了一个属性，该属性将被Processor、ReportingTask、ParameterProvider或ControllerService使用。属性的定义包括其名称、属性描述、可选的默认值、验证逻辑和指示说明是否需要该属性才能使Processor有效。PropertyDescriptor是通过实例化PropertyDescriptor的实例来创建的。构造器类，调用适当的方法来填充有关属性的详细信息，最后调用构建方法。 Validator属性描述符必须指定一个或多个验证器，用于确保用户输入的属性值是有效的。如果Validator指示属性值无效，则在该属性变为有效之前，组件将无法运行或使用。如果没有指定Validator，组件将被认为是无效的，NiFi将报告不支持该属性。 ValidationContext当验证属性值时，ValidationContext可以用来获取ControllerServices，创建PropertyValue对象，并使用表达式语言编译和计算属性值。 PropertyValue返回给Processor的所有属性值都以PropertyValue对象的形式返回。该对象具有将值从String转换为其他形式(如数字和时间段)的方便方法，并提供用于求值Expression Language的API。 Relationship关系定义了FlowFile可以从处理器传输到的路由。通过实例化Relationship的实例来 Relationship.Builder ，调用适当的方法来填充关系的详细信息，最后调用构建方法。 StateManager StateManager为处理器、报告任务和控制器服务提供了一种容易存储和检索状态的机制， 该API类似于ConcurrentHashMap，但每个操作都需要一个Scope。 这个Scope表示这个state是存在本地还是集群维度的。 ProcessorInitializationContext在创建了一个Processor之后，它的initialize方法将被InitializationContext对象调用。该对象向处理器公开在整个处理器生命周期中不会改变的配置，例如处理器的唯一标识符。 ComponentLog建议处理器通过ComponentLog接口执行日志记录，而不是获取第三方日志记录器的直接实例。这是因为通过ComponentLog进行日志记录允许框架将超过可配置严重性级别的日志消息呈现给用户界面，从而允许在发生重要事件时通知监视数据流的人员。此外，它通过在DEBUG模式下记录堆栈跟踪并在日志消息中提供处理器的唯一标识符，为所有处理器提供一致的日志记录格式。 三、AbstractProcessor API由于绝大多数处理器将通过扩展AbstractProcessor来创建，因此我们将在本节中研究抽象类。AbstractProcessor提供了几个处理器开发人员会感兴趣的方法。 1、 处理器初始化 在创建Processor之后，在调用任何其他方法之前，将调用AbstractProcessor的init方法。 该方法接受一个参数，类型为ProcessorInitializationContext。 上下文对象向处理器提供一个ComponentLog、处理器的唯一标识符和一个 ControllerServiceLookup (可用于与已配置的ControllerServices交互)。这些对象中的每一个都由AbstractProcessor存储，并且可以由子类分别通过getLogger、getIdentifier和getControllerservicellookup方法获得。 2、 暴露处理器属性大多数处理器在使用之前都需要一定数量的用户配置。 处理器支持的属性通过getSupportedPropertyDescriptors方法公开给框架。 此方法不接受任何参数，并返回PropertyDescriptor对象的列表。列表中对象的顺序很重要，因为它决定了属性在用户界面中呈现的顺序。 动态处理器属性 除了标准属性之外，有时还希望允许用户配置名称不是预定义的其他属性。 这可以通过覆盖getSupportedDynamicPropertyDescriptor方法来实现。 此方法接受String作为其唯一参数，该参数指示属性的名称。该方法返回一个PropertyDescriptor对象，该对象可用于验证属性的名称和值。 从这个方法返回的任何PropertyDescriptor都应该在PropertyDescriptor中设置isDynamic的值为true。。AbstractProcessor的默认行为是不允许任何动态创建的属性。 敏感动态属性动态属性的默认实现不将属性值视为敏感值。在配置FlowFile属性或自定义表达式等特性时，这种方法是足够的，但它不能为密码或密钥等值提供保护。 NiFi 1.17.0通过一个名为SupportsSensitiveDynamicProperties的注解引入了对敏感动态属性的框架支持。注释可以通过getSupportedDynamicPropertyDescriptor方法应用于支持动态属性的处理器、控制器服务或报告任务。注释表明组件允许将单个动态属性标记为敏感属性，以用于持久化和框架处理。 getSupportedDynamicPropertyDescriptor必须返回一个 sensitive 设置为false的PropertyDescriptor，以允许自定义敏感状态。在此方法中将敏感字段设置为true将强制将所有动态属性作为敏感属性处理。这种方法允许在受支持的组件中升级敏感状态，但不降级。 敏感属性值的安全处理是带注释的类的责任。支持敏感动态属性的组件不能记录属性值或将属性值作为FlowFile属性提供。 3、 验证处理器属性如果处理器的配置无效，则处理器无法启动。 处理器属性的验证可以通过在PropertyDescriptor上设置Validator或通过PropertyDescriptor限制属性的允许值来实现。Builder的allowableValues方法或identifiesControllerService方法。 此外，如果一个属性依赖于另一个属性( PropertyDescriptor.Builder’s dependsOn` method ），切不满足的话则会被校验住。 1234567PropertyDescriptor USE_FILE = new PropertyDescriptor.Buildler() .name(&quot;Use File&quot;) .displayName(&quot;Use File&quot;) .required(true) .allowableValues(&quot;true&quot;, &quot;false&quot;) .defaultValue(&quot;true&quot;) .build(); 或者 1234567PropertyDescriptor FILE = new PropertyDescriptor.Builder() .name(&quot;File to Use&quot;) .displayName(&quot;File to Use&quot;) .required(true) .addValidator(StandardValidators.FILE_EXISTS_VALIDATOR) .dependsOn(USE_FILE, &quot;true&quot;) .build(); 有时单独验证一个Processor的属性是不够的。为此，AbstractProcessor公开了一个customValidate方法。该方法接受ValidationContext类型的单个参数。这个方法的返回值是一个ValidationResult对象的集合，它描述了在验证过程中发现的任何问题。只有那些isValid方法返回false的ValidationResult对象才应该被返回。 只有当所有属性根据其关联的验证器和允许值都有效时，才会调用此方法。也就是说，只有当所有属性本身都有效时，这个方法才会被调用，并且这个方法允许将处理器的配置作为一个整体进行验证。 4、响应配置中的更改 有时，当处理器的属性发生变化时，我们希望它立即做出反应。 onPropertyModified方法允许处理器这样做。当用户更改处理器的属性值时，将为每个修改的属性调用onPropertyModified方法。 该方法接受三个参数:PropertyDescriptor(表示修改了哪个属性、旧值和新值。 如果属性之前没有值，第二个参数将为空。 如果该属性被删除，则第三个参数将为空。重要的是要注意，无论值是否有效，都会调用此方法。这个方法将只在值被实际修改时调用，而不是在用户更新处理器而不更改其值时调用。在调用此方法时，可以保证调用此方法的线程是当前在处理器中执行代码的唯一线程，除非处理器本身创建了自己的线程。 5、 执行工作 当处理器有工作要做时，它通过框架调用它的onTrigger方法来进行调度。 该方法有两个参数:一个ProcessContext和一个ProcessSession。onTrigger方法的第一步通常是通过调用ProcessSession上的get方法来获取要在其上执行工作的FlowFile。 对于从外部源摄取数据到NiFi的处理器，跳过此步骤。然后处理器可以自由地检查FlowFile属性;添加、删除或修改属性;读取或修改FlowFile内容;并将FlowFiles传输到适当的关系。 6、 处理器何时被触发处理器的onTrigger方法只有在计划运行时才会被调用，并且处理器有工作要做。如果满足以下任何一个条件，就称处理器存在工作 目标是处理器的连接在其队列中至少有一个FlowFile 处理器没有传入连接 处理器用@TriggerWhenEmpty注释 有几个因素会影响处理器的onTrigger方法何时被调用。 首先，除非用户已将Processor配置为运行，否则不会触发Processor。如果处理器被安排运行，框架会定期(周期由用户在用户界面中配置)检查处理器是否有工作要做。如果是，框架将检查处理器的下游目的地。 如果处理器的任何出站连接已满，默认情况下，处理器将不会被安排运行。 但是，@TriggerWhenAnyDestinationAvailable注释可以添加到Processor的类中。 在这种情况下，需求被更改为只有一个下游目的地必须是“可用的”(如果Connection队列未满，则认为目的地是“可用的”)，而不是要求所有下游目的地都可用。 与处理器调度相关的还有 @TriggerSerially 注释。使用此注释的处理器永远不会有多个线程同时运行onTrigger方法。但是，需要注意的是，执行代码的线程在调用之间可能会发生变化。因此，仍然必须小心确保处理器是线程安全的 7、组件生命周期@OnAdded @OnAdded注释会在创建组件时立即调用一个方法 ， initialize 方法将在组件构造之后被调用，然后是带有@OnAdded注释的方法。 该方法在组件的生命周期中只会被调用一次。带有此注释的方法必须不带参数。 @OnEnabled @OnEnabled注释可以用来指示一个方法应该在控制器服务被启用时被调用。 任何具有此注释的方法都会在每次用户启用该服务时被调用。此外，每次重启NiFi时，如果将NiFi配置为“ auto-resume state ”并且启用了服务，则将调用该方法。 如果带有此注释的方法抛出Throwable，则将为该组件发出一条日志消息和公告。在这种情况下，服务将保持在“ ENABLING ”状态，并且将不可用。带有此注释的所有方法将在延迟后再次调用。在所有带有此注释的方法都返回而不抛出任何东西之前，该服务将无法使用。 @OnRemoved @OnRemoved注释导致在组件从流中移除之前调用一个方法。这允许在删除组件之前清理资源。带有此注释的方法必须不带参数。如果带有此注释的方法抛出异常，该组件仍将被删除。 @OnScheduled 每次计划运行组件时都应调用该方法。因为ControllerServices没有被调度，所以在ControllerService上使用这个注释是没有意义的。 它应该仅用于处理器和 Reporting Tasks 。如果具有此注释的任何方法抛出Exception，则不会调用具有此注释的其他方法，并将向用户显示通知。 在这种情况下，然后触发带有@OnUnscheduled注释的方法，然后触发带有@OnStopped注释的方法(在此状态下，如果这些方法中的任何一个抛出异常，这些异常将被忽略)。 然后，该组件将在一段时间内执行，这段时间称为“Administrative yield Duration”，这是在nifi中配置的一个值。 最后，进程将再次启动，直到所有带@OnScheduled注释的方法都返回而不抛出任何异常。 带有此注释的方法可以不带参数，也可以只带一个参数。如果使用单个参数变体，如果组件是Processor，则参数必须是ProcessContext类型，如果组件是ReportingTask，则参数必须是ConfigurationContext类型。 @OnUnscheduled每当处理器或ReportingTask不再调度运行时，将调用带有此注释的方法。此时，在Processor的onTrigger方法中可能仍有许多线程处于活动状态。如果这样的方法抛出异常，将生成一条日志消息，否则将忽略该异常，并且仍将调用带有此注释的其他方法。带有此注释的方法可以不带参数，也可以只带一个参数。如果使用单个参数变体，如果组件是Processor或ConfigurationContext，则参数必须是ProcessContext类型 @OnStopped 当处理器或ReportingTask不再调度运行并且所有线程都从onTrigger方法返回时，将调用带有此注释的方法。如果这样的方法抛出异常，将生成一条日志消息，否则该异常将被忽略;使用此注释的其他方法仍将被调用。带有此注释的方法允许接受0或1个参数。如果使用了参数，如果组件是ReportingTask，则参数的类型必须是ConfigurationContext;如果组件是Processor，则参数的类型必须是ProcessContext。 @OnShutdown任何带有@OnShutdown注释的方法都将在NiFi成功关闭时被调用。如果这样的方法抛出异常，将生成一条日志消息，否则将忽略该异常，并且仍将调用带有此注释的其他方法。带有此注释的方法必须不带参数。注意:虽然NiFi将尝试在使用它的所有组件上调用带有此注释的方法，但这并不总是可能的。 例如，进程可能意外终止，在这种情况下，它没有机会调用这些方法。因此，虽然使用此注释的方法可用于清理资源，但不应依赖于关键业务逻辑。 8、组件通知@OnPrimaryNodeStateChange @OnPrimaryNodeStateChange注释会在集群中主节点的状态发生变化时立即调用方法。带有此注释的方法要么不带参数，要么只带一个PrimaryNodeState类型的参数。PrimaryNodeState提供有关更改内容的上下文，以便组件可以采取适当的操作。PrimaryNodeState枚举器有两种可能的值:ELECTED PRIMARY NODE(接收此状态的节点已被选为NiFi集群的主节点)或PRIMARY NODE REVOKED( 接收此状态的节点是主节点，但现在其主节点角色已被撤销) 9.、约束组件受限制的组件是可用于执行操作员通过NIFI REST API/UI提供的任意不固定的代码，或者可以使用NIFI OS凭据在NIFI主机系统上获取或更改数据。 这些组件可以被授权的NiFi用户用于超出应用程序的预期用途，升级特权，或者可能暴露有关NiFi进程或主机系统内部的数据。所有这些功能都应该被认为是特权的，管理员应该知道这些功能，并为一部分受信任的用户显式地启用它们。 处理器、控制器服务或报告任务可以使用@Restricted注释进行标记。这将导致组件被视为受限组件，并且需要将用户显式地添加到可以访问受限组件的用户列表中。一旦用户被允许访问受限制的组件，他们将被允许创建和修改这些组件，假设所有其他权限都被允许。如果不能访问受限制的组件，用户仍然会知道这些类型的组件的存在，但即使有其他足够的条件，也无法创建或修改它们。 10、状态管理从ProcessContext、ReportingContext和ControllerServiceInitializationContext中，组件可以调用getStateManager()方法。这个状态管理器负责提供一个简单的API来存储和检索状态。 该机制旨在使开发人员能够轻松地存储一组密钥/值对，检索这些值并原子更新它们。该状态可以在群集中局部存储在节点上，也可以在所有节点中存储。 然而，需要注意的是，该机制的目的只是提供一种存储非常“简单”状态的机制。 因此，API只允许存储和检索Map&lt;String, String&gt;，并自动替换整个Map。此外，目前唯一支持存储集群范围状态的实现是由ZooKeeper支持的。 因此，在序列化之后，整个State Map的大小必须小于1mb。试图存储超过此值将导致抛出异常。如果处理器管理状态所需的交互比这更复杂(例如，必须存储和检索大量数据，或者必须单独存储和获取单个键)，则应该使用不同的机制(例如，与外部数据库通信)。 Scope当与状态管理器通信时，所有方法调用都需要提供Scope。这个Scope将是Scope.LOCAL或Scope.CLUSTER。如果NiFi在集群中运行，则此Scope向框架提供有关操作应该如何发生的重要信息。 如果状态使用 Scope.CLUSTER 存储。集群中的所有节点都将使用相同的状态存储机制进行通信。如果使用 Scope.LOCAL ，那么每个节点将看到状态的不同表示。 还值得注意的是，如果将NiFi配置为作为独立实例运行，而不是在集群中运行，则 Scope总是使用Scope.LOCAL。这样做是为了允许NiFi组件的开发人员以一种一致的方式编写代码，而不必担心NiFi实例是否集群。相反，开发人员应该假设实例是集群的，并相应地编写代码。 11. 报告处理器的活动 处理器负责报告其活动，以便用户能够了解其数据发生了什么。处理器应通过ComponentLog记录事件，该事件可通过初始化访问或调用AbstractProcessor的GetLogger方法访问。 此外，处理器应使用通过ProcessSession的 getProvenanceReporter 方法获得的 ProvenanceReporter 接口。 ProvenanceReporter应该用于指示从外部源接收内容或将内容发送到外部位置的任何时间。 ProvenanceReTorter还具有报告何时克隆，分叉或修改的流文件以及将多个流文件合并到单个流纸上以及将流纸与其他一些标识符关联的方法。 但是，这些功能不太重要，因为该框架能够检测到这些内容并代表处理器发出适当的事件。 然而，对于处理器开发人员来说，发出这些事件是最佳实践，因为它在代码中变得明确说明这些事件正在发出，并且开发人员能够为事件提供其他细节，例如该动作采取了有关所采取的措施的信息。 如果处理器发出事件，则该框架将不会发出重复的事件。相反，它总是假设处理器开发人员比框架更了解处理器上下文中发生的事情。 但是，框架可能会发出另一个事件。例如，如果处理器对FlowFile的内容及其属性进行修改，然后仅发射 ATTRIBUTES_MODIFIED 事件，则该框架将发出 CONTENT_MODIFIED 事件。","path":"2024/02/24/NiFi自定义扩展文档/","date":"02-24","excerpt":"","tags":[{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"},{"name":"文档","slug":"文档","permalink":"https://castile.github.io/tags/%E6%96%87%E6%A1%A3/"}]},{"title":"无状态的NiFi","text":"介绍Apache NiFi应用程序可以被认为是两个独立但相互交织的组件:流作者组件和流引擎。通过将这两个组件集成到一个应用程序中，NiFi允许用户创建数据流并在同一个用户界面中实时运行它。 然而，这两个概念是可以分开的。NiFi可以用来创建流，然后不仅可以由NiFi运行，还可以由其他兼容的数据流引擎运行。Apache NiFi项目提供了几个这样的数据流引擎:Apache NiFi本身、MiNiFi Java (Apache NiFi的一个子项目)、MiNiFi c++ (Apache NiFi的一个子项目)和无状态NiFi 这些数据流引擎中的每一个都有自己的优点和缺点，因此它们有自己最擅长解决的特定用例。本文将介绍无状态NiFi是什么，如何使用它，以及它的优点和缺点 传统的NiFiNiFi被设计为作为大型多租户应用程序运行。它努力充分利用提供给它的所有资源，包括磁盘/存储和许多线程。通常，单个NiFi实例跨许多不同的节点集群，形成一个大型的内聚数据流，该数据流可能由许多不同的子流组成。一般来说，NiFi将承担交付给它的数据的所有权。它将数据可靠地存储在磁盘上，直到它被传递到所有必要的目的地。此数据的交付可以在流中的不同位置进行优先级排序，以便将对特定目的地最重要的数据首先交付到该目的地，而相同的数据可以根据优先级以不同的顺序交付到另一个目的地。NiFi在完成所有这些工作的同时，保持非常细粒度的沿袭，并保持流中每个组件所看到的数据缓冲区(数据沿袭和数据滚动缓冲区的组合称为data Provenance)。 这些特性中的每一个都非常重要，可以提供一个非常强大、广泛、全面的视图，了解数据是如何在企业上操作和流经企业的。然而，在一些用例中，更轻量级的应用程序可以更好地服务于这些用例。一个能够与NiFi可以交互的所有不同端点进行交互的应用程序，并执行NiFi可以执行的所有转换、路由、过滤和处理。但是一个应用程序被设计为只运行一个小的子流，而不是一个有许多源和汇的大数据流。 无状态NiFi进入无状态NiFi(在本文档中也简称为“无状态”)。无状态NiFi中的许多概念与典型的Apache NiFi引擎中的概念不同。 无状态提供了一个占用空间更小的数据流引擎。它不包括用于编写或监视数据流的用户界面，而是运行使用NiFi应用程序编写的数据流。NiFi在能够访问快速存储(如SSD和NVMe驱动器)时表现最佳，而Stateless则将所有数据存储在内存中。 这意味着如果无状态NiFi停止，它将不再能够直接访问正在运行的数据。因此，无状态应该只用于数据源可靠且可重放的数据流，或者数据丢失不是关键问题的场景。 一个非常常见的用例是让无状态NiFi从Apache Kafka或JMS读取数据，然后执行一些路由/过滤/操作，最后将数据传递到另一个目的地。如果像这样的数据流要在NiFi中运行，那么数据将从源被消耗，写入NiFi的内部存储库，并得到确认，因此NiFi将获得该数据的所有权。然后，它将负责将其传递到所有目的地，即使应用程序重新启动也是如此。 但是，使用无状态NiFi，数据将被使用，然后传输到流中的下一个处理器。数据不会被写入任何类型的内部存储库，也不会被确认。流中的下一个处理器将处理数据，然后将其传递下去。只有当数据到达整个数据流的末端时，才会确认从源接收到的数据。如果在处理完成之前重新启动Stateless，则数据尚未得到确认，因此只是再次使用它。这允许在内存中处理数据，而不必担心数据丢失，但它也让源承担了可靠地存储数据并使数据可重放的责任。 可兼容的数据流如上所述，无状态NiFi要求数据源既可靠又可重放。这限制了无状态可以合理交互的源。此外，对于无状态引擎能够运行的数据流，还有一些其他限制。 1、 单一来源、单一目标在无状态状态下运行的每个数据流应该保持在单个源和单个接收器或目的地。由于Stateless不存储它正在处理的数据，也不存储元数据，例如数据流中数据排队的位置，因此将单个FlowFile发送到多个目的地可能导致数据重复。 考虑一个流，其中数据从Apache Kafka消费，然后交付到HDFS和S3。如果数据存储在HDFS中，然后存储到S3失败，则整个会话将被回滚，并且必须再次使用数据。因此，数据可能会被第二次消费并交付给HDFS。如果这种情况继续发生，数据将继续从Kafka提取并存储在HDFS中。根据目的地和流配置，这可能不是一个问题(除了浪费资源之外)，但在许多情况下，这是一个重要的问题。 因此，如果要使用无状态引擎运行数据流，那么应该将这样的数据流分解为两个不同的数据流。第一个将数据从Apache Kafka传送到HDFS，另一个将数据从Apache Kafka传送到S3。每个数据流都应该为Kafka使用一个单独的Consumer Group，这将导致每个数据流获得相同数据的副本 2、对合并的支持可能有限由于无状态NiFi中的数据从头到尾同步地通过数据流传输，因此使用需要多个flowfile(如MergeContent和MergeRecord)的处理器可能无法接收成功所需的所有数据。如果处理器有数据排队并被触发，但没有取得任何进展，则无状态引擎将再次触发源处理器，以便向处理器提供额外的数据 然而，这可能导致数据不断被引入的情况，这取决于处理器的行为。为了避免这种情况，可以通过配置限制可能带入数据流的单个调用的数据量。如果数据流配置将每次调用的数据量限制为10 MB，但是配置了MergeContent直到至少有100 MB的可用数据才创建bin，则数据流将继续触发MergeContent运行，而不进行任何进展，直到达到最大bin年龄(如果配置)或数据流超时。 此外，根据运行Stateless的上下文，触发源组件可能不会提供额外的数据。例如，如果在数据在输入端口中排队，然后触发数据流的环境中运行无状态，则随后触发输入端口运行将不会产生额外的数据 因此，确保任何包含合并FlowFiles逻辑的数据流都配置了MergeContent和MergeRecord的最大Bin Age是很重要的。 3、故障处理在传统的NiFi中，将从给定处理器的“失败”连接循环回同一处理器是很常见的。这导致处理器不断尝试处理FlowFile，直到它成功为止。这可能非常重要，因为通常一个NiFi接收数据，它负责获得该数据的所有权，并且必须能够保存该数据，直到下游服务能够接收它并随后交付该数据。 然而，对于无状态NiFi，假定数据源既可靠又可重放。此外，根据设计，无状态NiFi在重启后不会保存数据。因此，对故障处理的考虑可能会有所不同。使用无状态NiFi，如果无法将数据传递到下游系统，通常最好将FlowFile路由到输出端口，然后将输出端口标记为故障端口(参见下面的[失败端口](#failure- Ports)了解更多信息)。 4、流不应该加载大量文件在传统的NiFi中，FlowFile内容存储在磁盘上，而不是内存中。因此，它能够处理任何大小的数据，只要它适合磁盘。然而，在无状态中，FlowFile内容存储在内存中，在JVM堆中。因此，通常不建议尝试将大量文件(例如100 GB数据集)加载到无状态NiFi中。这样做通常会导致OutOfMemoryError，或者至少会导致大量垃圾收集，从而降低性能。 特性对比如上所述，无状态NiFi提供了一组不同于传统NiFi的特性和权衡。在这里，我们总结一下关键的区别。这种比较并不详尽，但可以快速了解这两个运行时是如何运行的。| Feature | Traditional NiFi | Stateless NiFi ||———|——————|—————-|| 数据持久性 | 数据可靠地存储在磁盘上的FlowFile和Content Repositories中 | 数据存储在内存中，必须在重新启动时再次从源端使用 || 数据排序 | 数据在每个连接中根据选择的优先级排序独立排序 | 数据按照接收到的顺序在系统中流动(先进先出/ FIFO) || Site-to-Site | 支持完整的Site-to-Site功能，包括服务器和客户端角色 | 可以向NiFi实例推送或从NiFi实例拉取，但不能接收传入的站点到站点连接。也就是说，作为客户端而不是服务器工作 || Form Factor | 旨在利用多个内核和磁盘的优势 | 轻巧的外形因素。很容易嵌入到另一个应用程序。单线程处理 || Heap Considerations | 通常，许多用户正在使用许多处理器。不应该将FlowFile内容加载到堆中，因为它很容易导致堆耗尽 | 较小的数据流使用较少的堆。Flow一次只对一个或几个FlowFile进行操作，并将FlowFile的内容保存在Java堆的内存中。 || Data Provenance | 完全存储、索引的数据来源，可以通过UI浏览并通过Reporting Tasks导出 | 有限的数据来源功能，事件存储在内存中。无法查看，但可以使用Reporting Tasks导出。但是，由于它们在内存中，因此它们将在重新启动时丢失，并且可能在导出之前滚出 || 嵌入性 | 虽然在技术上可以嵌入传统的NiFi，但不建议这样做，因为它会启动一个重量级的用户界面，处理复杂的身份验证和授权，以及几个基于文件的外部依赖项，这可能很难管理 | 具有最小的外部依赖关系(包含扩展的目录和用于临时存储的工作目录)，并且更易于管理。可嵌入性是无状态NiFi的一个重要特性。 |","path":"2023/11/26/Stateless-NiFi/","date":"11-26","excerpt":"","tags":[{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"},{"name":"Stateless","slug":"Stateless","permalink":"https://castile.github.io/tags/Stateless/"}]},{"title":"NiFi身份验证与授权验证（2）","text":"授权验证（Authorization）概述访问Nifi界面相当于你想进入一个商业写字楼，门口保安可能会拦住你要查看你的身份证（身份验证）。现在保安从身份证上知道了我们的名字（身份验证成功），但是他依然需要确定你是在这个写字楼工作才能让你进去。为此他查找大楼员工花名册（授权验证）。只有当你的名字出现在名册上时你才会被放行。 Nifi授权验证模块与两个数据库有关：一个是授权用户身份数据库（UserGroupProvider），另一个是用户权限数据库（AccessPolicyProvider） 其中，UserGroupProvider里面列出了所有被授权用户的用户名。只有在这个数据库里面的用户名才真正有权限使用Nifi。而AccessPolicyProvider里面列出了这些被授权用户以及他们所获得的权限之间的一一对应关系。 因此，Nifi的授权验证模块需要做的，就是先拿从身份验证模块得来的用户名与UserGroupProvider里的用户名做核对，看是否能找到对应的条目。如果有，再到AccessPolicyProvider里查看该用户有哪些权限。 接下来，我们就看看，在Nifi当中是怎么对UserGroupProvider和AccessPolicyProvider进行设置的。 授权验证设置Nifi 会在./conf/authorizers.xml这个文件中寻找UserGroupProvider和AccessPolicyProvider的设置。 12345678910111213141516171819202122232425262728293031&lt;authorizers&gt; &lt;userGroupProvider&gt; &lt;identifier&gt;file-user-group-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.FileUserGroupProvider&lt;/class&gt; &lt;property name=&quot;Users File&quot;&gt;./conf/users.xml&lt;/property&gt; &lt;property name=&quot;Legacy Authorized Users File&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Initial User Identity 1&quot;&gt;CN=castile-nifi, OU=nifi&lt;/property&gt; &lt;/userGroupProvider&gt; &lt;accessPolicyProvider&gt; &lt;identifier&gt;file-access-policy-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.FileAccessPolicyProvider&lt;/class&gt; &lt;property name=&quot;User Group Provider&quot;&gt;file-user-group-provider&lt;/property&gt; &lt;property name=&quot;Authorizations File&quot;&gt;./conf/authorizations.xml&lt;/property&gt; &lt;property name=&quot;Initial Admin Identity&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Legacy Authorized Users File&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Identity 1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Group&quot;&gt;&lt;/property&gt; &lt;/accessPolicyProvider&gt;&lt;authorizer&gt; &lt;identifier&gt;managed-authorizer&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.StandardManagedAuthorizer&lt;/class&gt; &lt;property name=&quot;Access Policy Provider&quot;&gt;file-access-policy-provider&lt;/property&gt; &lt;/authorizer&gt;&lt;/authorizers&gt; 1、 UserGroupProvider 设置FileUserGroupProvider的使用最为简单，其本质是把所有授权用户名都存在一个文件里面。在./conf/authorizers.xml文件中与FileUserGroupProvider相关的有以下条目： 这个文件储存用户名的文件默认是./conf/users.xml。它可以有类似以下内容 1234567&lt;tenants&gt; &lt;groups/&gt; &lt;users&gt; &lt;user identifier=&quot;66fa993d-f882-396e-bc79-3ff4b6994470&quot; identity=&quot;CN=castile-nifi, OU=nifi&quot;/&gt; &lt;/users&gt;&lt;/tenants&gt; 里面配置一些用户的信息 2、 AccessPolicyProvider 设置 Nifi自带AccessPolicyProvider是FileAccessPolicyProvider。在authorizers.xml中相关的设置有以下的条目： 12345678910&lt;accessPolicyProvider&gt; &lt;identifier&gt;file-access-policy-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.FileAccessPolicyProvider&lt;/class&gt; &lt;property name=&quot;User Group Provider&quot;&gt;file-user-group-provider&lt;/property&gt; &lt;property name=&quot;Authorizations File&quot;&gt;./conf/authorizations.xml&lt;/property&gt; &lt;property name=&quot;Initial Admin Identity&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Legacy Authorized Users File&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Identity 1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Group&quot;&gt;&lt;/property&gt;&lt;/accessPolicyProvider&gt; 可以看到，在属性User Group Provider中我们指定了使用哪一个UserGroupProvider。而Authorizations File指定了权限数据都存在哪个文件，默认是./conf/authorizations.xml。这个文件中有类似以下的内容： 12345678910111213&lt;authorizations&gt; &lt;policies&gt; &lt;policy identifier=&quot;f99bccd1-a30e-3e4a-98a2-dbc708edc67f&quot; resource=&quot;/flow&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;3fbc23d1-30d2-3068-ba89-9066202e13d7&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;b8775bd4-704a-34c6-987b-84f2daf7a515&quot; resource=&quot;/restricted-components&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;3fbc23d1-30d2-3068-ba89-9066202e13d7&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;ff96062a-fa99-36dc-9942-0f6442ae7212&quot; resource=&quot;/policies&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;3fbc23d1-30d2-3068-ba89-9066202e13d7&quot;/&gt; &lt;/policy&gt; &lt;/policies&gt;&lt;/authorizations&gt; 在这个文件中列出了每一条的权限（Policy），而每条权限都对应一个用户，这样形成了一一对应的关系，而Nifi也能够因此确定每个用户拥有什么权限。 3、 Authorizer设置12345&lt;authorizer&gt; &lt;identifier&gt;managed-authorizer&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.StandardManagedAuthorizer&lt;/class&gt; &lt;property name=&quot;Access Policy Provider&quot;&gt;file-access-policy-provider&lt;/property&gt; &lt;/authorizer&gt; Nifi自带有managed-authorizer和single-user-authorizer，注意我们要在这里指定AccessPolicyProvider。然后，在nifi.properties中，我们要在以下属性指定我们需要用的authorizer: 123nifi.security.user.authorizer=managed-authorizer 或者：nifi.security.user.authorizer=single-user-authorizer 这样，我们就告诉了Nifi我们使用的是managed-authorizer，然后managed-authorizer又指定了使用的AccessPolicyProvider，而AccessPolicyProvider又指定了所使用的UserGroupProvider。整个权限验证模块的设置就是这样子被串了起来。 多用户授权在生产环境中推荐使用nifi.security.user.authorizer=managed-authorizer , 这样可以为多个用户登录nifi并设置相应的权限。 在user.xml添加一个用户，并不设置任何权限 我们是要手动添加条目到./conf/users.xml和./conf/authorizations.xml吗？并不需要，我们可以通过在Nifi的UI界面操作来添加。不过，首先你得有一个管理员账号来登录进Nifi界面才行。无论你采用哪种身份验证方法，对于一个新的加密Nifi，你必须在authorizers.xml的AccessPolicyProvider中找到这一项： 1&lt;property name=&quot;Initial Admin Identity&quot;&gt;&lt;/property&gt; 把你的用户名添加进去即可： 1234567891011&lt;accessPolicyProvider&gt; &lt;identifier&gt;file-access-policy-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.FileAccessPolicyProvider&lt;/class&gt; &lt;property name=&quot;User Group Provider&quot;&gt;file-user-group-provider&lt;/property&gt; &lt;property name=&quot;Authorizations File&quot;&gt;./conf/authorizations.xml&lt;/property&gt; &lt;property name=&quot;Initial Admin Identity&quot;&gt;admin&lt;/property&gt; &lt;property name=&quot;Legacy Authorized Users File&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Identity 1&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Node Group&quot;&gt;&lt;/property&gt; &lt;/accessPolicyProvider&gt; 配置Initial User Identity 1： admin 12345678910 &lt;userGroupProvider&gt; &lt;identifier&gt;file-user-group-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authorization.FileUserGroupProvider&lt;/class&gt; &lt;property name=&quot;Users File&quot;&gt;./conf/users.xml&lt;/property&gt; &lt;property name=&quot;Legacy Authorized Users File&quot;&gt;&lt;/property&gt; &lt;property name=&quot;Initial User Identity 1&quot;&gt;admin&lt;/property&gt;&lt;!-- &lt;property name=&quot;Initial User Identity 1&quot;&gt;CN=admin, OU=nifi&lt;/property&gt; --&gt; &lt;/userGroupProvider&gt; 保存，重启Nifi。当你再次访问UI时就发现，关于权限的错误已经消除，主界面也可以进去了。实际上，当你添加了Initial Admin Identity并重启后，Nifi在后台把这名用户添加到了users.xml中，并且在authorizations.xml中添加了一些基础的权限。 user.xml中： 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;&lt;tenants&gt; &lt;groups/&gt; &lt;users&gt; &lt;user identifier=&quot;admin&quot; identity=&quot;admin&quot;/&gt; &lt;!-- &lt;user identifier=&quot;6743d555-1f60-343a-9038-0be6fdcbf33b&quot; identity=&quot;CN=admin, OU=nifi&quot;/&gt; --&gt; &lt;/users&gt;&lt;/tenants&gt; 当你使用初始管理员账号进入Nifi以后，你会发现大部分的地方都是灰色的，你基本没法做任何操作（下图） authorizations.xml中的配置湖自动生成： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;authorizations&gt; &lt;policies&gt; &lt;policy identifier=&quot;f99bccd1-a30e-3e4a-98a2-dbc708edc67f&quot; resource=&quot;/flow&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;87dce6d5-be9f-3392-a4ef-dd58a553a6a0&quot; resource=&quot;/data/process-groups/2ba3a086-018b-1000-6247-3dcbfaf4602f&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;2cb459c4-151d-3671-9d9b-7fa7f1448886&quot; resource=&quot;/data/process-groups/2ba3a086-018b-1000-6247-3dcbfaf4602f&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;f5e329a9-16eb-3aaf-a969-3778d17ad1e4&quot; resource=&quot;/process-groups/2ba3a086-018b-1000-6247-3dcbfaf4602f&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;3be25fe5-3d07-302c-9bf9-0b03fa9fb77d&quot; resource=&quot;/process-groups/2ba3a086-018b-1000-6247-3dcbfaf4602f&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;b8775bd4-704a-34c6-987b-84f2daf7a515&quot; resource=&quot;/restricted-components&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;627410be-1717-35b4-a06f-e9362b89e0b7&quot; resource=&quot;/tenants&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;15e4e0bd-cb28-34fd-8587-f8d15162cba5&quot; resource=&quot;/tenants&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;ff96062a-fa99-36dc-9942-0f6442ae7212&quot; resource=&quot;/policies&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;ad99ea98-3af6-3561-ae27-5bf09e1d969d&quot; resource=&quot;/policies&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;2e1015cb-0fed-3005-8e0d-722311f21a03&quot; resource=&quot;/controller&quot; action=&quot;R&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;policy identifier=&quot;c6322e6c-4cc1-3bcc-91b3-2ed2111674cf&quot; resource=&quot;/controller&quot; action=&quot;W&quot;&gt; &lt;user identifier=&quot;admin&quot;/&gt; &lt;/policy&gt; &lt;/policies&gt;&lt;/authorizations&gt; 可以 通过点击右上侧的菜单栏并选择 user创建用户、Policies可以为用户进行权限管理 创建用户后，自动会写入到user.xml中 TroubleShooting1、 更改user.xml文件，user部分的identity不能有相同的 2、 严格匹配，不能有“”，区分大小写 3、 当你在配置的是CN=admin, OU=nifi这种格式，那么会会从中解析出admin 作为用户名","path":"2023/10/15/NiFi身份验证与授权验证（2）/","date":"10-15","excerpt":"","tags":[{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"},{"name":"SSL","slug":"SSL","permalink":"https://castile.github.io/tags/SSL/"}]},{"title":"NiFi身份验证与授权验证（1）","text":"NiFi身份验证和授权验证介绍身份验证（Authentication）以及授权验证（Authorization）在Nifi里面是两个相当独立的模块。其中身份验证主要的任务是确认当前操作用户是否真的是声称的身份。当用户的身份被证实以后，它的用户名会被传递到授权验证模块，而授权验证模块会在它的数据库里面查找该用户名，并确认该用户有什么权限。打个比喻，如果你想进入一个商业写字楼，门口保安可能会拦住你要查看你的身份证（身份验证）。然后他会从一个员工名册上查找你的名字（授权验证）。只有当你的名字出现在名册上时你才会被放行。 下图表明了Nifi中这两个系统间的关系。当用户试图访问Nifi时，他必须首先通过身份验证。身份验证的时候Nifi可能需要参考一个外部的身份数据库（Identity Provider），如LDAP，Kerberos，OpenID Connect等。当确认你的身份后，你的用户名会被送到授权验证模块进一步核对。授权模块在确认你的权限时也需要参考一个身份数据库（可以是一个文档，或者是LDAP服务器）以及一个记录着用户身份与权限对应关系的数据库。 、 身份验证和权限验证是完全可以采用不同的身份数据库的。所以我们说这两个系统相当独立，唯一把他们连接在一起的就是用户名的传递。 NiFi 基本配置Nifi支持好几种用户验证方式：TLS, LDAP, Kerberos, OpenID Connect, Apache Knox等。我们主要介绍TLS以及LDAP两种方式。只要弄明白这两种，其余方式的设置都很类似。 要开启用户验证功能，我们首先必须设置Nifi，使之只接受https安全连接。要达到这个目的，我们需要更改位于./conf 目录下的nifi.properties设置文件里的以下几项属性 nifi.web.http.port：去除原来的8080，使该行变为nifi.web.http.port=，防止用户从非加密的http端口访问 nifi.web.https.host：设为运行Nifi的主机名字，例如host-01 nifi.web.https.port：我们用8443作为https端口 nifi.security.keystore：keystore的路径，例如/opt/nifi/secrets/keystore.jks nifi.security.keystoreType：设为JKS nifi.security.keystorePasswd：keystore的密码。 nifi.security.truststore：truststore的路径，例如/opt/nifi/secrets/truststore.jks nifi.security.truststoreType：设为JKS nifi.security.truststorePasswd：truststore的密码。 nifi.remote.input.secure：设为true，使得Nifi之间的Site-to-Site通信也用加密的方式。 生成keystroe和truststore当我们要把Nifi设置成加密模式时，我们需要为其提供keystore和truststore。如果我们想通过TLS身份验证访问Nifi的UI时，我们还需要生成一个客户端的PKCS12文件来导入浏览器中。以下简单介绍怎么用Java自带的keytool来生成以上所提及的文件。 1、生成KeyStore 以下命令生成一个包含自签证书（self-signed certificate）的Java keystore： 1keytool -genkey -keyalg RSA -alias nifi -keystore keystore.jks -keypass [password] -storepass [password] -validity 365 -keysize 4096 -dname &quot;CN=[hostname], OU=nifi&quot; [password]为你想设置的密码，替换[hostname]为你运行Nifi的机器的hostname 2、 生成PKCS12文件以及对应的truststorePKCS12文件是一种加密文件，一般用于存放证书以及对应的私钥。由于使用keytool无法直接生成PKCS12文件，我们首先生成一个包含自签证书的keystore（与上文生成Keystore的命令很相似）： 1keytool -genkey -keyalg RSA -alias client -keystore client_keystore.jks -keypass password -storepass password -validity 365 -keysize 4096 -dname &quot;CN=castile, OU=nifi&quot; 这里，我们只是随便设置了一个密码password，因为这个Keystore只是一个过渡的产物，我们最后不会用到，所以随便设置一个就好。 接着我们把这个keystore转化成PKCS12文件： 1keytool -importkeystore -srckeystore client_keystore.jks -destkeystore client.p12 -srcstoretype JKS -deststoretype PKCS12 -srcstorepass password -deststorepass as1234567890 -destkeypass as1234567890 -srcalias client -destalias client 除了生成PKCS12文件外，我们还需要生成一个信任PKCS12密匙文件中的证书的truststore。为此，我们先从之前的keystore中输出密匙的证书： 1keytool -export -keystore client_keystore.jks -alias client -file client.der -storepass password 当我们得到证书以后，我们把这个证书引入到truststore.jks当中： 1keytool -import -file client.der -alias client -keystore truststore.jks -storepass as1234567890 -noprompt 这是执行上述命令生成的文件： 访问nifi UI界面在浏览器输入：https://192.168.160.140:9443/nifi 现在要求你输入用户名和密码，但是这个用户名和密码到底是啥呢？查找官网文档得知，有一个 login-identity-providers.xml 默认配置了用户名和密码 1234567&lt;provider&gt; &lt;identifier&gt;single-user-provider&lt;/identifier&gt; &lt;class&gt;org.apache.nifi.authentication.single.user.SingleUserLoginIdentityProvider&lt;/class&gt; &lt;property name=&quot;Username&quot;&gt;3df4e52a-ab76-477c-9af4-513494f21110&lt;/property&gt; &lt;property name=&quot;Password&quot;&gt;$2b$12$NFheiU47xu8ezCrkt0Yz7Oxph/WRhmJaNwMPlDEPkynGSwxEPEibu&lt;/property&gt; &lt;/provider&gt; 但是，貌似没啥作用啊 原来，nifi启动的时候会自动生成一个随机用户名和密码，而且在login-single-user=credentials.xml中配置的密码是通过BCryptPasswordEncoder加密后的， 可以通过以下命令设置一个好记忆的密码： 1nifi.sh set-single-user-credentials USERNAME PASSWORD 设置完后可以登录界面了","path":"2023/10/14/NiFi身份验证与授权验证（1）/","date":"10-14","excerpt":"","tags":[{"name":"ssl","slug":"ssl","permalink":"https://castile.github.io/tags/ssl/"},{"name":"nifi","slug":"nifi","permalink":"https://castile.github.io/tags/nifi/"},{"name":"身份验证","slug":"身份验证","permalink":"https://castile.github.io/tags/%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81/"}]},{"title":"castile-rpc框架：动态代理实现RPC的调用和处理","text":"在一个RPC框架中，动态代理可以屏蔽rpc调用时低层的网络通讯、服务发现、负载均衡等具体细节。 使用 RPC 框架的时候，只需要调用接口方法，然后就拿到了返回结果。这些都是通过动态代理去实现的。 代理模式代理模式的优势是可以很好地遵循设计模式中的开闭原则，对扩展开发，对修改关闭。不需要关注目标类的实现细节，通过代理模式可以在不修改目标类的情况下，增强目标类功能的行为。 动态代理是一种代理模式，它提供了一种能够在运行时动态构建代理类以及动态调用目标方法的机制。为什么称为动态是因为代理类和被代理对象的关系是在运行时决定的，代理类可以看作是对被代理对象的包装，对目标方法的调用是通过代理类来完成的。所以通过代理模式可以有效地将服务提供者和服务消费者进行解耦，隐藏了 RPC 调用的具体细节。 服务消费者动态代理实现我们使用@RPCReference注解来标注一个服务端接口，通过一个自定义的RpcReferenceBean完成了所有执行方法的拦截。 RpcReferenceBean 中 init() 方法是代理对象的创建入口，代理对象创建如下所示： 12345678910111213/** * 初始化bean，返回代理对象 * * @throws Exception */ public void init() throws Exception &#123; RegistryService registryService = RegistryFactory.getInstance(registryAddr, RegistryType.valueOf(registryType)); this.object = Proxy.newProxyInstance( interfaceClass.getClassLoader(), new Class&lt;?&gt;[]&#123;interfaceClass&#125;, new RpcInvokerProxy(serviceVersion, timeout, registryService) ); &#125; RpcInvokerProxy 处理器是实现动态代理逻辑的核心所在，其中包含 RPC 调用时底层网络通信、服务发现、负载均衡等具体细节 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class RpcInvokerProxy implements InvocationHandler &#123; private final String serviceVersion; private final Long timeout; private final RegistryService registryService; public RpcInvokerProxy(String serviceVersion, long timeout, RegistryService registryService) &#123; this.serviceVersion = serviceVersion; this.timeout = timeout; this.registryService = registryService; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; CastileRpcProtocol&lt;RpcRequest&gt; rpcProtocol = new CastileRpcProtocol&lt;&gt;(); // 消息头 MessageHeader messageHeader = new MessageHeader(); // 消息id long requestId = RpcRequestHolder.REQUEST_ID_GEN.incrementAndGet(); // 魔数 messageHeader.setMagic(ProtocolConstants.MAGIC); // 版本 messageHeader.setVersion(ProtocolConstants.VERSION); // 序列化算法 messageHeader.setSerialization((byte) SerializationTypeEnum.HESSIAN.getType()); // 消息类型 messageHeader.setMsgType((byte) MsgType.REQUEST.getType()); messageHeader.setStatus((byte) MsgStatus.SUCCESS.getCode()); rpcProtocol.setMessageHeader(messageHeader); // 消息正文 RpcRequest rpcRequest = new RpcRequest(); rpcRequest.setServiceVersion(serviceVersion); rpcRequest.setClassName(method.getDeclaringClass().getName()); rpcRequest.setMethodName(method.getName()); rpcRequest.setParameterTypes(method.getParameterTypes()); rpcRequest.setParams(args); rpcProtocol.setBody(rpcRequest); // 创建rpc客户端，发送消息进行rpc调用 RpcConsumer consumer = new RpcConsumer(); RpcFuture&lt;RpcResponse&gt; rpcFuture = new RpcFuture&lt;&gt;(new DefaultPromise&lt;&gt;(new DefaultEventLoop()), timeout); RpcRequestHolder.REQUEST_MAP.put(requestId, rpcFuture); consumer.sendMessage(rpcProtocol, registryService); return rpcFuture.getPromise().get(rpcFuture.getTimeout(), TimeUnit.MILLISECONDS).getData(); &#125;&#125; invoke() 方法的核心流程主要分为三步：构造 RPC 协议对象、发起 RPC 远程调用、等待 RPC 调用执行结果。 发起 RPC 调用之前，我们需要找到最合适的服务节点，直接调用注册中心服务 RegistryService 的 discovery() 方法即可，默认是采用一致性 Hash 算法实现的服务发现 。为了尽可能使所有服务节点收到的请求流量更加均匀，需要为 discovery() 提供一个 invokerHashCode，一般可以采用 RPC 服务接口参数列表中第一个参数的 hashCode 作为参考依据。找到服务节点地址后，接下来通过 Netty 建立 TCP 连接，然后调用 writeAndFlush() 方法将数据发送到远端服务节点。 123456789101112131415161718192021222324public void sendMessage(CastileRpcProtocol&lt;RpcRequest&gt; protocolRequest, RegistryService registryService) throws Exception &#123; RpcRequest request = protocolRequest.getBody(); Object[] params = request.getParams(); String serviceKey = RpcServiceHelper.buildServiceKey(request.getMethodName(), request.getServiceVersion()); int invokeHashCode = params.length &gt; 0 ? params[0].hashCode() : serviceKey.hashCode(); // 找到需要发送到哪个服务实例 ServiceMetaData serviceMetaData = registryService.discovery(serviceKey, invokeHashCode); if (serviceMetaData != null) &#123; ChannelFuture channelFuture = bootstrap.connect(serviceMetaData.getServiceAddr(), serviceMetaData.getPort()).sync(); channelFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture channelFuture) throws Exception &#123; if (channelFuture.isSuccess()) &#123; log.info(&quot;connect rpc service &#123;&#125; om port &#123;&#125; success!&quot;, serviceMetaData.getServiceAddr(), serviceMetaData.getPort()); &#125; else &#123; log.error(&quot;connect rpc server &#123;&#125; on port &#123;&#125; failed.&quot;, serviceMetaData.getServiceAddr(), serviceMetaData.getPort()); channelFuture.cause().printStackTrace(); eventLoopGroup.shutdownGracefully(); &#125; &#125; &#125;); channelFuture.channel().writeAndFlush(protocolRequest); &#125; &#125; 发送RPC远程调用后，使用Promise机制等待拿到结果。 Promise 模式本质是一种异步编程模型，我们可以先拿到一个查看任务执行结果的凭证，不必等待任务执行完毕，当我们需要获取任务执行结果时，再使用凭证提供的相关接口进行获取。 服务提供者反射调用实现消费者通过netty发送消息给服务端后，rpc的请求数据经过解码器解码成CastileRpcProtocol对象后，再交由RpcRequestHandler执行rpcx请求调用： 123456789101112131415161718192021222324252627282930313233343536373839404142 protected void channelRead0(ChannelHandlerContext ctx, CastileRpcProtocol&lt;RpcRequest&gt; msg) throws Exception &#123; // 执行rpc调用比较耗时，因此放在业务线程池中去处理 RpcRequestProcessor.submitRequest(() -&gt; &#123; CastileRpcProtocol&lt;RpcResponse&gt; rpcProtocol = new CastileRpcProtocol&lt;&gt;(); RpcResponse rpcResponse = new RpcResponse(); MessageHeader messageHeader = msg.getMessageHeader(); messageHeader.setMsgType((byte) MsgType.RESPONSE.getType()); try &#123; RpcRequest request = msg.getBody(); String serviceKey = RpcServiceHelper.buildServiceKey(request.getClassName(), request.getServiceVersion()); // 获取bean对象 Object serviceBean = rpcServiceMap.get(serviceKey); if (serviceBean == null) &#123; // 不存在 throw new RuntimeException(String.format(&quot;service not exist: %s:%s&quot;, request.getClassName(), request.getMethodName())); &#125; Class&lt;?&gt; serviceClazz = serviceBean.getClass(); String methodName = request.getMethodName(); Object[] params = request.getParams(); Class&lt;?&gt;[] parameterTypes = request.getParameterTypes(); FastClass fastClass = FastClass.create(serviceClazz); int index = fastClass.getIndex(methodName, parameterTypes); Object result = fastClass.invoke(index, serviceBean, params); // 写回到response中 rpcResponse.setData(result); messageHeader.setStatus((byte) MsgStatus.SUCCESS.getCode()); rpcProtocol.setBody(rpcResponse); rpcProtocol.setMessageHeader(messageHeader); &#125; catch (Throwable throwable) &#123; messageHeader.setStatus((byte) MsgStatus.FAIL.getCode()); rpcResponse.setMessage(throwable.toString()); log.error(&quot;process request &#123;&#125; error&quot;, messageHeader.getRequestId(), throwable); &#125; ctx.writeAndFlush(rpcProtocol); &#125;); &#125;&#125; rpcServiceMap 中存放着服务提供者所有对外发布的服务接口，我们可以通过服务名和服务版本找到对应的服务接口。通过服务接口、方法名、方法参数列表、参数类型列表，我们一般可以使用反射的方式执行方法调用。为了加速服务接口调用的性能，我们采用 Cglib 提供的 FastClass 机制直接调用方法，Cglib 中 MethodProxy 对象就是采用了 FastClass 机制，它可以和 Method 对象完成同样的事情，但是相比于反射性能更高。 FastClass 机制并没有采用反射的方式调用被代理的方法，而是运行时动态生成一个新的 FastClass 子类，向子类中写入直接调用目标方法的逻辑。同时该子类会为代理类分配一个 int 类型的 index 索引，FastClass 即可通过 index 索引定位到需要调用的方法。 实现源码https://gitee.com/hongliangzhu/castile-rpc","path":"2023/10/08/castile-rpc框架：动态代理实现RPC的调用和处理/","date":"10-08","excerpt":"","tags":[{"name":"RPC","slug":"RPC","permalink":"https://castile.github.io/tags/RPC/"}]},{"title":"castile-rpc框架：服务治理-服务发现和负载均衡","text":"在一个分布式系统中，每个服务都有多个实例，如果服务实例节点出现负载比较高，那么可能会导致该节点上面的请求处理超时，影响可用性。so，一个良好的rpc框架需要 实现合理的负载均衡算法。 注册中心服务消费者在发起请求之前都需要根据需要调用的服务去服务中心去找那些服务端实例，而且每个服务都有上线和下线的概念，因此消费端还需要感知服务提供者的实例变化，在rpc框架中，一般使用注册中心来实现服务的发现和注册。 主流的注册中心有zookeeper、Eureka、Etcd？Consul、Nacos等， 高可用的注册中心对 RPC 框架至关重要。说到高可用自然离不开 CAP 理论，一致性 Consistency、可用性 Availability 和分区容忍性 Partition tolerance 是无法同时满足的，注册中心一般分为 CP 类型注册中心和 AP 类型注册中心 。 ● 一致性：指所有节点在同一时刻的数据完全一致。 ● 可用性：指服务一直可用，而且响应时间正常。例如，不管什么时候访问X节点和Y节点都可以正常获取数据值，而不会出现问题。 ● 分区容错性：指在遇到某节点或网络分区故障时，仍然能够对外提供满足一致性和可用性的服务。例如X节点和Y节点出现故障，但是依然可以很好地对外提供服务 CAP的取舍: 1、 满足CA舍弃P，也就是满足一致性和可用性，舍弃分区容错性。这也就意味着你的系统不是分布式的了，因为分布式就是把功能分开部署到不同的机器上。 2、满足CP舍弃A，也就是满足一致性和分区容错性，舍弃可用性。这也就意味着你的系统允许有一段时间访问失效等，不会出现数据不一致的情况。 3、满足AP舍弃C，也就是满足可用性和分区容错性，舍弃一致性。这也就意味着你的系统在并发访问的时候可能会出现数据不一致的情况。 在分布式系统中，为了避免单点故障，分区容错是不可避免的，所以对于注册中心来说只能从CP（优先保证数据一致性）、AP（优先保证数据可用性）中根据你的业务场景选择一种。 使用最为广泛的 Zookeeper 就是 CP 类型的注册中心，集群中会有一个节点作为 Leader，如果 Leader 节点挂了，会重新进行 Leader 选举，ZooKeeper 保证了所有节点的强一致性，但是在 Leader 选举的过程中是无法对外提供服务的，牺牲了部分可用性。Eureka 是典型的 AP 类型注册中心，在实现服务发现的场景下有很大的优势，整个集群是不存在 Leader、Flower 概念的，如果其中一个节点挂了，请求会立刻转移到其他节点上。可能会存在的问题是如果不同分区无法进行节点通信，那么可能会造成节点之间的数据是有差异的，所以 AP 类型的注册中心通过牺牲强一致性来保证高可用性 。 对于 RPC 框架而言，即使注册中心出现问题，也不应该影响服务的正常调用，所以 AP 类型的注册中心在该场景下相比于 CP 类型的注册中心更有优势。 对于成熟的 RPC 框架而言，会提供多种注册中心的选择，接下来我们便设计一个通用的注册中心接口，然后每种注册中心的实现都按该接口规范行扩展。 1234567891011121314public interface RegistryService &#123; /** * 注册微服务 * * @param serviceMetaData 服务元数据 */ void register(ServiceMetaData serviceMetaData) throws Exception; void unregister(ServiceMetaData serviceMetaData) throws Exception; ServiceMetaData discovery(String serviceName, int invokerHashCode) throws Exception; void destroy() throws IOException;&#125; RegistryService 接口包含注册中心四个基本操作：服务注册 register、服务注销 unRegister、服务发现 discovery、注册中心销毁 destroy。 负载均衡算法服务消费者在发起 RPC 调用之前，需要感知有多少服务端节点可用，然后从中选取一个进行调用。之前我们提到了几种常用的负载均衡策略：Round-Robin 轮询、Weighted Round-Robin 权重轮询、Least Connections 最少连接数、Consistent Hash 一致性 Hash 等。 一致性 Hash 算法可以保证每个服务节点分摊的流量尽可能均匀，而且能够把服务节点扩缩容带来的影响降到最低。下面我们一起看下一致性 Hash 算法的设计思路。 在服务端节点扩缩容时，一致性 Hash 算法会尽可能保证客户端发起的 RPC 调用还是固定分配到相同的服务节点上。一致性 Hash 算法是采用哈希环来实现的，通过 Hash 函数将对象和服务器节点放置在哈希环上，一般来说服务器可以选择 IP + Port 进行 Hash。 关于一致性hash算法可参考： https://zhuanlan.zhihu.com/p/482549860?utm_medium=social&amp;utm_oi=919687111576289280 负载均衡接口定义： 123public interface ServiceLoadBalancer&lt;T&gt; &#123; T select(List&lt;T&gt; servers, int hashCode);&#125; 基于zk实现的一致性hash算法如下： 1234567891011121314151617181920212223242526272829public class ZKConsistentHashLoadBalancer implements ServiceLoadBalancer&lt;ServiceInstance&lt;ServiceMetaData&gt;&gt; &#123; /** * 虚拟节点数，默认是10 */ private final static int VIRTUAL_NODE_SIZE = 10; private String buildServiceInstanceKey(ServiceInstance&lt;ServiceMetaData&gt; instance) &#123; ServiceMetaData payload = instance.getPayload(); return String.join(&quot;:&quot;, payload.getServiceAddr(), String.valueOf(payload.getPort())); &#125; @Override public ServiceInstance&lt;ServiceMetaData&gt; select(List&lt;ServiceInstance&lt;ServiceMetaData&gt;&gt; servers, int hashCode) &#123; TreeMap&lt;Integer, ServiceInstance&lt;ServiceMetaData&gt;&gt; ring = new TreeMap&lt;&gt;(); for (ServiceInstance&lt;ServiceMetaData&gt; instance : servers) &#123; for (int i = 0; i &lt; VIRTUAL_NODE_SIZE; i++) &#123; ring.put((buildServiceInstanceKey(instance) + VIRTUAL_NODE_SIZE + i).hashCode(), instance); &#125; &#125; // ceilingEntry() 方法找出大于或等于客户端 hashCode 的第一个节点，即为客户端对应要调用的服务节点 Map.Entry&lt;Integer, ServiceInstance&lt;ServiceMetaData&gt;&gt; entry = ring.ceilingEntry(hashCode); if (entry == null) &#123; entry = ring.firstEntry(); &#125; return entry.getValue(); &#125;&#125; 服务发现服务发现的实现思路比较简单，首先找出被调用服务所有的节点列表，然后通过 ZKConsistentHashLoadBalancer 提供的一致性 Hash 算法找出相应的服务节点。具体代码实现如下： 1234567891011@Override public ServiceMetaData discovery(String serviceName, int invokerHashCode) throws Exception &#123; Collection&lt;ServiceInstance&lt;ServiceMetaData&gt;&gt; serviceInstances = serviceDiscovery.queryForInstances(serviceName); // 通过一些负载均衡算法，选择一个服务实例 ServiceInstance&lt;ServiceMetaData&gt; instance = new ZKConsistentHashLoadBalancer().select((List&lt;ServiceInstance&lt;ServiceMetaData&gt;&gt;) serviceInstances, invokerHashCode); if (instance == null) &#123; return null; &#125; return instance.getPayload(); &#125;","path":"2023/09/27/castile-rpc框架：服务治理-服务发现和负载均衡/","date":"09-27","excerpt":"","tags":[{"name":"RPC","slug":"RPC","permalink":"https://castile.github.io/tags/RPC/"}]},{"title":"castile-rpc框架：通信协议的设计和编解码器的实现","text":"现在需要建立客户端和服务端之间的通信机制了，主要内容有： 服务消费者实现协议编码，向服务提供者发送调用数据。 服务提供者收到数据后解码，然后向服务消费者发送响应数据，暂时忽略 RPC 请求是如何被调用的。 服务消费者收到响应数据后成功返回。 1、RPC 通信方案设计 2、自定义RPC通信协议协议是服务消费者和服务提供者之间通信的基础，主流的 RPC 框架都会自定义通信协议，相比于 HTTP、HTTPS、JSON 等通用的协议，自定义协议可以实现更好的性能、扩展性以及安全性。 自定义协议要素 魔数，用来在第一时间判定是否是无效数据包 版本号，可以支持协议的升级 序列化算法，消息正文到底采用哪种序列化反序列化方式，可以由此扩展，例如：json、protobuf、hessian、jdk 状态： 失败还是成功？ 可选 消息类型，是请求、响应？这个 跟业务相关 请求序号，为了双工通信，提供异步能力 正文长度 消息正文 12345678910111213+---------------------------------------------------------------+| 魔数 2byte | 协议版本号 1byte | 序列化算法 1byte | 报文类型 1byte |+---------------------------------------------------------------+| 状态 1byte | 消息 ID 8byte | 数据长度 4byte |+---------------------------------------------------------------+| 数据内容 （长度不定） |+---------------------------------------------------------------+ 我们把协议分为协议头 Header 和协议体 Body 两个部分。协议头 Header 包含魔数、协议版本号、序列化算法、报文类型、状态、消息 ID、数据长度，协议体 Body 只包含数据内容部分，数据内容的长度是不固定的。RPC 请求和响应都可以使用该协议进行通信，对应协议实体类的定义如下所示： 12345678910111213@Datapublic class CastileRpcProtocol&lt;T&gt; implements Serializable &#123; /** * 消息头 */ private MessageHeader messageHeader; /** * 消息体 */ private T body;&#125; 12345678910111213@Datapublic class MessageHeader implements Serializable &#123; private short magic; private byte version; private byte serialization; private byte msgType; private byte status; private long requestId; private int msgLen;&#125; 3、序列化算法选型目前比较常用的序列化算法包括 Json、Kryo、Hessian、Protobuf 等，这些第三方序列化算法都比 Java 原生的序列化操作都更加高效。 我们设计了一个 RPC 序列化顶层接口， 所有的序列化算法都需要实现这个接口； 12345678910111213141516171819202122232425public interface RpcSerialization &#123; /** * 序列化 * * @param obj 待序列化数据 * @param &lt;T&gt; 序列化数据的类型 * @return 序列化后的字节流 * @throws IOException IO异常 */ &lt;T&gt; byte[] serialize(T obj) throws IOException; /** * 反序列化 * * @param buf 数据 * @param clazz 类型 * @param &lt;T&gt; 类型 * @return * @throws IOException */ &lt;T&gt; T deserialize(byte[] buf, Class&lt;T&gt; clazz) throws IOException;&#125; 我们为 RpcSerialization 提供了 HessianSerialization 和 JsonSerialization 两种类型的实现，为此，可以提供一个序列化工厂来切换不同的序列化算法 123456789101112131415public class SerializationFactory &#123; public static RpcSerialization getRpcSerialization(byte type)&#123; SerializationTypeEnum typeEnum = SerializationTypeEnum.findSerializationType(type); switch (typeEnum)&#123; case HESSIAN: return new HessianSerialization(); case JSON: return new JsonSerialization(); default: throw new IllegalArgumentException(&quot;serialization type is illegal, &quot; + type); &#125; &#125;&#125; 4、通信协议的编码器Netty 提供了两个最为常用的编解码抽象基类 MessageToByteEncoder 和 ByteToMessageDecoder，帮助我们很方便地扩展实现自定义协议。 12345678910111213141516171819202122232425262728293031323334353637public class MessageEncoder extends MessageToByteEncoder&lt;CastileRpcProtocol&gt; &#123; /* +---------------------------------------------------------------+ | 魔数 2byte | 协议版本号 1byte | 序列化算法 1byte | 报文类型 1byte | +---------------------------------------------------------------+ | 状态 1byte | 消息 ID 8byte | 数据长度 4byte | +---------------------------------------------------------------+ | 数据内容 （长度不定） | +---------------------------------------------------------------+ */ @Override protected void encode(ChannelHandlerContext channelHandlerContext, CastileRpcProtocol message, ByteBuf byteBuf) throws Exception &#123; MessageHeader messageHeader = message.getMessageHeader(); // 魔数 byteBuf.writeShort(messageHeader.getMagic()); // 协议版本号 byteBuf.writeByte(messageHeader.getVersion()); // 序列化算法 byteBuf.writeByte(messageHeader.getSerialization()); // 报文类型 byteBuf.writeByte(messageHeader.getMsgType()); // 状态 byteBuf.writeByte(messageHeader.getStatus()); // 消息id byteBuf.writeLong(messageHeader.getRequestId()); // 序列化 RpcSerialization rpcSerialization = SerializationFactory.getRpcSerialization(messageHeader.getSerialization()); byte[] body = rpcSerialization.serialize(message.getBody()); // 数据长度 byteBuf.writeInt(body.length); byteBuf.writeBytes(body); &#125;&#125; 在服务消费者或者服务提供者调用 writeAndFlush() 将数据写给对方前，都已经封装成 RpcRequest 或者 RpcResponse，所以可以采用 CastileRpcProtocol作为 RPC Encoder 编码器能够支持的编码类型。 5、 通信协议的解码器 解码器 相比于编码器 要复杂很多，解码器的目标是将字节流数据解码为消息对象，并传递给下一个 Inbound 处理器。整个解码过程有几个要点要特别注意： 只有当 ByteBuf 中内容大于协议头 Header 的固定的 18 字节时，才开始读取数据。 即使已经可以完整读取出协议头 Header，但是协议体 Body 有可能还未就绪。所以在刚开始读取数据时，需要使用 markReaderIndex() 方法标记读指针位置，当 ByteBuf 中可读字节长度小于协议体 Body 的长度时，再使用 resetReaderIndex() 还原读指针位置，说明现在 ByteBuf 中可读字节还不够一个完整的数据包。 这个其实也可以使用LengthFieldBasedFrameDecoder来处理粘包和半包问题 根据不同的报文类型 MsgType，需要反序列化出不同的协议体对象。在 RPC 请求调用的场景下，服务提供者需要将协议体内容反序列化成 MiniRpcRequest 对象；在 RPC 结果响应的场景下，服务消费者需要将协议体内容反序列化成 MiniRpcResponse 对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071@Slf4jpublic class MessageDecoder extends ByteToMessageDecoder &#123; @Override protected void decode(ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf, List&lt;Object&gt; list) throws Exception &#123; // 消息小于头长度，不完整数据 if (byteBuf.readableBytes() &lt; ProtocolConstants.HEADER_TOTAL_LEN) &#123; log.error(&quot;message length valid failed! please check request data&quot;); return; &#125; byteBuf.markReaderIndex(); // 魔数 short magic = byteBuf.readShort(); // 魔数不匹配，不是本系统消息 if (magic != ProtocolConstants.MAGIC) &#123; throw new IllegalArgumentException(&quot;magic number is illegal, &quot; + magic); &#125; byte version = byteBuf.readByte(); byte serializeType = byteBuf.readByte(); byte msgType = byteBuf.readByte(); byte status = byteBuf.readByte(); long requestId = byteBuf.readLong(); int dataLength = byteBuf.readInt(); if (byteBuf.readableBytes() &lt; dataLength) &#123; log.error(&quot;data readableBytes less than data length!&quot;); byteBuf.resetReaderIndex(); return; &#125; byte[] data = new byte[dataLength]; byteBuf.readBytes(data); // 获取消息类型 MsgType byTpye = MsgType.findByType(msgType); if (byTpye == null) &#123; throw new IllegalArgumentException(&quot;msgType number is illegal, &quot; + msgType); &#125; MessageHeader header = new MessageHeader(); header.setMagic(magic); header.setVersion(version); header.setSerialization(serializeType); header.setStatus(status); header.setRequestId(requestId); header.setMsgType(msgType); header.setMsgLen(dataLength); // 反序列化 RpcSerialization rpcSerialization = SerializationFactory.getRpcSerialization(serializeType); switch (byTpye) &#123; case REQUEST: RpcRequest rpcRequest = rpcSerialization.deserialize(data, RpcRequest.class); if (rpcRequest != null) &#123; CastileRpcProtocol&lt;RpcRequest&gt; castileRpcProtocol = new CastileRpcProtocol&lt;&gt;(); castileRpcProtocol.setMessageHeader(header); castileRpcProtocol.setBody(rpcRequest); list.add(castileRpcProtocol); &#125; break; case RESPONSE: RpcResponse rpcResponse = rpcSerialization.deserialize(data, RpcResponse.class); if (rpcResponse != null) &#123; CastileRpcProtocol&lt;RpcResponse&gt; castileRpcProtocol = new CastileRpcProtocol&lt;&gt;(); castileRpcProtocol.setMessageHeader(header); castileRpcProtocol.setBody(rpcResponse); list.add(castileRpcProtocol); &#125; case HEARTBEAT: // TODO break; &#125; &#125;&#125; 6、请求和响应处理消费者调用RPC请求后，服务端通过解码器将二进制的数据解码成CastileRpcProtocol对象，再传递给RpcRequestHandler处理器执行rpc调用。 RpcRequestHandler 也是一个 Inbound 处理器，它并不需要承担解码工作，所以 RpcRequestHandler 直接继承 SimpleChannelInboundHandler 即可，然后重写 channelRead0() 方法，具体实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Slf4jpublic class RpcRequestHandler extends SimpleChannelInboundHandler&lt;CastileRpcProtocol&lt;RpcRequest&gt;&gt; &#123; private final Map&lt;String, Object&gt; rpcServiceMap; public RpcRequestHandler(Map&lt;String, Object&gt; rpcServiceMap) &#123; this.rpcServiceMap = rpcServiceMap; &#125; @Override protected void channelRead0(ChannelHandlerContext ctx, CastileRpcProtocol&lt;RpcRequest&gt; msg) throws Exception &#123; // 执行rpc调用比较耗时，因此放在业务线程池中去处理 RpcRequestProcessor.submitRequest(() -&gt; &#123; CastileRpcProtocol&lt;RpcResponse&gt; rpcProtocol = new CastileRpcProtocol&lt;&gt;(); RpcResponse rpcResponse = new RpcResponse(); MessageHeader messageHeader = msg.getMessageHeader(); messageHeader.setMsgType((byte) MsgType.RESPONSE.getType()); try &#123; RpcRequest request = msg.getBody(); String serviceKey = RpcServiceHelper.buildServiceKey(request.getClassName(), request.getServiceVersion()); // 获取bean对象 Object serviceBean = rpcServiceMap.get(serviceKey); if (serviceBean == null) &#123; // 不存在 throw new RuntimeException(String.format(&quot;service not exist: %s:%s&quot;, request.getClassName(), request.getMethodName())); &#125; Class&lt;?&gt; serviceClazz = serviceBean.getClass(); String methodName = request.getMethodName(); Object[] params = request.getParams(); Class&lt;?&gt;[] parameterTypes = request.getParameterTypes(); FastClass fastClass = FastClass.create(serviceClazz); int index = fastClass.getIndex(methodName, parameterTypes); Object result = fastClass.invoke(index, serviceBean, params); // 写回到response中 rpcResponse.setData(result); messageHeader.setStatus((byte) MsgStatus.SUCCESS.getCode()); rpcProtocol.setBody(rpcResponse); rpcProtocol.setMessageHeader(messageHeader); &#125; catch (Throwable throwable) &#123; messageHeader.setStatus((byte) MsgStatus.FAIL.getCode()); rpcResponse.setMessage(throwable.toString()); log.error(&quot;process request &#123;&#125; error&quot;, messageHeader.getRequestId(), throwable); &#125; ctx.writeAndFlush(rpcProtocol); &#125;); &#125;&#125; 服务消费者在发起调用时，维护了请求 requestId 和 RpcFuture的映射关系，RpcResponseHandler 会根据请求的 requestId 找到对应发起调用的 RpcFuture，然后为 RpcFuture 设置响应结果。 123456789public class RpcResponseHandler extends SimpleChannelInboundHandler&lt;CastileRpcProtocol&lt;RpcResponse&gt;&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, CastileRpcProtocol&lt;RpcResponse&gt; msg) throws Exception &#123; long requestId = msg.getMessageHeader().getRequestId(); RpcFuture&lt;RpcResponse&gt; responseRpcFuture = RpcRequestHolder.REQUEST_MAP.remove(requestId); responseRpcFuture.getPromise().setSuccess(msg.getBody()); &#125;&#125; 12345678910111213@Datapublic class RpcFuture&lt;T&gt; &#123; private Promise&lt;T&gt; promise; private long timeout; public RpcFuture(Promise&lt;T&gt; promise, long timeout) &#123; this.promise = promise; this.timeout = timeout; &#125;&#125;","path":"2023/09/27/castile-rpc框架：通信协议的设计和编解码器的实现/","date":"09-27","excerpt":"","tags":[{"name":"RPC","slug":"RPC","permalink":"https://castile.github.io/tags/RPC/"}]},{"title":"castile-rpc框架：服务的注册与发现","text":"先考虑用户应该如何使用1、 服务端服务端定义一个服务接口 123456789101112131415/** * @author Hongliang Zhu * @create 2023-09-03 15:34 */public interface HelloService &#123; /** * 打招呼 * * @param name 姓名 * @return */ String hello(String name);&#125; 实现服务接口： 12345678910111213/** * @author Hongliang Zhu * @create 2023-09-03 15:35 */@RpcService(serviceInterface = HelloService.class, serviceVersion = &quot;1.0.0&quot;)public class HelloServiceImpl implements HelloService&#123; Override public String hello(String name) &#123; return &quot;hello&quot; + name; &#125;&#125; 在服务端启动的时候会向注册中心注册这个服务。 2、 消费端123456789101112@RestControllerpublic class HelloController &#123; @RpcReference(serviceVersion = &quot;1.0.0&quot;, timeout = 3000) private HelloFacade helloFacade; @RequestMapping(value = &quot;/hello&quot;, method = RequestMethod.GET) public String sayHello() &#123; return helloFacade.hello(&quot;mini rpc&quot;); &#125;&#125; 服务提供者提供服务1、RPC服务端服务提供者采用的是主从 Reactor 线程模型，启动过程包括配置线程池、Channel 初始化、端口绑定三个步骤 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.castile.rpc.provider;import com.castile.rpc.provider.autoconfig.RpcProperties;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.ChannelOption;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.logging.LoggingHandler;import lombok.extern.slf4j.Slf4j;import org.springframework.boot.ApplicationArguments;import org.springframework.boot.ApplicationRunner;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.net.InetAddress;/** * 启动RPC服务端， * &lt;p&gt; * 服务启动的时候进行服务发现与注册 * * @author Hongliang Zhu * @create 2023-09-03 22:10 */@Component@Slf4jpublic class RpcServerRunner implements ApplicationRunner &#123; @Resource private RpcProperties properties; public void run(ApplicationArguments args) throws Exception &#123; String address = InetAddress.getLocalHost().getHostAddress(); NioEventLoopGroup boss = new NioEventLoopGroup(); NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap().group(boss, worker) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new LoggingHandler()); // TODO 添加其他处理器， 如：编解码，消息请求处理 &#125; &#125;) .option(ChannelOption.SO_KEEPALIVE, true); ChannelFuture channelFuture = serverBootstrap.bind(address, this.properties.getPort()).sync(); log.info(&quot;连接信息：server addr &#123;&#125; started on port &#123;&#125;&quot;, address, this.properties.getPort()); channelFuture.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); &#125; &#125;&#125; 2、发布服务定义一个注解，用于标识一个服务 12345678910111213141516171819202122232425262728293031323334package com.castile.rpc.provider;import org.springframework.stereotype.Component;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * rpc服务注解 * * @author Hongliang Zhu * @create 2023-09-03 15:51 */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Componentpublic @interface RpcService &#123; /** * 服务所在的接口 * * @return 服务接口 */ Class&lt;?&gt; serviceInterface() default Object.class; /** * 服务版本 * * @return 版本 */ String version() default &quot;1.0.0&quot;;&#125; 有两个重要的属性，serviceInterface表示服务类型接口，version表示服务版本。 服务消费者必须指定完全一样的属性才能正确调用。有了 @RpcService 注解之后，我们就可以在服务实现类上使用它。 @RpcService 注解本质上就是 @Component，可以将服务实现类注册成 Spring 容器所管理的 Bean。这里需要了解Spring中Bean的生命周期了。 Spring的BeanPostProcessor接口提供了对Bean进行再加工的扩展点。 BeanPostProcessor 常用于处理自定义注解。自定义的 Bean 可以通过实现 BeanPostProcessor 接口，在 Bean 实例化的前后加入自定义的逻辑处理。如下所示，我们通过 RpcProvider 实现 BeanPostProcessor 接口，来实现对 声明 @RpcService 注解服务的自定义处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.castile.rpc.provider;import com.castile.rpc.provider.autoconfig.RpcProperties;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanPostProcessor;import org.springframework.stereotype.Component;import javax.annotation.Resource;import java.net.InetAddress;import java.net.UnknownHostException;import java.util.HashMap;import java.util.Map;/** * 扫描@RpcService注解，注册到注册中心中 * * @author Hongliang Zhu * @create 2023-09-03 23:25 */@Slf4j@Componentpublic class RpcProviderProcessor implements BeanPostProcessor &#123; private final Map&lt;String, Object&gt; rpcServices = new HashMap&lt;String, Object&gt;(); @Resource private RpcProperties properties; public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; RpcService rpcService = bean.getClass().getAnnotation(RpcService.class); if (rpcService != null) &#123; String serviceName = rpcService.serviceInterface().getName(); String serviceVersion = rpcService.version(); try &#123; String address = InetAddress.getLocalHost().getHostAddress(); ServiceMetaData serviceMetaData = new ServiceMetaData(); serviceMetaData.setPort(properties.getPort()); serviceMetaData.setServiceAddr(address); serviceMetaData.setServiceName(serviceName); serviceMetaData.setServiceVersion(serviceVersion); // TODO 封装注册信息，注册到注册中心 rpcServices.put(serviceName + &quot;#&quot; + serviceVersion, bean); &#125; catch (UnknownHostException e) &#123; log.error(&quot;failed to register service &#123;&#125;#&#123;&#125;&quot;, serviceName, serviceVersion, e); &#125; &#125; return bean; &#125;&#125; 服务消费者订阅服务消费者不属于常驻服务， 每次发起 RPC 调用时它才会去选择向哪个远端服务发送数据。 对于声明 @RpcReference 注解的成员变量，我们需要构造出一个可以真正进行 RPC 调用的 Bean，然后将它注册到 Spring 的容器中。 @RpcReference 注解的定义 ： 1234567891011121314151617181920@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface RpcReference &#123; /** * 引用的服务版本 * * @return 服务版本 */ String serviceVersion() default &quot;1.0.0&quot;; /** * rpc调用的超时时间 * * @return 超时时间 */ long timeout() default 3000;&#125; 需要为使用了@RpcReference注解的成员变量构造成一个自定义的bean对象，并且对该bean对象执行的所有方法进行拦截。 Spring 的 FactoryBean 接口可以帮助我们实现自定义的 Bean，FactoryBean 是一种特种的工厂 Bean，通过 getObject() 方法返回对象，而并不是 FactoryBean 本身。 有了 @RpcReference 注解和 RpcReferenceBean 之后，我们可以使用 Spring 的扩展点 BeanFactoryPostProcessor 对 Bean 的定义进行修改。上文中服务提供者使用的是 BeanPostProcessor，BeanFactoryPostProcessor 和 BeanPostProcessor 都是 Spring 的核心扩展点，它们之间有什么区别呢？BeanFactoryPostProcessor 是 Spring 容器加载 Bean 的定义之后以及 Bean 实例化之前执行，所以 BeanFactoryPostProcessor 可以在 Bean 实例化之前获取 Bean 的配置元数据，并允许用户对其修改。而 BeanPostProcessor 是在 Bean 初始化前后执行，它并不能修改 Bean 的配置信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465@Slf4j@Componentpublic class RpcConsumerPostProcessor implements ApplicationContextAware, BeanClassLoaderAware, BeanFactoryPostProcessor &#123; public static final String INIT_METHOD_NAME = &quot;init&quot;; private final Map&lt;String, BeanDefinition&gt; rpcRefBeanDefinitions = new LinkedHashMap&lt;&gt;(); private ApplicationContext context; private ClassLoader classLoader; @Override public void setBeanClassLoader(ClassLoader classLoader) &#123; this.classLoader = classLoader; &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory configurableListableBeanFactory) throws BeansException &#123; String[] beanDefinitionNames = configurableListableBeanFactory.getBeanDefinitionNames(); for (String beanDefName : beanDefinitionNames) &#123; BeanDefinition beanDefinition = configurableListableBeanFactory.getBeanDefinition(beanDefName); final String beanClassName = beanDefinition.getBeanClassName(); if (beanClassName != null) &#123; Class&lt;?&gt; clazz = ClassUtils.resolveClassName(beanClassName, this.classLoader); ReflectionUtils.doWithFields(clazz, this::parseRpcReference); &#125; &#125; // beanClassName = null BeanDefinitionRegistry registry = (BeanDefinitionRegistry) configurableListableBeanFactory; this.rpcRefBeanDefinitions.forEach((beanName, definition) -&gt; &#123; if (context.containsBean(beanName)) &#123; throw new IllegalArgumentException(&quot;application context already has a bean named &quot; + beanName); &#125; else &#123; // 注册到spring中 registry.registerBeanDefinition(beanName, rpcRefBeanDefinitions.get(beanName)); log.info(&quot;registered RpcReferenceBean &#123;&#125; success.&quot;, beanName); &#125; &#125;); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.context = applicationContext; &#125; private void parseRpcReference(Field field) &#123; RpcReference annotation = AnnotationUtils.getAnnotation(field, RpcReference.class); if (annotation != null) &#123; BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RpcReferenceBean.class); builder.setInitMethodName(INIT_METHOD_NAME); builder.addPropertyValue(&quot;interfaceClass&quot;, field.getType()); builder.addPropertyValue(&quot;serviceVersion&quot;, annotation.serviceVersion()); builder.addPropertyValue(&quot;timeout&quot;, annotation.timeout()); AbstractBeanDefinition definition = builder.getBeanDefinition(); rpcRefBeanDefinitions.put(field.getName(), definition); &#125; &#125;&#125;","path":"2023/09/24/castile-rpc框架：服务的注册与发现/","date":"09-24","excerpt":"","tags":[{"name":"rpc","slug":"rpc","permalink":"https://castile.github.io/tags/rpc/"}]},{"title":"castile-rpc框架","text":"RPC服务框架架构 RPC又称远程过程调用（Remote Procedure Call），用于解决分布式系统中服务之间的调用问题。他可以实现开发者能够像调用本地的方法一样去调用远程的服务。包含了三个重要的组成部分，分别是注册中心、服务提供者、服务消费者，其中，服务消费者也称之为客户端。 在一次RPC调用的时候，这三个组成部分的交互过程大致如下： 1、 服务提供者（微服务）启动的时候，会将自己的对外开发的服务列表（接口信息）注册到服务中心中，消费者想注册中心去订阅服务提供者的地址。 2、 消费者会通过一个本地的代理模块区调用服务提供者，这个代理Proxy模块会将调用的方法。参数等数据封装成网络字节流的形式去传输 3、在传输之前需要确定发给哪一个服务端，因此会先从服务列表中选取一个服务地址（可以做负载均衡），并将数据通过网络发送给服务端。 4、 服务提供者接受到消息后，进行解码，拿到要调用的方法和参数。 5、服务提供者根据解码后的请求去调用对应的服务，然后将返回结果封装成字节流发送给服务消费者。 服务的注册和发现首先最重要的是服务提供者可以去注册到注册中心，消费者可以去注册中心订阅服务。 为什么要有注册中心呢？传统的分布式系统一般是通过http去调用远端服务，这往往需要知道具体的服务端地址、调用信息等，系统之间的耦合比较严重，为了更好的去洁癖客户端和服务端，引入了注册中心，可以优雅地处理服务的上线和下线。 注册中心实现服务的注册和发现功能。服务端自行注册服务列表，服务下线的时候需要将自己的服务列表元数据移除，并可通知对应的客户端。客户端发起调用的时候，自己去订阅获取注册中心的服务列表，并通过一些负载均衡算法选择其中的一个实例进行调用， 那么，如何处理服务下线的问题，服务下线是需要移除注册中心该服务的一些信息的，最能想到的办法就是，服务端主动发送清理消息给注册中心，但是如果服务节点异常退出，比如节点断点了，断网等，还来不及发送消息给注册中心，那么注册中心就一直存在异常服务节点的元数据了，从而可能会造成服务调用失败的问题。 为了避免上述问题，实现服务优雅下线比较好的方式是采用主动通知 + 心跳检测的方案。除了主动通知注册中心下线外，还需要增加节点与注册中心的心跳检测功能，这个过程也叫作探活。心跳检测可以由节点或者注册中心负责，例如注册中心可以向服务节点每 60s 发送一次心跳包，如果 3 次心跳包都没有收到请求结果，可以任务该服务节点已经下线 通信协议和序列化RPC 是远程调用，必然离不开网络通信协议。客户端在向服务端发起调用之前，需要考虑采用何种方式将调用信息进行编码，并传输到服务端。因为 RPC 框架对性能有非常高的要求，所以通信协议应该越简单越好，这样可以减少编解码的性能损耗。 RPC 框架可以基于不同的协议实现，大部分主流 RPC 框架会选择 TCP、HTTP 协议，出名的 gRPC 框架使用的则是 HTTP2。TCP、HTTP、HTTP2 都是稳定可靠的，但其实使用 UDP 协议也是可以的，具体看业务使用的场景 。 客户端和服务端在通信过程中要传输的数据主要有： 调用的接口名称 方法 请求参数 调用属性等信息 这些数据需要在客户端序列化成二进制，通过网络传输到服务端。服务端需要通过反序列化得到调用的信息，然后利用反射调用对应的方法，最后将结果、状态码、异常等信息返回。 调用方式1、 同步调用客户端线程发起RPC调用后会一直阻塞，知道拿到返回的结果。 2、 异步调用客户端发起调用后不会再阻塞等待，而是拿到 RPC 框架返回的 Future 对象，调用结果会被服务端缓存，客户端自行决定后续何时获取返回结果 3、 回调调用客户端发起调用的时候，将callback对象传给rpc框架，无需等待结果。当得到服务端响应结果或者超时的时候，会执行用户注册的回调函数。callback一般包含onResponse 和 onException 两个方法，分别对应成功返回和异常返回两种情况。 4、 OneWay单向调用 客户端发起请求之后直接返回 ，忽略他的返回结果。 线程模型线程模型是RPC框架重要关注的部分，首先需要知道IO线程和业务线程的区别。 以Dubbo框架为例， Dubbo 使用 Netty 作为底层的网络通信框架，采用了我们熟悉的主从 Reactor 线程模型，其中 Boss 和 Worker 线程池就可以看作 I/O 线程。I/O 线程可以理解为主要负责处理网络数据，例如事件轮询、编解码、数据传输等。 业务逻辑如果能够立即完成，也可以使用 I/O 线程进行处理，这样可以省去线程上下文切换的开销。如果业务逻辑耗时较多，例如包含查询数据库、复杂规则计算等耗时逻辑，那么 I/O 必须将这些请求分发到业务线程池中进行处理，以免阻塞 I/O 线程 那么哪些请求需要在 I/O 线程中执行，哪些又需要在业务线程池中执行呢？Dubbo 框架的做法值得借鉴，它给用户提供了多种选择，它一共提供了 5 种分发策略，如下表格所示 策略类型 描述 all 所有的请求、事件、心跳等都发送到业务线程池，也就是说Worker线程接收到事件后，会将事件提交到业务线程池中 connection 连接建立、断开事件放入队列排队执行，其他所有的消息都分发到业务线程池执行 direct 所有事件都在IO线程池中执行 execution 只有请求类的消息分发到业务线程池中执行，响应和其他事件消息直接在IO线程池中处理 message 只有请求响应消息被分发到业务线程池中执行，其他事件消息都在IO线程池中执行 负载均衡服务提供者和服务消费者多实例的，如何保证服务提供者的所有节点的负载均衡呢。主流的方法有以下几种： Round-Robin 轮询。 Weighted Round-Robin 权重轮询 Least Connections 最少连接数 Consistent Hash 一致性 Hash。","path":"2023/09/03/castile-rpc框架/","date":"09-03","excerpt":"","tags":[{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"},{"name":"rpc","slug":"rpc","permalink":"https://castile.github.io/tags/rpc/"}]},{"title":"算子链","text":"并行子任务和并行度在 Flink 执行过程中，每一个算子（operator）可以包含一个或多个子任务（operator subtask）， 这些子任务在不同的线程、不同的物理机或不同的容器中完全独立地执行 一个特定算子的子任务（subtask）的个数被称之为其并行度（parallelism）。 包含并行子任务的数据流，就是并行数据流，它需要多个分区（stream partition）来分配并行任 算子间的数据传输 一个数据流在算子之间传输数据的形式可以是一对一（one-to-one）的直 通 (forwarding)模式，也可以是打乱的重分区（redistributing）模式，具体是哪一种形式，取决 于算子的种类。 （1）一对一（One-to-one，forwarding） 数据流维护着分区以及元素的顺序。比如图中的 source 和 map 算子，source 算子读取数据之后，可以直接发送给 map 算子做处理，它们之间不需要重新分区，也不需要 调整数据的顺序。这就意味着 map 算子的子任务，看到的元素个数和顺序跟 source 算子的子 任务产生的完全一样，保证着“一对一”的关系。map、filter、flatMap 等算子都是这种 one-to-one 的对应关系 （2）重分区（Redistributing） 在这种模式下，数据流的分区会发生改变。比图中的 map 和后面的 keyBy/window 算子之 间（这里的 keyBy 是数据传输算子，后面的 window、apply 方法共同构成了 window 算子）, 以及 keyBy/window 算子和 Sink 算子之间，都是这样的关系。 合并算子链在 Flink 中，并行度相同的一对一（one to one）算子操作，可以直接链接在一起形成一个 “大”的任务（task），这样原来的算子就成为了真正任务里的一部分 每个 task 会被一个线程执行。这样的技术被称为“算子链”（Operator Chain）。 Source 和 map 之间满足了算子链的要求，所以可以直接合并 在一起，形成了一个任务；因为并行度为 2，所以合并后的任务也有两个并行子任务。这样， 这个数据流图所表示的作业最终会有 5 个任务，由 5 个线程并行执行 将算子链接成 task 是非常有效的优 化：可以减少线程之间的切换和基于缓存区的数据交换，在减少时延的同时提升吞吐量。","path":"2023/09/03/算子链/","date":"09-03","excerpt":"","tags":[{"name":"Flink","slug":"Flink","permalink":"https://castile.github.io/tags/Flink/"},{"name":"Operator Chain","slug":"Operator-Chain","permalink":"https://castile.github.io/tags/Operator-Chain/"}]},{"title":"任务和任务槽Slot","text":"任务槽 （Task Slots）Flink 中每一个 worker(也就是 TaskManager)都是一个 JVM 进程，它可 6以启动多个独立的线程，来并行执行多个子任务（subtask）。 任务槽（task slot）其实表示了 TaskManager 拥有计算资源的一个固定大小的子集。 这些资源就是用来独立执行一个子任务的 假如一个 TaskManager 有三个 slot，那么它会将管理的内存平均分成三份，每个 slot 独自 占据一份。这样一来，我们在 slot 上执行一个子任务时，相当于划定了一块内存“专款专用”， 就不需要跟来自其他作业的任务去竞争内存资源了。所以现在我们只要 2 个 TaskManager，就 可以并行处理分配好的 5 个任务了。 slot 目前仅仅用来隔离内存，不会涉及 CPU 的隔离。在具体应用时，可 以将 slot 数量配置为机器的 CPU 核心数，尽量避免不同任务之间对 CPU 的竞争。这也是开发 环境默认并行度设为机器 CPU 数量的原因 。 任务对任务槽的共享 默认情况下，Flink 是允许子任务共享 slot 的。 只要属于同一个作业，那么对于不同任务节点的并行子任务，就可以放到同一个 slot 上执行。 每个任务节点的并行子任务一字排开，占据不同的 slot；而不同 的任务节点的子任务可以共享 slot。一个 slot 中，可以将程序处理的所有任务都放在这里执行， 我们把它叫作保存了整个作业的运行管道（pipeline）。 我们知道，一个 slot 对应了一组独立的计算资源。在之前不做共享的时候，每个任务都平 等地占据了一个 slot，但其实不同的任务对资源的占用是不同的。例如这里的前两个任务， source/map 尽管是两个算子合并算子链得到的，但它只是基本的数据读取和简单转换，计算耗 时极短，一般也不需要太大的内存空间；而 window 算子所做的窗口操作，往往会涉及大量的 数据、状态存储和计算，我们一般把这类任务叫作“资源密集型”（intensive）任务。当它们 被平等地分配到独立的 slot 上时，实际运行我们就会发现，大量数据到来时 source/map 和 sink 任务很快就可以完成，但 window 任务却耗时很久；于是下游的 sink 任务占据的 slot 就会等待 闲置，而上游的 source/map 任务受限于下游的处理能力，也会在快速处理完一部分数据后阻 塞对应的资源开始等待（相当于处理背压）。这样资源的利用就出现了极大的不平衡，“忙的忙 死，闲的闲死”。 解决这一问题的思路就是允许 slot 共享。当我们将资源密集型和非密集型的任务同时放到 一个 slot 中，它们就可以自行分配对资源占用的比例，从而保证最重的活平均分配给所有的 TaskManager。 同一个任务节点的并行子任务是不能共享 slot 的，所以允许 slot 共享之后，运行作业所需的 slot 数量正好就是作业中所有算子并行度的最大值。这样一来，我们考虑当前集群需 要配置多少 slot 资源时，就不需要再去详细计算一个作业总共包含多少个并行子任务了，只看 最大的并行度就够了。 任务槽和并行度的关系假设一共有 3 个 TaskManager，每一个 TaskManager 中的 slot 数量设置为 3 个，那么一共有 9 个 task slot，表示集群最多能并行执行 9 个任务 而我们定义 WordCount 程序的处理操作是四个转换算子： source→ flatMap→ reduce→ sink 当所有算子并行度相同时，容易看出 source 和 flatMap 可以合并算子链，于是最终有三个任务节点.。如果我们没有任何并行度设置，而配置文件中默认 parallelism.default=1，那么程序运行的 默认并行度为 1，总共有 3 个任务。由于不同算子的任务可以共享任务槽，所以最终占用的 slot 只有 1 个。9 个 slot 只用了 1 个，有 8 个空闲。 设置并行度为 2，那么总共有 6 个任务，共享任 务槽之后会占用 2 个 slot： 把并行度设置为 9，这样所有 27 个任务就会完全占用 9 个 slot。 这是当前集群资源下能执行的最大并行度，计算资源得到了充分的利用 再考虑对于某个算子单独设置并行度的场景。 考虑到输出可能是写入 文件，那会希望不要并行写入多个文件，就需要设置 sink 算子的并行度为 1。这时其他的算子 并行度依然为 9，所以总共会有 19 个子任务。根据 slot 共享的原则，它们最终还是会占用全 部的 9 个 slot，而 sink 任务只在其中一个 slot 上执行 整个流处理程序的并行度，就应该是所有算子并行度中最大的那个， 这代表了运行程序需要的 slot 数量。","path":"2023/09/03/任务和任务槽Slot/","date":"09-03","excerpt":"","tags":[{"name":"Flink","slug":"Flink","permalink":"https://castile.github.io/tags/Flink/"},{"name":"Slots","slug":"Slots","permalink":"https://castile.github.io/tags/Slots/"}]},{"title":"领域驱动设计04-限界上下文","text":"1、 限界上下文的含义限界上下文(Bounded Context)， Context 表现了业务流程的场景片段。整个业务流程由诸多具有时序的活动组成，随着流程的进行，不同的活动需要不同的角色参与，并导致上下文因为某个活动的产生随之发生切换。因而，上下文（Context）其实是动态的业务流程被边界（Bounded）静态切分的产物。 一个复杂系统的领域驱动设计，就是以子域为中心进行领域建模，绘制出一张一张的领域模型设计，然后以此作为基础指导程序设计。这一张一张的领域模型设计，称为“限界上下文”（Context Bounds，CB）。 根据业务相关性、耦合的强弱程度、分离的关注点对这些活动进行归类，找到不同类别之间存在的边界，这就是限界上下文的含义。上下文（Context）是业务目标，限界（Bounded）则是保护和隔离上下文的边界，避免业务目标的不单一而带来的混乱与概念的不一致。 2、限界上下文的价值观察角度的不同，限界上下文划定的边界也有所不同。大体可以分为如下三个方面： 领域逻辑层面：限界上下文确定了领域模型的业务边界，维护了模型的完整性与一致性，从而降低系统的业务复杂度。 团队合作层面：限界上下文确定了开发团队的工作边界，建立了团队之间的合作模式，避免团队之间的沟通变得混乱，从而降低系统的管理复杂度。 技术实现层面：限界上下文确定了系统架构的应用边界，保证了系统层和上下文领域层各自的一致性，建立了上下文之间的集成方式，从而降低系统的技术复杂度。 这三种边界体现了限界上下文对不同边界的控制力。业务边界是对领域模型的控制，工作边界是对开发协作的控制，应用边界是对技术风险的控制。引入限界上下文的目的，其实不在于如何划分边界，而在于如何控制边界。 EventStorming 创始人 Alberto Brandolini 对限界上下文的理解： bounded context are a mean of safety（限界上下文意味着安全），如何理解安全呢？ 他的意思是： being in control and no surprise。 Surprise leads to stress and stress leads to no learning, just hard work. （出乎意料的惊讶会导致压力，而压力就会使得团队疲于加班，缺少学习。） 其实限界上下文并不是大多数人理解的那样，是模块、服务、组件或者子系统，而是你对领域模型、团队合作以及技术风险的控制。大领域的模型切割成一个一个小的领域模型是很重要的， 更小的模型为我们的软件设计和开发带来了更多的好处，它使得团队能够根据自己的设计和开发职责确定更为明确的工作边界 。 小的模型也为项目带来了更好的可维护性：由于上下文由边界确定，因此对其的修改也不会给整个模型的其他部分造成影响。显然，通过限界上下文对领域模型进行分解，就能保证在其边界内创建的模型内聚性更高，在边界隔离下，受到变化的影响也更小，反映为团队合作的工作边界，就更容易保证团队之间的沟通与协作。 限界上下文是“分而治之”架构原则的体现，我们引入它的目的其实为了控制（应对）软件的复杂度，它并非某种固定的设计单元，我们不能说它就是模块、服务或组件，而是通过它来帮助我们做出高内聚低耦合的设计。 可以把限界上下文看成是一个“自治”的单元。 所谓“自治”就是满足四个特征：最小完备、稳定空间、自我履行、独立进化。如下图所示的自治单元就是限界上下文，映射到编码实现，则可能是模块、组件或服务： 最小完备是实现“自治”的基本条件。自治单元的职责是完整的，不需要依赖别的单元的功能。最小完备是指不要将不必要的职责被错误地添加到该自治单元内。 自我履行表示自治单元自身决定需要做什么， 从拟人的角度来思考，就是这些自治单元能够对外部请求做出符合自身利益的明智判断，是否应该履行该职责，由限界上下文拥有的信息来决定。 例如，在当订单上下文履行了验证订单的职责之后，需要执行支付活动时，由于与支付相关的业务行为要操作的信息已经超出了订单上下文的范畴，就应该将该职责转移到支付上下文。自我履行其实意味着对知识的掌握，为避免风险，你要履行的职责一定是你掌握的知识范畴之内。 稳定空间指的是减少外界变化对限界上下文内部的影响。 稳定空间符合开放封闭原则（OCP），即对修改是封闭的，对扩展是开放的，该原则其实体现了一个单元的封闭空间与开放空间。封闭空间体现为对细节的封装与隐藏，开放空间体现为对共性特征的抽象与统一，二者共同确保了整个空间的稳定。 独立进化与稳定空间刚好相反，指的是减少限界上下文的变化对外界的影响。 如果借用限界上下文的上下游关系来阐释，则稳定空间寓意下游限界上下文，无论上游怎么变，我自岿然不动；独立进化寓意上游限界上下文，无论下游有多少，我凌寒独自开。实现上看，要做到独立进化，就必须保证对外公开接口的稳定性，因为这些接口往往被众多消费者使用，一旦修改，就会牵一发而动全身。一个独立进化的限界上下文，需要接口设计良好，符合标准规范，并在版本上考虑了兼容与演化。 这四个要素是高内聚低耦合思想的体现。我们需要根据业务关注点和技术关注点，尽可能将强相关性的内容放到同一个限界上下文中，同时降低限界上下文之间的耦合。对于整个系统架构而言，不同的限界上下文可以采用不同的架构风格与技术决策，而在每个限界上下文内部保持自己的技术独立性与一致性。由于限界上下文边界对技术实现的隔离，不同限界上下文内部实现的多样性并不会影响整体架构的一致性。 3、 限界上下文分离了业务边界引入限界上下文的目的，不在于如何划分，而在于如何控制边界。 可以说，限界上下文是连接问题域与解决方案域的重要桥梁。 限界上下文用于区分领域边界，我们在理解领域模型时，是基于当前所在的上下文作为概念语境的， 这样的设计既保证了限界上下文之间的松散耦合，又能够维持限界上下文各自领域模型的一致性，此时的限界上下文成为了保障领域模型不受污染的边界屏障。 在面向对象设计中，行之有效的“接口隔离原则”如果跨越了多个限界上下文，就变得不合理了。要降低耦合同时又能避免重复，更好的解决方案是让每一个限界上下文拥有自己的领域模型，该领域模型仅仅满足符合当前上下文需要的产品唯一表示。 虽然不同的限界上下文都存在相同的 Product 领域模型，但由于有了限界上下文作为边界，使得我们在理解领域模型时，是基于当前所在的上下文作为概念语境的。这样的设计既保证了限界上下文之间的松散耦合，又能够维持限界上下文各自领域模型的一致性，此时的限界上下文成为了保障领域模型不受污染的边界屏障。 4、 限界上下文明确了工作边界 一个理想的开发团队规模最好能符合亚马逊公司提出的“Two-Pizza Teams”，即 2PTs 规则，该规则认为“让团队保持在两个披萨能让成员吃饱的小规模”，大体而言，就是将团队成员人数控制在 7~10 人左右。为何要保证这样的规模呢？因为小团队能够更有效保证有效的沟通。 传统的“组件团队”强调的是专业技能与功能重用，例如，熟练掌握数据库开发技能的成员组建一个数据库团队，深谙前端框架的成员组建一个前端开发团队。这种遵循“专业的事情交给专业的人去做”原则的团队组建模式，可以更好地发挥每个人的技能特长，然而牺牲的却是团队成员业务知识的缺失，客户价值的漠视。这种团队组建模式也加大了团队之间的沟通成本，导致系统的整体功能无法持续和频繁的集成。 特性团队， 是一个端对端的开发垂直细分领域的跨职能团队，它将需求分析、架构设计、开发测试等多个角色糅合在一起，专注于领域逻辑，实现该领域特性的完整的端对端开发。 特性团队专注的领域特性，是与领域驱动设计中限界上下文对应的领域是相对应的。当我们确定了限界上下文时，其实也就等同于确定了特性团队的工作边界，确定了限界上下文之间的关系，也就意味着确定了特性团队之间的合作模式；反之亦然。之所以如此，则是因为康威定律（Conway’s Law）为我们提供了理论支持 康威定律认为：“任何组织在设计一套系统（广义概念上的系统）时，所交付的设计方案在结构上都与该组织的沟通结构保持一致。” 在康威定律中起到关键杠杆作用的是沟通成本。如果同一个限界上下文的工作交给了两个不同的团队分工完成，为了合力解决问题，就必然需要这两个团队进行密切的沟通。然而，团队间的沟通成本显然要高于团队内的沟通成本，为了降低日趋增高的成本，就需要重新划分团队。反过来，如果让同一个团队分头做两个限界上下文的工作，则会因为工作的弱相关性带来自然而然的团队隔离。 5、 限界上下文封装了应用边界在划分上下文的时候，不能只满足于业务边界的确立，还需要从控制技术复杂度的角度来考虑技术实现。高并发系统，功能重用，实时性，第三服务集成，遗留系统等案例从技术层面为系统划分边界，这种边界也是由限界上下文完成的，以形成对技术实现的隔离，避免不同的技术方案选择互相干扰导致架构混乱。","path":"2023/06/06/领域驱动设计04-限界上下文/","date":"06-06","excerpt":"","tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"限界上下文","slug":"限界上下文","permalink":"https://castile.github.io/tags/%E9%99%90%E7%95%8C%E4%B8%8A%E4%B8%8B%E6%96%87/"}]},{"title":"领域驱动设计03-应用领域场景分析提炼领域知识","text":"领域场景分析的 6W 模型 组成场景的要素常常被称之为 6W 模型，即描写场景的过程必须包含 Who、What、Why、Where、When 与 hoW 这六个要素。 在 6W 模型中，可以将领域功能划分为三个层次，即业务价值、业务功能和业务实现。 在分析一个需求的时候，要建立场景，识别该场景中的用户角色（Who），通过分析改用户的特征与属性 来辨别该角色在整个场景中参与的活动。这意味着我们需要明确业务功能（What），思考这一功能给该角色能够带来什么样的业务价值（Why）。在不同场景中同一个用户可能代表不同的角色，比如在订单系统中，角色就是买家；在评论系统中，角色变成了评论者。 在利用场景进行建模时，还要充分考虑场景的边界，即 6W 模型中的 Where。例如，在“下订单”的案例中，验证商品库存量的业务实现需要调用库存提供的接口，该功能属于下订单场景的边界之外。领域驱动设计引入了限界上下文（Bounded Context）来解决这一问题。 业务场景分析的 6W 模型给出了具有指导意义的约束，要求我们提炼的领域知识必须具备模型的六个要素。 6W 模型也是对领域逻辑的一种检验，如果提炼出来的领域逻辑缺乏部分要素，就有可能忽略一些重要的领域概念、规则与约束。这种缺失会对后续的领域建模直接产生影响。 领域场景分析的方法 如果将 6W 模型看做是领域分析的抽象，那么这些领域分析方法就是对 6W 模型各种不同的实现。 这些模式主要有： 用例（Use Case） 用户故事（User Story） 测试驱动开发（TDD） 用例尤其是用例图的抽象能力更强，更擅长于对系统整体需求进行场景分析；用户故事提供了场景分析的固定模式，善于表达具体场景的业务细节；测试驱动开发则强调对业务的分解，利用编写测试用例的形式驱动领域建模，即使不采用测试先行，让开发者转换为调用者角度去思考领域对象及行为，也是一种很好的建模思想与方法。 在提炼领域知识的过程中，我们可以将这三种领域场景分析方法结合起来运用，在不同层次的领域场景中选择不同的场景分析方法，才不至于好高骛远，缺乏对细节的把控，也不至于一叶障目，只见树木不见森林。","path":"2023/05/25/领域驱动设计03-应用领域场景分析提炼领域知识/","date":"05-25","excerpt":"","tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"}]},{"title":"领域驱动设计02-应对软件的复杂性","text":"应对软件的复杂性需求引起的软件复杂度包含了业务复杂度和技术复杂度： 技术复杂度来自需求的质量属性，诸如安全、高性能、高并发、高可用性等需求，为软件设计带来了极大的挑战，让人痛苦的是这些因素彼此之间可能又互相矛盾、互相影响。 业务复杂度对应了客户的业务需求，因而这种复杂度往往会随着需求规模的增大而增加。由于需求不可能做到完全独立，一旦规模扩大到一定程度，不仅产生了功能数量的增加，还会因为功能互相之间的依赖与影响使得这种复杂度产生叠加，进而影响到整个系统的质量属性，比如系统的可维护性与可扩展性。 技术复杂度与业务复杂度并非完全独立，二者混合在一起产生的化合作用更让系统的复杂度变得不可预期，难以掌控。 1、隔离业务复杂度与技术复杂度 要避免业务逻辑的复杂度与技术实现的复杂度混淆在一起，首要任务就是确定业务逻辑与技术实现的边界，从而隔离各自的复杂度。 例如，在电商的领域逻辑中，订单业务关注的业务规则包括验证订单有效性、计算订单总额、提交和审核订单的流程等；技术关注点则从实现层面保障这些业务能够正确地完成，包括确保分布式系统之间的数据一致性，确保服务之间通信的正确性等。 业务逻辑并不关心技术是如何实现的，无论采用何种技术，只要业务需求不变，业务规则就不会发生变化。换言之，在理想状态下，我们应该保证业务规则与技术实现是正交的。 领域驱动设计通过分层架构与六边形架构来确保业务逻辑与技术实现的隔离 2、分层架构的关注点分离 分层架构遵循了“关注点分离”原则，将属于业务逻辑的关注点放到领域层（Domain Layer）中，而将支撑业务逻辑的技术实现放到基础设施层（Infrastructure Layer）中。同时，领域驱动设计又颇具创见的引入了应用层（Application Layer），应用层扮演了双重角色。一方面它作为业务逻辑的外观（Facade），暴露了能够体现业务用例的应用服务接口；另一方面它又是业务逻辑与技术实现的粘合剂，实现二者之间的协作。 下图展现的就是一个典型的领域驱动设计分层架构，蓝色区域的内容与业务逻辑有关，灰色区域的内容与技术实现有关，二者泾渭分明，然后汇合在应用层。应用层确定了业务逻辑与技术实现的边界，通过直接依赖或者依赖注入（DI，Dependency Injection）的方式将二者结合起来： 3、六边形架构的内外分离 由 Cockburn 提出的六边形架构则以“内外分离”的方式，更加清晰地勾勒出了业务逻辑与技术实现的边界，且将业务逻辑放在了架构的核心位置。这种架构模式改变了我们观察系统架构的视角： 体现业务逻辑的应用层与领域层处于六边形架构的内核，并通过内部的六边形边界与基础设施的模块隔离开。当我们在进行软件开发时，只要恪守架构上的六边形边界，则不会让技术实现的复杂度污染到业务逻辑，保证了领域的整洁。边界还隔离了变化产生的影响。如果我们在领域层或应用层抽象了技术实现的接口，再通过依赖注入将控制的方向倒转，业务内核就会变得更加的稳定，不会因为技术选型或其他决策的变化而导致领域代码的修改。 4、限界上下文的分而治之面对一个庞大的问题域，可以划分一些子系统，这些子系统内部也可以进行分层架构。不同子系统之间的抽象层次是一致的，这种概念在DDD中称之为“限界上下文（Bounded Context）”。 通过限界上下文“分而治之”的思想对问题域进行分解，有效地控制了问题域的规模，进而控制了整个系统的规模。 限界上下文对整个系统进行了划分，在将一个大系统拆分为一个个小系统后，我们再利用分层架构与六边形架构思想对其进行逻辑分层，以确保业务逻辑与技术实现的隔离，其设计会变得更易于把控，系统的架构也会变得更加清晰。 在一个复杂系统中，可以将识别出来的限界上下文定义为微服务，并对外公开REST服务接口。 UI Applications 是一个薄薄的展现层，它会调用后端的 RESTful 服务，也使得服务在保证接口不变的前提下能够单独演化。每个服务都是独立的，可以单独部署，因而可以针对服务建立单独的代码库和对应的特性团队（Feature Team）。服务的重用性和可扩展性也有了更好的保障，服务与 UI 之间的集成变得更简单，整个架构会更加清晰。 5、领域模型对领域知识的抽象以一个软件项目管理流程来举例子。在一个团队中，使用的软件开发流程大致有如下几类： 瀑布式开发： 需求、分析、设计、编码、测试、验收 RUP（ Rational Unified Process 统一软件开发过程）： 先启阶段（Inception）、细化阶段（Elaboration）、构造阶段（Construction）与交付阶段（Transition）。 每个阶段可以包含一到多个迭代，每个迭代有不同的工作，如业务建模、分析设计、配置与变更管理 XP（ Extreme Programming ）： 极限编程作为一种敏捷方法，迭代的增量式开发。先做预研（ Architectual Spike，又被译为架构穿刺 ），初始方案确定后就可以进入每次小版本的交付（Release Planning）。 每个小版本交付又被划分为多个周期相同的迭代。在迭代过程中，要求执行一些必须的活动，如编写用户故事、故事点估算、验收测试等。 Scrum：确定系统待办项（Product Backlog）、指定发布计划和组件团队、Sprint迭代。 Sprint 迭代过程是一个固定时长的项目过程，在这个过程中，整个团队需要召开计划会议、每日站会（Daliy Scrum）、评审会议（Sprint Review）和回顾会议（Sprint Retrospective）。 领域分析 领域建模就是要从这些纷繁复杂的领域逻辑中寻找到能够表示项目管理领域的概念，并利用面向对象建模范式或其他范式对概念进行抽象，并确定它们之间的关系。 上面说的几种开发流程在概念上会有差别，比如瀑布模式有六个节阶段，但是没有发布、迭代这些概念。RUP有阶段，有迭代，但是没有发布。Scrum又为迭代引入了Sprint概念。 除了业务概念外，他们的业务规则也会有不一样的地方。 首先，从项目管理系统的角度看，无论针对何种项目管理流程，我们的主题需求是不变的，就是要为这些管理流程制定软件开发计划（Plan） 计划可以由多个阶段（Phase）组成 阶段（Phase）包含了发布（Release） 每个发布又包含了一到多个迭代（Iteration） 每个迭代可以开展多种不同的活动（Activity） 对于计划而言，我们还需要跟踪任务（Task） 所以我们可以根据上述分析提炼出统一的领域模型： 项目管理者更加方便地制定项目计划，产品经理提出了计划模板功能。当管理者选择对应的项目管理生命周期类型后，系统会自动创建满足其规则的初始计划。 在模型中，LifeCycle Specification 是一个隐含的概念，遵循领域驱动设计提出的规格（Specification）模式，封装了项目开发生命周期的约束规则。 领域模型以可视化的方式清晰地表达了业务含义， 我们可以根据这个模型来指导后面的程序设计与编码实现，当需求有变更的时候可以根据模型进行更新。同时，领域建模可以很好在团队之间传递知识， 有利于让开发人员从纷繁复杂的业务中解脱出来，从而可以在一定程度上控制业务的复杂度对我们软件交付的影响。","path":"2023/05/18/领域驱动设计02-应对软件的复杂性/","date":"05-18","excerpt":"","tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"软件复杂性","slug":"软件复杂性","permalink":"https://castile.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%A4%8D%E6%9D%82%E6%80%A7/"}]},{"title":"领域驱动设计01-概览","text":"领域驱动设计概览领域驱动设计是一种面向对象的建模方法。 将要解决的业务概念和业务规则转换为软件系统中的类型以及类型的属性与行为，通过合理运用面向对象的封装、继承和多态等设计要素，降低或隐藏整个系统的业务复杂性，并使得系统具有更好的扩展性，应对纷繁多变的现实业务问题。 领域驱动设计的提出，是设计观念的转变，蕴含了全新的设计思想、设计原则与设计过程。 领域驱动设计过程 领域驱动设计强调领域模型的重要性，并通过模型驱动设计来保障领域模型与程序设计的一致。从业务需求中提炼出统一语言（Ubiquitous Language），再基于统一语言建立领域模型；这个领域模型会指导着程序设计以及编码实现；最后，又通过重构来发现隐式概念，并运用设计模式改进设计与开发质量 这个过程是一个覆盖软件全生命周期的设计闭环，每个环节的输出都可以作为下一个环节的输入，而在其中扮演重要指导作用的则是“领域模型” 。这是一个 螺旋式的迭代设计过程。 在为问题域寻求解决方案时，需要从宏观层次划分不同业务关注点的子领域，然后再深入到子领域中从微观层次对领域进行建模。宏观层次是战略的层面，微观层次是战术的层面，只有将战略设计与战术设计结合起来，才是完整的领域驱动设计。 战略设计阶段 领域驱动设计的战略设计阶段是从下面两个方面来考量的 ： 问题域方面：针对问题域，引入限界上下文（Bounded Context）和上下文映射（Context Map）对问题域进行合理的分解，识别出核心领域（Core Domain）与子领域（SubDomain），并确定领域的边界以及它们之间的关系，维持模型的完整性。 架构方面：通过分层架构来隔离关注点，尤其是将领域实现独立出来，能够更利于领域模型的单一性与稳定性；引入六边形架构可以清晰地表达领域与技术基础设施的边界；CQRS 模式则分离了查询场景和命令场景，针对不同场景选择使用同步或异步操作，来提高架构的低延迟性与高并发能力。 战术设计阶段 整个软件系统被分解为多个限界上下文（或领域）后，就可以分而治之，对每个限界上下文进行战术设计。领域驱动设计并不牵涉到技术层面的实现细节，在战术层面，它主要应对的是领域的复杂性。领域驱动设计用以表示模型的主要要素包括： 值对象（Value Object） 实体（Entity） 领域服务（Domain Service） 领域事件（Domain Event） 资源库（Repository） 工厂（Factory） 聚合（Aggregate） 应用服务（Application Service） 领域驱动设计围绕着领域模型进行设计，通过分层架构（Layered Architecture）将领域独立出来。表示领域模型的对象包括：实体、值对象和领域服务，领域逻辑都应该封装在这些对象中。这一严格的设计原则可以避免业务逻辑渗透到领域层之外，导致技术实现与业务逻辑的混淆。在领域驱动设计的演进中，又引入了领域事件来丰富领域模型。 聚合是一种边界，它可以封装一到多个实体与值对象，并维持该边界范围之内的业务完整性。在聚合中，至少包含一个实体，且只有实体才能作为聚合根（Aggregate Root）。注意，在领域驱动设计中，没有任何一个类是单独的聚合，因为聚合代表的是边界概念，而非领域概念。在极端情况下，一个聚合可能有且只有一个实体。 工厂和资源库都是对领域对象生命周期的管理。前者负责领域对象的创建，往往用于封装复杂或者可能变化的创建逻辑；后者则负责从存放资源的位置（数据库、内存或者其他 Web 资源）获取、添加、删除或者修改领域对象。领域模型中的资源库不应该暴露访问领域对象的技术实现细节。","path":"2023/05/17/领域驱动设计01-概览/","date":"05-17","excerpt":"","tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"战略设计","slug":"战略设计","permalink":"https://castile.github.io/tags/%E6%88%98%E7%95%A5%E8%AE%BE%E8%AE%A1/"},{"name":"战术设计","slug":"战术设计","permalink":"https://castile.github.io/tags/%E6%88%98%E6%9C%AF%E8%AE%BE%E8%AE%A1/"}]},{"title":"Flink之聚合算子","text":"聚合算子 我们往往需要对大量的数据进行统计或整合，从而提炼出更有用的 信息。比如要对每个词出现的频次进行叠加统计。这种操作，计算的结果不仅依赖当前数据，还跟之前的数据有关，相当于要把所有数据聚在一起进行汇总合并 ——这就是所谓的“聚合”（Aggregation），也对应着 MapReduce 中的 reduce 操作。 KeyBy DataStream 是没有直接进行聚合的 API 的。因为我们对海量数据做聚合 肯定要进行分区并行处理，这样才能提高效率。所以在 Flink 中，要做聚合，需要先进行分区； 这个操作就是通过 keyBy 来完成的。 基于不同的 key，流中的数据将被分配到不同的分区中去，这样一来，所 有具有相同的 key 的数据，都将被发往同一个分区，那么下一步算子操作就将会在同一个 slot 中进行处理了。 简单聚合 有了按键分区的数据流 KeyedStream，我们就可以基于它进行聚合操作了。Flink 为我们 内置实现了一些最基本、最简单的聚合 API，主要有以下几种： ⚫ sum()：在输入流上，对指定的字段做叠加求和的操作。 ⚫ min()：在输入流上，对指定的字段求最小值。 ⚫ max()：在输入流上，对指定的字段求最大值。 ⚫ minBy()：与 min()类似，在输入流上针对指定字段求最小值。不同的是，min()只计 算指定字段的最小值，其他字段会保留最初第一个数据的值；而 minBy()则会返回包 含字段最小值的整条数据。 ⚫ maxBy()：与 max()类似，在输入流上针对指定字段求最大值。两者区别与 min()/minBy()完全一致。 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.hlz.flink.chapter05;import org.apache.flink.api.java.functions.KeySelector;import org.apache.flink.streaming.api.datastream.DataStreamSource;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;/** * 简单聚合操作2 * * @author Hongliang Zhu * @create 2023-05-04 23:33 */public class SimpleAggregation &#123; public static void main(String[] args) throws Exception &#123; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(4); DataStreamSource&lt;Event&gt; streamSource = env.fromElements( new Event(&quot;Mary&quot;, &quot;./home&quot;, 1000L), new Event(&quot;Bob&quot;, &quot;./cart&quot;, 2000L), new Event(&quot;Alice&quot;, &quot;./prod?id=100&quot;, 3000L), new Event(&quot;Bob&quot;, &quot;./home&quot;, 4000L), new Event(&quot;Bob&quot;, &quot;./prod?id=9&quot;, 5000L), new Event(&quot;Bob&quot;, &quot;./prod?id=2&quot;, 6000L), new Event(&quot;Mary&quot;, &quot;./prod?id=3&quot;, 7000L) ); // 按键分组后聚合,提取当 streamSource.keyBy(new KeySelector&lt;Event, String&gt;() &#123; @Override public String getKey(Event value) throws Exception &#123; return value.user; &#125; &#125;).max(&quot;timeStamp&quot;) .print(&quot;max: &quot;); env.execute(); &#125;&#125; 输出： max: &gt; Event{user=’Mary’, url=’./home’, timeStamp=1970-01-01 08:00:01.0}max: &gt; Event{user=’Bob’, url=’./cart’, timeStamp=1970-01-01 08:00:02.0}max: &gt; Event{user=’Alice’, url=’./prod?id=100’, timeStamp=1970-01-01 08:00:03.0}max: &gt; Event{user=’Bob’, url=’./cart’, timeStamp=1970-01-01 08:00:04.0}max: &gt; Event{user=’Bob’, url=’./cart’, timeStamp=1970-01-01 08:00:05.0}max: &gt; Event{user=’Bob’, url=’./cart’, timeStamp=1970-01-01 08:00:06.0}max: &gt; Event{user=’Mary’, url=’./home’, timeStamp=1970-01-01 08:00:07.0} 看红色这一条数据，第四条数据中的路径应该是/home，但是这里却是原来的/cart，说明max()只计 算指定字段的最小值，其他字段会保留最初第一个数据的。 把max()换成maxBy(), 结果输出如下： maxBy: &gt; Event{user=’Mary’, url=’./home’, timeStamp=1970-01-01 08:00:01.0}maxBy: &gt; Event{user=’Bob’, url=’./cart’, timeStamp=1970-01-01 08:00:02.0}maxBy: &gt; Event{user=’Alice’, url=’./prod?id=100’, timeStamp=1970-01-01 08:00:03.0}maxBy: &gt; Event{user=’Bob’, url=’./home’, timeStamp=1970-01-01 08:00:04.0}maxBy: &gt; Event{user=’Bob’, url=’./prod?id=9’, timeStamp=1970-01-01 08:00:05.0}maxBy: &gt; Event{user=’Bob’, url=’./prod?id=2’, timeStamp=1970-01-01 08:00:06.0}maxBy: &gt; Event{user=’Mary’, url=’./prod?id=3’, timeStamp=1970-01-01 08:00:07.0} 第四条数据已经中url变成了本身的数据了。 规约聚合 与简单聚合类似，reduce 操作也会将 KeyedStream 转换为 DataStream。它不会改变流的元 素数据类型，所以输出类型和输入类型是一样的。 调用 KeyedStream 的 reduce 方法时，需要传入一个参数，实现 ReduceFunction 接口， ReduceFunction 接口里需要实现 reduce()方法，这个方法接收两个输入事件，经过转换处 理之后输出一个相同类型的事件；所以，对于一组数据，我们可以先取两个进行合并，然后再 将合并的结果看作一个数据、再跟后面的数据合并，最终会将它“简化”成唯一的一个数据， 这也就是 reduce“归约”的含义。 我们将数据流按照用户 id 进行分区，然后用一个 reduce 算子实现 sum 的功能，统计每个 用户访问的频次；进而将所有统计结果分到一组，用另一个 reduce 算子实现 maxBy 的功能， 记录所有用户中访问频次最高的那个，也就是当前访问量最大的用户是谁。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package com.hlz.flink.chapter05;import org.apache.flink.api.common.functions.ReduceFunction;import org.apache.flink.api.common.typeinfo.TypeHint;import org.apache.flink.api.java.tuple.Tuple3;import org.apache.flink.streaming.api.datastream.DataStreamSource;import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;/** * reduce操作 * * @author Hongliang Zhu * @create 2023-02-16 23:29 */public class TransReduceTest &#123; public static void main(String[] args) throws Exception &#123; StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1);// DataStreamSource&lt;Event&gt; source = env.addSource(new ClickSource()); DataStreamSource&lt;Event&gt; source = env.fromElements( new Event(&quot;Mary&quot;, &quot;./mary&quot;, 1000L), new Event(&quot;Bob&quot;, &quot;./hello&quot;, 2000L), new Event(&quot;Alice&quot;, &quot;./prod&quot;, 3000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L), new Event(&quot;Bob&quot;, &quot;./prod&quot;, 5000L), new Event(&quot;Bob&quot;, &quot;./prod1&quot;, 6000L), new Event(&quot;Bob&quot;, &quot;./prod2&quot;, 7000L), new Event(&quot;Bob&quot;, &quot;./prod3&quot;, 8000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L), new Event(&quot;Alice&quot;, &quot;./prod2&quot;, 4000L)); // 将Event类型转换成Tuple元组类型// SingleOutputStreamOperator&lt;Tuple3&lt;String, String, Long&gt;&gt; tupleStream = source.map(e -&gt; Tuple3.of(e.getUser(), e.getUrl(), 1L)).returns(new TypeHint&lt;Tuple3&lt;String, String, Long&gt;&gt;() &#123;// &#125;); SingleOutputStreamOperator&lt;Tuple3&lt;String, String, Long&gt;&gt; reduceStream = source .map(e -&gt; Tuple3.of(e.getUser(), e.getUrl(), 1L)) .returns(new TypeHint&lt;Tuple3&lt;String, String, Long&gt;&gt;() &#123; &#125;) .keyBy(t -&gt; t.f0) .reduce(new ReduceFunction&lt;Tuple3&lt;String, String, Long&gt;&gt;() &#123; @Override public Tuple3&lt;String, String, Long&gt; reduce(Tuple3&lt;String, String, Long&gt; value1, Tuple3&lt;String, String, Long&gt; value2) throws Exception &#123; // 每到一条数据，pv加1 return Tuple3.of(value1.f0, value2.f1, value1.f2 + value2.f2); &#125; &#125;).keyBy(r -&gt; &quot;hello&quot;).reduce(new ReduceFunction&lt;Tuple3&lt;String, String, Long&gt;&gt;() &#123; // 找最大值 @Override public Tuple3&lt;String, String, Long&gt; reduce(Tuple3&lt;String, String, Long&gt; value1, Tuple3&lt;String, String, Long&gt; value2) throws Exception &#123; return value1.f2 &gt; value2.f2 ? value1 : value2; &#125; &#125;); reduceStream.print(&quot;reduceStream&quot;); env.execute(); &#125;&#125; 输出: reduceStream&gt; (Mary,./mary,1)reduceStream&gt; (Bob,./hello,1)reduceStream&gt; (Alice,./prod,1)reduceStream&gt; (Alice,./prod2,2)reduceStream&gt; (Bob,./prod,2)reduceStream&gt; (Bob,./prod1,3)reduceStream&gt; (Bob,./prod2,4)reduceStream&gt; (Bob,./prod3,5)reduceStream&gt; (Bob,./prod3,5)reduceStream&gt; (Bob,./prod3,5)reduceStream&gt; (Alice,./prod2,5)reduceStream&gt; (Alice,./prod2,6)reduceStream&gt; (Alice,./prod2,7) FAQ在使用max操作的时候，报错Cannot reference field by field expression on GenericType&lt;com.hlz.flink.chapter05.Event&gt;Field expressions are only supported on POJO types, tuples, and case classes. (See the Flink documentation on what is considered a POJO.) 这是因为我们定义的Event对象不是标准的POJO对象， 标准的POJO类的要求： 所有成员变量都是私有的，用private修饰 每个成员变量都有对应的getter和setter 有一个无参的构造方法 我们Event没有无参构造，因此需要加上","path":"2023/05/06/Flink之聚合算子/","date":"05-06","excerpt":"","tags":[{"name":"Flink","slug":"Flink","permalink":"https://castile.github.io/tags/Flink/"},{"name":"聚合","slug":"聚合","permalink":"https://castile.github.io/tags/%E8%81%9A%E5%90%88/"},{"name":"聚合算子","slug":"聚合算子","permalink":"https://castile.github.io/tags/%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90/"},{"name":"算子","slug":"算子","permalink":"https://castile.github.io/tags/%E7%AE%97%E5%AD%90/"}]},{"title":"castile-seckill项目jmeter性能压测","text":"Jmeter下载https://jmeter.apache.org/download_jmeter.cgi#binaries jmeter使用简介简单测试我们先小测一把，模拟20个请求去访问商品详情页的接口 结果： 1、平均值接口响应为13ms 2、90线：表示有90%的请求的响应在26ms 3、95线：表示有95%的请求响应在33ms 4、吞吐量：2.1/s 发现容量问题server端并发线程数上不去 我们使用的是springboot内嵌的tomcat 查看当前java进行开启的线程数量：pstree 123[root@localhost config]# pstree -p 20919 | wc -l29 目前有29个线程 100个线程、循环10次 500个线程、循环10次 5000个线程，循环100服务已经出现拒绝连接了： 线程数量一直在219个： 原因分析spring-configuration-metadata.json 项目使用的是springboot内嵌的tomcat容器，并且没有对参数进行特定设置；查看springboot的默认配置： server.tomcat.accept-count： 等待队列的长度，默认100 server.tomcat.max-connections： 最大可被连接数，默认8192 server.tomcat.threads.min-spare：最小工作线程数，默认10 server.tomcat.threads.max： 最大工作线程数， 默认200 默认配置下，连接超过8192后出现拒绝连接情况 默认配置项啊，触发的请求超过200+100后拒绝处理。 更改tomcat服务端参数： 12345678910111213141516171819202122232425262728# 数据源spring: datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.cj.jdbc.Driver username: root password: 123456 url: jdbc:mysql://localhost:3306/castile-seckill?characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=false&amp;useJDBCCompliantTimezoneShift=true&amp;useLegacyDatetimeCode=false&amp;serverTimezone=Asia/Shanghai # 404问题的处理, 非通用异常的返回设置 mvc: throw-exception-if-no-handler-found: true web: resources: add-mappings: truemybatis: mapper-locations: classpath:mapping/*.xmlserver: port: 9090 tomcat: accept-count: 1000 threads: max: 800 min-spare: 100 容器重新启动后，可以看到还没有开始压测的时候，启动后的线程数量为119： 优化后： 2000个线程，循环100 最大开启线程数819个 定制内嵌tomcat开发12345678910111213141516171819202122232425262728293031323334package com.castile.secondkill.config;import org.apache.catalina.connector.Connector;import org.apache.coyote.http11.Http11NioProtocol;import org.springframework.boot.web.embedded.tomcat.TomcatConnectorCustomizer;import org.springframework.boot.web.embedded.tomcat.TomcatServletWebServerFactory;import org.springframework.boot.web.server.ConfigurableWebServerFactory;import org.springframework.boot.web.server.WebServerFactoryCustomizer;import org.springframework.context.annotation.Configuration;/** * 当Spring容器内没有TomcatEmbeddedServletContainerFactory这个bean时，会把此bean加载到Spring容器中 * * @author Hongliang Zhu * @create 2023-3-27 23:01:05 */@Configurationpublic class WebServerConfiguration implements WebServerFactoryCustomizer&lt;ConfigurableWebServerFactory&gt; &#123; @Override public void customize(ConfigurableWebServerFactory factory) &#123; // 使用对应工厂类提供给我们的接口定制化我们的tomcat onnector ((TomcatServletWebServerFactory) factory).addConnectorCustomizers(new TomcatConnectorCustomizer() &#123; @Override public void customize(Connector connector) &#123; Http11NioProtocol protocol = (Http11NioProtocol) connector.getProtocolHandler(); // 设置30秒内没有请求则断开keepalive连接 protocol.setKeepAliveTimeout(30000); // 当客户端发送超过10000个请求则自动断开keepalive连接 protocol.setMaxKeepAliveRequests(10000); &#125; &#125;); &#125;&#125; KeepAliveTimeout: 多少毫秒后不响应就断开keepalive MaxKeepAliveRequests： 多少次请求后keepalive断开 设置这两个参数是为了保证我们的系统不受客户端请求的拖累，在满足需求的同时提升性能 单web容量上限线程数量：4U8G内存单进程调度线程数量800-1000以上后就花费巨大的时间在cpu的调度上 等待队列长度： 对列做缓冲池使用，但不能无限长，消耗内存，出队入队也耗cpu mysql数据库QPS容量问题经验 主键查询：千万级别数据= 1-10ms 唯一索引查询：千万级别数据 = 10-100ms 非唯一索引查询： 千万级别数据=100-1000ms 无索引： 百万条数据=1000ms+ 非插入更新删除操作： 同查询","path":"2023/03/27/castile-seckill项目jmeter性能压测/","date":"03-27","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://castile.github.io/tags/SpringBoot/"},{"name":"秒杀项目","slug":"秒杀项目","permalink":"https://castile.github.io/tags/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE/"}]},{"title":"castile-seckill项目云端部署","text":"本地打包我们使用jar包与配置文件分离的方式进行打包： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!--不打入jar包的文件类型或者路径--&gt; &lt;excludes&gt; &lt;exclude&gt;**/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- 执行的主程序路径 --&gt; &lt;mainClass&gt;com.castile.secondkill.CastileSeckillApplication&lt;/mainClass&gt; &lt;!--是否要把第三方jar放到manifest的classpath中--&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!--生成的manifest中classpath的前缀，因为要把第三方jar放到lib目录下，所以classpath的前缀是lib/--&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!-- 打包时 MANIFEST.MF 文件不记录的时间戳版本 --&gt; &lt;useUniqueVersions&gt;false&lt;/useUniqueVersions&gt; &lt;/manifest&gt; &lt;manifestEntries&gt; &lt;!-- 在 Class-Path 下添加配置文件的路径 --&gt; &lt;Class-Path&gt;config/&lt;/Class-Path&gt; &lt;/manifestEntries&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib/&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;resources&gt; &lt;!--把配置文件打包到指定路径--&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/config&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 配置文件放在config目录下，项目依赖的jar包放在lib目录下。 docker远程访问 修改 /usr/lib/systemd/system/docker.service 文件，ExecStart中加入如下内容 -H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock 重启docker让它生效 12systemctl daemon-reload systemctl restart docker idea测试docker连接 可以看到连接成功： 制作镜像 项目中引入docker-maven-plugin插件，在pom.xml引入插件并做相应的配置： 1、打包的时候忽略resource配置12345678&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;excludes&gt; &lt;exclude&gt;**/**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;/resources&gt; 2. lib、config目录的构建12345678910111213141516171819202122232425262728293031323334353637383940&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib/&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-resources&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-resources&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;resources&gt; &lt;!--把配置文件打包到指定路径--&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/config&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; 3、启动类-boot-jar1234567891011121314151617181920212223242526&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt; &lt;groupId&gt;none-group&lt;/groupId&gt; &lt;/include&gt; &lt;/includes&gt; &lt;layout&gt;ZIP&lt;/layout&gt; &lt;attach&gt;true&lt;/attach&gt; &lt;classifier&gt;boot&lt;/classifier&gt; &lt;!-- 执行的主程序路径 --&gt; &lt;mainClass&gt;com.castile.secondkill.CastileSeckillApplication&lt;/mainClass&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt; repackage &lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 4、镜像构建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;plugin&gt; &lt;!-- https://mvnrepository.com/artifact/com.spotify/docker-maven-plugin --&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.2.2&lt;/version&gt; &lt;executions&gt; &lt;!-- 当mvn执行install操作的时候，执行docker的build和push --&gt; &lt;execution&gt; &lt;id&gt;buildAndPush&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt;&lt;!-- &lt;goal&gt;build&lt;/goal&gt;--&gt;&lt;!-- &lt;goal&gt;push&lt;/goal&gt;--&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;build-docker&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 连接到 带docker环境的linux服务器 编译image --&gt; &lt;dockerHost&gt;$&#123;docker.host&#125;&lt;/dockerHost&gt; &lt;!-- push到 docker hub 开始 --&gt; &lt;!-- serverId 这个是配置在maven的setting.xml中私服的登录账户信息--&gt; &lt;retryPushCount&gt;1&lt;/retryPushCount&gt; &lt;retryPushTimeout&gt;2000&lt;/retryPushTimeout&gt; &lt;registryUrl&gt;$&#123;docker.registry&#125;&lt;/registryUrl&gt; &lt;!-- 格式：私有仓库/镜像名称:版本号, 如果要执行push操作， 那么镜像名称必须为私有仓库为前缀，不然无效。--&gt; &lt;imageName&gt;$&#123;docker.registry&#125;/$&#123;project.artifactId&#125;:$&#123;imageVersion&#125;&lt;/imageName&gt; &lt;!-- push到 docker hub 结束 --&gt; &lt;!--指定dockerfile文件路径--&gt; &lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt; &lt;!-- optionally overwrite tags every time image is built with docker:build --&gt; &lt;forceTags&gt;true&lt;/forceTags&gt; &lt;buildArgs&gt; &lt;SERVICE_PACKAGE&gt;$&#123;project.basedir&#125;/../../target/$&#123;finalName&#125;.tar.gz&lt;/SERVICE_PACKAGE&gt; &lt;/buildArgs&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/opt/castile/app&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;lib/*&lt;/include&gt; &lt;include&gt;config/**/*&lt;/include&gt; &lt;include&gt;*-boot.jar&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;!-- &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;$&#123;finalName&#125;.tar.gz&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt;--&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; 5、Dockerfile12345678910FROM openjdk:8ARG SERVICE_PACKAGEMAINTAINER zhuhongliang &#x27;castile.github.io&#x27;ENV APP_HOME=/opt/castile/appADD opt/castile/app /opt/castile/app/EXPOSE 9090WORKDIR /opt/castile/app#CMD /bin/bash $&#123;APP_HOME&#125;/config/docker-start.shENTRYPOINT [&quot;java&quot;, &quot;-Xbootclasspath/a:/opt/castile/app/config&quot;, &quot;-Djava.ext.dirs=/opt/castile/app/lib:$JAVA_HOME/jre/lib/ext&quot;,&quot;-jar&quot;,&quot;/opt/castile/app/castile-seckill-0.0.1-SNAPSHOT-boot.jar&quot;] 推送至docker私服： 启动部署12docker run -d --name castile -p 9090:9090 -v /opt/applications/castile-seckill/config/:/opt/castile/app/config 192.168.160.140:5000/castile-seckill:0.0.1-SNAPSHOT 这里设置宿主机的opt/applications/castile-seckill/config/目录和容器内/opt/castile/app/config目录映射，为了修改配置方便些。 执行的java命令： 1java -Xbootclasspath/a:/opt/castile/app/config -Djava.ext.dirs=/opt/castile/app/lib:$JAVA_HOME/jre/lib/ext -jar /opt/castile/app/castile-seckill-0.0.1-SNAPSHOT-boot.jar 部署msql因为项目依赖mysql，因此需要把mysql容器先启动，再启动项目 1docker run --name mysql8 -v /var/mysql/data:/var/lib/mysql -v /var/mysql/conf.d -e MYSQL_ROOT_PASSWORD=123456 -p 3306: 3306 -d mysql:8.0.32 设置远程访问： 1select host, user, plugin, authentication_string, password_expired from user; 12345ALTER USER root@&#x27;%&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;123456&#x27;;ALTER USER root@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;123456&#x27;;刷新权限 FLUSH PRIVILEGES; 测试访问浏览器输入： 1http://192.168.160.140:9090/login.html 已经可以成功访问啦，可以验证基本功能都正常。","path":"2023/03/26/cstile-seckill项目云端部署/","date":"03-26","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"秒杀项目","slug":"秒杀项目","permalink":"https://castile.github.io/tags/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE/"}]},{"title":"spring-batch核心概念","text":"批处理领域语言下图是批处理整体框架， spring Batch提供了层、组件和技术服务的物理实现，这些层、组件和技术服务通常存在于健壮的、可维护的系统中，用于创建从简单到复杂的批处理应用程序，其基础设施和扩展用于处理非常复杂的处理需求。 黄色部分代表了Spring-batch的核心组件，每一个Job有一或者多个步骤（Step），每个Step都有一个ItemReader、ItemWriter和一个ItemProcessor。而启动一个Job需要一个Job执行器（JobLauncher），并且需要存储有关当前Job进程中的一些元数据（JobRepository）。 1. Job Job是封装整个批处理过程的实体。在Spring-Batch中，一个Job可以简单看做多个Step的容器。 它将逻辑上属于一个流的多个步骤组合在一起，并允许配置所有步骤的全局属性，例如可重新启动性。 一个Job可以通过XMl、或者java配置的方式进行配置。主要包含： job的名称 Step的定义和顺序 Job是否可以restart Job接口的默认实现有SimpleJob，提供了一些默认实现。使用Java 的配置方式 12345@Bean public Job footballJob()&#123; SimpleJob simpleJob = new SimpleJob(); return simpleJob; &#125; 2. JobInstance代表是一个Job真正运行的实例。每个Job可以执行多次，每个JobInstance都与一个JobParameter绑定。 JobInstance的定义与要加载的数据完全无关。完全由ItemReader实现决定如何加载数据。 使用相同的JobInstance决定是否使用以前执行的“状态”(即ExecutionContext，)。使用一个新的JobInstance意味着“从头开始”，而使用一个现有的实例通常意味着“从你离开的地方开始”。 3. JobParameters那么如何区分JobInstance之间的不同呢？答案就是JobParameters。JobParameters作为一系列的启动参数用于启动一个批处理任务。 假如一个Job启动了两个实例： 一个在1月1号启动，一个在1月2号启动，他们各自有自己的JobParameters。那么约定：JobInstance = Job+identifying JobParameters 。这允许开发人员有效地控制JobInstance的定义方式，因为他们可以控制传入的参数。 4. JobExecutionJobExecution表示一个Job运行中的技术概念。 执行可能以失败或成功结束，但与给定执行对应的JobInstance不被认为是完成的，除非执行成功完成 。 以前面描述的EndOfDay 的Job为例，考虑在第一次运行时失败的JobInstance。如果使用与第一次运行(01-01-2017)相同的标识作业参数再次运行它，则会创建一个新的JobExecution。但是，仍然只有一个JobInstance。 一个Job定义了任务是怎么样的以及是怎么被执行的， 然而，jobeexecution是运行期间实际发生情况的主要存储机制，它包含许多必须控制和持久化的属性。 Property Definition Status A BatchStatus object that indicates the status of the execution. While running, it is BatchStatus#STARTED. If it fails, it is BatchStatus#FAILED. If it finishes successfully, it is BatchStatus#COMPLETED startTime A java.util.Date representing the current system time when the execution was started. This field is empty if the job has yet to start. endTime A java.util.Date representing the current system time when the execution finished, regardless of whether or not it was successful. The field is empty if the job has yet to finish. exitStatus The ExitStatus, indicating the result of the run. It is most important, because it contains an exit code that is returned to the caller. See chapter 5 for more details. The field is empty if the job has yet to finish. createTime A java.util.Date representing the current system time when the JobExecution was first persisted. The job may not have been started yet (and thus has no start time), but it always has a createTime, which is required by the framework for managing job level ExecutionContexts. lastUpdated A java.util.Date representing the last time a JobExecution was persisted. This field is empty if the job has yet to start. executionContext The “property bag” containing any user data that needs to be persisted between executions. failureExceptions The list of exceptions encountered during the execution of a Job. These can be useful if more than one exception is encountered during the failure of a Job. 这些属性是持久化的，因此可以完全确定一个execution的执行状态。 5. Step 它封装了批处理作业的一个独立的顺序阶段。 每个Job都完全由一个或多个步骤（Step）组成。一个步骤包含定义和控制实际批处理所需的所有信息。 6. StepExecution 每次运行Step时都会创建一个新的StepExecution，类似于jobeexecution。但是，如果一个步骤执行失败是因为它之前的步骤失败，则不会为它持久执行。 只有当其Step实际启动时，才会创建StepExecution。 Property Definition Status A BatchStatus object that indicates the status of the execution. While running, the status is BatchStatus.STARTED. If it fails, the status is BatchStatus.FAILED. If it finishes successfully, the status is BatchStatus.COMPLETED. startTime A java.util.Date representing the current system time when the execution was started. This field is empty if the step has yet to start. endTime A java.util.Date representing the current system time when the execution finished, regardless of whether or not it was successful. This field is empty if the step has yet to exit. exitStatus The ExitStatus indicating the result of the execution. It is most important, because it contains an exit code that is returned to the caller. See chapter 5 for more details. This field is empty if the job has yet to exit. executionContext The “property bag” containing any user data that needs to be persisted between executions. readCount The number of items that have been successfully read. writeCount The number of items that have been successfully written. commitCount The number of transactions that have been committed for this execution. rollbackCount The number of times the business transaction controlled by the Step has been rolled back. readSkipCount The number of times read has failed, resulting in a skipped item. processSkipCount The number of times process has failed, resulting in a skipped item. filterCount The number of items that have been ‘filtered’ by the ItemProcessor. writeSkipCount The number of times write has failed, resulting in a skipped item. 7. ExecutionContextExecutionContext代表一系列key-value的数据map。 好的使用例子是方便重新启动。以平面文件输入为例，在处理单个行时，框架定期在提交点持久化ExecutionContext。 8. JobRepository JobRepository是上述概念的持久化机制。提供了一些CRUD的操作、 当Job第一次启动时，从存储库中获得jobeexecution，并且在执行过程中，通过将StepExecution和jobeexecution实现传递给存储库来持久化它们。 9. JobLauncherJob 执行器、 10. Item Reader ItemReader是一种抽象，表示对Step的输入的检索，每次一项。当ItemReader耗尽了它所能提供的项时，它将通过返回null来表示。关于ItemReader接口及其各种实现的更多细节可以在Readers和writer中找到。 11. Item Writer 它表示一个步骤的输出，一次一批或一组项目。通常，ItemWriter不知道它接下来应该接收的输入，只知道在当前调用中传递的项。 12. Item Processor每一条数据的处理逻辑。 如果在处理该项时确定该项无效，则返回null表示不应写入该项。 配置执行批处理作业时的一个关键问题是重新启动作业时的行为。如果特定JobInstance的jobeexecute已经存在，则启动Job被认为是“重新启动” Restartability属性 将restarttable设置为false意味着此Job不支持再次启动。重新启动不可重新启动的作业将引发JobRestartException异常 EnableBatchProcessing @EnableBatchProcessing提供了用于构建批处理任务的基本配置。在这个基本配置中，除了许多可用于自动连接的bean之外，还创建了一个StepScope实例 JobRepository: bean name “jobRepository” JobLauncher: bean name “jobLauncher” JobRegistry: bean name “jobRegistry” PlatformTransactionManager: bean name “transactionManager” JobBuilderFactory: bean name “jobBuilders” StepBuilderFactory: bean name “stepBuilders” 改变存储机制可能不需要将Job的状态存储在数据库中， 出于这个原因，Spring批处理提供了作业存储库的内存中的Map版本。 1234567// This would reside in your BatchConfigurer implementation@Overrideprotected JobRepository createJobRepository() throws Exception &#123; MapJobRepositoryFactoryBean factory = new MapJobRepositoryFactoryBean(); factory.setTransactionManager(transactionManager); return factory.getObject();&#125; 请注意，内存中的存储库是不稳定的，因此不允许在JVM实例之间重新启动。它也不能保证同时启动两个具有相同参数的作业实例，并且不适合在多线程作业或本地分区Step中使用。因此，只要需要这些特性，就使用存储库的数据库版本。 确实需要定义事务管理器，因为存储库中存在回滚语义，而且业务逻辑可能仍然是事务性的(例如RDBMS访问)。出于测试目的，许多人发现ResourcelessTransactionManager很有用。 但是MapJobRepositoryFactoryBean已经过时了，将会在Spring-Batch 5.x版本中移除。因此如果想要基于内存的操作，那么可以配置一个本地的数据库，如H2， Apache Derby or HSQLDB 等， 12345678@Beanpublic DataSource dataSource() &#123; return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.H2) .addScript(&quot;/org/springframework/batch/core/schema-drop-h2.sql&quot;) .addScript(&quot;/org/springframework/batch/core/schema-h2.sql&quot;) .build();&#125; 配置数据源后需要结合createJobRepository来设置。 配置Configuring a JobLauncher 获得jobeexecution后，将它传递给Job的execute方法，最终将jobeexecution返回给调用者，如下图所示 12345678@Beanpublic JobLauncher jobLauncher() &#123; SimpleJobLauncher jobLauncher = new SimpleJobLauncher(); jobLauncher.setJobRepository(jobRepository()); jobLauncher.setTaskExecutor(new SimpleAsyncTaskExecutor()); jobLauncher.afterPropertiesSet(); return jobLauncher;&#125;","path":"2023/02/26/spring-batch核心概念/","date":"02-26","excerpt":"","tags":[{"name":"spring-batch","slug":"spring-batch","permalink":"https://castile.github.io/tags/spring-batch/"}]},{"title":"Netty-优化与源码分析","text":"四. 优化与源码1. 优化1.1 扩展序列化算法序列化，反序列化主要用在消息正文的转换上 序列化时，需要将 Java 对象变为要传输的数据（可以是 byte[]，或 json 等，最终都需要变成 byte[]） 反序列化时，需要将传入的正文数据还原成 Java 对象，便于处理 目前的代码仅支持 Java 自带的序列化，反序列化机制，核心代码如下 1234567891011// 反序列化byte[] body = new byte[bodyLength];byteByf.readBytes(body);ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(body));Message message = (Message) in.readObject();message.setSequenceId(sequenceId);// 序列化ByteArrayOutputStream out = new ByteArrayOutputStream();new ObjectOutputStream(out).writeObject(message);byte[] bytes = out.toByteArray(); 为了支持更多序列化算法，抽象一个 Serializer 接口 123456789public interface Serializer &#123; // 反序列化方法 &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes); // 序列化方法 &lt;T&gt; byte[] serialize(T object);&#125; 提供两个实现，我这里直接将实现加入了枚举类 Serializer.Algorithm 中 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748enum SerializerAlgorithm implements Serializer &#123; // Java 实现 Java &#123; @Override public &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes) &#123; try &#123; ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bytes)); Object object = in.readObject(); return (T) object; &#125; catch (IOException | ClassNotFoundException e) &#123; throw new RuntimeException(&quot;SerializerAlgorithm.Java 反序列化错误&quot;, e); &#125; &#125; @Override public &lt;T&gt; byte[] serialize(T object) &#123; try &#123; ByteArrayOutputStream out = new ByteArrayOutputStream(); new ObjectOutputStream(out).writeObject(object); return out.toByteArray(); &#125; catch (IOException e) &#123; throw new RuntimeException(&quot;SerializerAlgorithm.Java 序列化错误&quot;, e); &#125; &#125; &#125;, // Json 实现(引入了 Gson 依赖) Json &#123; @Override public &lt;T&gt; T deserialize(Class&lt;T&gt; clazz, byte[] bytes) &#123; return new Gson().fromJson(new String(bytes, StandardCharsets.UTF_8), clazz); &#125; @Override public &lt;T&gt; byte[] serialize(T object) &#123; return new Gson().toJson(object).getBytes(StandardCharsets.UTF_8); &#125; &#125;; // 需要从协议的字节中得到是哪种序列化算法 public static SerializerAlgorithm getByInt(int type) &#123; SerializerAlgorithm[] array = SerializerAlgorithm.values(); if (type &lt; 0 || type &gt; array.length - 1) &#123; throw new IllegalArgumentException(&quot;超过 SerializerAlgorithm 范围&quot;); &#125; return array[type]; &#125;&#125; 增加配置类和配置文件 123456789101112131415161718192021222324252627public abstract class Config &#123; static Properties properties; static &#123; try (InputStream in = Config.class.getResourceAsStream(&quot;/application.properties&quot;)) &#123; properties = new Properties(); properties.load(in); &#125; catch (IOException e) &#123; throw new ExceptionInInitializerError(e); &#125; &#125; public static int getServerPort() &#123; String value = properties.getProperty(&quot;server.port&quot;); if(value == null) &#123; return 8080; &#125; else &#123; return Integer.parseInt(value); &#125; &#125; public static Serializer.Algorithm getSerializerAlgorithm() &#123; String value = properties.getProperty(&quot;serializer.algorithm&quot;); if(value == null) &#123; return Serializer.Algorithm.Java; &#125; else &#123; return Serializer.Algorithm.valueOf(value); &#125; &#125;&#125; 配置文件 1serializer.algorithm=Json 修改编解码器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 必须和 LengthFieldBasedFrameDecoder 一起使用，确保接到的 ByteBuf 消息是完整的 */public class MessageCodecSharable extends MessageToMessageCodec&lt;ByteBuf, Message&gt; &#123; @Override public void encode(ChannelHandlerContext ctx, Message msg, List&lt;Object&gt; outList) throws Exception &#123; ByteBuf out = ctx.alloc().buffer(); // 1. 4 字节的魔数 out.writeBytes(new byte[]&#123;1, 2, 3, 4&#125;); // 2. 1 字节的版本, out.writeByte(1); // 3. 1 字节的序列化方式 jdk 0 , json 1 out.writeByte(Config.getSerializerAlgorithm().ordinal()); // 4. 1 字节的指令类型 out.writeByte(msg.getMessageType()); // 5. 4 个字节 out.writeInt(msg.getSequenceId()); // 无意义，对齐填充 out.writeByte(0xff); // 6. 获取内容的字节数组 byte[] bytes = Config.getSerializerAlgorithm().serialize(msg); // 7. 长度 out.writeInt(bytes.length); // 8. 写入内容 out.writeBytes(bytes); outList.add(out); &#125; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; int magicNum = in.readInt(); byte version = in.readByte(); byte serializerAlgorithm = in.readByte(); // 0 或 1 byte messageType = in.readByte(); // 0,1,2... int sequenceId = in.readInt(); in.readByte(); int length = in.readInt(); byte[] bytes = new byte[length]; in.readBytes(bytes, 0, length); // 找到反序列化算法 Serializer.Algorithm algorithm = Serializer.Algorithm.values()[serializerAlgorithm]; // 确定具体消息类型 Class&lt;? extends Message&gt; messageClass = Message.getMessageClass(messageType); Message message = algorithm.deserialize(messageClass, bytes);// log.debug(&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;&quot;, magicNum, version, serializerType, messageType, sequenceId, length);// log.debug(&quot;&#123;&#125;&quot;, message); out.add(message); &#125;&#125; 其中确定具体消息类型，可以根据 消息类型字节 获取到对应的 消息 class 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Datapublic abstract class Message implements Serializable &#123; /** * 根据消息类型字节，获得对应的消息 class * @param messageType 消息类型字节 * @return 消息 class */ public static Class&lt;? extends Message&gt; getMessageClass(int messageType) &#123; return messageClasses.get(messageType); &#125; private int sequenceId; private int messageType; public abstract int getMessageType(); public static final int LoginRequestMessage = 0; public static final int LoginResponseMessage = 1; public static final int ChatRequestMessage = 2; public static final int ChatResponseMessage = 3; public static final int GroupCreateRequestMessage = 4; public static final int GroupCreateResponseMessage = 5; public static final int GroupJoinRequestMessage = 6; public static final int GroupJoinResponseMessage = 7; public static final int GroupQuitRequestMessage = 8; public static final int GroupQuitResponseMessage = 9; public static final int GroupChatRequestMessage = 10; public static final int GroupChatResponseMessage = 11; public static final int GroupMembersRequestMessage = 12; public static final int GroupMembersResponseMessage = 13; public static final int PingMessage = 14; public static final int PongMessage = 15; private static final Map&lt;Integer, Class&lt;? extends Message&gt;&gt; messageClasses = new HashMap&lt;&gt;(); static &#123; messageClasses.put(LoginRequestMessage, LoginRequestMessage.class); messageClasses.put(LoginResponseMessage, LoginResponseMessage.class); messageClasses.put(ChatRequestMessage, ChatRequestMessage.class); messageClasses.put(ChatResponseMessage, ChatResponseMessage.class); messageClasses.put(GroupCreateRequestMessage, GroupCreateRequestMessage.class); messageClasses.put(GroupCreateResponseMessage, GroupCreateResponseMessage.class); messageClasses.put(GroupJoinRequestMessage, GroupJoinRequestMessage.class); messageClasses.put(GroupJoinResponseMessage, GroupJoinResponseMessage.class); messageClasses.put(GroupQuitRequestMessage, GroupQuitRequestMessage.class); messageClasses.put(GroupQuitResponseMessage, GroupQuitResponseMessage.class); messageClasses.put(GroupChatRequestMessage, GroupChatRequestMessage.class); messageClasses.put(GroupChatResponseMessage, GroupChatResponseMessage.class); messageClasses.put(GroupMembersRequestMessage, GroupMembersRequestMessage.class); messageClasses.put(GroupMembersResponseMessage, GroupMembersResponseMessage.class); &#125;&#125; 1.2 参数调优1）CONNECT_TIMEOUT_MILLIS 属于 SocketChannal 参数 用在客户端建立连接时，如果在指定毫秒内无法连接，会抛出 timeout 异常 SO_TIMEOUT 主要用在阻塞 IO，阻塞 IO 中 accept，read 等都是无限等待的，如果不希望永远阻塞，使用它调整超时时间 1234567891011121314151617181920@Slf4jpublic class TestConnectionTimeout &#123; public static void main(String[] args) &#123; NioEventLoopGroup group = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap() .group(group) .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 300) .channel(NioSocketChannel.class) .handler(new LoggingHandler()); ChannelFuture future = bootstrap.connect(&quot;127.0.0.1&quot;, 8080); future.sync().channel().closeFuture().sync(); // 断点1 &#125; catch (Exception e) &#123; e.printStackTrace(); log.debug(&quot;timeout&quot;); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 另外源码部分 io.netty.channel.nio.AbstractNioChannel.AbstractNioUnsafe#connect 123456789101112131415161718192021@Overridepublic final void connect( final SocketAddress remoteAddress, final SocketAddress localAddress, final ChannelPromise promise) &#123; // ... // Schedule connect timeout. int connectTimeoutMillis = config().getConnectTimeoutMillis(); if (connectTimeoutMillis &gt; 0) &#123; connectTimeoutFuture = eventLoop().schedule(new Runnable() &#123; @Override public void run() &#123; ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise; ConnectTimeoutException cause = new ConnectTimeoutException(&quot;connection timed out: &quot; + remoteAddress); // 断点2 if (connectPromise != null &amp;&amp; connectPromise.tryFailure(cause)) &#123; close(voidPromise()); &#125; &#125; &#125;, connectTimeoutMillis, TimeUnit.MILLISECONDS); &#125; // ...&#125; 2）SO_BACKLOG 属于 ServerSocketChannal 参数 123456789101112131415161718192021sequenceDiagramparticipant c as clientparticipant s as serverparticipant sq as syns queueparticipant aq as accept queues -&gt;&gt; s : bind()s -&gt;&gt; s : listen()c -&gt;&gt; c : connect()c -&gt;&gt; s : 1. SYNNote left of c : SYN_SENDs -&gt;&gt; sq : putNote right of s : SYN_RCVDs -&gt;&gt; c : 2. SYN + ACKNote left of c : ESTABLISHEDc -&gt;&gt; s : 3. ACKsq -&gt;&gt; aq : putNote right of s : ESTABLISHEDaq --&gt;&gt; s : s -&gt;&gt; s : accept() 第一次握手，client 发送 SYN 到 server，状态修改为 SYN_SEND，server 收到，状态改变为 SYN_REVD，并将该请求放入 sync queue 队列 第二次握手，server 回复 SYN + ACK 给 client，client 收到，状态改变为 ESTABLISHED，并发送 ACK 给 server 第三次握手，server 收到 ACK，状态改变为 ESTABLISHED，将该请求从 sync queue 放入 accept queue 其中 在 linux 2.2 之前，backlog 大小包括了两个队列的大小，在 2.2 之后，分别用下面两个参数来控制 sync queue - 半连接队列 大小通过 /proc/sys/net/ipv4/tcp_max_syn_backlog 指定，在 syncookies 启用的情况下，逻辑上没有最大值限制，这个设置便被忽略 accept queue - 全连接队列 其大小通过 /proc/sys/net/core/somaxconn 指定，在使用 listen 函数时，内核会根据传入的 backlog 参数与系统参数，取二者的较小值 如果 accpet queue 队列满了，server 将发送一个拒绝连接的错误信息到 client netty 中 可以通过 option(ChannelOption.SO_BACKLOG, 值) 来设置大小 可以通过下面源码查看默认大小 123456public class DefaultServerSocketChannelConfig extends DefaultChannelConfig implements ServerSocketChannelConfig &#123; private volatile int backlog = NetUtil.SOMAXCONN; // ...&#125; 课堂调试关键断点为：io.netty.channel.nio.NioEventLoop#processSelectedKey oio 中更容易说明，不用 debug 模式 12345678public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket ss = new ServerSocket(8888, 2); Socket accept = ss.accept(); System.out.println(accept); System.in.read(); &#125;&#125; 客户端启动 4 个 123456789101112131415public class Client &#123; public static void main(String[] args) throws IOException &#123; try &#123; Socket s = new Socket(); System.out.println(new Date()+&quot; connecting...&quot;); s.connect(new InetSocketAddress(&quot;localhost&quot;, 8888),1000); System.out.println(new Date()+&quot; connected...&quot;); s.getOutputStream().write(1); System.in.read(); &#125; catch (IOException e) &#123; System.out.println(new Date()+&quot; connecting timeout...&quot;); e.printStackTrace(); &#125; &#125;&#125; 第 1，2，3 个客户端都打印，但除了第一个处于 accpet 外，其它两个都处于 accept queue 中 12Tue Apr 21 20:30:28 CST 2020 connecting...Tue Apr 21 20:30:28 CST 2020 connected... 第 4 个客户端连接时 123Tue Apr 21 20:53:58 CST 2020 connecting...Tue Apr 21 20:53:59 CST 2020 connecting timeout...java.net.SocketTimeoutException: connect timed out 3）ulimit -n 属于操作系统参数 4）TCP_NODELAY 属于 SocketChannal 参数 5）SO_SNDBUF &amp; SO_RCVBUF SO_SNDBUF 属于 SocketChannal 参数 SO_RCVBUF 既可用于 SocketChannal 参数，也可以用于 ServerSocketChannal 参数（建议设置到 ServerSocketChannal 上） 6）ALLOCATOR 属于 SocketChannal 参数 用来分配 ByteBuf， ctx.alloc() 7）RCVBUF_ALLOCATOR 属于 SocketChannal 参数 控制 netty 接收缓冲区大小 负责入站数据的分配，决定入站缓冲区的大小（并可动态调整），统一采用 direct 直接内存，具体池化还是非池化由 allocator 决定 1.3 RPC 框架1）准备工作这些代码可以认为是现成的，无需从头编写练习 为了简化起见，在原来聊天项目的基础上新增 Rpc 请求和响应消息 123456789101112131415@Datapublic abstract class Message implements Serializable &#123; // 省略旧的代码 public static final int RPC_MESSAGE_TYPE_REQUEST = 101; public static final int RPC_MESSAGE_TYPE_RESPONSE = 102; static &#123; // ... messageClasses.put(RPC_MESSAGE_TYPE_REQUEST, RpcRequestMessage.class); messageClasses.put(RPC_MESSAGE_TYPE_RESPONSE, RpcResponseMessage.class); &#125;&#125; 请求消息 123456789101112131415161718192021222324252627282930313233343536373839@Getter@ToString(callSuper = true)public class RpcRequestMessage extends Message &#123; /** * 调用的接口全限定名，服务端根据它找到实现 */ private String interfaceName; /** * 调用接口中的方法名 */ private String methodName; /** * 方法返回类型 */ private Class&lt;?&gt; returnType; /** * 方法参数类型数组 */ private Class[] parameterTypes; /** * 方法参数值数组 */ private Object[] parameterValue; public RpcRequestMessage(int sequenceId, String interfaceName, String methodName, Class&lt;?&gt; returnType, Class[] parameterTypes, Object[] parameterValue) &#123; super.setSequenceId(sequenceId); this.interfaceName = interfaceName; this.methodName = methodName; this.returnType = returnType; this.parameterTypes = parameterTypes; this.parameterValue = parameterValue; &#125; @Override public int getMessageType() &#123; return RPC_MESSAGE_TYPE_REQUEST; &#125;&#125; 响应消息 1234567891011121314151617@Data@ToString(callSuper = true)public class RpcResponseMessage extends Message &#123; /** * 返回值 */ private Object returnValue; /** * 异常值 */ private Exception exceptionValue; @Override public int getMessageType() &#123; return RPC_MESSAGE_TYPE_RESPONSE; &#125;&#125; 服务器架子 123456789101112131415161718192021222324252627282930313233@Slf4jpublic class RpcServer &#123; public static void main(String[] args) &#123; NioEventLoopGroup boss = new NioEventLoopGroup(); NioEventLoopGroup worker = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); // rpc 请求消息处理器，待实现 RpcRequestMessageHandler RPC_HANDLER = new RpcRequestMessageHandler(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.channel(NioServerSocketChannel.class); serverBootstrap.group(boss, worker); serverBootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder()); ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(RPC_HANDLER); &#125; &#125;); Channel channel = serverBootstrap.bind(8080).sync().channel(); channel.closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;server error&quot;, e); &#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); &#125; &#125;&#125; 客户端架子 123456789101112131415161718192021222324252627282930public class RpcClient &#123; public static void main(String[] args) &#123; NioEventLoopGroup group = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); // rpc 响应消息处理器，待实现 RpcResponseMessageHandler RPC_HANDLER = new RpcResponseMessageHandler(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(group); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder()); ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(RPC_HANDLER); &#125; &#125;); Channel channel = bootstrap.connect(&quot;localhost&quot;, 8080).sync().channel(); channel.closeFuture().sync(); &#125; catch (Exception e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 服务器端的 service 获取 1234567891011121314151617181920212223242526public class ServicesFactory &#123; static Properties properties; static Map&lt;Class&lt;?&gt;, Object&gt; map = new ConcurrentHashMap&lt;&gt;(); static &#123; try (InputStream in = Config.class.getResourceAsStream(&quot;/application.properties&quot;)) &#123; properties = new Properties(); properties.load(in); Set&lt;String&gt; names = properties.stringPropertyNames(); for (String name : names) &#123; if (name.endsWith(&quot;Service&quot;)) &#123; Class&lt;?&gt; interfaceClass = Class.forName(name); Class&lt;?&gt; instanceClass = Class.forName(properties.getProperty(name)); map.put(interfaceClass, instanceClass.newInstance()); &#125; &#125; &#125; catch (IOException | ClassNotFoundException | InstantiationException | IllegalAccessException e) &#123; throw new ExceptionInInitializerError(e); &#125; &#125; public static &lt;T&gt; T getService(Class&lt;T&gt; interfaceClass) &#123; return (T) map.get(interfaceClass); &#125;&#125; 相关配置 application.properties 12serializer.algorithm=Jsoncn.itcast.server.service.HelloService=cn.itcast.server.service.HelloServiceImpl 2）服务器 handler1234567891011121314151617181920212223242526272829@Slf4j@ChannelHandler.Sharablepublic class RpcRequestMessageHandler extends SimpleChannelInboundHandler&lt;RpcRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, RpcRequestMessage message) &#123; RpcResponseMessage response = new RpcResponseMessage(); response.setSequenceId(message.getSequenceId()); try &#123; // 获取真正的实现对象 HelloService service = (HelloService) ServicesFactory.getService(Class.forName(message.getInterfaceName())); // 获取要调用的方法 Method method = service.getClass().getMethod(message.getMethodName(), message.getParameterTypes()); // 调用方法 Object invoke = method.invoke(service, message.getParameterValue()); // 调用成功 response.setReturnValue(invoke); &#125; catch (Exception e) &#123; e.printStackTrace(); // 调用异常 response.setExceptionValue(e); &#125; // 返回结果 ctx.writeAndFlush(response); &#125;&#125; 3）客户端代码第一版只发消息 1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4jpublic class RpcClient &#123; public static void main(String[] args) &#123; NioEventLoopGroup group = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); RpcResponseMessageHandler RPC_HANDLER = new RpcResponseMessageHandler(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(group); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder()); ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(RPC_HANDLER); &#125; &#125;); Channel channel = bootstrap.connect(&quot;localhost&quot;, 8080).sync().channel(); ChannelFuture future = channel.writeAndFlush(new RpcRequestMessage( 1, &quot;cn.itcast.server.service.HelloService&quot;, &quot;sayHello&quot;, String.class, new Class[]&#123;String.class&#125;, new Object[]&#123;&quot;张三&quot;&#125; )).addListener(promise -&gt; &#123; if (!promise.isSuccess()) &#123; Throwable cause = promise.cause(); log.error(&quot;error&quot;, cause); &#125; &#125;); channel.closeFuture().sync(); &#125; catch (Exception e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 4）客户端 handler 第一版12345678@Slf4j@ChannelHandler.Sharablepublic class RpcResponseMessageHandler extends SimpleChannelInboundHandler&lt;RpcResponseMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, RpcResponseMessage msg) throws Exception &#123; log.debug(&quot;&#123;&#125;&quot;, msg); &#125;&#125; 5）客户端代码 第二版包括 channel 管理，代理，接收结果 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596@Slf4jpublic class RpcClientManager &#123; public static void main(String[] args) &#123; HelloService service = getProxyService(HelloService.class); System.out.println(service.sayHello(&quot;zhangsan&quot;));// System.out.println(service.sayHello(&quot;lisi&quot;));// System.out.println(service.sayHello(&quot;wangwu&quot;)); &#125; // 创建代理类 public static &lt;T&gt; T getProxyService(Class&lt;T&gt; serviceClass) &#123; ClassLoader loader = serviceClass.getClassLoader(); Class&lt;?&gt;[] interfaces = new Class[]&#123;serviceClass&#125;; // sayHello &quot;张三&quot; Object o = Proxy.newProxyInstance(loader, interfaces, (proxy, method, args) -&gt; &#123; // 1. 将方法调用转换为 消息对象 int sequenceId = SequenceIdGenerator.nextId(); RpcRequestMessage msg = new RpcRequestMessage( sequenceId, serviceClass.getName(), method.getName(), method.getReturnType(), method.getParameterTypes(), args ); // 2. 将消息对象发送出去 getChannel().writeAndFlush(msg); // 3. 准备一个空 Promise 对象，来接收结果 指定 promise 对象异步接收结果线程 DefaultPromise&lt;Object&gt; promise = new DefaultPromise&lt;&gt;(getChannel().eventLoop()); RpcResponseMessageHandler.PROMISES.put(sequenceId, promise);// promise.addListener(future -&gt; &#123;// // 线程// &#125;); // 4. 等待 promise 结果 promise.await(); if(promise.isSuccess()) &#123; // 调用正常 return promise.getNow(); &#125; else &#123; // 调用失败 throw new RuntimeException(promise.cause()); &#125; &#125;); return (T) o; &#125; private static Channel channel = null; private static final Object LOCK = new Object(); // 获取唯一的 channel 对象 public static Channel getChannel() &#123; if (channel != null) &#123; return channel; &#125; synchronized (LOCK) &#123; // t2 if (channel != null) &#123; // t1 return channel; &#125; initChannel(); return channel; &#125; &#125; // 初始化 channel 方法 private static void initChannel() &#123; NioEventLoopGroup group = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); RpcResponseMessageHandler RPC_HANDLER = new RpcResponseMessageHandler(); Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(group); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder()); ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(RPC_HANDLER); &#125; &#125;); try &#123; channel = bootstrap.connect(&quot;localhost&quot;, 8080).sync().channel(); channel.closeFuture().addListener(future -&gt; &#123; group.shutdownGracefully(); &#125;); &#125; catch (Exception e) &#123; log.error(&quot;client error&quot;, e); &#125; &#125;&#125; 6）客户端 handler 第二版123456789101112131415161718192021222324@Slf4j@ChannelHandler.Sharablepublic class RpcResponseMessageHandler extends SimpleChannelInboundHandler&lt;RpcResponseMessage&gt; &#123; // 序号 用来接收结果的 promise 对象 public static final Map&lt;Integer, Promise&lt;Object&gt;&gt; PROMISES = new ConcurrentHashMap&lt;&gt;(); @Override protected void channelRead0(ChannelHandlerContext ctx, RpcResponseMessage msg) throws Exception &#123; log.debug(&quot;&#123;&#125;&quot;, msg); // 拿到空的 promise Promise&lt;Object&gt; promise = PROMISES.remove(msg.getSequenceId()); if (promise != null) &#123; Object returnValue = msg.getReturnValue(); Exception exceptionValue = msg.getExceptionValue(); if(exceptionValue != null) &#123; promise.setFailure(exceptionValue); &#125; else &#123; promise.setSuccess(returnValue); &#125; &#125; &#125;&#125; 2. 源码分析2.1 启动剖析我们就来看看 netty 中对下面的代码是怎样进行处理的 12345678910111213141516171819202122//1 netty 中使用 NioEventLoopGroup （简称 nio boss 线程）来封装线程和 selectorSelector selector = Selector.open(); //2 创建 NioServerSocketChannel，同时会初始化它关联的 handler，以及为原生 ssc 存储 configNioServerSocketChannel attachment = new NioServerSocketChannel();//3 创建 NioServerSocketChannel 时，创建了 java 原生的 ServerSocketChannelServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false);//4 启动 nio boss 线程执行接下来的操作//5 注册（仅关联 selector 和 NioServerSocketChannel），未关注事件SelectionKey selectionKey = serverSocketChannel.register(selector, 0, attachment);//6 head -&gt; 初始化器 -&gt; ServerBootstrapAcceptor -&gt; tail，初始化器是一次性的，只为添加 acceptor//7 绑定端口serverSocketChannel.bind(new InetSocketAddress(8080));//8 触发 channel active 事件，在 head 中关注 op_accept 事件selectionKey.interestOps(SelectionKey.OP_ACCEPT); 入口 io.netty.bootstrap.ServerBootstrap#bind 关键代码 io.netty.bootstrap.AbstractBootstrap#doBind 12345678910111213141516171819202122232425262728293031323334353637private ChannelFuture doBind(final SocketAddress localAddress) &#123; // 1. 执行初始化和注册 regFuture 会由 initAndRegister 设置其是否完成，从而回调 3.2 处代码 final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.cause() != null) &#123; return regFuture; &#125; // 2. 因为是 initAndRegister 异步执行，需要分两种情况来看，调试时也需要通过 suspend 断点类型加以区分 // 2.1 如果已经完成 if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); // 3.1 立刻调用 doBind0 doBind0(regFuture, channel, localAddress, promise); return promise; &#125; // 2.2 还没有完成 else &#123; final PendingRegistrationPromise promise = new PendingRegistrationPromise(channel); // 3.2 回调 doBind0 regFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; Throwable cause = future.cause(); if (cause != null) &#123; // 处理异常... promise.setFailure(cause); &#125; else &#123; promise.registered(); // 3. 由注册线程去执行 doBind0 doBind0(regFuture, channel, localAddress, promise); &#125; &#125; &#125;); return promise; &#125;&#125; 关键代码 io.netty.bootstrap.AbstractBootstrap#initAndRegister 123456789101112131415161718final ChannelFuture initAndRegister() &#123; Channel channel = null; try &#123; channel = channelFactory.newChannel(); // 1.1 初始化 - 做的事就是添加一个初始化器 ChannelInitializer init(channel); &#125; catch (Throwable t) &#123; // 处理异常... return new DefaultChannelPromise(new FailedChannel(), GlobalEventExecutor.INSTANCE).setFailure(t); &#125; // 1.2 注册 - 做的事就是将原生 channel 注册到 selector 上 ChannelFuture regFuture = config().group().register(channel); if (regFuture.cause() != null) &#123; // 处理异常... &#125; return regFuture;&#125; 关键代码 io.netty.bootstrap.ServerBootstrap#init 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 这里 channel 实际上是 NioServerSocketChannelvoid init(Channel channel) throws Exception &#123; final Map&lt;ChannelOption&lt;?&gt;, Object&gt; options = options0(); synchronized (options) &#123; setChannelOptions(channel, options, logger); &#125; final Map&lt;AttributeKey&lt;?&gt;, Object&gt; attrs = attrs0(); synchronized (attrs) &#123; for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: attrs.entrySet()) &#123; @SuppressWarnings(&quot;unchecked&quot;) AttributeKey&lt;Object&gt; key = (AttributeKey&lt;Object&gt;) e.getKey(); channel.attr(key).set(e.getValue()); &#125; &#125; ChannelPipeline p = channel.pipeline(); final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; synchronized (childOptions) &#123; currentChildOptions = childOptions.entrySet().toArray(newOptionArray(0)); &#125; synchronized (childAttrs) &#123; currentChildAttrs = childAttrs.entrySet().toArray(newAttrArray(0)); &#125; // 为 NioServerSocketChannel 添加初始化器 p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(final Channel ch) throws Exception &#123; final ChannelPipeline pipeline = ch.pipeline(); ChannelHandler handler = config.handler(); if (handler != null) &#123; pipeline.addLast(handler); &#125; // 初始化器的职责是将 ServerBootstrapAcceptor 加入至 NioServerSocketChannel ch.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; pipeline.addLast(new ServerBootstrapAcceptor( ch, currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; &#125;);&#125; 关键代码 io.netty.channel.AbstractChannel.AbstractUnsafe#register 1234567891011121314151617181920212223242526public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 一些检查，略... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; // 首次执行 execute 方法时，会启动 nio 线程，之后注册等操作在 nio 线程上执行 // 因为只有一个 NioServerSocketChannel 因此，也只会有一个 boss nio 线程 // 这行代码完成的事实是 main -&gt; nio boss 线程的切换 eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; // 日志记录... closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125;&#125; io.netty.channel.AbstractChannel.AbstractUnsafe#register0 123456789101112131415161718192021222324252627282930313233private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; // 1.2.1 原生的 nio channel 绑定到 selector 上，注意此时没有注册 selector 关注事件，附件为 NioServerSocketChannel doRegister(); neverRegistered = false; registered = true; // 1.2.2 执行 NioServerSocketChannel 初始化器的 initChannel pipeline.invokeHandlerAddedIfNeeded(); // 回调 3.2 io.netty.bootstrap.AbstractBootstrap#doBind0 safeSetSuccess(promise); pipeline.fireChannelRegistered(); // 对应 server socket channel 还未绑定，isActive 为 false if (isActive()) &#123; if (firstRegistration) &#123; pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; // Close the channel directly to avoid FD leak. closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125;&#125; 关键代码 io.netty.channel.ChannelInitializer#initChannel 123456789101112131415161718private boolean initChannel(ChannelHandlerContext ctx) throws Exception &#123; if (initMap.add(ctx)) &#123; // Guard against re-entrance. try &#123; // 1.2.2.1 执行初始化 initChannel((C) ctx.channel()); &#125; catch (Throwable cause) &#123; exceptionCaught(ctx, cause); &#125; finally &#123; // 1.2.2.2 移除初始化器 ChannelPipeline pipeline = ctx.pipeline(); if (pipeline.context(this) != null) &#123; pipeline.remove(this); &#125; &#125; return true; &#125; return false;&#125; 关键代码 io.netty.bootstrap.AbstractBootstrap#doBind0 12345678910111213141516// 3.1 或 3.2 执行 doBind0private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;);&#125; 关键代码 io.netty.channel.AbstractChannel.AbstractUnsafe#bind 123456789101112131415161718192021222324252627282930313233343536public final void bind(final SocketAddress localAddress, final ChannelPromise promise) &#123; assertEventLoop(); if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; if (Boolean.TRUE.equals(config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress) localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.maybeSuperUser()) &#123; // 记录日志... &#125; boolean wasActive = isActive(); try &#123; // 3.3 执行端口绑定 doBind(localAddress); &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); closeIfClosed(); return; &#125; if (!wasActive &amp;&amp; isActive()) &#123; invokeLater(new Runnable() &#123; @Override public void run() &#123; // 3.4 触发 active 事件 pipeline.fireChannelActive(); &#125; &#125;); &#125; safeSetSuccess(promise);&#125; 3.3 关键代码 io.netty.channel.socket.nio.NioServerSocketChannel#doBind 1234567protected void doBind(SocketAddress localAddress) throws Exception &#123; if (PlatformDependent.javaVersion() &gt;= 7) &#123; javaChannel().bind(localAddress, config.getBacklog()); &#125; else &#123; javaChannel().socket().bind(localAddress, config.getBacklog()); &#125;&#125; 3.4 关键代码 io.netty.channel.DefaultChannelPipeline.HeadContext#channelActive 12345public void channelActive(ChannelHandlerContext ctx) &#123; ctx.fireChannelActive(); // 触发 read (NioServerSocketChannel 上的 read 不是读取数据，只是为了触发 channel 的事件注册) readIfIsAutoRead();&#125; 关键代码 io.netty.channel.nio.AbstractNioChannel#doBeginRead 123456789101112131415protected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; final int interestOps = selectionKey.interestOps(); // readInterestOp 取值是 16，在 NioServerSocketChannel 创建时初始化好，代表关注 accept 事件 if ((interestOps &amp; readInterestOp) == 0) &#123; selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 2.2 NioEventLoop 剖析NioEventLoop 线程不仅要处理 IO 事件，还要处理 Task（包括普通任务和定时任务）， 提交任务代码 io.netty.util.concurrent.SingleThreadEventExecutor#execute 123456789101112131415161718192021public void execute(Runnable task) &#123; if (task == null) &#123; throw new NullPointerException(&quot;task&quot;); &#125; boolean inEventLoop = inEventLoop(); // 添加任务，其中队列使用了 jctools 提供的 mpsc 无锁队列 addTask(task); if (!inEventLoop) &#123; // inEventLoop 如果为 false 表示由其它线程来调用 execute，即首次调用，这时需要向 eventLoop 提交首个任务，启动死循环，会执行到下面的 doStartThread startThread(); if (isShutdown()) &#123; // 如果已经 shutdown，做拒绝逻辑，代码略... &#125; &#125; if (!addTaskWakesUp &amp;&amp; wakesUpForTask(task)) &#123; // 如果线程由于 IO select 阻塞了，添加的任务的线程需要负责唤醒 NioEventLoop 线程 wakeup(inEventLoop); &#125;&#125; 唤醒 select 阻塞线程io.netty.channel.nio.NioEventLoop#wakeup 123456@Overrideprotected void wakeup(boolean inEventLoop) &#123; if (!inEventLoop &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.wakeup(); &#125;&#125; 启动 EventLoop 主循环 io.netty.util.concurrent.SingleThreadEventExecutor#doStartThread 12345678910111213141516171819202122232425private void doStartThread() &#123; assert thread == null; executor.execute(new Runnable() &#123; @Override public void run() &#123; // 将线程池的当前线程保存在成员变量中，以便后续使用 thread = Thread.currentThread(); if (interrupted) &#123; thread.interrupt(); &#125; boolean success = false; updateLastExecutionTime(); try &#123; // 调用外部类 SingleThreadEventExecutor 的 run 方法，进入死循环，run 方法见下 SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; logger.warn(&quot;Unexpected exception from an event executor: &quot;, t); &#125; finally &#123; // 清理工作，代码略... &#125; &#125; &#125;);&#125; io.netty.channel.nio.NioEventLoop#run 主要任务是执行死循环，不断看有没有新任务，有没有 IO 事件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273protected void run() &#123; for (;;) &#123; try &#123; try &#123; // calculateStrategy 的逻辑如下： // 有任务，会执行一次 selectNow，清除上一次的 wakeup 结果，无论有没有 IO 事件，都会跳过 switch // 没有任务，会匹配 SelectStrategy.SELECT，看是否应当阻塞 switch (selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.BUSY_WAIT: case SelectStrategy.SELECT: // 因为 IO 线程和提交任务线程都有可能执行 wakeup，而 wakeup 属于比较昂贵的操作，因此使用了一个原子布尔对象 wakenUp，它取值为 true 时，表示该由当前线程唤醒 // 进行 select 阻塞，并设置唤醒状态为 false boolean oldWakenUp = wakenUp.getAndSet(false); // 如果在这个位置，非 EventLoop 线程抢先将 wakenUp 置为 true，并 wakeup // 下面的 select 方法不会阻塞 // 等 runAllTasks 处理完成后，到再循环进来这个阶段新增的任务会不会及时执行呢? // 因为 oldWakenUp 为 true，因此下面的 select 方法就会阻塞，直到超时 // 才能执行，让 select 方法无谓阻塞 select(oldWakenUp); if (wakenUp.get()) &#123; selector.wakeup(); &#125; default: &#125; &#125; catch (IOException e) &#123; rebuildSelector0(); handleLoopException(e); continue; &#125; cancelledKeys = 0; needsToSelectAgain = false; // ioRatio 默认是 50 final int ioRatio = this.ioRatio; if (ioRatio == 100) &#123; try &#123; processSelectedKeys(); &#125; finally &#123; // ioRatio 为 100 时，总是运行完所有非 IO 任务 runAllTasks(); &#125; &#125; else &#123; final long ioStartTime = System.nanoTime(); try &#123; processSelectedKeys(); &#125; finally &#123; // 记录 io 事件处理耗时 final long ioTime = System.nanoTime() - ioStartTime; // 运行非 IO 任务，一旦超时会退出 runAllTasks runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; try &#123; if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; return; &#125; &#125; &#125; catch (Throwable t) &#123; handleLoopException(t); &#125; &#125;&#125; ⚠️ 注意 这里有个费解的地方就是 wakeup，它既可以由提交任务的线程来调用（比较好理解），也可以由 EventLoop 线程来调用（比较费解），这里要知道 wakeup 方法的效果： 由非 EventLoop 线程调用，会唤醒当前在执行 select 阻塞的 EventLoop 线程 由 EventLoop 自己调用，会本次的 wakeup 会取消下一次的 select 操作 参考下图 io.netty.channel.nio.NioEventLoop#select 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private void select(boolean oldWakenUp) throws IOException &#123; Selector selector = this.selector; try &#123; int selectCnt = 0; long currentTimeNanos = System.nanoTime(); // 计算等待时间 // * 没有 scheduledTask，超时时间为 1s // * 有 scheduledTask，超时时间为 `下一个定时任务执行时间 - 当前时间` long selectDeadLineNanos = currentTimeNanos + delayNanos(currentTimeNanos); for (;;) &#123; long timeoutMillis = (selectDeadLineNanos - currentTimeNanos + 500000L) / 1000000L; // 如果超时，退出循环 if (timeoutMillis &lt;= 0) &#123; if (selectCnt == 0) &#123; selector.selectNow(); selectCnt = 1; &#125; break; &#125; // 如果期间又有 task 退出循环，如果没这个判断，那么任务就会等到下次 select 超时时才能被执行 // wakenUp.compareAndSet(false, true) 是让非 NioEventLoop 不必再执行 wakeup if (hasTasks() &amp;&amp; wakenUp.compareAndSet(false, true)) &#123; selector.selectNow(); selectCnt = 1; break; &#125; // select 有限时阻塞 // 注意 nio 有 bug，当 bug 出现时，select 方法即使没有时间发生，也不会阻塞住，导致不断空轮询，cpu 占用 100% int selectedKeys = selector.select(timeoutMillis); // 计数加 1 selectCnt ++; // 醒来后，如果有 IO 事件、或是由非 EventLoop 线程唤醒，或者有任务，退出循环 if (selectedKeys != 0 || oldWakenUp || wakenUp.get() || hasTasks() || hasScheduledTasks()) &#123; break; &#125; if (Thread.interrupted()) &#123; // 线程被打断，退出循环 // 记录日志 selectCnt = 1; break; &#125; long time = System.nanoTime(); if (time - TimeUnit.MILLISECONDS.toNanos(timeoutMillis) &gt;= currentTimeNanos) &#123; // 如果超时，计数重置为 1，下次循环就会 break selectCnt = 1; &#125; // 计数超过阈值，由 io.netty.selectorAutoRebuildThreshold 指定，默认 512 // 这是为了解决 nio 空轮询 bug else if (SELECTOR_AUTO_REBUILD_THRESHOLD &gt; 0 &amp;&amp; selectCnt &gt;= SELECTOR_AUTO_REBUILD_THRESHOLD) &#123; // 重建 selector selector = selectRebuildSelector(selectCnt); selectCnt = 1; break; &#125; currentTimeNanos = time; &#125; if (selectCnt &gt; MIN_PREMATURE_SELECTOR_RETURNS) &#123; // 记录日志 &#125; &#125; catch (CancelledKeyException e) &#123; // 记录日志 &#125;&#125; 处理 keys io.netty.channel.nio.NioEventLoop#processSelectedKeys 123456789private void processSelectedKeys() &#123; if (selectedKeys != null) &#123; // 通过反射将 Selector 实现类中的就绪事件集合替换为 SelectedSelectionKeySet // SelectedSelectionKeySet 底层为数组实现，可以提高遍历性能（原本为 HashSet） processSelectedKeysOptimized(); &#125; else &#123; processSelectedKeysPlain(selector.selectedKeys()); &#125;&#125; io.netty.channel.nio.NioEventLoop#processSelectedKey 12345678910111213141516171819202122232425262728293031323334private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); // 当 key 取消或关闭时会导致这个 key 无效 if (!k.isValid()) &#123; // 无效时处理... return; &#125; try &#123; int readyOps = k.readyOps(); // 连接事件 if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; // 可写事件 if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; ch.unsafe().forceFlush(); &#125; // 可读或可接入事件 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // 如果是可接入 io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe#read // 如果是可读 io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read unsafe.read(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125;&#125; 2.3 accept 剖析nio 中如下代码，在 netty 中的流程 1234567891011121314151617181920//1 阻塞直到事件发生selector.select();Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator();while (iter.hasNext()) &#123; //2 拿到一个事件 SelectionKey key = iter.next(); //3 如果是 accept 事件 if (key.isAcceptable()) &#123; //4 执行 accept SocketChannel channel = serverSocketChannel.accept(); channel.configureBlocking(false); //5 关注 read 事件 channel.register(selector, SelectionKey.OP_READ); &#125; // ...&#125; 先来看可接入事件处理（accept） io.netty.channel.nio.AbstractNioMessageChannel.NioMessageUnsafe#read 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); allocHandle.reset(config); boolean closed = false; Throwable exception = null; try &#123; try &#123; do &#123; // doReadMessages 中执行了 accept 并创建 NioSocketChannel 作为消息放入 readBuf // readBuf 是一个 ArrayList 用来缓存消息 int localRead = doReadMessages(readBuf); if (localRead == 0) &#123; break; &#125; if (localRead &lt; 0) &#123; closed = true; break; &#125; // localRead 为 1，就一条消息，即接收一个客户端连接 allocHandle.incMessagesRead(localRead); &#125; while (allocHandle.continueReading()); &#125; catch (Throwable t) &#123; exception = t; &#125; int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; readPending = false; // 触发 read 事件，让 pipeline 上的 handler 处理，这时是处理 // io.netty.bootstrap.ServerBootstrap.ServerBootstrapAcceptor#channelRead pipeline.fireChannelRead(readBuf.get(i)); &#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); if (exception != null) &#123; closed = closeOnReadError(exception); pipeline.fireExceptionCaught(exception); &#125; if (closed) &#123; inputShutdown = true; if (isOpen()) &#123; close(voidPromise()); &#125; &#125; &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125;&#125; 关键代码 io.netty.bootstrap.ServerBootstrap.ServerBootstrapAcceptor#channelRead 12345678910111213141516171819202122232425262728public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // 这时的 msg 是 NioSocketChannel final Channel child = (Channel) msg; // NioSocketChannel 添加 childHandler 即初始化器 child.pipeline().addLast(childHandler); // 设置选项 setChannelOptions(child, childOptions, logger); for (Entry&lt;AttributeKey&lt;?&gt;, Object&gt; e: childAttrs) &#123; child.attr((AttributeKey&lt;Object&gt;) e.getKey()).set(e.getValue()); &#125; try &#123; // 注册 NioSocketChannel 到 nio worker 线程，接下来的处理也移交至 nio worker 线程 childGroup.register(child).addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; if (!future.isSuccess()) &#123; forceClose(child, future.cause()); &#125; &#125; &#125;); &#125; catch (Throwable t) &#123; forceClose(child, t); &#125;&#125; 又回到了熟悉的 io.netty.channel.AbstractChannel.AbstractUnsafe#register 方法 123456789101112131415161718192021222324public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; // 一些检查，略... AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; // 这行代码完成的事实是 nio boss -&gt; nio worker 线程的切换 eventLoop.execute(new Runnable() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; // 日志记录... closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125; &#125;&#125; io.netty.channel.AbstractChannel.AbstractUnsafe#register0 12345678910111213141516171819202122232425262728293031private void register0(ChannelPromise promise) &#123; try &#123; if (!promise.setUncancellable() || !ensureOpen(promise)) &#123; return; &#125; boolean firstRegistration = neverRegistered; doRegister(); neverRegistered = false; registered = true; // 执行初始化器，执行前 pipeline 中只有 head -&gt; 初始化器 -&gt; tail pipeline.invokeHandlerAddedIfNeeded(); // 执行后就是 head -&gt; logging handler -&gt; my handler -&gt; tail safeSetSuccess(promise); pipeline.fireChannelRegistered(); if (isActive()) &#123; if (firstRegistration) &#123; // 触发 pipeline 上 active 事件 pipeline.fireChannelActive(); &#125; else if (config().isAutoRead()) &#123; beginRead(); &#125; &#125; &#125; catch (Throwable t) &#123; closeForcibly(); closeFuture.setClosed(); safeSetFailure(promise, t); &#125;&#125; 回到了熟悉的代码 io.netty.channel.DefaultChannelPipeline.HeadContext#channelActive 12345public void channelActive(ChannelHandlerContext ctx) &#123; ctx.fireChannelActive(); // 触发 read (NioSocketChannel 这里 read，只是为了触发 channel 的事件注册，还未涉及数据读取) readIfIsAutoRead();&#125; io.netty.channel.nio.AbstractNioChannel#doBeginRead 123456789101112131415protected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; // 这时候 interestOps 是 0 final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; // 关注 read 事件 selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 2.4 read 剖析再来看可读事件 io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read，注意发送的数据未必能够一次读完，因此会触发多次 nio read 事件，一次事件内会触发多次 pipeline read，一次事件会触发一次 pipeline read complete 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public final void read() &#123; final ChannelConfig config = config(); if (shouldBreakReadReady(config)) &#123; clearReadPending(); return; &#125; final ChannelPipeline pipeline = pipeline(); // io.netty.allocator.type 决定 allocator 的实现 final ByteBufAllocator allocator = config.getAllocator(); // 用来分配 byteBuf，确定单次读取大小 final RecvByteBufAllocator.Handle allocHandle = recvBufAllocHandle(); allocHandle.reset(config); ByteBuf byteBuf = null; boolean close = false; try &#123; do &#123; byteBuf = allocHandle.allocate(allocator); // 读取 allocHandle.lastBytesRead(doReadBytes(byteBuf)); if (allocHandle.lastBytesRead() &lt;= 0) &#123; byteBuf.release(); byteBuf = null; close = allocHandle.lastBytesRead() &lt; 0; if (close) &#123; readPending = false; &#125; break; &#125; allocHandle.incMessagesRead(1); readPending = false; // 触发 read 事件，让 pipeline 上的 handler 处理，这时是处理 NioSocketChannel 上的 handler pipeline.fireChannelRead(byteBuf); byteBuf = null; &#125; // 是否要继续循环 while (allocHandle.continueReading()); allocHandle.readComplete(); // 触发 read complete 事件 pipeline.fireChannelReadComplete(); if (close) &#123; closeOnRead(pipeline); &#125; &#125; catch (Throwable t) &#123; handleReadException(pipeline, byteBuf, t, close, allocHandle); &#125; finally &#123; if (!readPending &amp;&amp; !config.isAutoRead()) &#123; removeReadOp(); &#125; &#125;&#125; io.netty.channel.DefaultMaxMessagesRecvByteBufAllocator.MaxMessageHandle#continueReading(io.netty.util.UncheckedBooleanSupplier) 123456789101112public boolean continueReading(UncheckedBooleanSupplier maybeMoreDataSupplier) &#123; return // 一般为 true config.isAutoRead() &amp;&amp; // respectMaybeMoreData 默认为 true // maybeMoreDataSupplier 的逻辑是如果预期读取字节与实际读取字节相等，返回 true (!respectMaybeMoreData || maybeMoreDataSupplier.get()) &amp;&amp; // 小于最大次数，maxMessagePerRead 默认 16 totalMessages &lt; maxMessagePerRead &amp;&amp; // 实际读到了数据 totalBytesRead &gt; 0;&#125;","path":"2022/12/03/Netty04-优化与源码/","date":"12-03","excerpt":"","tags":[{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"}]},{"title":"Netty 进阶","text":"三. Netty 进阶1. 粘包与半包1.1 粘包现象服务端代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class HelloWorldServer &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldServer.class); void start() &#123; NioEventLoopGroup boss = new NioEventLoopGroup(1); NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.channel(NioServerSocketChannel.class); serverBootstrap.group(boss, worker); serverBootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;connected &#123;&#125;&quot;, ctx.channel()); super.channelActive(ctx); &#125; @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;disconnect &#123;&#125;&quot;, ctx.channel()); super.channelInactive(ctx); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = serverBootstrap.bind(8080); log.debug(&quot;&#123;&#125; binding...&quot;, channelFuture.channel()); channelFuture.sync(); log.debug(&quot;&#123;&#125; bound...&quot;, channelFuture.channel()); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;server error&quot;, e); &#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); log.debug(&quot;stoped&quot;); &#125; &#125; public static void main(String[] args) &#123; new HelloWorldServer().start(); &#125;&#125; 客户端代码希望发送 10 个消息，每个消息是 16 字节 12345678910111213141516171819202122232425262728293031323334353637public class HelloWorldClient &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldClient.class); public static void main(String[] args) &#123; NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; log.debug(&quot;connetted...&quot;); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;sending...&quot;); Random r = new Random(); char c = &#x27;a&#x27;; for (int i = 0; i &lt; 10; i++) &#123; ByteBuf buffer = ctx.alloc().buffer(); buffer.writeBytes(new byte[]&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15&#125;); ctx.writeAndFlush(buffer); &#125; &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;127.0.0.1&quot;, 8080).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; worker.shutdownGracefully(); &#125; &#125;&#125; 服务器端的某次输出，可以看到一次就接收了 160 个字节，而非分 10 次接收 12345678910111213141516171819202108:24:46 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0x81e0fda5] binding...08:24:46 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0x81e0fda5, L:/0:0:0:0:0:0:0:0:8080] bound...08:24:55 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x94132411, L:/127.0.0.1:8080 - R:/127.0.0.1:58177] REGISTERED08:24:55 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x94132411, L:/127.0.0.1:8080 - R:/127.0.0.1:58177] ACTIVE08:24:55 [DEBUG] [nioEventLoopGroup-3-1] c.i.n.HelloWorldServer - connected [id: 0x94132411, L:/127.0.0.1:8080 - R:/127.0.0.1:58177]08:24:55 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x94132411, L:/127.0.0.1:8080 - R:/127.0.0.1:58177] READ: 160B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000010| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000020| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000030| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000040| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000050| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000060| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000070| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000080| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000090| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................|+--------+-------------------------------------------------+----------------+08:24:55 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x94132411, L:/127.0.0.1:8080 - R:/127.0.0.1:58177] READ COMPLETE 1.2 半包现象客户端代码希望发送 1 个消息，这个消息是 160 字节，代码改为 12345ByteBuf buffer = ctx.alloc().buffer();for (int i = 0; i &lt; 10; i++) &#123; buffer.writeBytes(new byte[]&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15&#125;);&#125;ctx.writeAndFlush(buffer); 为现象明显，服务端修改一下接收缓冲区，其它代码不变 1serverBootstrap.option(ChannelOption.SO_RCVBUF, 10); 服务器端的某次输出，可以看到接收的消息被分为两节，第一次 20 字节，第二次 140 字节 1234567891011121314151617181920212223242526272808:43:49 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0x4d6c6a84] binding...08:43:49 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0x4d6c6a84, L:/0:0:0:0:0:0:0:0:8080] bound...08:44:23 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] REGISTERED08:44:23 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] ACTIVE08:44:23 [DEBUG] [nioEventLoopGroup-3-1] c.i.n.HelloWorldServer - connected [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221]08:44:24 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] READ: 20B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 01 02 03 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |................||00000010| 00 01 02 03 |.... |+--------+-------------------------------------------------+----------------+08:44:24 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] READ COMPLETE08:44:24 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] READ: 140B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000010| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000020| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000030| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000040| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000050| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000060| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000070| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f 00 01 02 03 |................||00000080| 04 05 06 07 08 09 0a 0b 0c 0d 0e 0f |............ |+--------+-------------------------------------------------+----------------+08:44:24 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x1719abf7, L:/127.0.0.1:8080 - R:/127.0.0.1:59221] READ COMPLETE 注意 serverBootstrap.option(ChannelOption.SO_RCVBUF, 10) 影响的底层接收缓冲区（即滑动窗口）大小，仅决定了 netty 读取的最小单位，netty 实际每次读取的一般是它的整数倍 1.3 现象分析粘包 现象，发送 abc def，接收 abcdef 原因 应用层：接收方 ByteBuf 设置太大（Netty 默认 1024） 滑动窗口：假设发送方 256 bytes 表示一个完整报文，但由于接收方处理不及时且窗口大小足够大，这 256 bytes 字节就会缓冲在接收方的滑动窗口中，当滑动窗口中缓冲了多个报文就会粘包 Nagle 算法：会造成粘包 半包 现象，发送 abcdef，接收 abc def 原因 应用层：接收方 ByteBuf 小于实际发送数据量 滑动窗口：假设接收方的窗口只剩了 128 bytes，发送方的报文大小是 256 bytes，这时放不下了，只能先发送前 128 bytes，等待 ack 后才能发送剩余部分，这就造成了半包 MSS 限制：当发送的数据超过 MSS 限制后，会将数据切分发送，就会造成半包 本质是因为 TCP 是流式协议，消息无边界 滑动窗口 TCP 以一个段（segment）为单位，每发送一个段就需要进行一次确认应答（ack）处理，但如果这么做，缺点是包的往返时间越长性能就越差 为了解决此问题，引入了窗口概念，窗口大小即决定了无需等待应答而可以继续发送的数据最大值 窗口实际就起到一个缓冲区的作用，同时也能起到流量控制的作用 图中深色的部分即要发送的数据，高亮的部分即窗口 窗口内的数据才允许被发送，当应答未到达前，窗口必须停止滑动 如果 1001~2000 这个段的数据 ack 回来了，窗口就可以向前滑动 接收方也会维护一个窗口，只有落在窗口内的数据才能允许接收 MSS 限制 链路层对一次能够发送的最大数据有限制，这个限制称之为 MTU（maximum transmission unit），不同的链路设备的 MTU 值也有所不同，例如 以太网的 MTU 是 1500 FDDI（光纤分布式数据接口）的 MTU 是 4352 本地回环地址的 MTU 是 65535 - 本地测试不走网卡 MSS 是最大段长度（maximum segment size），它是 MTU 刨去 tcp 头和 ip 头后剩余能够作为数据传输的字节数 ipv4 tcp 头占用 20 bytes，ip 头占用 20 bytes，因此以太网 MSS 的值为 1500 - 40 = 1460 TCP 在传递大量数据时，会按照 MSS 大小将数据进行分割发送 MSS 的值在三次握手时通知对方自己 MSS 的值，然后在两者之间选择一个小值作为 MSS Nagle 算法 即使发送一个字节，也需要加入 tcp 头和 ip 头，也就是总字节数会使用 41 bytes，非常不经济。因此为了提高网络利用率，tcp 希望尽可能发送足够大的数据，这就是 Nagle 算法产生的缘由 该算法是指发送端即使还有应该发送的数据，但如果这部分数据很少的话，则进行延迟发送 如果 SO_SNDBUF 的数据达到 MSS，则需要发送 如果 SO_SNDBUF 中含有 FIN（表示需要连接关闭）这时将剩余数据发送，再关闭 如果 TCP_NODELAY = true，则需要发送 已发送的数据都收到 ack 时，则需要发送 上述条件不满足，但发生超时（一般为 200ms）则需要发送 除上述情况，延迟发送 1.4 解决方案 短链接，发一个包建立一次连接，这样连接建立到连接断开之间就是消息的边界，缺点效率太低 每一条消息采用固定长度，缺点浪费空间 每一条消息采用分隔符，例如 \\n，缺点需要转义 每一条消息分为 head 和 body，head 中包含 body 的长度 方法1，短链接以解决粘包为例 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class HelloWorldClient &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldClient.class); public static void main(String[] args) &#123; // 分 10 次发送 for (int i = 0; i &lt; 10; i++) &#123; send(); &#125; &#125; private static void send() &#123; NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; log.debug(&quot;conneted...&quot;); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;sending...&quot;); ByteBuf buffer = ctx.alloc().buffer(); buffer.writeBytes(new byte[]&#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15&#125;); ctx.writeAndFlush(buffer); // 发完即关 ctx.close(); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;, 8080).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; worker.shutdownGracefully(); &#125; &#125;&#125; 输出，略 半包用这种办法还是不好解决，因为接收方的缓冲区大小是有限的 方法2，固定长度让所有数据包长度固定（假设长度为 8 字节），服务器端加入 1ch.pipeline().addLast(new FixedLengthFrameDecoder(8)); 客户端测试代码，注意, 采用这种方法后，客户端什么时候 flush 都可以 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class HelloWorldClient &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldClient.class); public static void main(String[] args) &#123; NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; log.debug(&quot;connetted...&quot;); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;sending...&quot;); // 发送内容随机的数据包 Random r = new Random(); char c = &#x27;a&#x27;; ByteBuf buffer = ctx.alloc().buffer(); for (int i = 0; i &lt; 10; i++) &#123; byte[] bytes = new byte[8]; for (int j = 0; j &lt; r.nextInt(8); j++) &#123; bytes[j] = (byte) c; &#125; c++; buffer.writeBytes(bytes); &#125; ctx.writeAndFlush(buffer); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;192.168.0.103&quot;, 9090).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; worker.shutdownGracefully(); &#125; &#125;&#125; 客户端输出 1234567891011121314151612:07:00 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - connetted...12:07:00 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x3c2ef3c2] REGISTERED12:07:00 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x3c2ef3c2] CONNECT: /192.168.0.103:909012:07:00 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x3c2ef3c2, L:/192.168.0.103:53155 - R:/192.168.0.103:9090] ACTIVE12:07:00 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - sending...12:07:00 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x3c2ef3c2, L:/192.168.0.103:53155 - R:/192.168.0.103:9090] WRITE: 80B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 61 61 61 00 00 00 00 62 00 00 00 00 00 00 00 |aaaa....b.......||00000010| 63 63 00 00 00 00 00 00 64 00 00 00 00 00 00 00 |cc......d.......||00000020| 00 00 00 00 00 00 00 00 66 66 66 66 00 00 00 00 |........ffff....||00000030| 67 67 67 00 00 00 00 00 68 00 00 00 00 00 00 00 |ggg.....h.......||00000040| 69 69 69 69 69 00 00 00 6a 6a 6a 6a 00 00 00 00 |iiiii...jjjj....|+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x3c2ef3c2, L:/192.168.0.103:53155 - R:/192.168.0.103:9090] FLUSH 服务端输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656612:06:51 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0xe3d9713f] binding...12:06:51 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0xe3d9713f, L:/192.168.0.103:9090] bound...12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] REGISTERED12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] ACTIVE12:07:00 [DEBUG] [nioEventLoopGroup-3-1] c.i.n.HelloWorldServer - connected [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155]12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 61 61 61 00 00 00 00 |aaaa.... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 62 00 00 00 00 00 00 00 |b....... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 63 63 00 00 00 00 00 00 |cc...... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 64 00 00 00 00 00 00 00 |d....... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 00 00 00 00 00 00 00 |........ |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 66 66 66 66 00 00 00 00 |ffff.... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 67 67 67 00 00 00 00 00 |ggg..... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 00 00 00 00 00 00 00 |h....... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 69 69 69 69 69 00 00 00 |iiiii... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6a 6a 6a 6a 00 00 00 00 |jjjj.... |+--------+-------------------------------------------------+----------------+12:07:00 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0xd739f137, L:/192.168.0.103:9090 - R:/192.168.0.103:53155] READ COMPLETE 缺点是，数据包的大小不好把握 长度定的太大，浪费 长度定的太小，对某些数据包又显得不够 方法3，固定分隔符服务端加入，默认以 \\n 或 \\r\\n 作为分隔符，如果超出指定长度仍未出现分隔符，则抛出异常 1ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); 客户端在每条消息之后，加入 \\n 分隔符 12345678910111213141516171819202122232425262728293031323334353637383940414243public class HelloWorldClient &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldClient.class); public static void main(String[] args) &#123; NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; log.debug(&quot;connetted...&quot;); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;sending...&quot;); Random r = new Random(); char c = &#x27;a&#x27;; ByteBuf buffer = ctx.alloc().buffer(); for (int i = 0; i &lt; 10; i++) &#123; for (int j = 1; j &lt;= r.nextInt(16)+1; j++) &#123; buffer.writeByte((byte) c); &#125; buffer.writeByte(10); c++; &#125; ctx.writeAndFlush(buffer); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;192.168.0.103&quot;, 9090).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; worker.shutdownGracefully(); &#125; &#125;&#125; 客户端输出 12345678910111213141514:08:18 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - connetted...14:08:18 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x1282d755] REGISTERED14:08:18 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x1282d755] CONNECT: /192.168.0.103:909014:08:18 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x1282d755, L:/192.168.0.103:63641 - R:/192.168.0.103:9090] ACTIVE14:08:18 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - sending...14:08:18 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x1282d755, L:/192.168.0.103:63641 - R:/192.168.0.103:9090] WRITE: 60B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 0a 62 62 62 0a 63 63 63 0a 64 64 0a 65 65 65 |a.bbb.ccc.dd.eee||00000010| 65 65 65 65 65 65 65 0a 66 66 0a 67 67 67 67 67 |eeeeeee.ff.ggggg||00000020| 67 67 0a 68 68 68 68 0a 69 69 69 69 69 69 69 0a |gg.hhhh.iiiiiii.||00000030| 6a 6a 6a 6a 6a 6a 6a 6a 6a 6a 6a 0a |jjjjjjjjjjj. |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0x1282d755, L:/192.168.0.103:63641 - R:/192.168.0.103:9090] FLUSH 服务端输出 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616214:08:18 [DEBUG] [nioEventLoopGroup-3-5] c.i.n.HelloWorldServer - connected [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641]14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 1B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 |a |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 3B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 62 62 62 |bbb |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 3B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 63 63 63 |ccc |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 2B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 64 64 |dd |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 10B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 65 65 65 65 65 65 65 65 65 65 |eeeeeeeeee |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 2B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 66 66 |ff |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 7B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 67 67 67 67 67 67 67 |ggggggg |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 4B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 68 68 68 |hhhh |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 7B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 69 69 69 69 69 69 69 |iiiiiii |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ: 11B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6a 6a 6a 6a 6a 6a 6a 6a 6a 6a 6a |jjjjjjjjjjj |+--------+-------------------------------------------------+----------------+14:08:18 [DEBUG] [nioEventLoopGroup-3-5] i.n.h.l.LoggingHandler - [id: 0xa4b3be43, L:/192.168.0.103:9090 - R:/192.168.0.103:63641] READ COMPLETE 缺点，处理字符数据比较合适，但如果内容本身包含了分隔符（字节数据常常会有此情况），那么就会解析错误 方法4，预设长度在发送消息前，先约定用定长字节表示接下来数据的长度 12// 最大长度，长度偏移，长度占用字节，长度调整，剥离字节数ch.pipeline().addLast(new LengthFieldBasedFrameDecoder(1024, 0, 1, 0, 1)); 客户端代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class HelloWorldClient &#123; static final Logger log = LoggerFactory.getLogger(HelloWorldClient.class); public static void main(String[] args) &#123; NioEventLoopGroup worker = new NioEventLoopGroup(); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; log.debug(&quot;connetted...&quot;); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; log.debug(&quot;sending...&quot;); Random r = new Random(); char c = &#x27;a&#x27;; ByteBuf buffer = ctx.alloc().buffer(); for (int i = 0; i &lt; 10; i++) &#123; byte length = (byte) (r.nextInt(16) + 1); // 先写入长度 buffer.writeByte(length); // 再 for (int j = 1; j &lt;= length; j++) &#123; buffer.writeByte((byte) c); &#125; c++; &#125; ctx.writeAndFlush(buffer); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;192.168.0.103&quot;, 9090).sync(); channelFuture.channel().closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; worker.shutdownGracefully(); &#125; &#125;&#125; 客户端输出 12345678910111213141516171814:37:10 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - connetted...14:37:10 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0xf0f347b8] REGISTERED14:37:10 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0xf0f347b8] CONNECT: /192.168.0.103:909014:37:10 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0xf0f347b8, L:/192.168.0.103:49979 - R:/192.168.0.103:9090] ACTIVE14:37:10 [DEBUG] [nioEventLoopGroup-2-1] c.i.n.HelloWorldClient - sending...14:37:10 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0xf0f347b8, L:/192.168.0.103:49979 - R:/192.168.0.103:9090] WRITE: 97B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 09 61 61 61 61 61 61 61 61 61 09 62 62 62 62 62 |.aaaaaaaaa.bbbbb||00000010| 62 62 62 62 06 63 63 63 63 63 63 08 64 64 64 64 |bbbb.cccccc.dddd||00000020| 64 64 64 64 0f 65 65 65 65 65 65 65 65 65 65 65 |dddd.eeeeeeeeeee||00000030| 65 65 65 65 0d 66 66 66 66 66 66 66 66 66 66 66 |eeee.fffffffffff||00000040| 66 66 02 67 67 02 68 68 0e 69 69 69 69 69 69 69 |ff.gg.hh.iiiiiii||00000050| 69 69 69 69 69 69 69 09 6a 6a 6a 6a 6a 6a 6a 6a |iiiiiii.jjjjjjjj||00000060| 6a |j |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-2-1] i.n.h.l.LoggingHandler - [id: 0xf0f347b8, L:/192.168.0.103:49979 - R:/192.168.0.103:9090] FLUSH 服务端输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666714:36:50 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0xdff439d3] binding...14:36:51 [DEBUG] [main] c.i.n.HelloWorldServer - [id: 0xdff439d3, L:/192.168.0.103:9090] bound...14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] REGISTERED14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] ACTIVE14:37:10 [DEBUG] [nioEventLoopGroup-3-1] c.i.n.HelloWorldServer - connected [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979]14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 9B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 61 61 61 61 61 61 61 61 |aaaaaaaaa |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 9B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 62 62 62 62 62 62 62 62 62 |bbbbbbbbb |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 6B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 63 63 63 63 63 63 |cccccc |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 64 64 64 64 64 64 64 64 |dddddddd |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 15B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 65 65 65 65 65 65 65 65 65 65 65 65 65 65 65 |eeeeeeeeeeeeeee |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 13B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 66 66 66 66 66 66 66 66 66 66 66 66 66 |fffffffffffff |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 2B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 67 67 |gg |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 2B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 68 |hh |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 14B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 69 69 69 69 69 69 69 69 69 69 69 69 69 69 |iiiiiiiiiiiiii |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ: 9B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6a 6a 6a 6a 6a 6a 6a 6a 6a |jjjjjjjjj |+--------+-------------------------------------------------+----------------+14:37:10 [DEBUG] [nioEventLoopGroup-3-1] i.n.h.l.LoggingHandler - [id: 0x744f2b47, L:/192.168.0.103:9090 - R:/192.168.0.103:49979] READ COMPLETE 2. 协议设计与解析2.1 为什么需要协议？TCP/IP 中消息传输基于流的方式，没有边界。 协议的目的就是划定消息的边界，制定通信双方要共同遵守的通信规则 例如：在网络上传输 1下雨天留客天留我不留 是中文一句著名的无标点符号句子，在没有标点符号情况下，这句话有数种拆解方式，而意思却是完全不同，所以常被用作讲述标点符号的重要性 一种解读 1下雨天留客，天留，我不留 另一种解读 1下雨天，留客天，留我不？留 如何设计协议呢？其实就是给网络传输的信息加上“标点符号”。但通过分隔符来断句不是很好，因为分隔符本身如果用于传输，那么必须加以区分。因此，下面一种协议较为常用 1定长字节表示内容长度 + 实际内容 例如，假设一个中文字符长度为 3，按照上述协议的规则，发送信息方式如下，就不会被接收方弄错意思了 10f下雨天留客06天留09我不留 小故事 很久很久以前，一位私塾先生到一家任教。双方签订了一纸协议：“无鸡鸭亦可无鱼肉亦可白菜豆腐不可少不得束修金”。此后，私塾先生虽然认真教课，但主人家则总是给私塾先生以白菜豆腐为菜，丝毫未见鸡鸭鱼肉的款待。私塾先生先是很不解，可是后来也就想通了：主人把鸡鸭鱼肉的钱都会换为束修金的，也罢。至此双方相安无事。 年关将至，一个学年段亦告结束。私塾先生临行时，也不见主人家为他交付束修金，遂与主家理论。然主家亦振振有词：“有协议为证——无鸡鸭亦可，无鱼肉亦可，白菜豆腐不可少，不得束修金。这白纸黑字明摆着的，你有什么要说的呢？” 私塾先生据理力争：“协议是这样的——无鸡，鸭亦可；无鱼，肉亦可；白菜豆腐不可，少不得束修金。” 双方唇枪舌战，你来我往，真个是不亦乐乎！ 这里的束修金，也作“束脩”，应当是泛指教师应当得到的报酬 2.2 redis 协议举例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465NioEventLoopGroup worker = new NioEventLoopGroup();byte[] LINE = &#123;13, 10&#125;;try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(worker); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(new LoggingHandler()); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; // 会在连接 channel 建立成功后，会触发 active 事件 @Override public void channelActive(ChannelHandlerContext ctx) &#123; set(ctx); get(ctx); &#125; private void get(ChannelHandlerContext ctx) &#123; ByteBuf buf = ctx.alloc().buffer(); buf.writeBytes(&quot;*2&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;$3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;get&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;$3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;aaa&quot;.getBytes()); buf.writeBytes(LINE); ctx.writeAndFlush(buf); &#125; private void set(ChannelHandlerContext ctx) &#123; ByteBuf buf = ctx.alloc().buffer(); buf.writeBytes(&quot;*3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;$3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;set&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;$3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;aaa&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;$3&quot;.getBytes()); buf.writeBytes(LINE); buf.writeBytes(&quot;bbb&quot;.getBytes()); buf.writeBytes(LINE); ctx.writeAndFlush(buf); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf) msg; System.out.println(buf.toString(Charset.defaultCharset())); &#125; &#125;); &#125; &#125;); ChannelFuture channelFuture = bootstrap.connect(&quot;localhost&quot;, 6379).sync(); channelFuture.channel().closeFuture().sync();&#125; catch (InterruptedException e) &#123; log.error(&quot;client error&quot;, e);&#125; finally &#123; worker.shutdownGracefully();&#125; 2.3 http 协议举例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152NioEventLoopGroup boss = new NioEventLoopGroup();NioEventLoopGroup worker = new NioEventLoopGroup();try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.channel(NioServerSocketChannel.class); serverBootstrap.group(boss, worker); serverBootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new HttpServerCodec()); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;HttpRequest&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, HttpRequest msg) throws Exception &#123; // 获取请求 log.debug(msg.uri()); // 返回响应 DefaultFullHttpResponse response = new DefaultFullHttpResponse(msg.protocolVersion(), HttpResponseStatus.OK); byte[] bytes = &quot;&lt;h1&gt;Hello, world!&lt;/h1&gt;&quot;.getBytes(); response.headers().setInt(CONTENT_LENGTH, bytes.length); response.content().writeBytes(bytes); // 写回响应 ctx.writeAndFlush(response); &#125; &#125;); /*ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; log.debug(&quot;&#123;&#125;&quot;, msg.getClass()); if (msg instanceof HttpRequest) &#123; // 请求行，请求头 &#125; else if (msg instanceof HttpContent) &#123; //请求体 &#125; &#125; &#125;);*/ &#125; &#125;); ChannelFuture channelFuture = serverBootstrap.bind(8080).sync(); channelFuture.channel().closeFuture().sync();&#125; catch (InterruptedException e) &#123; log.error(&quot;server error&quot;, e);&#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully();&#125; 2.4 自定义协议要素 魔数，用来在第一时间判定是否是无效数据包 版本号，可以支持协议的升级 序列化算法，消息正文到底采用哪种序列化反序列化方式，可以由此扩展，例如：json、protobuf、hessian、jdk 指令类型，是登录、注册、单聊、群聊… 跟业务相关 请求序号，为了双工通信，提供异步能力 正文长度 消息正文 编解码器根据上面的要素，设计一个登录请求消息和登录响应消息，并使用 Netty 完成收发 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Slf4jpublic class MessageCodec extends ByteToMessageCodec&lt;Message&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, Message msg, ByteBuf out) throws Exception &#123; // 1. 4 字节的魔数 out.writeBytes(new byte[]&#123;1, 2, 3, 4&#125;); // 2. 1 字节的版本, out.writeByte(1); // 3. 1 字节的序列化方式 jdk 0 , json 1 out.writeByte(0); // 4. 1 字节的指令类型 out.writeByte(msg.getMessageType()); // 5. 4 个字节 out.writeInt(msg.getSequenceId()); // 无意义，对齐填充 out.writeByte(0xff); // 6. 获取内容的字节数组 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(msg); byte[] bytes = bos.toByteArray(); // 7. 长度 out.writeInt(bytes.length); // 8. 写入内容 out.writeBytes(bytes); &#125; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; int magicNum = in.readInt(); byte version = in.readByte(); byte serializerType = in.readByte(); byte messageType = in.readByte(); int sequenceId = in.readInt(); in.readByte(); int length = in.readInt(); byte[] bytes = new byte[length]; in.readBytes(bytes, 0, length); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes)); Message message = (Message) ois.readObject(); log.debug(&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;&quot;, magicNum, version, serializerType, messageType, sequenceId, length); log.debug(&quot;&#123;&#125;&quot;, message); out.add(message); &#125;&#125; 测试 123456789101112131415161718EmbeddedChannel channel = new EmbeddedChannel( new LoggingHandler(), new LengthFieldBasedFrameDecoder( 1024, 12, 4, 0, 0), new MessageCodec());// encodeLoginRequestMessage message = new LoginRequestMessage(&quot;zhangsan&quot;, &quot;123&quot;, &quot;张三&quot;);// channel.writeOutbound(message);// decodeByteBuf buf = ByteBufAllocator.DEFAULT.buffer();new MessageCodec().encode(null, message, buf);ByteBuf s1 = buf.slice(0, 100);ByteBuf s2 = buf.slice(100, buf.readableBytes() - 100);s1.retain(); // 引用计数 2channel.writeInbound(s1); // release 1channel.writeInbound(s2); 解读 💡 什么时候可以加 @Sharable 当 handler 不保存状态时，就可以安全地在多线程下被共享 但要注意对于编解码器类，不能继承 ByteToMessageCodec 或 CombinedChannelDuplexHandler 父类，他们的构造方法对 @Sharable 有限制 如果能确保编解码器不会保存状态，可以继承 MessageToMessageCodec 父类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Slf4j@ChannelHandler.Sharable/** * 必须和 LengthFieldBasedFrameDecoder 一起使用，确保接到的 ByteBuf 消息是完整的 */public class MessageCodecSharable extends MessageToMessageCodec&lt;ByteBuf, Message&gt; &#123; @Override protected void encode(ChannelHandlerContext ctx, Message msg, List&lt;Object&gt; outList) throws Exception &#123; ByteBuf out = ctx.alloc().buffer(); // 1. 4 字节的魔数 out.writeBytes(new byte[]&#123;1, 2, 3, 4&#125;); // 2. 1 字节的版本, out.writeByte(1); // 3. 1 字节的序列化方式 jdk 0 , json 1 out.writeByte(0); // 4. 1 字节的指令类型 out.writeByte(msg.getMessageType()); // 5. 4 个字节 out.writeInt(msg.getSequenceId()); // 无意义，对齐填充 out.writeByte(0xff); // 6. 获取内容的字节数组 ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(bos); oos.writeObject(msg); byte[] bytes = bos.toByteArray(); // 7. 长度 out.writeInt(bytes.length); // 8. 写入内容 out.writeBytes(bytes); outList.add(out); &#125; @Override protected void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception &#123; int magicNum = in.readInt(); byte version = in.readByte(); byte serializerType = in.readByte(); byte messageType = in.readByte(); int sequenceId = in.readInt(); in.readByte(); int length = in.readInt(); byte[] bytes = new byte[length]; in.readBytes(bytes, 0, length); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream(bytes)); Message message = (Message) ois.readObject(); log.debug(&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;, &#123;&#125;&quot;, magicNum, version, serializerType, messageType, sequenceId, length); log.debug(&quot;&#123;&#125;&quot;, message); out.add(message); &#125;&#125; 3. 聊天室案例3.1 聊天室业务介绍12345678910111213/** * 用户管理接口 */public interface UserService &#123; /** * 登录 * @param username 用户名 * @param password 密码 * @return 登录成功返回 true, 否则返回 false */ boolean login(String username, String password);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 会话管理接口 */public interface Session &#123; /** * 绑定会话 * @param channel 哪个 channel 要绑定会话 * @param username 会话绑定用户 */ void bind(Channel channel, String username); /** * 解绑会话 * @param channel 哪个 channel 要解绑会话 */ void unbind(Channel channel); /** * 获取属性 * @param channel 哪个 channel * @param name 属性名 * @return 属性值 */ Object getAttribute(Channel channel, String name); /** * 设置属性 * @param channel 哪个 channel * @param name 属性名 * @param value 属性值 */ void setAttribute(Channel channel, String name, Object value); /** * 根据用户名获取 channel * @param username 用户名 * @return channel */ Channel getChannel(String username);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 聊天组会话管理接口 */public interface GroupSession &#123; /** * 创建一个聊天组, 如果不存在才能创建成功, 否则返回 null * @param name 组名 * @param members 成员 * @return 成功时返回组对象, 失败返回 null */ Group createGroup(String name, Set&lt;String&gt; members); /** * 加入聊天组 * @param name 组名 * @param member 成员名 * @return 如果组不存在返回 null, 否则返回组对象 */ Group joinMember(String name, String member); /** * 移除组成员 * @param name 组名 * @param member 成员名 * @return 如果组不存在返回 null, 否则返回组对象 */ Group removeMember(String name, String member); /** * 移除聊天组 * @param name 组名 * @return 如果组不存在返回 null, 否则返回组对象 */ Group removeGroup(String name); /** * 获取组成员 * @param name 组名 * @return 成员集合, 没有成员会返回 empty set */ Set&lt;String&gt; getMembers(String name); /** * 获取组成员的 channel 集合, 只有在线的 channel 才会返回 * @param name 组名 * @return 成员 channel 集合 */ List&lt;Channel&gt; getMembersChannel(String name);&#125; 3.2 聊天室业务-登录1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4jpublic class ChatServer &#123; public static void main(String[] args) &#123; NioEventLoopGroup boss = new NioEventLoopGroup(); NioEventLoopGroup worker = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); try &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.channel(NioServerSocketChannel.class); serverBootstrap.group(boss, worker); serverBootstrap.childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder()); ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;LoginRequestMessage&gt;() &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, LoginRequestMessage msg) throws Exception &#123; String username = msg.getUsername(); String password = msg.getPassword(); boolean login = UserServiceFactory.getUserService().login(username, password); LoginResponseMessage message; if(login) &#123; message = new LoginResponseMessage(true, &quot;登录成功&quot;); &#125; else &#123; message = new LoginResponseMessage(false, &quot;用户名或密码不正确&quot;); &#125; ctx.writeAndFlush(message); &#125; &#125;); &#125; &#125;); Channel channel = serverBootstrap.bind(8080).sync().channel(); channel.closeFuture().sync(); &#125; catch (InterruptedException e) &#123; log.error(&quot;server error&quot;, e); &#125; finally &#123; boss.shutdownGracefully(); worker.shutdownGracefully(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111@Slf4jpublic class ChatClient &#123; public static void main(String[] args) &#123; NioEventLoopGroup group = new NioEventLoopGroup(); LoggingHandler LOGGING_HANDLER = new LoggingHandler(LogLevel.DEBUG); MessageCodecSharable MESSAGE_CODEC = new MessageCodecSharable(); CountDownLatch WAIT_FOR_LOGIN = new CountDownLatch(1); AtomicBoolean LOGIN = new AtomicBoolean(false); try &#123; Bootstrap bootstrap = new Bootstrap(); bootstrap.channel(NioSocketChannel.class); bootstrap.group(group); bootstrap.handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new ProcotolFrameDecoder());// ch.pipeline().addLast(LOGGING_HANDLER); ch.pipeline().addLast(MESSAGE_CODEC); ch.pipeline().addLast(&quot;client handler&quot;, new ChannelInboundHandlerAdapter() &#123; // 接收响应消息 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; log.debug(&quot;msg: &#123;&#125;&quot;, msg); if ((msg instanceof LoginResponseMessage)) &#123; LoginResponseMessage response = (LoginResponseMessage) msg; if (response.isSuccess()) &#123; // 如果登录成功 LOGIN.set(true); &#125; // 唤醒 system in 线程 WAIT_FOR_LOGIN.countDown(); &#125; &#125; // 在连接建立后触发 active 事件 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; // 负责接收用户在控制台的输入，负责向服务器发送各种消息 new Thread(() -&gt; &#123; Scanner scanner = new Scanner(System.in); System.out.println(&quot;请输入用户名:&quot;); String username = scanner.nextLine(); System.out.println(&quot;请输入密码:&quot;); String password = scanner.nextLine(); // 构造消息对象 LoginRequestMessage message = new LoginRequestMessage(username, password); // 发送消息 ctx.writeAndFlush(message); System.out.println(&quot;等待后续操作...&quot;); try &#123; WAIT_FOR_LOGIN.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 如果登录失败 if (!LOGIN.get()) &#123; ctx.channel().close(); return; &#125; while (true) &#123; System.out.println(&quot;==================================&quot;); System.out.println(&quot;send [username] [content]&quot;); System.out.println(&quot;gsend [group name] [content]&quot;); System.out.println(&quot;gcreate [group name] [m1,m2,m3...]&quot;); System.out.println(&quot;gmembers [group name]&quot;); System.out.println(&quot;gjoin [group name]&quot;); System.out.println(&quot;gquit [group name]&quot;); System.out.println(&quot;quit&quot;); System.out.println(&quot;==================================&quot;); String command = scanner.nextLine(); String[] s = command.split(&quot; &quot;); switch (s[0])&#123; case &quot;send&quot;: ctx.writeAndFlush(new ChatRequestMessage(username, s[1], s[2])); break; case &quot;gsend&quot;: ctx.writeAndFlush(new GroupChatRequestMessage(username, s[1], s[2])); break; case &quot;gcreate&quot;: Set&lt;String&gt; set = new HashSet&lt;&gt;(Arrays.asList(s[2].split(&quot;,&quot;))); set.add(username); // 加入自己 ctx.writeAndFlush(new GroupCreateRequestMessage(s[1], set)); break; case &quot;gmembers&quot;: ctx.writeAndFlush(new GroupMembersRequestMessage(s[1])); break; case &quot;gjoin&quot;: ctx.writeAndFlush(new GroupJoinRequestMessage(username, s[1])); break; case &quot;gquit&quot;: ctx.writeAndFlush(new GroupQuitRequestMessage(username, s[1])); break; case &quot;quit&quot;: ctx.channel().close(); return; &#125; &#125; &#125;, &quot;system in&quot;).start(); &#125; &#125;); &#125; &#125;); Channel channel = bootstrap.connect(&quot;localhost&quot;, 8080).sync().channel(); channel.closeFuture().sync(); &#125; catch (Exception e) &#123; log.error(&quot;client error&quot;, e); &#125; finally &#123; group.shutdownGracefully(); &#125; &#125;&#125; 3.3 聊天室业务-单聊服务器端将 handler 独立出来 登录 handler 1234567891011121314151617@ChannelHandler.Sharablepublic class LoginRequestMessageHandler extends SimpleChannelInboundHandler&lt;LoginRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, LoginRequestMessage msg) throws Exception &#123; String username = msg.getUsername(); String password = msg.getPassword(); boolean login = UserServiceFactory.getUserService().login(username, password); LoginResponseMessage message; if(login) &#123; SessionFactory.getSession().bind(ctx.channel(), username); message = new LoginResponseMessage(true, &quot;登录成功&quot;); &#125; else &#123; message = new LoginResponseMessage(false, &quot;用户名或密码不正确&quot;); &#125; ctx.writeAndFlush(message); &#125;&#125; 单聊 handler 12345678910111213141516@ChannelHandler.Sharablepublic class ChatRequestMessageHandler extends SimpleChannelInboundHandler&lt;ChatRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, ChatRequestMessage msg) throws Exception &#123; String to = msg.getTo(); Channel channel = SessionFactory.getSession().getChannel(to); // 在线 if(channel != null) &#123; channel.writeAndFlush(new ChatResponseMessage(msg.getFrom(), msg.getContent())); &#125; // 不在线 else &#123; ctx.writeAndFlush(new ChatResponseMessage(false, &quot;对方用户不存在或者不在线&quot;)); &#125; &#125;&#125; 3.4 聊天室业务-群聊创建群聊 12345678910111213141516171819202122@ChannelHandler.Sharablepublic class GroupCreateRequestMessageHandler extends SimpleChannelInboundHandler&lt;GroupCreateRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, GroupCreateRequestMessage msg) throws Exception &#123; String groupName = msg.getGroupName(); Set&lt;String&gt; members = msg.getMembers(); // 群管理器 GroupSession groupSession = GroupSessionFactory.getGroupSession(); Group group = groupSession.createGroup(groupName, members); if (group == null) &#123; // 发生成功消息 ctx.writeAndFlush(new GroupCreateResponseMessage(true, groupName + &quot;创建成功&quot;)); // 发送拉群消息 List&lt;Channel&gt; channels = groupSession.getMembersChannel(groupName); for (Channel channel : channels) &#123; channel.writeAndFlush(new GroupCreateResponseMessage(true, &quot;您已被拉入&quot; + groupName)); &#125; &#125; else &#123; ctx.writeAndFlush(new GroupCreateResponseMessage(false, groupName + &quot;已经存在&quot;)); &#125; &#125;&#125; 群聊 123456789101112@ChannelHandler.Sharablepublic class GroupChatRequestMessageHandler extends SimpleChannelInboundHandler&lt;GroupChatRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, GroupChatRequestMessage msg) throws Exception &#123; List&lt;Channel&gt; channels = GroupSessionFactory.getGroupSession() .getMembersChannel(msg.getGroupName()); for (Channel channel : channels) &#123; channel.writeAndFlush(new GroupChatResponseMessage(msg.getFrom(), msg.getContent())); &#125; &#125;&#125; 加入群聊 123456789101112@ChannelHandler.Sharablepublic class GroupJoinRequestMessageHandler extends SimpleChannelInboundHandler&lt;GroupJoinRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, GroupJoinRequestMessage msg) throws Exception &#123; Group group = GroupSessionFactory.getGroupSession().joinMember(msg.getGroupName(), msg.getUsername()); if (group != null) &#123; ctx.writeAndFlush(new GroupJoinResponseMessage(true, msg.getGroupName() + &quot;群加入成功&quot;)); &#125; else &#123; ctx.writeAndFlush(new GroupJoinResponseMessage(true, msg.getGroupName() + &quot;群不存在&quot;)); &#125; &#125;&#125; 退出群聊 123456789101112@ChannelHandler.Sharablepublic class GroupQuitRequestMessageHandler extends SimpleChannelInboundHandler&lt;GroupQuitRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, GroupQuitRequestMessage msg) throws Exception &#123; Group group = GroupSessionFactory.getGroupSession().removeMember(msg.getGroupName(), msg.getUsername()); if (group != null) &#123; ctx.writeAndFlush(new GroupJoinResponseMessage(true, &quot;已退出群&quot; + msg.getGroupName())); &#125; else &#123; ctx.writeAndFlush(new GroupJoinResponseMessage(true, msg.getGroupName() + &quot;群不存在&quot;)); &#125; &#125;&#125; 查看成员 123456789@ChannelHandler.Sharablepublic class GroupMembersRequestMessageHandler extends SimpleChannelInboundHandler&lt;GroupMembersRequestMessage&gt; &#123; @Override protected void channelRead0(ChannelHandlerContext ctx, GroupMembersRequestMessage msg) throws Exception &#123; Set&lt;String&gt; members = GroupSessionFactory.getGroupSession() .getMembers(msg.getGroupName()); ctx.writeAndFlush(new GroupMembersResponseMessage(members)); &#125;&#125; 3.5 聊天室业务-退出123456789101112131415161718@Slf4j@ChannelHandler.Sharablepublic class QuitHandler extends ChannelInboundHandlerAdapter &#123; // 当连接断开时触发 inactive 事件 @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; SessionFactory.getSession().unbind(ctx.channel()); log.debug(&quot;&#123;&#125; 已经断开&quot;, ctx.channel()); &#125; // 当出现异常时触发 @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; SessionFactory.getSession().unbind(ctx.channel()); log.debug(&quot;&#123;&#125; 已经异常断开 异常是&#123;&#125;&quot;, ctx.channel(), cause.getMessage()); &#125;&#125; 3.6 聊天室业务-空闲检测连接假死原因 网络设备出现故障，例如网卡，机房等，底层的 TCP 连接已经断开了，但应用程序没有感知到，仍然占用着资源。 公网网络不稳定，出现丢包。如果连续出现丢包，这时现象就是客户端数据发不出去，服务端也一直收不到数据，就这么一直耗着 应用程序线程阻塞，无法进行数据读写 问题 假死的连接占用的资源不能自动释放 向假死的连接发送数据，得到的反馈是发送超时 服务器端解决 怎么判断客户端连接是否假死呢？如果能收到客户端数据，说明没有假死。因此策略就可以定为，每隔一段时间就检查这段时间内是否接收到客户端数据，没有就可以判定为连接假死 12345678910111213141516// 用来判断是不是 读空闲时间过长，或 写空闲时间过长// 5s 内如果没有收到 channel 的数据，会触发一个 IdleState#READER_IDLE 事件ch.pipeline().addLast(new IdleStateHandler(5, 0, 0));// ChannelDuplexHandler 可以同时作为入站和出站处理器ch.pipeline().addLast(new ChannelDuplexHandler() &#123; // 用来触发特殊事件 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception&#123; IdleStateEvent event = (IdleStateEvent) evt; // 触发了读空闲事件 if (event.state() == IdleState.READER_IDLE) &#123; log.debug(&quot;已经 5s 没有读到数据了&quot;); ctx.channel().close(); &#125; &#125;&#125;); 客户端定时心跳 客户端可以定时向服务器端发送数据，只要这个时间间隔小于服务器定义的空闲检测的时间间隔，那么就能防止前面提到的误判，客户端可以定义如下心跳处理器 12345678910111213141516// 用来判断是不是 读空闲时间过长，或 写空闲时间过长// 3s 内如果没有向服务器写数据，会触发一个 IdleState#WRITER_IDLE 事件ch.pipeline().addLast(new IdleStateHandler(0, 3, 0));// ChannelDuplexHandler 可以同时作为入站和出站处理器ch.pipeline().addLast(new ChannelDuplexHandler() &#123; // 用来触发特殊事件 @Override public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception&#123; IdleStateEvent event = (IdleStateEvent) evt; // 触发了写空闲事件 if (event.state() == IdleState.WRITER_IDLE) &#123; // log.debug(&quot;3s 没有写数据了，发送一个心跳包&quot;); ctx.writeAndFlush(new PingMessage()); &#125; &#125;&#125;);","path":"2022/12/03/Netty03-进阶/","date":"12-03","excerpt":"","tags":[{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"}]},{"title":"消息中间件-RabbitMQ","text":"消息中间件-RabbitMQ一、 介绍1. 消息队列 MQ(message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常 见的上下游“逻辑解耦+物理解耦”的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不 用依赖其他服务。 2. 为什么要使用MQ 流量削峰 应用解耦： 子系统间通过消息队列来通信，提升系统可用性 异步处理 3. 分类 ActiveMQ： 优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较 低的概率丢失数据 缺点:官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。 Kafka：大数据场景常用，百万级TPS、吞吐量高 RocketMQ： 出自阿里巴巴， 单机吞吐量十万级,可用性非常高，分布式架构,消息可以做到 0 丢失,MQ 功能较为完善，还是分 布式的，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降,源码是 java 我们可以自己阅 读源码，定制自己公司的 MQ 。 RabbitMQ ： 2007 年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最 主流的消息中间件之一 。 吞吐量到万级 ，支持多语言，社区活跃度高。 二、 RabbitMQ RabbitMQ 是一个消息中间件 它接受并转发消息。你可以把它当做一个快递站点，当你要发送一个包 裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。RabbitMQ 与快递站的主要区别在于，它不处理快件而是接收， 存储和转发消息数据。 1. 核心概念 生产者： 产生数据发送消息的程序 交换机： 交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息 推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推 送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。 队列： 队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式 。 消费者： 消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者。 Broker：接收和分发消息的应用，RabbitMQ Server 就是 Message Broker。 Virtual host：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出 多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等。 Connection：publisher／consumer 和 broker 之间的 TCP 连接。 Channel：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销 Exchange：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发 消息到 queue 中去。常用的类型有：direct (point-to-point), topic (publish-subscribe) and fanout (multicast)。 Queue：消息最终被送到这里等待 consumer 取 走。 Binding：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保 存到 exchange 中的查询表中，用于 message 的分发依据 。 2. 工作模式有7种工作模式： RabbitMQ Tutorials — RabbitMQ 2. Hello World最简单工作方式，生产者消费者模式。 123456789101112public class Producer &#123; public final static String QUEUE_NAME = &quot;hello&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Channel channel = RabbitMqUtils.getChannel(); channel.queueDeclare(QUEUE_NAME, false, false, false, null); channel.basicPublish(&quot;&quot;, QUEUE_NAME, null, &quot;hello rabbitMq&quot;.getBytes()); &#125;&#125; 消费者 123456789101112131415161718public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Channel channel = RabbitMqUtils.getChannel(); System.out.println(&quot;等待接收消息.........&quot;); //推送的消息如何进行消费的接口回调 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody()); System.out.println(message); &#125;; //取消消费的一个回调接口 如在消费的时候队列被删除掉了 CancelCallback cancelCallback = (consumerTag) -&gt; System.out.println(&quot;消息消费被中断&quot;); channel.basicConsume(Producer.QUEUE_NAME, deliverCallback, cancelCallback); &#125;&#125; 3. Work Queues 工作队列(又称任务队列)的主要思想是避免立即执行资源密集型任务，而不得不等待它完成。 相反我们安排任务在之后执行。我们把任务封装为消息并将其发送到队列。在后台运行的工作进 程将弹出任务并最终执行作业。当有多个工作线程时，这些工作线程将一起处理这些任务。 多个消费者，轮询分发消息。 4. 消息应答 消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成 了部分突然它挂掉了，会发生什么情况。RabbitMQ 一旦向消费者传递了一条消息，便立即将该消 息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续 发送给该消费这的消息，因为它无法接收到。 为了保证消息在发送过程中不丢失，rabbitmq 引入消息应答机制，消息应答就是:消费者在接收 到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。 1. 自动应答 消息发送后立即被认为已经传送成功，这种模式需要在**高吞吐量和数据传输安全性方面做权 衡,**因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失 了,当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当 然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使 得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以 某种速率能够处理这些消息的情况下使用 Channel.basicAck(用于肯定确认) RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了 、 Channel.basicNack(用于否定确认) Channel.basicReject(用于否定确认) 与 Channel.basicNack 相比少一个参数 不处理该消息了直接拒绝，可以将其丢弃了 2. 手动应答 5. RabbitMQ持久化队列持久化： 要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化。 但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新 创建一个持久化的队列，不然就会出现错误。 消息持久化： 要想让消息实现持久化需要在消息生产者修改代码MessageProperties.PERSISTENT_TEXT_PLAIN 添 加这个属性。 将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是 这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没 有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。 6. 多劳多得，不公平分发 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是 很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间 处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好。 为了避免这种情况，我们可以设置参数 channel.basicQos(1) . 消费者代码： 123456789101112131415161718192021222324252627282930public class QoSConsumer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Channel channel = RabbitMqUtils.getChannel(); channel.queueDeclare(&quot;qos_queue&quot;, false, false, false, null); // 每次消费一条数据 channel.basicQos(1); // 自动ack关闭 channel.basicConsume(&quot;qos_queue&quot;,false, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;receive a message: &quot; + new String(body)); // 手动ack channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;); &#125;&#125; 生产者： 12345678910111213public class QosProducer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Channel channel = RabbitMqUtils.getChannel(); channel.queueDeclare(&quot;qos_queue&quot;, false, false, false, null); for (int i = 0; i &lt; 20; i++) &#123; channel.basicPublish(&quot;&quot;, &quot;qos_queue&quot;, null, (&quot;message&quot; + i).getBytes()); &#125; channel.close(); &#125;&#125; 意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个 任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完 成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加 新的 worker 或者改变其他存储任务的策略。 8. 发布确认机制 生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消 息都将会被指派一个唯一的 ID(从 1 开始)，一旦消息被投递到所有匹配的队列之后，broker 就会 发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了， 如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产 者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。 confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道 返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方 法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息， 生产者应用程序同样可以在回调方法中处理该 nack 消息 单个确认机制123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.hlz.rabbit.mq.confirm;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.Channel;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * 单个确认发布缺点： 发布速度特别的慢，因为如果没有确认发布的消息就会 * 阻塞所有后续消息的发布 * * @author Hongliang Zhu * @create 2022-11-28 23:02 */public class PubModConfirmProducer &#123; public static void main(String[] args) &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; // 开启发布确认 channel.confirmSelect(); channel.queueDeclare(&quot;queue-pub-confirm&quot;, false, false, false, null); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 200; i++) &#123; String message = &quot;confirm&quot; + i; channel.basicPublish(&quot;&quot;, &quot;queue-pub-confirm&quot;, null, message.getBytes()); boolean flag = channel.waitForConfirms(); if (flag) &#123; System.out.println(&quot;消息：&quot; + message + &quot;发送成功..&quot;); &#125; &#125; long end = System.currentTimeMillis(); System.out.println(&quot;发布200个单独确认消息,耗时&quot; + (end - start) + &quot;ms&quot;); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; waitForConfirmsOrDie(long)这个方法只有在消息被确认 的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。 缺点就是: 发布速度特别的慢，因为如果没有确认发布的消息就会 阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某 些应用程序来说这可能已经足够了。 批量确认发布12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.hlz.rabbit.mq.confirm;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.Channel;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * 批量确认发布 * * @author Hongliang Zhu * @create 2022-11-28 23:02 */public class PubModConfirmBatchProducer &#123; public static void main(String[] args) &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; // 开启发布确认 channel.confirmSelect(); //批量确认消息大小 int batchSize = 100; //未确认消息个数 int outstandingMessageCount = 0; channel.queueDeclare(&quot;queue-pub-confirm&quot;, false, false, false, null); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 200; i++) &#123; String message = &quot;confirm&quot; + i; channel.basicPublish(&quot;&quot;, &quot;queue-pub-confirm&quot;, null, message.getBytes()); outstandingMessageCount++; if (outstandingMessageCount == batchSize) &#123; channel.waitForConfirms(); outstandingMessageCount = 0; &#125; channel.waitForConfirms(); &#125; //为了确保还有剩余没有确认消息 再次确认 if (outstandingMessageCount &gt; 0) &#123; channel.waitForConfirms(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot;发布 200个批量确认消息,耗时&quot; + (end - start) + &quot;ms&quot;); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 异步发布确认 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package com.hlz.rabbit.mq.confirm;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.Channel;import com.rabbitmq.client.ConfirmCallback;import java.io.IOException;import java.util.concurrent.ConcurrentNavigableMap;import java.util.concurrent.ConcurrentSkipListMap;import java.util.concurrent.TimeoutException;/** * 异步确认发布 * * @author Hongliang Zhu * @create 2022-11-28 23:02 */public class PubModConfirmAsyncProducer &#123; public static void main(String[] args) &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; // 开启发布确认 channel.confirmSelect(); /** * 线程安全有序的一个哈希表，适用于高并发的情况 * 1.轻松的将序号与消息进行关联 * 2.轻松批量删除条目 只要给到序列号 * 3.支持并发访问 */ ConcurrentSkipListMap&lt;Long, String&gt; outStandingConfirm = new ConcurrentSkipListMap&lt;&gt;(); /* 确认收到消息的一个回调 1. 消息序列号 2. true可以确认小于等于当前序列号的消息 false表示确认当前序列号 */ ConfirmCallback confirmCallback = new ConfirmCallback() &#123; @Override public void handle(long deliveryTag, boolean multiple) throws IOException &#123; if (multiple) &#123; //返回的是小于等于当前序列号的未确认消息，是一个 map ConcurrentNavigableMap&lt;Long, String&gt; confirmed = outStandingConfirm.headMap(deliveryTag, true); // 清除该部分 confirmed.clear(); &#125; else &#123; // 只清除当前序列号的消息 outStandingConfirm.remove(deliveryTag); &#125; &#125; &#125;; ConfirmCallback nackCallBack = new ConfirmCallback() &#123; @Override public void handle(long deliveryTag, boolean multiple) throws IOException &#123; String message = outStandingConfirm.get(deliveryTag); System.out.println(&quot;发布的消息&quot; + message + &quot;未被确认， 序列号为：&quot; + deliveryTag); &#125; &#125;; // 添加异步确认的监听器 channel.addConfirmListener(confirmCallback, nackCallBack); channel.queueDeclare(&quot;queue-pub-confirm&quot;, false, false, false, null); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 200; i++) &#123; String message = &quot;confirm-async&quot; + i; outStandingConfirm.put(channel.getNextPublishSeqNo(), message); channel.basicPublish(&quot;&quot;, &quot;queue-pub-confirm&quot;, null, message.getBytes()); &#125; long end = System.currentTimeMillis(); //异步发布确认的方式：发布 200个消息,耗时15ms ，性能最好！ System.out.println(&quot;异步发布确认的方式：发布 200个消息,耗时&quot; + (end - start) + &quot;ms&quot;); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 9. 交换机 RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。 生产者只能将消息发送到交换机(exchange)，交换机工作的内容非常简单，一方面它接收来 自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消 息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。 1. 交换机的类型 直接(direct), 主题(topic) ,标题(headers) , 扇出(fanout) 2. 无名交换机 空字符串表示默认或无名称交换机：消息能路由发送到队列中其实 是由 routingKey(bindingkey)绑定 key 指定的，如果它存在的话 。 3. 队列绑定bindings 什么是 bingding 呢，binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队 列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定。 队列只对它绑定的交换机的消息感兴趣。绑定用参数：routingKey 来表示，也可称该参数为 binding key， 创建绑定我们用代码:channel.queueBind(queueName, EXCHANGE_NAME, “routingKey”);绑定之后的 意义由其交换类型决定。 4. fanout Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的 所有队列中。系统中默认有些 exchange 类型。 123456789101112131415161718192021public static void main(String[] args) &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; // 定义交换机 channel.exchangeDeclare(&quot;test-fanout&quot;, BuiltinExchangeType.FANOUT); // 定义队列 channel.queueDeclare(&quot;test-fanout-queue1&quot;, false, false, false, null); channel.queueDeclare(&quot;test-fanout-queue2&quot;, false, false, false, null); // 队列绑定交换机 channel.queueBind(&quot;test-fanout-queue1&quot;, &quot;test-fanout&quot;, &quot;&quot;); channel.queueBind(&quot;test-fanout-queue2&quot;, &quot;test-fanout&quot;, &quot;&quot;); // 发送消息 RabbitMqUtils.console(channel, &quot;test-fanout&quot;, &quot;&quot;); &#125; catch (TimeoutException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 5. Direct exchange 在上面这张图中，我们可以看到 X 绑定了两个队列，绑定类型是 direct。队列Q1 绑定键为 orange， 队列 Q2 绑定键有两个:一个绑定键为 black，另一个绑定键为 green. 在这种绑定情况下，生产者发布消息到 exchange 上，绑定键为 orange 的消息会被发布到队列 Q1。绑定键为 black和green 的消息会被发布到队列 Q2，其他消息类型的消息将被丢弃。 如上图，如果 exchange 的绑定类型是direct，但是它绑定的多个队列的 key 如果都相同，在这种情 况下虽然绑定类型是 direct 但是它表现的就和 fanout 有点类似了 6. Topics 发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单 词列表，以点号分隔开。这些单词可以是任意单词，比如说：”stock.usd.nyse”, “nyse.vmw”, “quick.orange.rabbit”.这种类型的。当然这个单词列表最多不能超过 255 个字节。 *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.hlz.rabbit.mq.topic;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import java.io.IOException;import java.util.concurrent.TimeoutException;/** *(星号)可以代替一个单词 #(井号)可以替代零个或多个单词 * 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了 * 如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了 * @author Hongliang Zhu * @create 2022-11-21 20:56 */public class TopicProducer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; Channel channel = RabbitMqUtils.getChannel(); // 定义交换机 channel.exchangeDeclare(&quot;my-topic&quot;, BuiltinExchangeType.TOPIC, false); // 定义队列 channel.queueDeclare(&quot;test-queue1&quot;, false, false, false, null); channel.queueDeclare(&quot;test-queue2&quot;, false, false, false, null); channel.queueDeclare(&quot;test-queue3&quot;, false, false, false, null); // 队列绑定 channel.queueBind(&quot;test-queue1&quot;, &quot;my-topic&quot;, &quot;#.order.error&quot;); channel.queueBind(&quot;test-queue2&quot;, &quot;my-topic&quot;, &quot;#.error&quot;); channel.queueBind(&quot;test-queue3&quot;, &quot;my-topic&quot;, &quot;*.info.*&quot;); // 发送消息 channel.basicPublish(&quot;my-topic&quot;, &quot;test.order.error&quot;, null, &quot;test.order.error == &gt;order订单日志，级别为error&quot;.getBytes()); channel.basicPublish(&quot;my-topic&quot;, &quot;hi.test.order.error&quot;, null, &quot;hi.test.order.error == &gt; order订单日志，级别为error&quot;.getBytes()); channel.basicPublish(&quot;my-topic&quot;, &quot;test.info.apple&quot;, null, &quot;test.info.apple == &gt;info日志&quot;.getBytes()); channel.basicPublish(&quot;my-topic&quot;, &quot;test.error&quot;, null, &quot;test.info.apple == &gt;info日志&quot;.getBytes()); RabbitMqUtils.console(channel, &quot;my-topic&quot;, &quot;test.order.error&quot;); &#125;&#125; 当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了 如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了 10. 死信队列 死信，顾名思义就是无法被消费的消息，字面意思可以这样理 解，一般来说，producer 将消息投递到 broker 或者直接到queue 里了，consumer 从 queue 取出消息 进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有 后续的处理，就变成了死信，有死信自然就有了死信队列。 1. 应用场景 为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发生异常时，将消息投入死信队列中。还有比如说: 用户在商城下单成功并点击去支付后在指定时间未支付时自动失效。 2. 死信来源 消息 TTL 过期 队列达到最大长度(队列满了，无法再添加数据到 mq 中) 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false 3. 死信实战 生产者： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.hlz.rabbit.mq.dead;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.AMQP;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import java.io.IOException;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeoutException;/** * 死信队列生产者 * * @author Hongliang Zhu * @create 2022-11-21 22:15 */public class DeadProducer &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; try (Channel channel = RabbitMqUtils.getChannel()) &#123; channel.exchangeDeclare(&quot;normal_exchange&quot;, BuiltinExchangeType.DIRECT); // 死信交换机 channel.exchangeDeclare(&quot;dead-exchange&quot;, BuiltinExchangeType.DIRECT); // 声明死信队列 channel.queueDeclare(&quot;dead-queue&quot;, false, false, false, null); // 死信队列绑定死信交换机 channel.queueBind(&quot;dead-queue&quot;, &quot;dead-exchange&quot;, &quot;lisi&quot;); // 正常队列绑定死信队列信息 Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); // 正常队列设置死信交换机 params.put(&quot;x-dead-letter-exchange&quot;, &quot;dead-exchange&quot;); //正常队列设置死信 routing-key params.put(&quot;x-dead-letter-routing-key&quot;, &quot;lisi&quot;); // 设置队列长度限制 params.put(&quot;x-max-length&quot;, 6); // 声明正常队列 String normalQueue = &quot;normal-queue&quot;; channel.queueDeclare(normalQueue, false, false, false, params); channel.queueBind(normalQueue, &quot;normal_exchange&quot;, &quot;zhangsan&quot;); // 设置消息的ttl时间// AMQP.BasicProperties basicProperties = new AMQP.BasicProperties().builder().expiration(&quot;10000&quot;).build(); for (int i = 1; i &lt;= 10; i++) &#123; String message = &quot;info&quot; + i; channel.basicPublish(&quot;normal_exchange&quot;, &quot;zhangsan&quot;, null, message.getBytes()); System.out.println(&quot;生产者发送消息:&quot; + message); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者 12345678910111213141516171819202122232425262728293031323334353637383940package com.hlz.rabbit.mq.dead;import com.hlz.rabbit.mq.util.RabbitMqUtils;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;/** * 死信队列生产者 * * @author Hongliang Zhu * @create 2022-11-21 22:15 */public class DeadConsumer1 &#123; public static void main(String[] args) throws IOException, TimeoutException &#123; try &#123; Channel channel = RabbitMqUtils.getChannel(); channel.exchangeDeclare(&quot;dead-exchange&quot;, BuiltinExchangeType.DIRECT); System.out.println(&quot;等待接收死信队列消息........... &quot;); channel.basicConsume(&quot;dead-queue&quot;, true, new DeliverCallback() &#123; @Override public void handle(String consumerTag, Delivery message) throws IOException &#123; String data = new String(message.getBody(), &quot;UTF-8&quot;); System.out.println(data); &#125; &#125;, new CancelCallback() &#123; @Override public void handle(String consumerTag) throws IOException &#123; &#125; &#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 11. 延时队列 延时队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望 在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的 元素的队列。 1. 应用场景 订单在十分钟之内未支付则自动取消 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。 用户注册成功后，如果三天内没有登陆则进行短信提醒。 用户发起退款，如果三天内没有得到处理则通知相关运营人员。 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 。 2. TTL TTL 是什么呢？TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有 消息的最大存活时间。 Time To Live。 单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置TTL 属性的队列，那么这 条消息如果在TTL 设置的时间内没有被消费，则会成为”死信”。如果同时配置了队列的TTL 和消息的 TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。 消息设置TTL 1234rabbitTemplate.convertAndSend(&quot;X&quot;, &quot;XC&quot;, message, message1 -&gt; &#123; message1.getMessageProperties().setExpiration(ttlTime); return message1; &#125;); 队列设置TTL 12args.put(&quot;x-message-ttl&quot;, 40000); QueueBuilder.durable(Queue_B).withArguments(args).build(); 如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队 列中)，而消息设置TTL方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者 之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需 要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以 直接投递该消息到消费者，否则该消息将会被丢弃。 3. 延时队列实现https://gitee.com/hongliangzhu/mid-mq/tree/master/springboot-rabbitmq-producer/src/main/java/com/hlz/mid/mq/producer/ttl","path":"2022/12/03/消息中间件-RabbitMQ/","date":"12-03","excerpt":"","tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://castile.github.io/tags/RabbitMQ/"},{"name":"mq","slug":"mq","permalink":"https://castile.github.io/tags/mq/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://castile.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"Flink集群部署","text":"Flink集群部署Flink几个关键主件： 客户端（Client）、作业管理器（JobManager）和 任务管理器（TaskManager）。我们的代码，实际上是由客户端获取并做转换，之后提交给 JobManger 的。所以 JobManager 就是 Flink 集群里的“管事人”，对作业进行中央调度管理； 而它获取到要执行的作业后，会进一步处理转换，然后分发任务给众多的 TaskManager。这里 的 TaskManager，就是真正“干活的人”，数据的处理操作都是它们来做的。 1. 环境配置 Flink 是一个分布式的流处理框架，所以实际应用一般都需要搭建集群环境。我们在进行 Flink 安装部署的学习时，需要准备 3 台 Linux 机器 。 进入 Flink 官网，下载 1.13.0 版本安装包 flink-1.13.0-bin-scala_2.12.tgz，注意此处选用对 应 scala 版本为 scala 2.12 的安装包 https://archive.apache.org/dist/flink/flink-1.13.0/ 解压： 12345678cd /opt/mkdir flinktar -zxvf flink-1.13.0-bin-scala_2.12.tgz -C /opt/flink/flink-1.13.0/flink-1.13.0/log/flink-1.13.0/LICENSEflink-1.13.0/lib/…… Flink 是典型的 Master-Slave 架构的分布式数据处理框架，其中 Master 角色对应着 JobManager，Slave 角色则对应 TaskManager。我们对三台节点服务器的角色分配如 节点服务器 castile castile2 castile3 角色 JobManager TaskManager TaskManager 2. 集群配置 进入 conf 目录下，修改 flink-conf.yaml 文件，修改 jobmanager.rpc.address 参数为 castile，如下所示 这就指定了 castile(192.168.160.200)节点服务器为 JobManager 节点。 修改workers文件， 将另外两台节点服务器添加为本 Flink 集群的 TaskManager 节点 1234vim workers castile2castile3 这样就指定了 castile2和 castile3为 TaskManager 节点。 另外，在 flink-conf.yaml 文件中还可以对集群中的 JobManager 和 TaskManager 组件 进行优化配置，主要配置项如下 : jobmanager.memory.process.size：对 JobManager 进程可使用到的全部内存进行配置， 包括 JVM 元空间和其他开销，默认为 1600M，可以根据集群规模进行适当调整。 taskmanager.memory.process.size：对 TaskManager 进程可使用到的全部内存进行配置， 包括 JVM 元空间和其他开销，默认为 1600M，可以根据集群规模进行适当调整。 taskmanager.numberOfTaskSlots：对每个 TaskManager 能够分配的 Slot 数量进行配置， 默认为 1，可根据 TaskManager 所在的机器能够提供给 Flink 的 CPU 数量决定。所谓 Slot 就是 TaskManager 中具体运行一个任务所分配的计算资源。 parallelism.default：Flink 任务执行的默认并行度，优先级低于代码中进行的并行度配 置和任务提交时使用参数指定的并行度数量 3. 集群内容分发脚本配置修改完毕后，将Flink安装目录分发给另外两个节点服务器 12345678910111213141516171819202122232425262728293031323334353637#! /bin/bash#1 获取输入参数个数，如果没有参数，直接退出pcount=$#if [ $pcount -lt 1 ]then echo No Enough Arguement! exit;fi#2. 遍历集群所有机器for host in castile2 castile3do echo ==================== $host ==================== #3. 递归遍历所有目录 for file in $@ do #4 判断文件是否存在 if [ -e $file ] then #5. 获取全路径 pdir=$(cd -P $(dirname $file); pwd) echo pdir=$pdir #6. 获取当前文件的名称 fname=$(basename $file) echo fname=$fname #7. 通过ssh执行命令：在$host主机上递归创建文件夹（如果存在该文件夹） ssh $host &quot;source /etc/profile;mkdir -p $pdir&quot; #8. 远程同步文件至$host主机的$USER用户的$pdir文件夹下 rsync -av $pdir/$fname $USER@$host:$pdir else echo $file Does Not Exists! fi donedone 分发： 可以看到其他两个节点服务器已经收到： 4. 启动集群 （1）在 castile节点服务器上执行 start-cluster.sh 启动 Flink 集群： 12345[root@castile bin]# ./start-cluster.shStarting cluster.Starting standalonesession daemon on host castile.Starting taskexecutor daemon on host castile2.Starting taskexecutor daemon on host castile3. 查看进程情况 123456789101112131415[root@castile bin]# jps82890 StandaloneSessionClusterEntrypoint83038 Jps[root@castile2 conf]# jps3426 TaskManagerRunner3478 Jps[root@castile3 flink-1.13.0]# jps3459 TaskManagerRunner3530 Jps 5. 访问WebUI 启动成功后，同样可以访问 Apache Flink Web Dashboard 对 flink 集群和任务进行监控管理，如图 所示。 这里可以明显看到，当前集群的 TaskManager 数量为 2；由于默认每个 TaskManager 的 Slot 数量为 1，所以总 Slot 数和可用 Slot 数都为 2。 还可以查看TaskManager节点的资源情况： 至此，我们Flink的一个集群就搭建起来了，我们可以使用web界面进行作业的提交。","path":"2022/11/27/Flink集群部署/","date":"11-27","excerpt":"","tags":[{"name":"flink","slug":"flink","permalink":"https://castile.github.io/tags/flink/"}]},{"title":"docker文档","text":"Docker 官方文档地址:https://www.docker.com/get-started 中文参考手册:https://docker_practice.gitee.io/zh-cn/ 1.什么是 Docker1.1 官方定义 最新官网首页 1234# 1.官方介绍- We have a complete container solution for you - no matter who you are and where you are on your containerization journey.- 翻译: 我们为你提供了一个完整的容器解决方案,不管你是谁,不管你在哪,你都可以开始容器的的旅程。- 官方定义: docker是一个容器技术。 1.2 Docker的起源12345Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 2.为什么是Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来 这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。 优势1: 一致的运行环境,更轻松的迁移 服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了 这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。 优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源 公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器 在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。 优势3: 通过镜像复制N多个环境一致容器 3.Docker和虚拟机区别 关于Docker与虚拟机的区别，我在网上找到的一张图，非常直观形象地展示出来，话不多说，直接上图。 比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-&gt;虚拟物理内存-&gt;真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-&gt;真正物理内存。 传统虚拟机 Docker容器 磁盘占用 几个GB到几十个GB左右 几十MB到几百MB左右 CPU内存占用 虚拟操作系统非常占用CPU和内存 Docker引擎占用极低 启动速度 （从开机到运行项目）几分钟 （从开启容器到运行项目）几秒 安装管理 需要专门的运维技术 安装、管理方便 应用部署 每次部署都费时费力 从第二次部署开始轻松简捷 耦合性 多个应用服务安装到一起，容易互相影响 每个应用服务一个容器，达成隔离 系统依赖 无 需求相同或相似的内核，目前推荐是Linux 4.Docker的安装4.1 安装docker(centos7.x) 卸载原始docker 12345678$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装docker依赖 123$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置docker的yum源 123$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker 1$ sudo yum install docker-ce docker-ce-cli containerd.io 指定版本安装docker 123$ yum list docker-ce --showduplicates | sort -r$ sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io$ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 关闭docker 1$ sudo systemctl stop docker 测试docker安装 1$ sudo docker run hello-world 4.2 bash安装(通用所有平台) 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装：执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。 12$ curl -fsSL get.docker.com -o get-docker.sh$ sudo sh get-docker.sh --mirror Aliyun 启动docker 12$ sudo systemctl enable docker$ sudo systemctl start docker 创建docker用户组 1$ sudo groupadd docker 将当前用户加入docker组 1$ sudo usermod -aG docker $USER 测试docker安装是否正确 1$ docker run hello-world 5.Docker 的核心架构 镜像: 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 容器: 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 仓库:用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 dockerFile:docker生成镜像配置文件,用来书写自定义镜像的一些配置 tar:一个对镜像打包的文件,日后可以还原成镜像 6. Docker 配置阿里镜像加速服务6.1 docker 运行流程 6.2 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://lz2nib3q.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://1sbuq3iu.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 验证docker的镜像加速是否生效 1234567[root@localhost ~]# docker info .......... 127.0.0.0/8 Registry Mirrors: &#x27;https://lz2nib3q.mirror.aliyuncs.com/&#x27; Live Restore Enabled: false Product License: Community Engine 7.Docker的入门应用7.1 docker 的第一个程序 docker run hello-world 12345678910111213141516171819202122[root@localhost ~]# docker run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 8.常用命令6.1 辅助命令1234# 1.安装完成辅助命令 docker version -------------------------- 查看docker的信息 docker info -------------------------- 查看更详细的信息 docker --help -------------------------- 帮助命令 6.2 Images 镜像命令12345678910111213141516# 1.查看本机中所有镜像 docker images -------------------------- 列出本地所有镜像 -a 列出所有镜像（包含中间映像层） -q 只显示镜像id# 2.搜索镜像 docker search [options] 镜像名 ------------------- 去dockerhub上查询当前镜像 -s 指定值 列出收藏数不少于指定值的镜像 --no-trunc 显示完整的镜像信息# 3.从仓库下载镜像 docker pull 镜像名[:TAG|@DIGEST] ----------------- 下载镜像# 4.删除镜像 docker rmi 镜像名 -------------------------- 删除镜像 -f 强制删除 6.3 Contrainer 容器命令1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859# 1.运行容器 docker run 镜像名 -------------------------- 镜像名新建并启动容器 --name 别名为容器起一个名字 -d 启动守护式容器（在后台启动容器） -p 映射端口号：原始端口号 指定端口号启动 例：docker run -it --name myTomcat -p 8888:8080 tomcat docker run -d --name myTomcat -P tomcat# 2.查看运行的容器 docker ps -------------------------- 列出所有正在运行的容器 -a 正在运行的和历史运行过的容器 -q 静默模式，只显示容器编号# 3.停止|关闭|重启容器 docker start 容器名字或者容器id --------------- 开启容器 docker restart 容器名或者容器id --------------- 重启容器 docker stop 容器名或者容器id ------------------ 正常停止容器运行 docker kill 容器名或者容器id ------------------ 立即停止容器运行# 4.删除容器 docker rm -f 容器id和容器名 docker rm -f $(docker ps -aq) -------------------------- 删除所有容器# 5.查看容器内进程 docker top 容器id或者容器名 ------------------ 查看容器内的进程# 6.查看查看容器内部细节 docker inspect 容器id ------------------ 查看容器内部细节# 7.查看容器的运行日志 docker logs [OPTIONS] 容器id或容器名 ------------------ 查看容器日志 -t 加入时间戳 -f 跟随最新的日志打印 实时监听日志 --tail 数字 显示最后多少条# 8.进入容器内部 docker exec [options] 容器id 容器内命令 ------------------ 进入容器执行命令 -i 以交互模式运行容器，通常与-t一起使用 -t 分配一个伪终端 shell窗口 bash # 9.容器和宿主机之间复制文件 docker cp 文件|目录 容器id:容器路径 ----------------- 将宿主机复制到容器内部 docker cp 容器id:容器内资源路径 宿主机目录路径 ----------------- 将容器内资源拷贝到主机上# 10.数据卷(volum)实现与宿主机共享目录 docker run -v 宿主机的路径|任意别名:/容器内的路径 镜像名 注意: 1.如果是宿主机路径必须是绝对路径,宿主机目录会覆盖容器内目录内容 2.如果是别名则会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中# 11.打包镜像 docker save 镜像名 -o 名称.tar# 12.载入镜像 docker load -i 名称.tar# 13.容器打包成新的镜像 docker commit -m &quot;描述信息&quot; -a &quot;作者信息&quot; （容器id或者名称）打包的镜像名称:标签 7.docker的镜像原理7.1 镜像是什么？ 镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。 7.2 为什么一个镜像会那么大？ 镜像就是花卷 UnionFS（联合文件系统）: Union文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。 7.3 Docker镜像原理 docker的镜像实际是由一层一层的文件系统组成。 bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。 rootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。 我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。 .jpg) 7.4 为什么docker镜像要采用这种分层结构呢? 最大的一个好处就是资源共享 比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。 8.Docker安装常用服务8.1 安装mysql可以参考这个进行进一步的设置，比如设置远程连接： https://blog.csdn.net/qq_42971035/article/details/127831101 12345678910111213141516171819202122232425262728# 1.拉取mysql镜像到本地 docker pull mysql:tag (tag不加默认最新版本) # 2.运行mysql服务 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:tag --没有暴露外部端口外部不能连接 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag --没有暴露外部端口# 3.进入mysql容器 docker exec -it 容器名称|容器id bash# 4.外部查看mysql日志 docker logs 容器名称|容器id# 5.使用自定义配置参数 docker run --name mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:tag# 6.将容器数据位置与宿主机位置挂载保证数据安全 docker run --name mysql -v /root/mysql/data:/var/lib/mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag# 7.通过其他客户端访问 如在window系统|macos系统使用客户端工具访问 # 8.将mysql数据库备份为sql文件 docker exec mysql|容器id sh -c &#x27;exec mysqldump --all-databases -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#x27; &gt; /root/all-databases.sql --导出全部数据 docker exec mysql sh -c &#x27;exec mysqldump --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#x27; &gt; /root/all-databases.sql --导出指定库数据 docker exec mysql sh -c &#x27;exec mysqldump --no-data --databases 库表 -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#x27; &gt; /root/all-databases.sql --导出指定库数据不要数据# 9.执行sql文件到mysql中 docker exec -i mysql sh -c &#x27;exec mysql -uroot -p&quot;$MYSQL_ROOT_PASSWORD&quot;&#x27; &lt; /root/xxx.sql 8.2 安装Redis服务12345678910111213141516171819202122232425262728# 1.在docker hub搜索redis镜像 docker search redis# 2.拉取redis镜像到本地 docker pull redis# 3.启动redis服务运行容器 docker run --name redis -d redis:tag (没有暴露外部端口) docker run --name redis -p 6379:6379 -d redis:tag (暴露外部宿主机端口为6379进行连接) # 4.查看启动日志 docker logs -t -f 容器id|容器名称# 5.进入容器内部查看 docker exec -it 容器id|名称 bash # 6.加载外部自定义配置启动redis容器 默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 1. wget http://download.redis.io/releases/redis-5.0.8.tar.gz 下载官方安装包 2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 3. 修改需要自定义的配置 bind 0.0.0.0 开启远程权限 appenonly yes 开启aof持久化 4. 加载配置启动 docker run --name redis -v /root/redis:/usr/local/etc/redis -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf # 7.将数据目录挂在到本地保证数据安全 docker run --name redis -v /root/redis/data:/data -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 8.3 安装Nginx123456789101112131415161718192021222324252627# 1.在docker hub搜索nginx docker search nginx# 2.拉取nginx镜像到本地 [root@localhost ~]# docker pull nginx Using default tag: latest latest: Pulling from library/nginx afb6ec6fdc1c: Pull complete b90c53a0b692: Pull complete 11fa52a0fdc0: Pull complete Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest# 3.启动nginx容器 docker run -p 80:80 --name nginx01 -d nginx# 4.进入容器 docker exec -it nginx01 /bin/bash 查找目录: whereis nginx 配置文件: /etc/nginx/nginx.conf# 5.复制配置文件到宿主机 docker cp nginx01(容器id|容器名称):/etc/nginx/nginx.conf 宿主机名录# 6.挂在nginx配置以及html到宿主机外部 docker run --name nginx02 -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html -p 80:80 -d nginx 8.4 安装Tomcat123456789101112131415# 1.在docker hub搜索tomcat docker search tomcat# 2.下载tomcat镜像 docker pull tomcat# 3.运行tomcat镜像 docker run -p 8080:8080 -d --name mytomcat tomcat# 4.进入tomcat容器 docker exec -it mytomcat /bin/bash# 5.将webapps目录挂载在外部 docker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d --name mytomcat tomcat 8.5 安装MongoDB数据库12345678910111213141516171819# 1.运行mongDB docker run -d -p 27017:27017 --name mymongo mongo ---无须权限 docker logs -f mymongo --查看mongo运行日志# 2.进入mongodb容器 docker exec -it mymongo /bin/bash 直接执行mongo命令进行操作# 3.常见具有权限的容器 docker run --name mymongo -p 27017:27017 -d mongo --auth# 4.进入容器配置用户名密码 mongo use admin 选择admin库 db.createUser(&#123;user:&quot;root&quot;,pwd:&quot;root&quot;,roles:[&#123;role:&#x27;root&#x27;,db:&#x27;admin&#x27;&#125;]&#125;) //创建用户,此用户创建成功,则后续操作都需要用户认证 exit# 5.将mongoDB中数据目录映射到宿主机中 docker run -d -p 27017:27017 -v /root/mongo/data:/data/db --name mymongo mongo 8.6 安装ElasticSearch 注意:调高JVM线程数限制数量 0.拉取镜像运行elasticsearch123456# 1.dockerhub 拉取镜像 docker pull elasticsearch:6.4.2# 2.查看docker镜像 docker images# 3.运行docker镜像 docker run -p 9200:9200 -p 9300:9300 elasticsearch:6.4.2 启动出现如下错误 1. 预先配置123456789# 1.在centos虚拟机中，修改配置sysctl.conf vim /etc/sysctl.conf# 2.加入如下配置 vm.max_map_count=262144 # 3.启用配置 sysctl -p 注：这一步是为了防止启动容器时，报出如下错误： bootstrap checks failed max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 2.启动EleasticSearch容器1234# 0.复制容器中data目录到宿主机中 docker cp 容器id:/usr/share/share/elasticsearch/data /root/es# 1.运行ES容器 指定jvm内存大小并指定ik分词器位置 docker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=&quot;-Xms128m -Xmx128m&quot; -v /root/es/plugins:/usr/share/elasticsearch/plugins -v /root/es/data:/usr/share/elasticsearch/data elasticsearch:6.4.2 3.安装IK分词器123456789101112131415161718192021222324252627# 1.下载对应版本的IK分词器 wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.2/elasticsearch-analysis-ik-6.4.2.zip# 2.解压到plugins文件夹中 yum install -y unzip unzip -d ik elasticsearch-analysis-ik-6.4.2.zip# 3.添加自定义扩展词和停用词 cd plugins/elasticsearch/config vim IKAnalyzer.cfg.xml &lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext_dict.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;ext_stopwords.dic&lt;/entry&gt; &lt;/properties&gt;# 4.在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 vim ext_dict.dic 加入扩展词即可# 5. 在ik分词器目录下config目录中创建ext_stopword.dic文件 vim ext_stopwords.dic 加入停用词即可# 6.重启容器生效 docker restart 容器id# 7.将此容器提交成为一个新的镜像 docker commit -a=&quot;xiaochen&quot; -m=&quot;es with IKAnalyzer&quot; 容器id xiaochen/elasticsearch:6.4.2 4. 安装Kibana12345# 1.下载kibana镜像到本地 docker pull kibana:6.4.2# 2.启动kibana容器 docker run -d --name kibana -e ELASTICSEARCH_URL=http://10.15.0.3:9200 -p 5601:5601 kibana:6.4.2 8.7 安装rabbitmq123456789101112131415161718192021# 下载镜像docker pull rabbitmq# 创建并运行rabbotmq容器docker run -d -p 15672:15672 -p 5672:5672 \\ -e RABBITMQ_DEFAULT_VHOST=my_vhost \\ -e RABBITMQ_DEFAULT_USER=admin \\ -e RABBITMQ_DEFAULT_PASS=admin \\ --hostname myRabbit \\ --name rabbitmq \\ rabbitmq:3.8.16 -d：表示在后台运行容器；-p：将容器的端口 5672（应用访问端口）和 15672 （控制台Web端口号）映射到主机中；-e：指定环境变量：RABBITMQ_DEFAULT_VHOST：默认虚拟机名；RABBITMQ_DEFAULT_USER：默认的用户名；RABBITMQ_DEFAULT_PASS：默认的用户密码；--hostname：指定主机名（RabbitMQ 的一个重要注意事项是它根据所谓的 节点名称 存储数据，默认为主机名）；--name rabbitmq：设置容器名称；rabbitmq：容器使用的镜像名称； 启动 rabbitmq_managementdocker exec -it rabbitmq rabbitmq-plugins enable rabbitmq_management 访问ip:15672即可打开管理页面： 10.Docker中出现如下错误解决方案12[root@localhost ~]# docker search mysql 或者 docker pull 这些命令无法使用Error response from daemon: Get https://index.docker.io/v1/search?q=mysql&amp;n=25: x509: certificate has expired or is not yet valid 注意:这个错误的原因在于是系统的时间和docker hub时间不一致,需要做系统时间与网络时间同步 1234567# 1.安装时间同步 sudo yum -y install ntp ntpdate# 2.同步时间 sudo ntpdate cn.pool.ntp.org# 3.查看本机时间 date# 4.从新测试 9.Dockerfile9.1 什么是DockerfileDockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。 通过架构图可以看出通过DockerFile可以直接构建镜像 9.2 Dockerfile解析过程 9.3 Dockerfile的保留命令官方说明:https://docs.docker.com/engine/reference/builder/ 保留字 作用 FROM 当前镜像是基于哪个镜像的 第一个指令必须是FROM MAINTAINER 镜像维护者的姓名和邮箱地址 RUN 构建镜像时需要运行的指令 EXPOSE 当前容器对外暴露出的端口号 WORKDIR 指定在创建容器后，终端默认登录进来的工作目录，一个落脚点 ENV 用来在构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包 COPY 类似于ADD，拷贝文件和目录到镜像中将从构建上下文目录中&lt;原路径&gt;的文件/目录复制到新的一层的镜像内的&lt;目标路径&gt;位置 VOLUME 容器数据卷，用于数据保存和持久化工作 CMD 指定一个容器启动时要运行的命令Dockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换 ENTRYPOINT 指定一个容器启动时要运行的命令ENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数 9.3.1 FROM 命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现 语法: 123FROM &lt;image&gt;FROM &lt;image&gt;[:&lt;tag&gt;] 使用版本不写为latestFROM &lt;image&gt;[@&lt;digest&gt;] 使用摘要 9.3.2 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃] 语法: 1MAINTAINER &lt;name&gt; 9.3.3 RUN 命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步 语法: 12345RUN &lt;command&gt; (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)RUN echo helloRUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (exec form)RUN [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;] 9.3.4 EXPOSE 命令 用来指定构建的镜像在运行为容器时对外暴露的端口 语法: 12EXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcpEXPOSE 80/udp 9.3.5 CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。 语法: 123CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;] (exec form, this is the preferred form)CMD [&quot;param1&quot;,&quot;param2&quot;] (as default parameters to ENTRYPOINT)CMD command param1 param2 (shell form) 9.3.6 WORKDIR 命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。 语法: 123456WORKDIR /path/to/workdirWORKDIR /aWORKDIR bWORKDIR c`注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对` 9.3.7 ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。 语法： 12ENV &lt;key&gt; &lt;value&gt;ENV &lt;key&gt;=&lt;value&gt; ... 9.3.8 ADD 命令 用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。 语法: 12345ADD hom* /mydir/ 通配符添加多个文件ADD hom?.txt /mydir/ 通配符添加ADD test.txt relativeDir/ 可以指定相对路径ADD test.txt /absoluteDir/ 也可以指定绝对路径ADD url 9.3.9 COPY 命令 用来将context目录中指定文件复制到镜像的指定目录中 语法: 12COPY src destCOPY [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;] 9.3.10 VOLUME 命令 用来定义容器运行时可以挂在到宿主机的目录 语法: 1VOLUME [&quot;/data&quot;] 9.3.11 ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似 语法: 12 [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]ENTRYPOINT command param1 param2 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。 9.3.11 ENTRYPOINT命令9.4 Dockerfile构建springboot项目部署1.准备springboot可运行项目 2.将可运行项目放入linux虚拟机中 3.编写Dockerfile123456FROM openjdk:8WORKDIR /emsADD ems.jar /emsEXPOSE 8989ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;]CMD [&quot;ems.jar&quot;] 4.构建镜像1[root@localhost ems]# docker build -t ems . 5.运行镜像1[root@localhost ems]# docker run -p 8989:8989 ems 6.访问项目1http://10.15.0.8:8989/ems/login.html 10.高级网络配置10.1 说明当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。 同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。 当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 10.2 查看网络信息1# docker network ls 10.3 创建一个网桥1# docker network create -d bridge 网桥名称 10.4 删除一个网桥1# docker network rm 网桥名称 10.5 容器之前使用网络通信12# 1.查询当前网络配置- docker network ls 1234NETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local 12# 2.创建桥接网络- docker network create -d bridge info 12345678[root@centos ~]# docker network create -d bridge info6e4aaebff79b1df43a064e0e8fdab08f52d64ce34db78dd5184ce7aaaf550a2f[root@centos ~]# docker network lsNETWORK ID NAME DRIVER SCOPE8e424e5936b7 bridge bridge local17d974db02da docker_gwbridge bridge locald6c326e433f7 host host local6e4aaebff79b info bridge local 1234# 3.启动容器指定使用网桥- docker run -d -p 8890:80 --name nginx001 --network info nginx - docker run -d -p 8891:80 --name nginx002 --network info nginx `注意:一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通` 12345678910111213141516[root@centos ~]# docker run -d -p 8890:80 --name nginx001 --network info nginx c315bcc94e9ddaa36eb6c6f16ca51592b1ac8bf1ecfe9d8f01d892f3f10825fe[root@centos ~]# docker run -d -p 8891:80 --name nginx002 --network info nginxf8682db35dd7fb4395f90edb38df7cad71bbfaba71b6a4c6e2a3a525cb73c2a5[root@centos ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf8682db35dd7 nginx &quot;/docker-entrypoint.…&quot; 3 seconds ago Up 2 seconds 0.0.0.0:8891-&gt;80/tcp nginx002c315bcc94e9d nginx &quot;/docker-entrypoint.…&quot; 7 minutes ago Up 7 minutes 0.0.0.0:8890-&gt;80/tcp nginx001b63169d43792 mysql:5.7.19 &quot;docker-entrypoint.s…&quot; 7 minutes ago Up 7 minutes 3306/tcp mysql_mysql.1.s75qe5kkpwwttyf0wrjvd2cda[root@centos ~]# docker exec -it f8682db35dd7 /bin/bashroot@f8682db35dd7:/# curl http://nginx001&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;..... 11.高级数据卷配置11.1 说明数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性： 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 11.2 创建数据卷123[root@centos ~]# docker volume create my-volmy-vol 11.3 查看数据卷12[ro 11.4 挂载数据卷123456789101112131415[root@centos ~]# docker run -d -P --name web -v my-vol:/usr/share/nginx/html nginx[root@centos ~]# docker inspect web &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;my-vol&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/my-vol/_data&quot;, &quot;Destination&quot;: &quot;/usr/share/nginx/html&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Mode&quot;: &quot;z&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;&quot; &#125; ], 11.5 删除数据卷12docker volume rm my-vol 12.Docker Compose12.1 简介Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose 上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。 Compose 中有两个重要的概念： 服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。 Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 12.2 安装与卸载1.linux 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 123$ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose$ sudo chmod +x /usr/local/bin/docker-compose 2.macos、window Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 3.bash命令补全12$ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose &gt; /etc/bash_completion.d/docker-compose 4.卸载 如果是二进制包方式安装的，删除二进制文件即可。 12$ sudo rm /usr/local/bin/docker-compose 5.测试安装成功123$ docker-compose --version docker-compose version 1.25.5, build 4667896b 12.3 docker compose使用12# 1.相关概念 首先介绍几个术语。 服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 12# 2.场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。 springboot应用 mysql服务 redis服务 elasticsearch服务 ……. 123# 3.docker-compose模板- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html 1234567891011121314151617181920212223242526272829303132version: &quot;3.0&quot;services: mysqldb: image: mysql:5.7.19 container_name: mysql ports: - &quot;3306:3306&quot; volumes: - /root/mysql/conf:/etc/mysql/conf.d - /root/mysql/logs:/logs - /root/mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: root networks: - ems depends_on: - redis redis: image: redis:4.0.14 container_name: redis ports: - &quot;6379:6379&quot; networks: - ems volumes: - /root/redis/data:/data command: redis-server networks: ems: 123# 4.通过docker-compose运行一组容器- 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html 123[root@centos ~]# docker-compose up //前台启动一组服务[root@centos ~]# docker-compose up -d //后台启动一组服务 12.4 docker-compose 模板文件模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。 默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。 12345678910version: &quot;3&quot;services: webapp: image: examples/web ports: - &quot;80:80&quot; volumes: - &quot;/data&quot; 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。 如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。 下面分别介绍各个指令的用法。 build指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。 123456version: &#x27;3&#x27;services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。 使用 dockerfile 指令指定 Dockerfile 文件名。 使用 arg 指令指定构建镜像时的变量。 12345678910version: &#x27;3&#x27;services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command覆盖容器启动后默认执行的命令。 12command: echo &quot;hello world&quot; container_name指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。 12container_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。 depends_on解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web 123456789101112131415version: &#x27;3&#x27;services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。 env_file从文件中获取环境变量，可以为单独的文件路径或列表。 如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。 如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。 1234567env_file: .envenv_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。 123# common.env: Set development environmentPROG_ENV=development environment设置环境变量。你可以使用数组或字典两种格式。 只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。 12345678environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括 12y|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF healthcheck通过命令检查容器是否健康运行。 123456healthcheck: test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost&quot;] interval: 1m30s timeout: 10s retries: 3 image指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。 1234image: ubuntuimage: orchardup/postgresqlimage: a4bc65fd networks配置容器连接的网络。 123456789101112version: &quot;3&quot;services: some-service: networks: - some-network - other-networknetworks: some-network: other-network: ports暴露端口信息。 使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。 123456ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。 sysctls配置容器内核参数。 12345678sysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits指定容器的 ulimits 限制值。 例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。 123456ulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。 该指令中路径支持相对路径。 12345volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。 1234567891011version: &quot;3&quot;services: my_src: image: mysql:8.0 volumes: - mysql_data:/var/lib/mysqlvolumes: mysql_data: 12.5 docker-compose 常用命令1. 命令对象与格式对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。 执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。 docker-compose 命令的基本的使用格式是 12docker-compose [-f=&lt;arg&gt;...] [options] [COMMAND] [ARGS...] 2. 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 3.命令使用说明up格式为 docker-compose up [options] [SERVICE...]。 该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。 链接的服务都将会被自动启动，除非已经处于运行状态。 可以说，大部分时候都可以直接通过该命令来启动一个项目。 默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。 当通过 Ctrl-C 停止命令时，所有容器将会停止。 如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。 默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容 down 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 ps格式为 docker-compose ps [options] [SERVICE...]。 列出项目中目前的所有容器。 选项： -q 只打印容器的 ID 信息。 restart格式为 docker-compose restart [options] [SERVICE...]。 重启项目中的服务。 选项： -t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm格式为 docker-compose rm [options] [SERVICE...]。 删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。 选项： -f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 start格式为 docker-compose start [SERVICE...]。 启动已经存在的服务容器。 stop格式为 docker-compose stop [options] [SERVICE...]。 停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。 选项： -t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top查看各个服务容器内运行的进程。 unpause格式为 docker-compose unpause [SERVICE...]。 恢复处于暂停状态中的服务。 13.docker可视化工具13.1 安装Portainer官方安装说明：https://www.portainer.io/installation/ 12345678910[root@ubuntu1804 ~]#docker pull portainer/portainer[root@ubuntu1804 ~]#docker volume create portainer_dataportainer_data[root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer20db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3[root@ubuntu1804 ~]#docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES20db26b67b79 portainer/portainer &quot;/portainer&quot; 5 seconds ago Up 4 seconds 0.0.0.0:8000-&gt;8000/tcp, 0.0.0.0:9000-&gt;9000/tcp portainer 13.2 登录和使用Portainer 用浏览器访问：http://localhost:9000 常见问题1. WARNING: IPv4 forwarding is disabled. Networking will not work. 无法访问ipv4[root@castile ~]# docker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d –name mytomcat tomcat:8.0.53WARNING: IPv4 forwarding is disabled. Networking will not work.61464b009339e82adf1f81c3dbabea1c4910b037006a2d2666e28b4706f4b3a6 解决： 1234vi /etc/sysctl.conf添加net.ipv4.ip_forward=1 重启network和docker 1systemctl restart network &amp;&amp; systemctl restart docker","path":"2022/11/20/docker文档/","date":"11-20","excerpt":"","tags":[]},{"title":"VM虚拟机ping通外网check","text":"VM虚拟机ping通外网check每隔一段时间，家里的虚拟机就无法ping外网了，先做一个记录，方便后续设置： 出现此问题大概率是因为网关设置错误 保持vm8网卡中的网关、vmware网络编辑器中的NAT模式中网关、具体虚拟机中网络配置中的GATEWAY一致 附上一个配置： 123456789101112131415161718192021222324TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=staticDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=94566983-eb19-4cae-a2f1-29c4a308bc2fIPADDR=192.168.160.200NETMASK=255.255.255.0GATEWAY=192.168.160.2DNS=114.114.114.114HWADDR=00:0C:29:55:5C:E4DEVICE=ens33ONBOOT=yesIPV6_PRIVACY=noPREFIX=24DNS1=8.8.8.8","path":"2022/11/20/VM虚拟机ping通外网check/","date":"11-20","excerpt":"","tags":[{"name":"linux","slug":"linux","permalink":"https://castile.github.io/tags/linux/"}]},{"title":"blog操作步骤","text":"创建博客的操作 新建 1hexo n 文章名称 此时文章在source/_drafts/ 目录下 发布到post 1hexo p 文章名称 生成 1hexo g 部署 1hexo deploy","path":"2022/11/20/blog操作步骤/","date":"11-20","excerpt":"","tags":[{"name":"blog","slug":"blog","permalink":"https://castile.github.io/tags/blog/"}]},{"title":"建造者设计模式","text":"建造者设计模式将一个复杂对象的构建和它的表示分离，使得同样的构建过程，可以创建不同的表示 流行实践Joshua Bloch改进的建造者模式（主流方式） 下面这个实现了建造者模式的类，注意以下6点： 1，它里面的静态内部类MyCacheBuilder才是神来之笔。（主类是产品，静态内部类是工厂，工厂生产产品） 2，它的构造函数是private的（有点像单例模式，防止用户绕开工厂，自己直接建立对象） 3，它的参数，没有提供set方法（主类（产品）是只读的，绝对的线程安全） 4，它里面必须（不能为空）的参数，添加了final关键字 5，静态内部类MyCacheBuilder的set方法，不同于常规的set方法，注意它的返回值 6，静态内部类MyCacheBuilder的build方法，非常重要。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class MyCache&lt;K, V&gt; &#123; /** * 初始化容量,必须 */ private final int initialCapacity; /** * 最大数量，必须 */ private final long maximumSize; /** * 并行等级。决定segment数量的参数 */ private int concurrencyLevel = -1; /** * 最大权重 */ private long maximumWeight = -1L; /** * 写操作后失效时间 */ private long expireAfterWriteNanos = -1L; /** * 访问操作后失效时间 */ private long expireAfterAccessNanos = -1L; private MyCache(MyCacheBuilder myCacheBuilder) &#123; this.initialCapacity = myCacheBuilder.initialCapacity; this.maximumSize = myCacheBuilder.maximumSize; this.concurrencyLevel = myCacheBuilder.concurrencyLevel; this.maximumWeight = myCacheBuilder.maximumWeight; this.expireAfterWriteNanos = myCacheBuilder.expireAfterWriteNanos; this.expireAfterAccessNanos = myCacheBuilder.expireAfterAccessNanos; &#125; @Override public String toString() &#123; return &quot;MyCache&#123;&quot; + &quot;initialCapacity=&quot; + initialCapacity + &quot;, maximumSize=&quot; + maximumSize + &quot;, concurrencyLevel=&quot; + concurrencyLevel + &quot;, maximumWeight=&quot; + maximumWeight + &quot;, expireAfterWriteNanos=&quot; + expireAfterWriteNanos + &quot;, expireAfterAccessNanos=&quot; + expireAfterAccessNanos + &#x27;&#125;&#x27;; &#125; public void put(K key, V value) &#123; &#125; public V get(K key) &#123; return null; &#125; public static class MyCacheBuilder&lt;K, V&gt; &#123; /** * 初始化容量,必须 */ private final int initialCapacity; /** * 最大数量，必须 */ private final long maximumSize; private final Map&lt;String, String&gt; cacheMap = null; /** * 并行等级。决定segment数量的参数 */ private int concurrencyLevel = -1; /** * 最大权重 */ private long maximumWeight = -1L; /** * 写操作后失效时间 */ private long expireAfterWriteNanos = -1L; /** * 访问操作后失效时间 */ private long expireAfterAccessNanos = -1L; public MyCacheBuilder(int initialCapacity, long maximumSize) &#123; this.initialCapacity = initialCapacity; this.maximumSize = maximumSize; &#125; public MyCacheBuilder setConcurrencyLevel(int concurrencyLevel) &#123; this.concurrencyLevel = concurrencyLevel; return this; &#125; public MyCacheBuilder setMaximumWeight(long maximumWeight) &#123; this.maximumWeight = maximumWeight; return this; &#125; public MyCacheBuilder setExpireAfterWriteNanos(long expireAfterWriteNanos) &#123; this.expireAfterWriteNanos = expireAfterWriteNanos; return this; &#125; public MyCacheBuilder setExpireAfterAccessNanos(long expireAfterAccessNanos) &#123; this.expireAfterAccessNanos = expireAfterAccessNanos; return this; &#125; public MyCache build() &#123; return new MyCache&lt;K, V&gt;(this); &#125; &#125;&#125; 源码中的建造者模式 JDK： 查询条件： repo:^github.com/openjdk/jdk$ file:^src/java.base -file:test lang:Java file:builder.java count:all StringBuilder类 Calendar类 Spring框架中的建造者模式 ： repo:^github.com/spring-projects/spring-framework$ -file:test lang:Java file:builder.java count:all UriComponentsBuilder 致谢1.https://www.bilibili.com/read/cv17885668?spm_id_from=333.999.0.0","path":"2022/10/19/建造者设计模式/","date":"10-19","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"抽象工厂模式","text":"[toc] 抽象工厂模式和工厂方法模式相似，包含五种角色： 抽象工厂 具体工厂 抽象产品 具体产品 客户方角色 其通过抽象工厂定义的一系列的工厂方法，每个工厂方法生成一类抽象产品。 宗旨： 通过每一个具体的工厂，负责生产一系列相关或者相互依赖的产品。 概念提供一个创建一系列相关或者相互依赖对象的接口，而无需指定他们的具体类 对象工厂模式里面的产品，注意，产品有两类，抽象产品和具体产品，抽象工厂创建的都是抽象产品，具体工厂创建的都是具体产品的对象。 产品是有特点的，“一系列相关或者相互依赖的对象”，这里面包含了产品族的概念。 接口创建对象的接口，就是工厂模式的抽象工厂 具体类指的就是具体产品 基本思路N个工厂方法相加，是否等于抽象工厂 产品族出现之时，抽象工厂开工之际 产品族 VS 产品分类 N个工厂方法相加，是否等于抽象工厂一个导出模块，只支持Excel文件格式，远远不够没需要支持其他格式，比如SQL。CSV、甚至word、pdf等。 由原来的单一文件格式增加到三种、四种甚至更多的时候，如果多个工厂方法模式的相加，量变会不会引起质变？如果需求没变化的话，只是新增一种文件格式，并不会引起质的变化，只需要增加一套工厂方法模式即可。 只有产品族出现了，才需要使用更加复杂的更加强大的抽象工厂设计模式、 产品族出现之时，抽象工厂开工之际何为产品族？ 比如，我们的系统现在西药支持中国和俄罗斯两个国家的文件导出 中国： Excel文件（Excel2003， Excel2007）， SQL文件（Mysql、oracle） 俄罗斯：Excel文件（Excel2003， Excel2007）， SQL文件（Mysql、oracle） 中国就是一个产品族了。 产品族和产品分类两个概念很重要 按照上面的说法，Excel文件、SQL文件或者Word文件、PDF文件这些都属于产品分类。 一个抽象工厂模式，支持生产多个产品分类，而且产品分类下面，还可以再分类，也就是二级分类、三级分类等，比如Excel分类，可以分为Excel2003， Excel2007等 而导出的文件，如果要区分中国和俄罗斯，以及其他地区的国家，产品族就出现了。 族的本质也是分类，只是给分配换了一个名字而已，但是在抽象工厂模式里面，产品族有特殊的约定。 一个产品族，往往需要包含所有的产品分类（并不是必须的），比如俄罗斯地区的导出文件，也需要支持Excel、SQL、Word、PDF等各种文件。 一个系统，同一时刻，往往只能选择一个产品族，但是可以使用多个产品分类。比如，中国地区的商家，往往只会选择中国地区的文件导出。不会两个都需要，总之，不同产品族的产品一般不会同时使用，对于一个商家，可以选择多个产品分类，但是往往同一时刻，只需要选择一个产品族。 同一个产品族里面的产品，往往有依赖关系。同一个产品族，里面的不同的产品之间，可以有依赖性。而不同的产品族，里面的产品，则一般不会有依赖关系。比如中国地区的PDF文件格式不会依赖其他地区的文件格式，但是可以依赖中国地区其他分类的文件格式。 需求需要支持中国、俄罗斯的Excel和SQL文件格式的导出。Excel支持Excel2003和Excel2007，Sql文件支持mysql和oracle两种格式。 代码实现抽象工厂 12345public interface IFileExportFactory &#123; IExcelExport createExcelExport(FileType fileType); ISqlExport createSqlExport(FileType fileType);&#125; 具体工厂 12345678910111213141516171819202122232425262728293031public class ChinaFileExportFactory extends AbstractFileExportFactory &#123; private static final Logger LOG = LoggerFactory.getLogger(ChinaFileExportFactory.class); @Override public IExcelExport createExcelExport(FileType fileType) &#123; switch (fileType) &#123; case CHINA_EXCEL_2003: LOG.info(&quot;创建中国-excel2003文件导出对象&quot;); return new ChinaExcel2003Export(); case CHINA_EXCEL_2007: LOG.info(&quot;创建中国-excel2007文件导出对象&quot;); return new ChinaExcel2007Export(); default: &#125; return null; &#125; @Override public ISqlExport createSqlExport(FileType fileType) &#123; switch (fileType) &#123; case CHINA_MYSQL: LOG.info(&quot;创建中国-mysql文件导出对象&quot;); return new ChinaMysqlExport(); case CHINA_ORACLE: LOG.info(&quot;创建中国-oracle文件导出对象&quot;); return new ChinaOracleExport(); default: &#125; return null; &#125;&#125; 抽象产品和具体产品 123public interface IExcelExport &#123; void exportExcel(List&lt;SKU&gt; skuList);&#125; 1234567public class ChinaExcel2003Export implements IExcelExport &#123; private static final Logger LOG = LoggerFactory.getLogger(ChinaExcel2003Export.class); public void exportExcel(List&lt;SKU&gt; skuList) &#123; LOG.info(&quot;导出中国-excel2003文件&quot;); &#125;&#125; 12345public class ChinaExcel2007Export implements IExcelExport &#123; public void exportExcel(List&lt;SKU&gt; skuList) &#123; &#125;&#125; 12345public class RussiaExcel2003Export implements IExcelExport &#123; public void exportExcel(List&lt;SKU&gt; skuList) &#123; &#125;&#125; 1234public class RussiaExcel2007Export implements IExcelExport &#123; public void exportExcel(List&lt;SKU&gt; skuList) &#123; &#125;&#125; 客户方12345678910111213public class FileExportService &#123; private static final Logger LOG = LoggerFactory.getLogger(FileExportService.class); public void exportFile(List&lt;SKU&gt; skuList) &#123; LOG.info(&quot;文件导出服务&quot;); IFileExportFactory fileExportFactory = new ChinaFileExportFactory(); IExcelExport excelExport = fileExportFactory.createExcelExport(FileType.CHINA_EXCEL_2003); ISqlExport sqlExport = fileExportFactory.createSqlExport(FileType.CHINA_MYSQL); excelExport.exportExcel(skuList); sqlExport.exportSql(skuList); &#125;&#125; 抽象工厂模式如何扩展需求增加：文件格式增加PDF格式，国家增加对法国的支持 分析： 新增pdf文件格式，增加产品分类，需要进行以下操作： 增加pdf相关的抽象产品和具体产品，注意，具体产品的个数，一般等于产品族的数量。因为要支持中国、俄罗斯、法国 的pdf文件的导出，所以需要3个pdf的具体产品。 工厂方法里面需要增加响应的工厂方法，每一个工厂方法生产一类产品 以新增法国为例，增加产品族，需要增加以下操作 所有的产品分类，都需要增加对新的产品族的支持 增加产品族对应的具体工厂 看起来扩展一下还是比较复杂的。。。 使用场景（Scene）什么情况下使用抽象工厂模式？ 当一个系统中，需要创建的对象或者产品有多个类别，而且也有产品族出现时，就可以使用抽象工厂模式 开源代码搜索工厂模式的应用地址： https://sourcegraph.com/search 1repo:^github\\.com/spring-projects/spring-framework$ file:^spring-beans/src/main/java/org/springframework/beans/factory/BeanFactory\\.java doubble框架里面使用了非常经典的工厂方法模式+ 模板模式的案例","path":"2022/10/18/抽象工厂模式/","date":"10-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"工厂方法模式","text":"工厂方法模式定义一个用于创建对象的接口，让子类决定实例化哪个类，Factory Method 使一个类的实例化延迟到其子类。 工厂方法模式包含五种角色 抽象工厂 具体工厂 抽象产品 具体产品 客户方角色 宗旨： 在抽象工厂的接口和抽象类李面定义工厂方法，创建抽象产品。而将创建具体产品的操作延迟在具体的工厂和工厂方法中 目的： 解除框架在创建对象时，对具体类的依赖，实现两者的解耦。 和简单工厂模式的区别简单工厂模式决定创建的对象是根据工厂类中的静态工厂方法的入参来决定的，而工厂方法模式决定创建具体的对象是由具体的工厂类，也就是抽象工厂的子类来确定的。 接口这里的接口是用于创建对象的，往往会创建相应的抽象了，这里统称为抽象工厂。 子类指的是抽象工厂的子类，子类的任务时实现工厂接口中定义的工厂方法。抽象工厂的子类称之为工厂模式里面的具体工厂。 类让子类决定实例化哪个类，这个类指的就是具体的产品，返回的是一个真正的类 工厂方法模式示例代码12345678910111213141516171819202122232425public class FileExportService &#123; private static final Logger LOG = LoggerFactory.getLogger(FileExportService.class); public void exportExcel(List&lt;SKU&gt; skuList, FileType fileType) &#123; LOG.info(&quot;文件导出服务&quot;); IExcelExportFactory excelExportFactory = null; IExcelExport excelExport = null; switch (fileType) &#123; case EXCEL_2003: excelExportFactory = new Excel2003ExportFactory(); break; case EXCEL_2007: excelExportFactory = new Excel2007ExportFactory(); break; &#125; if (null != excelExportFactory) &#123; excelExport = excelExportFactory.createExcelExport(); excelExport.exportExcel(skuList); &#125; else &#123; LOG.info(&quot;不支持的文件类型&quot;); &#125; &#125;&#125; 类图： 这段代码和下面的代码是否类似？ 12345678910111213141516171819202122public class FileExportService &#123; private static final Logger LOG = LoggerFactory.getLogger(FileExportService.class); public void exportFile(List&lt;SKU&gt; skuList,FileType fileType)&#123; IExcelExport excelExport=null; switch (fileType)&#123; case EXCEL_2003: LOG.info(&quot;文件导出服务:excel2003&quot;); excelExport=new Excel2003Export(); break; case EXCEL_2007: LOG.info(&quot;文件导出服务:excel2007&quot;); excelExport=new Excel2003Export(); break; &#125; if(null !=excelExport)&#123; excelExport.exportExcel(skuList); &#125;else&#123; LOG.info(&quot;不支持的文件类型&quot;); &#125; &#125;&#125; Excel2003Export/Excel2003Export都是具体的产品了，上面的工厂方法模式实际上是创建了具体的工厂。两者逻辑以相似，但是灵魂却相似、 客户方角色使用Service服务，创建工厂比创建具体某个产品简单许多，因为具体的产品往往比较复杂，依赖较多，考虑的东西比较多，这里工厂方法模式将创建具体的产品的细节延迟到具体的工厂方法里面了。 工厂方法模式的另一种“形态”工厂方法模式常常和模板方法模式联合使用。抽象产品+抽象工厂 = 框架 规则： 抽象工厂里面定义的工厂方法里面去定义规则 流程：在抽象工厂的抽象类中定义模板方法 规则和流程定义得好不好，符不符合业务需求，扩展性强不强，就是体现架构师功力的地方。 何为架构师： 当你开始定义规则，当你开始关注接口和抽象类，当你开发的代码是给其他程序员提供支持和服务的时候，你就踏上了架构师之路！ 抽象工厂1234567891011121314151617181920212223242526272829303132333435363738394041424344public interface IExcelExportFactory &#123; /** * 工厂方法 * * @return */ IExcelFile createExcel(); /** * 工厂方法 * * @return */ IFileTitleRow createFileTitleRow(); /** * 工厂方法 * * @return */ ITableTitleRow createTableTitleRow(); /** * 工厂方法 * * @return */ IDataRow createDataRow(); /** * 工厂方法 * * @return */ ITotalRow createTotalRow(); /** * 模板方法模式：模板方法 * * @param skuList */ void exportExcel(List&lt;SKU&gt; skuList);&#125; 抽象类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public abstract class AbstractExcelExportFactory implements IExcelExportFactory &#123; private static final Logger LOG = LoggerFactory.getLogger(AbstractExcelExportFactory.class); /* *Excel文件 */ protected IExcelFile excelFile = null; /** * 模板方法模式：个性化方法，同时也是钩子方法 */ @Override public IFileTitleRow createFileTitleRow() &#123; //可以提供一个默认实现,创建文件标题行对象，并添加到excel文件中。。。 LOG.info(&quot;抽象工厂:创建文件标题行对象&quot;); return null; &#125; /** * 模板方法模式：个性化方法，同时也是钩子方法。 */ @Override public IExcelFile createExcel() &#123; //可以提供一个默认实现,比如创建一个excel2003对应的workbook。 LOG.info(&quot;抽象工厂:创建Excel文件对象，默认为2003版本&quot;); return new IExcelFile() &#123; @Override public void addFileTitleRow(IFileTitleRow fileTitleRow) &#123; &#125; @Override public void addTableTitleRow(ITableTitleRow tableTitleRow) &#123; &#125; @Override public void addDataRow(IDataRow dataRow) &#123; &#125; @Override public void addTotalRow(ITotalRow totalRow) &#123; &#125; &#125;; &#125; /** * 模板方法模式：模板方法 * * @param skuList */ @Override public final void exportExcel(List&lt;SKU&gt; skuList) &#123; LOG.info(&quot;抽象工厂-模板方法:导出Excel文件&quot;); excelFile = createExcel(); IFileTitleRow fileTitleRow = createFileTitleRow(); ITableTitleRow tableTitleRow = createTableTitleRow(); IDataRow dataRow = createDataRow(); ITotalRow totalRow = createTotalRow(); excelFile.addFileTitleRow(fileTitleRow); excelFile.addTableTitleRow(tableTitleRow); excelFile.addDataRow(dataRow); excelFile.addTotalRow(totalRow); &#125;&#125; 其中，客户方角色相当于此模板方法，使用了抽象工厂的工厂方法去创建对象。","path":"2022/10/18/工厂方法模式/","date":"10-18","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"简单工厂模式","text":"简单工厂模式 简单工厂（Simple factory）理解： According to definition from wikipedia, Factory Pattern is “A factory is an object for creating other objects”. Simple Factory Pattern is a Factory class in its simplest form (In comparison to Factory Method Pattern or Abstract Factory Pattern). In another way, we can say: In simple factory pattern, we have a factory class which has a method that returns different types of object based on given input. 有一个工厂类，根据不同的输入返回不同的对象。 123456789101112131415public class SimpleFactory &#123; private static final Logger LOG = LoggerFactory.getLogger(SimpleFactory.class); public static IExcelExport createExcelExport(FileType fileType)&#123; LOG.info(&quot;简单工厂&quot;); IExcelExport excelExport=null; switch (fileType)&#123; case EXCEL_2003: excelExport=new Excel2003Export(); break; case EXCEL_2007: excelExport=new Excel2007Export(); &#125; return excelExport; &#125; 三个关键词：方法、入参、返回值 方法负责创建对象的方法，可以叫做工厂方法 在加简单工厂模式中，为了简单，往往将这个方法定义成static，方便使用 一个工厂类中可以包含多个这样的方法，建议一个模块使用一个工厂类即可。 入参根据这个入参决定创建哪种类型的对象 入参的一般是常量或者枚举，便于方法里面的seich语句或者其他分支的语句进行判断 也有人喜欢直接传递一个Class类（需要实例化的对象），但是不推荐，因为违反了工厂模式的宗旨。 返回值工厂方法创建的是一类对象，所以返回值类型常常是一个接口，也可以是抽象的父类，而不会是一个具体的类。 痛点不符合开闭原则，同样的，如果需要增加一个，需要修改工厂类的代码","path":"2022/10/17/简单工厂模式/","date":"10-17","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"SSL/TLS协议","text":"非对称加密图片来源于： https://www.bilibili.com/video/BV1KY411x7Jp/?spm_id_from=333.788&amp;vd_source=4542f58f83b32442d5604ba46f2aa229 图解： 交换后：同样会被中间人知道交换了什么颜色 蓝色的私钥+对方的（私+公）= 咖啡色 红色的私钥+ 蓝色的（私+公） = 咖啡色 这个“咖啡色”就是他们之间的密钥了，重点是，这个“咖啡色”只能由他们自己私有的颜色才可以调制而成，其他人是无法得知的，包括这个中间人。 这便是非对称加密的核心所在，使用两个密钥来进行加密和解密。 公开密钥是所有人都拥有的，而私有密钥只有持有方才有的秘钥。 一般来说，私钥是放在服务器中，数据经过公钥加密就只能使用私钥解密，数据使用私钥加密就只能使用公钥解密。 服务端具有成对的秘钥，把自己的公钥公开出去，客户端使用公钥加密，就只能使用服务端的私有进行解密。 证书 证书里面包含的内容：域名、所属公司、时间日期、特定的公钥和私钥等 服务器安装了SSL证书后，客户端才可以使用https来访问服务器了，并将默认的80端口改为443端口。 TLS握手过程 客户端访问服务端 服务端响应客户端 服务器接着向客户端发送自己的证书，客户端可以根据自己的证书新人列表来确认这个服务器是否是可信的。 服务器把自己的公钥发送给了客户端，这里不会傻傻地把自己的私钥发送出去 如果是双向SSL通信的话， 告诉客户端自己发送完毕，Server Hello Done 以上步骤的通讯还没有加密，接下来客户端将进行响应了。 Client Key Exchange，客户端生成第三个随机数，称之为“预主密钥”。 第三个随机数会使用刚刚收到的公钥进行加密，并发送给服务器。 告诉服务器往后的数据就用商议好的算法和密钥来加密了 8 服务器这边的TLS握手已经成功 握手总结： 前面握手的部分使用的是非对称加密，后面得到会话密钥后就使用对称加密来通信了。 致谢 https://www.bilibili.com/video/BV1KY411x7Jp/?spm_id_from=333.788&amp;vd_source=4542f58f83b32442d5604ba46f2aa229","path":"2022/09/25/https/","date":"09-25","excerpt":"","tags":[{"name":"ssl","slug":"ssl","permalink":"https://castile.github.io/tags/ssl/"},{"name":"网络","slug":"网络","permalink":"https://castile.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"https","slug":"https","permalink":"https://castile.github.io/tags/https/"}]},{"title":"重构技巧（一）","text":"OO三要素封装、继承、多态 为什么要有public、private、protected修饰符？ 降低依赖。public公开，所有的成员都能使用，就增加了依赖，耦合 迪米特法则 A是当前设计的类，B是A要调用的类，称之为A的好朋友。什么类才会成为A的好朋友？ 字段、B作为A方法的一个参数、A负责创建了B C是B的朋友，对于A来说，C是朋友的朋友，并不是自己的朋友，相当于陌生人，故，迪米特法则也叫“不要和陌生人说话”。 12345678910111213package zhuhongliang.refactoring.demeter;public class Paperboy &#123; public void charge(Customer myCustomer, float payment) &#123; Wallet theWallet = myCustomer.getWallet(); if (theWallet.getTotalMoney() &gt; payment) &#123; theWallet.subtractMoney(payment); &#125; else &#123; //money not enough &#125; &#125;&#125; PaperBoy :超时收银员，charge收钱方法，需要接受顾客Customer参数传进来。 1234567891011121314151617package zhuhongliang.refactoring.demeter;public class Customer &#123; private String firstName; private String lastName; private Wallet myWallet; public String getFirstName()&#123; return firstName; &#125; public String getLastName()&#123; return lastName; &#125; public Wallet getWallet()&#123; return myWallet; &#125;&#125; 面向对象 拟人化，将每一个对象看做一个具有独立思考能力的人！ get、set 信息专家模式 下面是原来的代码： 123456789101112131415161718192021222324252627282930313233343536373839public class ParameterController &#123; public void fillParameters(HttpServletRequest request, ParameterGraph parameterGraph) &#123; for (Parameter para : parameterGraph.getParameters()) &#123; if (para instanceof SimpleParameter) &#123; SimpleParameter simplePara = (SimpleParameter) para; String[] values = request.getParameterValues(simplePara.getName()); simplePara.setValue(values); &#125; else &#123; if (para instanceof ItemParameter) &#123; ItemParameter itemPara = (ItemParameter) para; for (Item item : itemPara.getItems()) &#123; String[] values = request.getParameterValues(item.getName()); item.setValues(values); &#125; &#125; else &#123; TableParameter tablePara = (TableParameter) para; String[] rows = request.getParameterValues(tablePara.getRowName()); String[] columns = request.getParameterValues(tablePara.getColumnName()); String[] dataCells = request.getParameterValues(tablePara.getDataCellName()); int columnSize = columns.length; for (int i = 0; i &lt; rows.length; i++) &#123; for (int j = 0; j &lt; columns.length; j++) &#123; TableParameterElement element = new TableParameterElement(); element.setRow(rows[i]); element.setColumn(columns[j]); element.setDataCell(dataCells[columnSize * i + j]); tablePara.addElement(element); &#125; &#125; &#125; &#125; &#125; &#125;&#125; 问题 大量的if else ，看到if else就要敏感起来。 嵌套层次太多了，看看后面多少个大括号。 instanceof在静态语言中的使用可能会影响多态带来的好处。 信息专家模式： 让操作这些数据的行为分配给拥有这些数据的对象。 重构： 提取方法所以进行重构：Ctrl+Alt+M 12345678910111213141516171819202122232425262728293031323334private void fill(HttpServletRequest request, TableParameter para) &#123; TableParameter tablePara = para; String[] rows = request.getParameterValues(tablePara.getRowName()); String[] columns = request.getParameterValues(tablePara.getColumnName()); String[] dataCells = request.getParameterValues(tablePara.getDataCellName()); int columnSize = columns.length; for (int i = 0; i &lt; rows.length; i++) &#123; for (int j = 0; j &lt; columns.length; j++) &#123; TableParameterElement element = new TableParameterElement(); element.setRow(rows[i]); element.setColumn(columns[j]); element.setDataCell(dataCells[columnSize * i + j]); tablePara.addElement(element); &#125; &#125;&#125;private void fill(HttpServletRequest request, ItemParameter para) &#123; ItemParameter itemPara = para; for (Item item : itemPara.getItems()) &#123; String[] values = request.getParameterValues(item.getName()); item.setValues(values); &#125;&#125;private void fill(HttpServletRequest request, SimpleParameter para) &#123; SimpleParameter simplePara = para; String[] values = request.getParameterValues(simplePara.getName()); simplePara.setValue(values);&#125; 重构： 方法移动上面封装了是哪个函数，可以看到这些函数的参数是各自的Parameter（ItemParameter、SimpleParameter、TableParameter），所以需要移动这些方法到各自的类中，而不需要在当前ParameterController这个类里面。 移动方法的快捷键为： F6 然后方法名也需要做一定的修改：这个函数的意思是将request里面的value填充到parameter中，所以 应该是 parameter fill with request这样的语序。 修改完的代码如下： 12345678910111213141516public class ParameterController &#123; public void fillParameters(HttpServletRequest request, ParameterGraph parameterGraph) &#123; for (Parameter para : parameterGraph.getParameters()) &#123; if (para instanceof SimpleParameter) &#123; ((SimpleParameter) para).fillWith(request); &#125; else &#123; if (para instanceof ItemParameter) &#123; ((ItemParameter) para).fillWIth(request); &#125; else &#123; ((TableParameter) para).fillWith(request); &#125; &#125; &#125; &#125; 重构： Pull Members Up 抽象接口这个代码还有问题，可以看到这个三个Parameter类都有fillWith方法，他们都继承了Parameter接口，所以，可以将他们共有的方法抽象出来。放到接口这里。这里继续重构：Pull menbers Up 123456789package zhuhongliang.refactoring.report.engine;import javax.servlet.http.HttpServletRequest;public interface Parameter &#123; String getName(); void fillWith(HttpServletRequest request);&#125; 在接口这里定义了一个抽象方法。 然后可以看到这三个地方都变灰色了，这是无效的类型转换 重构： 用多态替换分支Replace Switch by Polymorphism这是上述这写操作的目的 可以发现代码一样，就不需要这么多if else了。。。 最终代码： 1234567public class ParameterController &#123; public void fillParameters(HttpServletRequest request, ParameterGraph parameterGraph) &#123; for (Parameter para : parameterGraph.getParameters()) &#123; para.fillWith(request); &#125; &#125;&#125; 这样就很简洁了，而且多态的优势也体现出来了。 特性依恋 特性依恋（嫉妒）就是原本不属于它的东西抢过来了，这是坏味道，需要重构。 回顾迪米特法则我们再看看现在的代码： 1234567public class ParameterController &#123; public void fillParameters(HttpServletRequest request, ParameterGraph parameterGraph) &#123; for (Parameter para : parameterGraph.getParameters()) &#123; para.fillWith(request); &#125; &#125;&#125; 对于当前类：ParameterController， HttpServletRequest和ParameterGraph是他的朋友，但是Parameter属于ParameterGraph的朋友，那么，Parameter是当前类ParameterController朋友的朋友，破坏了迪米特法则，可以继续重构：for循环的代码不属于当前类的职责，应该是ParameterGraph的职责。 1234567891011public class ParameterGraph &#123; public List&lt;Parameter&gt; getParameters() &#123; return null; &#125; public void fillWith(HttpServletRequest request) &#123; for (Parameter para : getParameters()) &#123; para.fillWith(request); &#125; &#125;&#125; 1234567public class ParameterController &#123; public void fillParameters(HttpServletRequest request, ParameterGraph parameterGraph) &#123; parameterGraph.fillWith(request); &#125;&#125; 继承 两个核心原则： 面向接口设计 组合/聚合有限复用原则 差异式编程，无差异，无继承。 重构案例： JDBC数据库访问框架PartDB的案例体现了关注点分离原则。重构后的代码遵循单一抽象层次原则（SLAP），即方法中的所有操作应该处于同一个抽象层次。例如如下概念就不在同一个抽象的层次上： 苹果、香蕉、土豆、蔬菜、水果、大白菜。 很明显，苹果和香蕉都是属于水果，水果属于上一层的； 同理，土豆和大白菜都属于蔬菜。 123456789101112131415161718192021222324252627public class PartDB &#123; private static final String DRIVER_CLASS = &quot;&quot;; private static final String DB_URL = &quot;&quot;; private static final String USER = &quot;&quot;; private static final String PASSWORD = &quot;&quot;; private static final String SQL_SELECT_PARTS = &quot;select * from part&quot;; private List&lt;Part&gt; partList = new ArrayList&lt;Part&gt;(); public void populate() throws Exception &#123; Connection c = null; try &#123; Class.forName(DRIVER_CLASS); c = DriverManager.getConnection(DB_URL, USER, PASSWORD); Statement stmt = c.createStatement(); ResultSet rs = stmt.executeQuery(SQL_SELECT_PARTS); while (rs.next()) &#123; Part p = new Part(); p.setName(rs.getString(&quot;name&quot;)); p.setBrand(rs.getString(&quot;brand&quot;)); p.setRetailPrice(rs.getDouble(&quot;retail_price&quot;)); partList.add(p); &#125; &#125; finally &#123; c.close(); &#125; &#125; 违背了关注点分离原则，技术上的关注点和业务上的关注点。 上下分离，上就是泛化，下就是特定，可以使用继承。把通用的东西往上提，把特定的东西往下走。左右分离也是另一种关注点分离。 下面对上述代码进行重构： 重构：对代码进行按照职责分离，抽取方法 上述三个职责，可以单独提取方法出来。 12345678910111213141516171819202122232425262728293031323334353637public class PartDB &#123; private static final String DRIVER_CLASS = &quot;&quot;; private static final String DB_URL = &quot;&quot;; private static final String USER = &quot;&quot;; private static final String PASSWORD = &quot;&quot;; private List&lt;Part&gt; partList = new ArrayList&lt;Part&gt;(); public void populate() throws Exception &#123; try (Connection connection = getConnection()) &#123; ResultSet rs = executeQuery(connection); PopulateEntities(rs); &#125; &#125; private void PopulateEntities(ResultSet rs) throws SQLException &#123; while (rs.next()) &#123; Part p = new Part(); p.setName(rs.getString(&quot;name&quot;)); p.setBrand(rs.getString(&quot;brand&quot;)); p.setRetailPrice(rs.getDouble(&quot;retail_price&quot;)); partList.add(p); &#125; &#125; private ResultSet executeQuery(Connection connection) throws SQLException &#123; Statement stmt = connection.createStatement(); return stmt.executeQuery(getSql()); &#125; private String getSql() &#123; return &quot;select * from part&quot;; &#125; private Connection executeQuery() throws Exception &#123; Class.forName(DRIVER_CLASS); return DriverManager.getConnection(DB_URL, USER, PASSWORD); &#125;&#125; 每一个方法都是在做一件相对内聚的事情。将具体的操作抽象出来，对于当前类，了解得越少越好。所谓抽象，就是关注what to do？ 比如getConnection()就主要是获取连接，但是怎么获取的我不需要知道，隐藏了细节。 populate()方法就比较简洁。 重构： 继承，通用的往上提我们再看这三个方法（popu：late() 、executeQuery、executeQuery），这是哪个方法无论是抽象层次还是实现层次都跟业务无关，都是通用的代码。唯一跟业务有关的就是sql语句和PopulateEntities方法。 快捷键： Ctrl+Shift+Alt+T –&gt; Extract super CLass DataBase 单独抽取一个父类出来： 123456789101112131415161718192021222324252627282930313233343536package zhuhongliang.cleancode.composemethods;import java.sql.*;/** * @author Hongliang Zhu * @create 2021-07-30 23:11 */public abstract class DataBase &#123; private static final String DRIVER_CLASS = &quot;&quot;; private static final String DB_URL = &quot;&quot;; private static final String USER = &quot;&quot;; private static final String PASSWORD = &quot;&quot;; public void populate() throws Exception &#123; try (Connection connection = getConnection()) &#123; ResultSet rs = executeQuery(connection); PopulateEntities(rs); &#125; &#125; protected abstract void PopulateEntities(ResultSet rs) throws SQLException; private ResultSet executeQuery(Connection connection) throws SQLException &#123; Statement stmt = connection.createStatement(); return stmt.executeQuery(getSql()); &#125; protected abstract String getSql(); private Connection getConnection() throws Exception &#123; Class.forName(DRIVER_CLASS); return DriverManager.getConnection(DB_URL, USER, PASSWORD); &#125;&#125; 重构案例 电子商务订单处理案例电子商务订单处理案例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package zhuhongliang.cleancode.slap.service;import zhuhongliang.cleancode.slap.entity.Customer;import zhuhongliang.cleancode.slap.entity.Training;import zhuhongliang.cleancode.slap.infrastructure.DatabasePool;import java.sql.*;import java.util.List;public class TrainingService &#123; private DatabasePool dbPool; public void subscribe(List&lt;Training&gt; trainings, Customer customer) throws SQLException &#123; Connection c = null; PreparedStatement ps = null; Statement s = null; ResultSet rs = null; boolean transactionState = false; try &#123; s = c.createStatement(); transactionState = c.getAutoCommit(); c.setAutoCommit(false); for (Training training : trainings) &#123; addTrainingItem(customer, training); &#125; addOrder(customer, trainings); c.commit(); &#125; catch (SQLException sqlx) &#123; c.rollback(); throw sqlx; &#125; finally &#123; try &#123; c.setAutoCommit(transactionState); dbPool.release(c); if (s != null) s.close(); if (ps != null) ps.close(); if (rs != null) rs.close(); &#125; catch (SQLException ignored) &#123; &#125; &#125; &#125; private void addOrder(Customer customer, List&lt;Training&gt; trainings) &#123; &#125; private void addTrainingItem(Customer customer, Training training) &#123; &#125;&#125;","path":"2021/10/14/cleancode2/","date":"10-14","excerpt":"","tags":[{"name":"refactory","slug":"refactory","permalink":"https://castile.github.io/tags/refactory/"}]},{"title":"Netty 入门","text":"二. Netty 入门1. 概述1.1 Netty 是什么？12Netty is an asynchronous event-driven network application frameworkfor rapid development of maintainable high performance protocol servers &amp; clients. Netty 是一个异步的、基于事件驱动的网络应用框架，用于快速开发可维护、高性能的网络服务器和客户端 1.2 Netty 的作者 他还是另一个著名网络应用框架 Mina 的重要贡献者 1.3 Netty 的地位Netty 在 Java 网络应用框架中的地位就好比：Spring 框架在 JavaEE 开发中的地位 以下的框架都使用了 Netty，因为它们有网络通信需求！ Cassandra - nosql 数据库 Spark - 大数据分布式计算框架 Hadoop - 大数据分布式存储框架 RocketMQ - ali 开源的消息队列 ElasticSearch - 搜索引擎 gRPC - rpc 框架 Dubbo - rpc 框架 Spring 5.x - flux api 完全抛弃了 tomcat ，使用 netty 作为服务器端 Zookeeper - 分布式协调框架 1.4 Netty 的优势 Netty vs NIO，工作量大，bug 多 需要自己构建协议 解决 TCP 传输问题，如粘包、半包 epoll 空轮询导致 CPU 100% 对 API 进行增强，使之更易用，如 FastThreadLocal =&gt; ThreadLocal，ByteBuf =&gt; ByteBuffer Netty vs 其它网络应用框架 Mina 由 apache 维护，将来 3.x 版本可能会有较大重构，破坏 API 向下兼容性，Netty 的开发迭代更迅速，API 更简洁、文档更优秀 久经考验，16年，Netty 版本 2.x 2004 3.x 2008 4.x 2013 5.x 已废弃（没有明显的性能提升，维护成本高） 2. Hello World2.1 目标开发一个简单的服务器端和客户端 客户端向服务器端发送 hello, world 服务器仅接收，不返回 加入依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.39.Final&lt;/version&gt;&lt;/dependency&gt; 2.2 服务器端1234567891011121314151617// 启动器， 负责组装 netty组件，启动服务器new ServerBootstrap() .group(new NioEventLoopGroup()) // 1 .channel(NioServerSocketChannel.class) // 2 .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; // 3 protected void initChannel(NioSocketChannel ch) &#123; ch.pipeline().addLast(new StringDecoder()); // 5 ch.pipeline().addLast(new SimpleChannelInboundHandler&lt;String&gt;() &#123; // 6 @Override protected void channelRead(ChannelHandlerContext ctx, String msg) &#123; // 打印上一步处理好的字符串 System.out.println(msg); &#125; &#125;); &#125; &#125;) .bind(8080); // 4 代码解读 1 处，创建 NioEventLoopGroup，可以简单理解为 线程池 + Selector 后面会详细展开 2 处，选择服务 Scoket 实现类，其中 NioServerSocketChannel 表示基于 NIO 的服务器端实现，其它实现还有 3 处，为啥方法叫 childHandler，是接下来添加的处理器都是给 SocketChannel 用的，而不是给 ServerSocketChannel。ChannelInitializer 处理器（仅执行一次），它的作用是待客户端 SocketChannel 建立连接后，执行 initChannel 以便添加更多的处理器. 4 处，ServerSocketChannel 绑定的监听端口 5 处，SocketChannel 的处理器，解码 ByteBuf =&gt; String 6 处，SocketChannel 的业务处理器，使用上一个处理器的处理结果 2.3 客户端12345678910111213new Bootstrap() .group(new NioEventLoopGroup()) // 1 .channel(NioSocketChannel.class) // 2 .handler(new ChannelInitializer&lt;Channel&gt;() &#123; // 3 @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); // 8 &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080) // 4 .sync() // 5 .channel() // 6 .writeAndFlush(new Date() + &quot;: hello world!&quot;); // 7 代码解读 1 处，创建 NioEventLoopGroup，同 Server 2 处，选择客户 Socket 实现类，NioSocketChannel 表示基于 NIO 的客户端实现，其它实现还有 3 处，添加 SocketChannel 的处理器，ChannelInitializer 处理器（仅执行一次），它的作用是待客户端 SocketChannel 建立连接后，执行 initChannel 以便添加更多的处理器 4 处，指定要连接的服务器和端口 5 处，Netty 中很多方法都是异步的，如 connect，这时需要使用 sync 方法等待 connect 建立连接完毕 6 处，获取 channel 对象，它即为通道抽象，可以进行数据读写操作 7 处，写入消息并清空缓冲区 8 处，消息会经过通道 handler 处理，这里是将 String =&gt; ByteBuf 发出 数据经过网络传输，到达服务器端，服务器端 5 和 6 处的 handler 先后被触发，走完一个流程 2.4 流程梳理 💡 提示 一开始需要树立正确的观念 把 channel 理解为数据的通道 把 msg 理解为流动的数据，最开始输入是 ByteBuf，但经过 pipeline 的加工，会变成其它类型对象，最后输出又变成 ByteBuf 把 handler 理解为数据的处理工序 工序有多道，合在一起就是 pipeline，pipeline 负责发布事件（读、读取完成…）传播给每个 handler， handler 对自己感兴趣的事件进行处理（重写了相应事件处理方法） handler 分 Inbound 和 Outbound 两类 Inbound 入站 ，数据输入的时候处理 Outbound 出站， 数据向客户端写出的时候处理 把 eventLoop 理解为处理数据的工人 工人可以管理多个 channel 的 io 操作，并且一旦工人负责了某个 channel，就要负责到底（绑定） 工人既可以执行 io 操作，也可以进行任务处理，每位工人有任务队列，队列里可以堆放多个 channel 的待处理任务，任务分为普通任务、定时任务 工人按照 pipeline 顺序，依次按照 handler 的规划（代码）处理数据，可以为每道工序指定不同的工人 3. 组件3.1 EventLoop事件循环对象 EventLoop 本质是一个单线程执行器（同时维护了一个 Selector），里面有 run 方法处理 Channel 上源源不断的 i o 事件。 它的继承关系比较复杂 一条线是继承自 j.u.c.ScheduledExecutorService 因此包含了线程池中所有的方法 另一条线是继承自 netty 自己的 OrderedEventExecutor， 提供了 boolean inEventLoop(Thread thread) 方法判断一个线程是否属于此 EventLoop 提供了 parent 方法来看看自己属于哪个 EventLoopGroup 事件循环组 EventLoopGroup 是一组 EventLoop，Channel 一般会调用 EventLoopGroup 的 register 方法来绑定其中一个 EventLoop，后续这个 Channel 上的 io 事件都由此 EventLoop 来处理（保证了 io 事件处理时的线程安全） 继承自 netty 自己的 EventExecutorGroup 实现了 Iterable 接口提供遍历 EventLoop 的能力 另有 next 方法获取集合中下一个 EventLoop 以一个简单的实现为例： 12345// 内部创建了两个 EventLoop, 每个 EventLoop 维护一个线程DefaultEventLoopGroup group = new DefaultEventLoopGroup(2);System.out.println(group.next());System.out.println(group.next());System.out.println(group.next()); 输出 123io.netty.channel.DefaultEventLoop@60f82f98io.netty.channel.DefaultEventLoop@35f983a6io.netty.channel.DefaultEventLoop@60f82f98 也可以使用 for 循环 1234DefaultEventLoopGroup group = new DefaultEventLoopGroup(2);for (EventExecutor eventLoop : group) &#123; System.out.println(eventLoop);&#125; 输出 12io.netty.channel.DefaultEventLoop@60f82f98io.netty.channel.DefaultEventLoop@35f983a6 💡 优雅关闭优雅关闭 shutdownGracefully 方法。该方法会首先切换 EventLoopGroup 到关闭状态从而拒绝新的任务的加入，然后在任务队列的任务都处理完成后，停止线程的运行。从而确保整体应用是在正常有序的状态下退出的 细分EventLoopGroup 细分1： boss线程只负责ServerSocketChannel上的accept事件， worker 只负责socketChannel上的读写。 细分2： 一个worker可以处理多个channel，但是如果一个channel的任务执行较长，会影响到其他channel上的任务。所以 可以将耗时的任务单独让一个EventLoop来执行、 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.hongliang.netty01.eventloop;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import lombok.extern.slf4j.Slf4j;import java.nio.charset.Charset;/** * @author Hongliang Zhu * @create 2021-09-25 12:45 */@Slf4jpublic class EventLoopServer &#123; public static void main(String[] args) &#123; // 细分2 EventLoopGroup group = new DefaultEventLoopGroup(); new ServerBootstrap() // 细分1： boss只负责 ServerSocketChannel 上的accept 事件。 worker .group(new NioEventLoopGroup(), new NioEventLoopGroup(2)) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(&quot;handler1&quot;, new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf)msg; log.debug(buf.toString(Charset.defaultCharset())); // 让消息传递给下一个handler ctx.fireChannelRead(msg); &#125; &#125;).addLast(group, &quot;handler2&quot;, new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead( ChannelHandlerContext ctx, Object msg) throws Exception &#123; ByteBuf buf = (ByteBuf)msg; log.debug(buf.toString(Charset.defaultCharset())); &#125; &#125;); &#125; &#125;) .bind(8080); &#125;&#125; 演示 NioEventLoop 处理 io 事件服务器端两个 nio worker 工人 12345678910111213141516171819new ServerBootstrap() .group(new NioEventLoopGroup(1), new NioEventLoopGroup(2)) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf byteBuf = msg instanceof ByteBuf ? ((ByteBuf) msg) : null; if (byteBuf != null) &#123; byte[] buf = new byte[16]; ByteBuf len = byteBuf.readBytes(buf, 0, byteBuf.readableBytes()); log.debug(new String(buf)); &#125; &#125; &#125;); &#125; &#125;).bind(8080).sync(); 客户端，启动三次，分别修改发送字符串为 zhangsan（第一次），lisi（第二次），wangwu（第三次） 1234567891011121314151617public static void main(String[] args) throws InterruptedException &#123; Channel channel = new Bootstrap() .group(new NioEventLoopGroup(1)) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; System.out.println(&quot;init...&quot;); ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); &#125; &#125;) .channel(NioSocketChannel.class).connect(&quot;localhost&quot;, 8080) .sync() .channel(); channel.writeAndFlush(ByteBufAllocator.DEFAULT.buffer().writeBytes(&quot;wangwu&quot;.getBytes())); Thread.sleep(2000); channel.writeAndFlush(ByteBufAllocator.DEFAULT.buffer().writeBytes(&quot;wangwu&quot;.getBytes())); 最后输出 12345622:03:34 [DEBUG] [nioEventLoopGroup-3-1] c.i.o.EventLoopTest - zhangsan 22:03:36 [DEBUG] [nioEventLoopGroup-3-1] c.i.o.EventLoopTest - zhangsan 22:05:36 [DEBUG] [nioEventLoopGroup-3-2] c.i.o.EventLoopTest - lisi 22:05:38 [DEBUG] [nioEventLoopGroup-3-2] c.i.o.EventLoopTest - lisi 22:06:09 [DEBUG] [nioEventLoopGroup-3-1] c.i.o.EventLoopTest - wangwu 22:06:11 [DEBUG] [nioEventLoopGroup-3-1] c.i.o.EventLoopTest - wangwu 可以看到两个工人轮流处理 channel，但工人与 channel 之间进行了绑定 再增加两个非 nio 工人 12345678910111213141516171819202122DefaultEventLoopGroup normalWorkers = new DefaultEventLoopGroup(2);new ServerBootstrap() .group(new NioEventLoopGroup(1), new NioEventLoopGroup(2)) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) &#123; ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(normalWorkers,&quot;myhandler&quot;, new ChannelInboundHandlerAdapter() &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf byteBuf = msg instanceof ByteBuf ? ((ByteBuf) msg) : null; if (byteBuf != null) &#123; byte[] buf = new byte[16]; ByteBuf len = byteBuf.readBytes(buf, 0, byteBuf.readableBytes()); log.debug(new String(buf)); &#125; &#125; &#125;); &#125; &#125;).bind(8080).sync(); 客户端代码不变，启动三次，分别修改发送字符串为 zhangsan（第一次），lisi（第二次），wangwu（第三次） 输出 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535422:19:48 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] REGISTERED22:19:48 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] ACTIVE22:19:48 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 7a 68 61 6e 67 73 61 6e |zhangsan |+--------+-------------------------------------------------+----------------+22:19:48 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] READ COMPLETE22:19:48 [DEBUG] [defaultEventLoopGroup-2-1] c.i.o.EventLoopTest - zhangsan 22:19:50 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] READ: 8B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 7a 68 61 6e 67 73 61 6e |zhangsan |+--------+-------------------------------------------------+----------------+22:19:50 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x251562d5, L:/127.0.0.1:8080 - R:/127.0.0.1:52588] READ COMPLETE22:19:50 [DEBUG] [defaultEventLoopGroup-2-1] c.i.o.EventLoopTest - zhangsan 22:20:24 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] REGISTERED22:20:24 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] ACTIVE22:20:25 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] READ: 4B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6c 69 73 69 |lisi |+--------+-------------------------------------------------+----------------+22:20:25 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] READ COMPLETE22:20:25 [DEBUG] [defaultEventLoopGroup-2-2] c.i.o.EventLoopTest - lisi 22:20:27 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] READ: 4B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6c 69 73 69 |lisi |+--------+-------------------------------------------------+----------------+22:20:27 [DEBUG] [nioEventLoopGroup-4-2] i.n.h.l.LoggingHandler - [id: 0x94b2a840, L:/127.0.0.1:8080 - R:/127.0.0.1:52612] READ COMPLETE22:20:27 [DEBUG] [defaultEventLoopGroup-2-2] c.i.o.EventLoopTest - lisi 22:20:38 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] REGISTERED22:20:38 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] ACTIVE22:20:38 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] READ: 6B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 77 61 6e 67 77 75 |wangwu |+--------+-------------------------------------------------+----------------+22:20:38 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] READ COMPLETE22:20:38 [DEBUG] [defaultEventLoopGroup-2-1] c.i.o.EventLoopTest - wangwu 22:20:40 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] READ: 6B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 77 61 6e 67 77 75 |wangwu |+--------+-------------------------------------------------+----------------+22:20:40 [DEBUG] [nioEventLoopGroup-4-1] i.n.h.l.LoggingHandler - [id: 0x79a26af9, L:/127.0.0.1:8080 - R:/127.0.0.1:52625] READ COMPLETE22:20:40 [DEBUG] [defaultEventLoopGroup-2-1] c.i.o.EventLoopTest - wangwu 可以看到，nio 工人和 非 nio 工人也分别绑定了 channel（LoggingHandler 由 nio 工人执行，而我们自己的 handler 由非 nio 工人执行） 💡 handler 执行中如何换人？关键代码 io.netty.channel.AbstractChannelHandlerContext#invokeChannelRead() 12345678910111213141516171819static void invokeChannelRead(final AbstractChannelHandlerContext next, Object msg) &#123; final Object m = next.pipeline.touch(ObjectUtil.checkNotNull(msg, &quot;msg&quot;), next); // 下一个 handler 的事件循环是否与当前的事件循环是同一个线程 EventExecutor executor = next.executor(); // 是，直接调用， 当前handler中的线程是否和eventLoop是同一个 if (executor.inEventLoop()) &#123; next.invokeChannelRead(m); &#125; // 不是，将要执行的代码作为任务提交给下一个事件循环处理（换人） else &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; next.invokeChannelRead(m); &#125; &#125;); &#125;&#125; 如果两个 handler 绑定的是同一个线程，那么就直接调用 否则，把要调用的代码封装为一个任务对象，由下一个 handler 的线程来调用 演示 NioEventLoop 处理普通任务NioEventLoop 除了可以处理 io 事件，同样可以向它提交普通任务 1234567NioEventLoopGroup nioWorkers = new NioEventLoopGroup(2);log.debug(&quot;server start...&quot;);Thread.sleep(2000);nioWorkers.execute(()-&gt;&#123; log.debug(&quot;normal task...&quot;);&#125;); 输出 1222:30:36 [DEBUG] [main] c.i.o.EventLoopTest2 - server start...22:30:38 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - normal task... 可以用来执行耗时较长的任务 演示 NioEventLoop 处理定时任务1234567NioEventLoopGroup nioWorkers = new NioEventLoopGroup(2);log.debug(&quot;server start...&quot;);Thread.sleep(2000);nioWorkers.scheduleAtFixedRate(() -&gt; &#123; log.debug(&quot;running...&quot;);&#125;, 0, 1, TimeUnit.SECONDS); 输出 12345622:35:15 [DEBUG] [main] c.i.o.EventLoopTest2 - server start...22:35:17 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running...22:35:18 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running...22:35:19 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running...22:35:20 [DEBUG] [nioEventLoopGroup-2-1] c.i.o.EventLoopTest2 - running...... 可以用来执行定时任务 3.2 Channelchannel 的主要作用 close() 可以用来关闭 channel closeFuture() 用来处理 channel 的关闭 sync 方法作用是同步等待 channel 关闭 而 addListener 方法是异步等待 channel 关闭 pipeline() 方法添加处理器 write() 方法将数据写入 writeAndFlush() 方法将数据写入并刷出 ChannelFuture这时刚才的客户端代码 12345678910111213new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080) .sync() .channel() .writeAndFlush(new Date() + &quot;: hello world!&quot;); 现在把它拆开来看 123456789101112ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080); // 1channelFuture.sync().channel().writeAndFlush(new Date() + &quot;: hello world!&quot;); 1 处返回的是 ChannelFuture 对象，它的作用是利用 channel() 方法来获取 Channel 对象 注意 connect 方法是异步的，意味着不等连接建立，方法执行就返回了。因此 channelFuture 对象中不能【立刻】获得到正确的 Channel 对象 实验如下： 1234567891011121314ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080);System.out.println(channelFuture.channel()); // 1channelFuture.sync(); // 2System.out.println(channelFuture.channel()); // 3 执行到 1 时，连接未建立，打印 [id: 0x2e1884dd] 执行到 2 时，sync 方法是同步等待连接建立完成 执行到 3 时，连接肯定建立了，打印 [id: 0x2e1884dd, L:/127.0.0.1:57191 - R:/127.0.0.1:8080] 除了用 sync 方法可以让异步操作同步以外，还可以使用回调的方式： 1234567891011121314ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080);System.out.println(channelFuture.channel()); // 1channelFuture.addListener((ChannelFutureListener) future -&gt; &#123; System.out.println(future.channel()); // 2&#125;); 执行到 1 时，连接未建立，打印 [id: 0x749124ba] ChannelFutureListener 会在连接建立时被调用（其中 operationComplete 方法），因此执行到 2 时，连接肯定建立了，打印 [id: 0x749124ba, L:/127.0.0.1:57351 - R:/127.0.0.1:8080] CloseFuture1234567891011121314151617181920212223242526272829303132333435363738394041424344@Slf4jpublic class CloseFutureClient &#123; public static void main(String[] args) throws InterruptedException &#123; NioEventLoopGroup group= new NioEventLoopGroup(); ChannelFuture channelFuture = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override // 在连接建立后被调用 protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); Channel channel = channelFuture.sync().channel(); log.debug(&quot;&#123;&#125;&quot;, channel); new Thread(()-&gt;&#123; Scanner scanner = new Scanner(System.in); while (true) &#123; String line = scanner.nextLine(); if (&quot;q&quot;.equals(line)) &#123; channel.close(); // close 异步操作 1s 之后// log.debug(&quot;处理关闭之后的操作&quot;); // 不能在这里善后 break; &#125; channel.writeAndFlush(line); &#125; &#125;, &quot;input&quot;).start(); // 获取 CloseFuture 对象， 1) 同步处理关闭， 2) 异步处理关闭 ChannelFuture closeFuture = channel.closeFuture(); /*log.debug(&quot;waiting close...&quot;); closeFuture.sync(); log.debug(&quot;处理关闭之后的操作&quot;);*/ closeFuture.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture future) throws Exception &#123; log.debug(&quot;处理关闭之后的操作&quot;); group.shutdownGracefully(); &#125; &#125;); &#125;&#125; 💡 异步提升的是什么 有些同学看到这里会有疑问：为什么不在一个线程中去执行建立连接、去执行关闭 channel，那样不是也可以吗？非要用这么复杂的异步方式：比如一个线程发起建立连接，另一个线程去真正建立连接 还有同学会笼统地回答，因为 netty 异步方式用了多线程、多线程就效率高。其实这些认识都比较片面，多线程和异步所提升的效率并不是所认为的 思考下面的场景，4 个医生给人看病，每个病人花费 20 分钟，而且医生看病的过程中是以病人为单位的，一个病人看完了，才能看下一个病人。假设病人源源不断地来，可以计算一下 4 个医生一天工作 8 小时，处理的病人总数是：4 * 8 * 3 = 96 经研究发现，看病可以细分为四个步骤，经拆分后每个步骤需要 5 分钟，如下 因此可以做如下优化，只有一开始，医生 2、3、4 分别要等待 5、10、15 分钟才能执行工作，但只要后续病人源源不断地来，他们就能够满负荷工作，并且处理病人的能力提高到了 4 * 8 * 12 效率几乎是原来的四倍 要点 单线程没法异步提高效率，必须配合多线程、多核 cpu 才能发挥异步的优势 异步并没有缩短响应时间，反而有所增加 合理进行任务拆分，也是利用异步的关键 3.3 Future &amp; Promise在异步处理时，经常用到这两个接口 首先要说明 netty 中的 Future 与 jdk 中的 Future 同名，但是是两个接口，netty 的 Future 继承自 jdk 的 Future，而 Promise 又对 netty Future 进行了扩展 jdk Future 只能同步等待任务结束（或成功、或失败）才能得到结果 netty Future 可以同步等待任务结束得到结果，也可以异步方式得到结果，但都是要等任务结束 netty Promise 不仅有 netty Future 的功能，而且脱离了任务独立存在，只作为两个线程间传递结果的容器 功能/名称 jdk Future netty Future Promise cancel 取消任务 - - isCanceled 任务是否取消 - - isDone 任务是否完成，不能区分成功失败 - - get 获取任务结果，阻塞等待 - - getNow - 获取任务结果，非阻塞，还未产生结果时返回 null - await - 等待任务结束，如果任务失败，不会抛异常，而是通过 isSuccess 判断 - sync - 等待任务结束，如果任务失败，抛出异常 - isSuccess - 判断任务是否成功 - cause - 获取失败信息，非阻塞，如果没有失败，返回null - addLinstener - 添加回调，异步接收结果 - setSuccess - - 设置成功结果 setFailure - - 设置失败结果 例1同步处理任务成功 12345678910111213141516DefaultEventLoop eventExecutors = new DefaultEventLoop();DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors);eventExecutors.execute(()-&gt;&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.debug(&quot;set success, &#123;&#125;&quot;,10); promise.setSuccess(10);&#125;);log.debug(&quot;start...&quot;);log.debug(&quot;&#123;&#125;&quot;,promise.getNow()); // 还没有结果log.debug(&quot;&#123;&#125;&quot;,promise.get()); 输出 123411:51:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start...11:51:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - null11:51:54 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set success, 1011:51:54 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - 10 例2异步处理任务成功 123456789101112131415161718192021DefaultEventLoop eventExecutors = new DefaultEventLoop();DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors);// 设置回调，异步接收结果promise.addListener(future -&gt; &#123; // 这里的 future 就是上面的 promise log.debug(&quot;&#123;&#125;&quot;,future.getNow());&#125;);// 等待 1000 后设置成功结果eventExecutors.execute(()-&gt;&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.debug(&quot;set success, &#123;&#125;&quot;,10); promise.setSuccess(10);&#125;);log.debug(&quot;start...&quot;); 输出 12311:49:30 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start...11:49:31 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set success, 1011:49:31 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - 10 例3同步处理任务失败 - sync &amp; get 1234567891011121314151617DefaultEventLoop eventExecutors = new DefaultEventLoop(); DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors); eventExecutors.execute(() -&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; RuntimeException e = new RuntimeException(&quot;error...&quot;); log.debug(&quot;set failure, &#123;&#125;&quot;, e.toString()); promise.setFailure(e); &#125;); log.debug(&quot;start...&quot;); log.debug(&quot;&#123;&#125;&quot;, promise.getNow()); promise.get(); // sync() 也会出现异常，只是 get 会再用 ExecutionException 包一层异常 输出 1234567891011121312:11:07 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start...12:11:07 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - null12:11:08 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error...Exception in thread &quot;main&quot; java.util.concurrent.ExecutionException: java.lang.RuntimeException: error... at io.netty.util.concurrent.AbstractFuture.get(AbstractFuture.java:41) at com.itcast.oio.DefaultPromiseTest2.main(DefaultPromiseTest2.java:34)Caused by: java.lang.RuntimeException: error... at com.itcast.oio.DefaultPromiseTest2.lambda$main$0(DefaultPromiseTest2.java:27) at io.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 例4同步处理任务失败 - await 123456789101112131415161718DefaultEventLoop eventExecutors = new DefaultEventLoop();DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors);eventExecutors.execute(() -&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; RuntimeException e = new RuntimeException(&quot;error...&quot;); log.debug(&quot;set failure, &#123;&#125;&quot;, e.toString()); promise.setFailure(e);&#125;);log.debug(&quot;start...&quot;);log.debug(&quot;&#123;&#125;&quot;, promise.getNow());promise.await(); // 与 sync 和 get 区别在于，不会抛异常log.debug(&quot;result &#123;&#125;&quot;, (promise.isSuccess() ? promise.getNow() : promise.cause()).toString()); 输出 123412:18:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start...12:18:53 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - null12:18:54 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error...12:18:54 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - result java.lang.RuntimeException: error... 例5异步处理任务失败 12345678910111213141516171819DefaultEventLoop eventExecutors = new DefaultEventLoop();DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors);promise.addListener(future -&gt; &#123; log.debug(&quot;result &#123;&#125;&quot;, (promise.isSuccess() ? promise.getNow() : promise.cause()).toString());&#125;);eventExecutors.execute(() -&gt; &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; RuntimeException e = new RuntimeException(&quot;error...&quot;); log.debug(&quot;set failure, &#123;&#125;&quot;, e.toString()); promise.setFailure(e);&#125;);log.debug(&quot;start...&quot;); 输出 12312:04:57 [DEBUG] [main] c.i.o.DefaultPromiseTest2 - start...12:04:58 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - set failure, java.lang.RuntimeException: error...12:04:58 [DEBUG] [defaultEventLoop-1-1] c.i.o.DefaultPromiseTest2 - result java.lang.RuntimeException: error... 例6await 死锁检查 123456789101112131415161718192021222324DefaultEventLoop eventExecutors = new DefaultEventLoop();DefaultPromise&lt;Integer&gt; promise = new DefaultPromise&lt;&gt;(eventExecutors);eventExecutors.submit(()-&gt;&#123; System.out.println(&quot;1&quot;); try &#123; promise.await(); // 注意不能仅捕获 InterruptedException 异常 // 否则 死锁检查抛出的 BlockingOperationException 会继续向上传播 // 而提交的任务会被包装为 PromiseTask，它的 run 方法中会 catch 所有异常然后设置为 Promise 的失败结果而不会抛出 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;2&quot;);&#125;);eventExecutors.submit(()-&gt;&#123; System.out.println(&quot;3&quot;); try &#123; promise.await(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;4&quot;);&#125;); 输出 1234567891011121314151617181920212223242526271234io.netty.util.concurrent.BlockingOperationException: DefaultPromise@47499c2a(incomplete) at io.netty.util.concurrent.DefaultPromise.checkDeadLock(DefaultPromise.java:384) at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:212) at com.itcast.oio.DefaultPromiseTest.lambda$main$0(DefaultPromiseTest.java:27) at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) at io.netty.util.concurrent.PromiseTask.run(PromiseTask.java:73) at io.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745)io.netty.util.concurrent.BlockingOperationException: DefaultPromise@47499c2a(incomplete) at io.netty.util.concurrent.DefaultPromise.checkDeadLock(DefaultPromise.java:384) at io.netty.util.concurrent.DefaultPromise.await(DefaultPromise.java:212) at com.itcast.oio.DefaultPromiseTest.lambda$main$1(DefaultPromiseTest.java:36) at io.netty.util.concurrent.PromiseTask$RunnableAdapter.call(PromiseTask.java:38) at io.netty.util.concurrent.PromiseTask.run(PromiseTask.java:73) at io.netty.channel.DefaultEventLoop.run(DefaultEventLoop.java:54) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:918) at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) at java.lang.Thread.run(Thread.java:745) 3.4 Handler &amp; PipelineChannelHandler 用来处理 Channel 上的各种事件，分为入站、出站两种。所有 ChannelHandler 被连成一串，就是 Pipeline 入站处理器通常是 ChannelInboundHandlerAdapter 的子类，主要用来读取客户端数据，写回结果 出站处理器通常是 ChannelOutboundHandlerAdapter 的子类，主要对写回结果进行加工 打个比喻，每个 Channel 是一个产品的加工车间，Pipeline 是车间中的流水线，ChannelHandler 就是流水线上的各道工序，而后面要讲的 ByteBuf 是原材料，经过很多工序的加工：先经过一道道入站工序，再经过一道道出站工序最终变成产品 先搞清楚顺序，服务端 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253new ServerBootstrap() .group(new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; protected void initChannel(NioSocketChannel ch) &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; System.out.println(1); ctx.fireChannelRead(msg); // 1 &#125; &#125;); ch.pipeline().addLast(new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; System.out.println(2); ctx.fireChannelRead(msg); // 2 &#125; &#125;); ch.pipeline().addLast(new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; System.out.println(3); ctx.channel().write(msg); // 3 &#125; &#125;); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter()&#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) &#123; System.out.println(4); ctx.write(msg, promise); // 4 &#125; &#125;); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter()&#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) &#123; System.out.println(5); ctx.write(msg, promise); // 5 &#125; &#125;); ch.pipeline().addLast(new ChannelOutboundHandlerAdapter()&#123; @Override public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) &#123; System.out.println(6); ctx.write(msg, promise); // 6 &#125; &#125;); &#125; &#125;) .bind(8080); 客户端 12345678910111213new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;Channel&gt;() &#123; @Override protected void initChannel(Channel ch) &#123; ch.pipeline().addLast(new StringEncoder()); &#125; &#125;) .connect(&quot;127.0.0.1&quot;, 8080) .addListener((ChannelFutureListener) future -&gt; &#123; future.channel().writeAndFlush(&quot;hello,world&quot;); &#125;); 服务器端打印： 123456123654 可以看到，ChannelInboundHandlerAdapter 是按照 addLast 的顺序执行的，而 ChannelOutboundHandlerAdapter 是按照 addLast 的逆序执行的。ChannelPipeline 的实现是一个 ChannelHandlerContext（包装了 ChannelHandler） 组成的双向链表 入站处理器中，ctx.fireChannelRead(msg) 是 调用下一个入站处理器 如果注释掉 1 处代码，则仅会打印 1 如果注释掉 2 处代码，则仅会打印 1 2 3 处的 ctx.channel().write(msg) 会 从尾部开始触发 后续出站处理器的执行 如果注释掉 3 处代码，则仅会打印 1 2 3 类似的，出站处理器中，ctx.write(msg, promise) 的调用也会 触发上一个出站处理器 如果注释掉 6 处代码，则仅会打印 1 2 3 6 ctx.channel().write(msg) vs ctx.write(msg) 都是触发出站处理器的执行 ctx.channel().write(msg) 从尾部开始查找出站处理器 ctx.write(msg) 是从当前节点找上一个出站处理器 3 处的 ctx.channel().write(msg) 如果改为 ctx.write(msg) 仅会打印 1 2 3，因为节点3 之前没有其它出站处理器了 6 处的 ctx.write(msg, promise) 如果改为 ctx.channel().write(msg) 会打印 1 2 3 6 6 6… 因为 ctx.channel().write() 是从尾部开始查找，结果又是节点6 自己 图1 - 服务端 pipeline 触发的原始流程，图中数字代表了处理步骤的先后次序 3.5 ByteBuf是对字节数据的封装 1）创建12ByteBuf buffer = ByteBufAllocator.DEFAULT.buffer(10);log(buffer); 上面代码创建了一个默认的 ByteBuf（池化基于直接内存的 ByteBuf），初始容量是 10 输出 1read index:0 write index:0 capacity:10 其中 log 方法参考如下 1234567891011private static void log(ByteBuf buffer) &#123; int length = buffer.readableBytes(); int rows = length / 16 + (length % 15 == 0 ? 0 : 1) + 4; StringBuilder buf = new StringBuilder(rows * 80 * 2) .append(&quot;read index:&quot;).append(buffer.readerIndex()) .append(&quot; write index:&quot;).append(buffer.writerIndex()) .append(&quot; capacity:&quot;).append(buffer.capacity()) .append(NEWLINE); appendPrettyHexDump(buf, buffer); System.out.println(buf.toString());&#125; 2）直接内存 vs 堆内存堆内存分配效率高，但是读写效率低。直接内存则反之。 可以使用下面的代码来创建池化基于堆的 ByteBuf 1ByteBuf buffer = ByteBufAllocator.DEFAULT.heapBuffer(10); 也可以使用下面的代码来创建池化基于直接内存的 ByteBuf 1ByteBuf buffer = ByteBufAllocator.DEFAULT.directBuffer(10); 直接内存创建和销毁的代价昂贵，但读写性能高（少一次内存复制），适合配合池化功能一起用 直接内存对 GC 压力小，因为这部分内存不受 JVM 垃圾回收的管理，但也要注意及时主动释放 3）池化 vs 非池化池化的最大意义在于可以重用 ByteBuf，优点有 没有池化，则每次都得创建新的 ByteBuf 实例，这个操作对直接内存代价昂贵，就算是堆内存，也会增加 GC 压力 有了池化，则可以重用池中 ByteBuf 实例，并且采用了与 jemalloc 类似的内存分配算法提升分配效率 高并发时，池化功能更节约内存，减少内存溢出的可能 池化功能是否开启，可以通过下面的系统环境变量来设置 1-Dio.netty.allocator.type=&#123;unpooled|pooled&#125; 4.1 以后，非 Android 平台默认启用池化实现，Android 平台启用非池化实现 4.1 之前，池化功能还不成熟，默认是非池化实现 4）组成ByteBuf 由四部分组成 最开始读写指针都在 0 位置 5）写入方法列表，省略一些不重要的方法 方法签名 含义 备注 writeBoolean(boolean value) 写入 boolean 值 用一字节 01|00 代表 true|false writeByte(int value) 写入 byte 值 writeShort(int value) 写入 short 值 writeInt(int value) 写入 int 值 Big Endian，即 0x250，写入后 00 00 02 50 writeIntLE(int value) 写入 int 值 Little Endian，即 0x250，写入后 50 02 00 00 writeLong(long value) 写入 long 值 writeChar(int value) 写入 char 值 writeFloat(float value) 写入 float 值 writeDouble(double value) 写入 double 值 writeBytes(ByteBuf src) 写入 netty 的 ByteBuf writeBytes(byte[] src) 写入 byte[] writeBytes(ByteBuffer src) 写入 nio 的 ByteBuffer int writeCharSequence(CharSequence sequence, Charset charset) 写入字符串 注意 这些方法的未指明返回值的，其返回值都是 ByteBuf，意味着可以链式调用 网络传输，默认习惯是 Big Endian 先写入 4 个字节 12buffer.writeBytes(new byte[]&#123;1, 2, 3, 4&#125;);log(buffer); 结果是 123456read index:0 write index:4 capacity:10 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 |.... |+--------+-------------------------------------------------+----------------+ 再写入一个 int 整数，也是 4 个字节 12buffer.writeInt(5);log(buffer); 结果是 123456read index:0 write index:8 capacity:10 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 00 00 00 05 |........ |+--------+-------------------------------------------------+----------------+ 还有一类方法是 set 开头的一系列方法，也可以写入数据，但不会改变写指针位置 6）扩容再写入一个 int 整数时，容量不够了（初始容量是 10），这时会引发扩容 12buffer.writeInt(6);log(buffer); 扩容规则是 如何写入后数据大小未超过 512，则选择下一个 16 的整数倍，例如写入后大小为 12 ，则扩容后 capacity 是 16 如果写入后数据大小超过 512，则选择下一个 2^n，例如写入后大小为 513，则扩容后 capacity 是 2^10=1024（2^9=512 已经不够了） 扩容不能超过 max capacity 会报错 结果是 123456read index:0 write index:12 capacity:16 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 00 00 00 05 00 00 00 06 |............ |+--------+-------------------------------------------------+----------------+ 7）读取例如读了 4 次，每次一个字节 12345System.out.println(buffer.readByte());System.out.println(buffer.readByte());System.out.println(buffer.readByte());System.out.println(buffer.readByte());log(buffer); 读过的内容，就属于废弃部分了，再读只能读那些尚未读取的部分 123456789101234read index:4 write index:12 capacity:16 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 00 00 05 00 00 00 06 |........ |+--------+-------------------------------------------------+----------------+ 如果需要重复读取 int 整数 5，怎么办？ 可以在 read 前先做个标记 mark 123buffer.markReaderIndex();System.out.println(buffer.readInt());log(buffer); 结果 12345675read index:8 write index:12 capacity:16 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 00 00 06 |.... |+--------+-------------------------------------------------+----------------+ 这时要重复读取的话，重置到标记位置 reset 12buffer.resetReaderIndex();log(buffer); 这时 123456read index:4 write index:12 capacity:16 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 00 00 00 05 00 00 00 06 |........ |+--------+-------------------------------------------------+----------------+ 还有种办法是采用 get 开头的一系列方法，这些方法不会改变 read index 8）retain &amp; release由于 Netty 中有堆外内存的 ByteBuf 实现，堆外内存最好是手动来释放，而不是等 GC 垃圾回收。 UnpooledHeapByteBuf 使用的是 JVM 内存，只需等 GC 回收内存即可 UnpooledDirectByteBuf 使用的就是直接内存了，需要特殊的方法来回收内存 PooledByteBuf 和它的子类使用了池化机制，需要更复杂的规则来回收内存 回收内存的源码实现，请关注下面方法的不同实现 protected abstract void deallocate() Netty 这里采用了引用计数法来控制回收内存，每个 ByteBuf 都实现了 ReferenceCounted 接口 每个 ByteBuf 对象的初始计数为 1 调用 release 方法计数减 1，如果计数为 0，ByteBuf 内存被回收 调用 retain 方法计数加 1，表示调用者没用完之前，其它 handler 即使调用了 release 也不会造成回收 当计数为 0 时，底层内存会被回收，这时即使 ByteBuf 对象还在，其各个方法均无法正常使用 谁来负责 release 呢？ 不是我们想象的（一般情况下） 123456ByteBuf buf = ...try &#123; ...&#125; finally &#123; buf.release();&#125; 请思考，因为 pipeline 的存在，一般需要将 ByteBuf 传递给下一个 ChannelHandler，如果在 finally 中 release 了，就失去了传递性（当然，如果在这个 ChannelHandler 内这个 ByteBuf 已完成了它的使命，那么便无须再传递） 基本规则是，谁是最后使用者，谁负责 release，详细分析如下 起点，对于 NIO 实现来讲，在 io.netty.channel.nio.AbstractNioByteChannel.NioByteUnsafe#read 方法中首次创建 ByteBuf 放入 pipeline（line 163 pipeline.fireChannelRead(byteBuf)） 入站 ByteBuf 处理原则 对原始 ByteBuf 不做处理，调用 ctx.fireChannelRead(msg) 向后传递，这时无须 release 将原始 ByteBuf 转换为其它类型的 Java 对象，这时 ByteBuf 就没用了，必须 release 如果不调用 ctx.fireChannelRead(msg) 向后传递，那么也必须 release 注意各种异常，如果 ByteBuf 没有成功传递到下一个 ChannelHandler，必须 release 假设消息一直向后传，那么 TailContext 会负责释放未处理消息（原始的 ByteBuf） 出站 ByteBuf 处理原则 出站消息最终都会转为 ByteBuf 输出，一直向前传，由 HeadContext flush 后 release 异常处理原则 有时候不清楚 ByteBuf 被引用了多少次，但又必须彻底释放，可以循环调用 release 直到返回 true TailContext 释放未处理消息逻辑 12345678910// io.netty.channel.DefaultChannelPipeline#onUnhandledInboundMessage(java.lang.Object)protected void onUnhandledInboundMessage(Object msg) &#123; try &#123; logger.debug( &quot;Discarded inbound message &#123;&#125; that reached at the tail of the pipeline. &quot; + &quot;Please check your pipeline configuration.&quot;, msg); &#125; finally &#123; ReferenceCountUtil.release(msg); &#125;&#125; 具体代码 1234567// io.netty.util.ReferenceCountUtil#release(java.lang.Object)public static boolean release(Object msg) &#123; if (msg instanceof ReferenceCounted) &#123; return ((ReferenceCounted) msg).release(); &#125; return false;&#125; 9）slice【零拷贝】的体现之一，对原始 ByteBuf 进行切片成多个 ByteBuf，切片后的 ByteBuf 并没有发生内存复制，还是使用原始 ByteBuf 的内存，切片后的 ByteBuf 维护独立的 read，write 指针 例，原始 ByteBuf 进行一些初始操作 1234ByteBuf origin = ByteBufAllocator.DEFAULT.buffer(10);origin.writeBytes(new byte[]&#123;1, 2, 3, 4&#125;);origin.readByte();System.out.println(ByteBufUtil.prettyHexDump(origin)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 02 03 04 |... |+--------+-------------------------------------------------+----------------+ 这时调用 slice 进行切片，无参 slice 是从原始 ByteBuf 的 read index 到 write index 之间的内容进行切片，切片后的 max capacity 被固定为这个区间的大小，因此不能追加 write 123ByteBuf slice = origin.slice();System.out.println(ByteBufUtil.prettyHexDump(slice));// slice.writeByte(5); 如果执行，会报 IndexOutOfBoundsException 异常 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 02 03 04 |... |+--------+-------------------------------------------------+----------------+ 如果原始 ByteBuf 再次读操作（又读了一个字节） 12origin.readByte();System.out.println(ByteBufUtil.prettyHexDump(origin)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 03 04 |.. |+--------+-------------------------------------------------+----------------+ 这时的 slice 不受影响，因为它有独立的读写指针 1System.out.println(ByteBufUtil.prettyHexDump(slice)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 02 03 04 |... |+--------+-------------------------------------------------+----------------+ 如果 slice 的内容发生了更改 12slice.setByte(2, 5);System.out.println(ByteBufUtil.prettyHexDump(slice)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 02 03 05 |... |+--------+-------------------------------------------------+----------------+ 这时，原始 ByteBuf 也会受影响，因为底层都是同一块内存 1System.out.println(ByteBufUtil.prettyHexDump(origin)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 03 05 |.. |+--------+-------------------------------------------------+----------------+ 10）duplicate【零拷贝】的体现之一，就好比截取了原始 ByteBuf 所有内容，并且没有 max capacity 的限制，也是与原始 ByteBuf 使用同一块底层内存，只是读写指针是独立的 11）copy会将底层内存数据进行深拷贝，因此无论读写，都与原始 ByteBuf 无关 12）CompositeByteBuf【零拷贝】的体现之一，可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免拷贝 有两个 ByteBuf 如下 123456ByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(5);buf1.writeBytes(new byte[]&#123;1, 2, 3, 4, 5&#125;);ByteBuf buf2 = ByteBufAllocator.DEFAULT.buffer(5);buf2.writeBytes(new byte[]&#123;6, 7, 8, 9, 10&#125;);System.out.println(ByteBufUtil.prettyHexDump(buf1));System.out.println(ByteBufUtil.prettyHexDump(buf2)); 输出 12345678910 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 05 |..... |+--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 06 07 08 09 0a |..... |+--------+-------------------------------------------------+----------------+ 现在需要一个新的 ByteBuf，内容来自于刚才的 buf1 和 buf2，如何实现？ 方法1： 12345ByteBuf buf3 = ByteBufAllocator.DEFAULT .buffer(buf1.readableBytes()+buf2.readableBytes());buf3.writeBytes(buf1);buf3.writeBytes(buf2);System.out.println(ByteBufUtil.prettyHexDump(buf3)); 结果 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 05 06 07 08 09 0a |.......... |+--------+-------------------------------------------------+----------------+ 这种方法好不好？回答是不太好，因为进行了数据的内存复制操作 方法2： 123CompositeByteBuf buf3 = ByteBufAllocator.DEFAULT.compositeBuffer();// true 表示增加新的 ByteBuf 自动递增 write index, 否则 write index 会始终为 0buf3.addComponents(true, buf1, buf2); 结果是一样的 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 05 06 07 08 09 0a |.......... |+--------+-------------------------------------------------+----------------+ CompositeByteBuf 是一个组合的 ByteBuf，它内部维护了一个 Component 数组，每个 Component 管理一个 ByteBuf，记录了这个 ByteBuf 相对于整体偏移量等信息，代表着整体中某一段的数据。 优点，对外是一个虚拟视图，组合这些 ByteBuf 不会产生内存复制 缺点，复杂了很多，多次操作会带来性能的损耗 13）UnpooledUnpooled 是一个工具类，类如其名，提供了非池化的 ByteBuf 创建、组合、复制等操作 这里仅介绍其跟【零拷贝】相关的 wrappedBuffer 方法，可以用来包装 ByteBuf 12345678ByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(5);buf1.writeBytes(new byte[]&#123;1, 2, 3, 4, 5&#125;);ByteBuf buf2 = ByteBufAllocator.DEFAULT.buffer(5);buf2.writeBytes(new byte[]&#123;6, 7, 8, 9, 10&#125;);// 当包装 ByteBuf 个数超过一个时, 底层使用了 CompositeByteBufByteBuf buf3 = Unpooled.wrappedBuffer(buf1, buf2);System.out.println(ByteBufUtil.prettyHexDump(buf3)); 输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 05 06 07 08 09 0a |.......... |+--------+-------------------------------------------------+----------------+ 也可以用来包装普通字节数组，底层也不会有拷贝操作 123ByteBuf buf4 = Unpooled.wrappedBuffer(new byte[]&#123;1, 2, 3&#125;, new byte[]&#123;4, 5, 6&#125;);System.out.println(buf4.getClass());System.out.println(ByteBufUtil.prettyHexDump(buf4)); 输出 123456class io.netty.buffer.CompositeByteBuf +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 01 02 03 04 05 06 |...... |+--------+-------------------------------------------------+----------------+ 💡 ByteBuf 优势 池化 - 可以重用池中 ByteBuf 实例，更节约内存，减少内存溢出的可能 读写指针分离，不需要像 ByteBuffer 一样切换读写模式 可以自动扩容 支持链式调用，使用更流畅 很多地方体现零拷贝，例如 slice、duplicate、CompositeByteBuf 4. 双向通信4.1 练习实现一个 echo server 编写 server 1234567891011121314151617181920212223new ServerBootstrap() .group(new NioEventLoopGroup()) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) &#123; ch.pipeline().addLast(new ChannelInboundHandlerAdapter()&#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf buffer = (ByteBuf) msg; System.out.println(buffer.toString(Charset.defaultCharset())); // 建议使用 ctx.alloc() 创建 ByteBuf ByteBuf response = ctx.alloc().buffer(); response.writeBytes(buffer); ctx.writeAndFlush(response); // 思考：需要释放 buffer 吗 // 思考：需要释放 response 吗 &#125; &#125;); &#125; &#125;).bind(8080); 编写 client 1234567891011121314151617181920212223242526272829303132333435NioEventLoopGroup group = new NioEventLoopGroup();Channel channel = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer&lt;NioSocketChannel&gt;() &#123; @Override protected void initChannel(NioSocketChannel ch) throws Exception &#123; ch.pipeline().addLast(new StringEncoder()); ch.pipeline().addLast(new ChannelInboundHandlerAdapter() &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf buffer = (ByteBuf) msg; System.out.println(buffer.toString(Charset.defaultCharset())); // 思考：需要释放 buffer 吗 &#125; &#125;); &#125; &#125;).connect(&quot;127.0.0.1&quot;, 8080).sync().channel();channel.closeFuture().addListener(future -&gt; &#123; group.shutdownGracefully();&#125;);new Thread(() -&gt; &#123; Scanner scanner = new Scanner(System.in); while (true) &#123; String line = scanner.nextLine(); if (&quot;q&quot;.equals(line)) &#123; channel.close(); break; &#125; channel.writeAndFlush(line); &#125;&#125;).start(); 💡 读和写的误解我最初在认识上有这样的误区，认为只有在 netty，nio 这样的多路复用 IO 模型时，读写才不会相互阻塞，才可以实现高效的双向通信，但实际上，Java Socket 是全双工的：在任意时刻，线路上存在A 到 B 和 B 到 A 的双向信号传输。即使是阻塞 IO，读和写是可以同时进行的，只要分别采用读线程和写线程即可，读不会阻塞写、写也不会阻塞读 例如 12345678910111213141516171819202122232425262728293031public class TestServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocket ss = new ServerSocket(8888); Socket s = ss.accept(); new Thread(() -&gt; &#123; try &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(s.getInputStream())); while (true) &#123; System.out.println(reader.readLine()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(() -&gt; &#123; try &#123; BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(s.getOutputStream())); // 例如在这个位置加入 thread 级别断点，可以发现即使不写入数据，也不妨碍前面线程读取客户端数据 for (int i = 0; i &lt; 100; i++) &#123; writer.write(String.valueOf(i)); writer.newLine(); writer.flush(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 客户端 1234567891011121314151617181920212223242526272829public class TestClient &#123; public static void main(String[] args) throws IOException &#123; Socket s = new Socket(&quot;localhost&quot;, 8888); new Thread(() -&gt; &#123; try &#123; BufferedReader reader = new BufferedReader(new InputStreamReader(s.getInputStream())); while (true) &#123; System.out.println(reader.readLine()); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); new Thread(() -&gt; &#123; try &#123; BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(s.getOutputStream())); for (int i = 0; i &lt; 100; i++) &#123; writer.write(String.valueOf(i)); writer.newLine(); writer.flush(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125;","path":"2021/09/25/Netty02-入门/","date":"09-25","excerpt":"","tags":[{"name":"NIO","slug":"NIO","permalink":"https://castile.github.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"}]},{"title":"NIO基础","text":"一. NIO 基础non-blocking io 非阻塞 IO 1. 三大组件1.1 Channel &amp; Bufferchannel 有一点类似于 stream，它就是读写数据的双向通道，可以从 channel 将数据读入 buffer，也可以将 buffer 的数据写入 channel，而之前的 stream 要么是输入，要么是输出，channel 比 stream 更为底层 123graph LRchannel --&gt; bufferbuffer --&gt; channel 常见的 Channel 有 FileChannel ：文件数据传输通道 DatagramChannel ：UDP数据 SocketChannel ：TCP数据 ServerSocketChannel buffer 则用来缓冲读写数据，常见的 buffer 有 ByteBuffer MappedByteBuffer DirectByteBuffer HeapByteBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer CharBuffer 1.2 Selectorselector 单从字面意思不好理解，需要结合服务器的设计演化来理解它的用途 多线程版设计123456graph TDsubgraph 多线程版t1(thread) --&gt; s1(socket1)t2(thread) --&gt; s2(socket2)t3(thread) --&gt; s3(socket3)end ⚠️ 多线程版缺点 内存占用高 线程上下文切换成本高 只适合连接数少的场景 线程池版设计1234567graph TDsubgraph 线程池版t4(thread) --&gt; s4(socket1)t5(thread) --&gt; s5(socket2)t4(thread) -.-&gt; s6(socket3)t5(thread) -.-&gt; s7(socket4)end ⚠️ 线程池版缺点 阻塞模式下，线程仅能处理一个 socket 连接 仅适合短连接场景 selector 版设计selector 的作用就是配合一个线程来管理多个 channel，获取这些 channel 上发生的事件，这些 channel 工作在非阻塞模式下，不会让线程吊死在一个 channel 上。适合连接数特别多，但流量低的场景（low traffic） 1234567graph TDsubgraph selector 版thread --&gt; selectorselector --&gt; c1(channel)selector --&gt; c2(channel)selector --&gt; c3(channel)end 调用 selector 的 select() 会阻塞直到 channel 发生了读写就绪事件，这些事件发生，select 方法就会返回这些事件交给 thread 来处理 2. ByteBuffer有一普通文本文件 data.txt，内容为 11234567890abcd 使用 FileChannel 来读取文件内容 1234567891011121314151617181920212223242526@Slf4jpublic class ChannelDemo1 &#123; public static void main(String[] args) &#123; try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/data.txt&quot;, &quot;rw&quot;)) &#123; FileChannel channel = file.getChannel(); ByteBuffer buffer = ByteBuffer.allocate(10); do &#123; // 向 buffer 写入 int len = channel.read(buffer); log.debug(&quot;读到字节数：&#123;&#125;&quot;, len); if (len == -1) &#123; break; &#125; // 切换 buffer 读模式 buffer.flip(); while(buffer.hasRemaining()) &#123; log.debug(&quot;&#123;&#125;&quot;, (char)buffer.get()); &#125; // 切换 buffer 写模式 buffer.clear(); &#125; while (true); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出 123456789101112131415161710:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 读到字节数：1010:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 110:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 210:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 310:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 410:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 510:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 610:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 710:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 810:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 910:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 010:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 读到字节数：410:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - a10:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - b10:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - c10:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - d10:39:03 [DEBUG] [main] c.i.n.ChannelDemo1 - 读到字节数：-1 2.1 ByteBuffer 正确使用姿势 向 buffer 写入数据，例如调用 channel.read(buffer) 调用 flip() 切换至读模式 从 buffer 读取数据，例如调用 buffer.get() 调用 clear() 或 compact() 切换至写模式 重复 1~4 步骤 2.2 ByteBuffer 结构ByteBuffer 有以下重要属性 capacity position limit 一开始 写模式下，position 是写入位置，limit 等于容量，下图表示写入了 4 个字节后的状态 flip 动作发生后，position 切换为读取位置，limit 切换为读取限制 读取 4 个字节后，状态 clear 动作发生后，状态 compact 方法，是把未读完的部分向前压缩，然后切换至写模式 💡 调试工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168public class ByteBufferUtil &#123; private static final char[] BYTE2CHAR = new char[256]; private static final char[] HEXDUMP_TABLE = new char[256 * 4]; private static final String[] HEXPADDING = new String[16]; private static final String[] HEXDUMP_ROWPREFIXES = new String[65536 &gt;&gt;&gt; 4]; private static final String[] BYTE2HEX = new String[256]; private static final String[] BYTEPADDING = new String[16]; static &#123; final char[] DIGITS = &quot;0123456789abcdef&quot;.toCharArray(); for (int i = 0; i &lt; 256; i++) &#123; HEXDUMP_TABLE[i &lt;&lt; 1] = DIGITS[i &gt;&gt;&gt; 4 &amp; 0x0F]; HEXDUMP_TABLE[(i &lt;&lt; 1) + 1] = DIGITS[i &amp; 0x0F]; &#125; int i; // Generate the lookup table for hex dump paddings for (i = 0; i &lt; HEXPADDING.length; i++) &#123; int padding = HEXPADDING.length - i; StringBuilder buf = new StringBuilder(padding * 3); for (int j = 0; j &lt; padding; j++) &#123; buf.append(&quot; &quot;); &#125; HEXPADDING[i] = buf.toString(); &#125; // Generate the lookup table for the start-offset header in each row (up to 64KiB). for (i = 0; i &lt; HEXDUMP_ROWPREFIXES.length; i++) &#123; StringBuilder buf = new StringBuilder(12); buf.append(NEWLINE); buf.append(Long.toHexString(i &lt;&lt; 4 &amp; 0xFFFFFFFFL | 0x100000000L)); buf.setCharAt(buf.length() - 9, &#x27;|&#x27;); buf.append(&#x27;|&#x27;); HEXDUMP_ROWPREFIXES[i] = buf.toString(); &#125; // Generate the lookup table for byte-to-hex-dump conversion for (i = 0; i &lt; BYTE2HEX.length; i++) &#123; BYTE2HEX[i] = &#x27; &#x27; + StringUtil.byteToHexStringPadded(i); &#125; // Generate the lookup table for byte dump paddings for (i = 0; i &lt; BYTEPADDING.length; i++) &#123; int padding = BYTEPADDING.length - i; StringBuilder buf = new StringBuilder(padding); for (int j = 0; j &lt; padding; j++) &#123; buf.append(&#x27; &#x27;); &#125; BYTEPADDING[i] = buf.toString(); &#125; // Generate the lookup table for byte-to-char conversion for (i = 0; i &lt; BYTE2CHAR.length; i++) &#123; if (i &lt;= 0x1f || i &gt;= 0x7f) &#123; BYTE2CHAR[i] = &#x27;.&#x27;; &#125; else &#123; BYTE2CHAR[i] = (char) i; &#125; &#125; &#125; /** * 打印所有内容 * @param buffer */ public static void debugAll(ByteBuffer buffer) &#123; int oldlimit = buffer.limit(); buffer.limit(buffer.capacity()); StringBuilder origin = new StringBuilder(256); appendPrettyHexDump(origin, buffer, 0, buffer.capacity()); System.out.println(&quot;+--------+-------------------- all ------------------------+----------------+&quot;); System.out.printf(&quot;position: [%d], limit: [%d]\\n&quot;, buffer.position(), oldlimit); System.out.println(origin); buffer.limit(oldlimit); &#125; /** * 打印可读取内容 * @param buffer */ public static void debugRead(ByteBuffer buffer) &#123; StringBuilder builder = new StringBuilder(256); appendPrettyHexDump(builder, buffer, buffer.position(), buffer.limit() - buffer.position()); System.out.println(&quot;+--------+-------------------- read -----------------------+----------------+&quot;); System.out.printf(&quot;position: [%d], limit: [%d]\\n&quot;, buffer.position(), buffer.limit()); System.out.println(builder); &#125; private static void appendPrettyHexDump(StringBuilder dump, ByteBuffer buf, int offset, int length) &#123; if (isOutOfBounds(offset, length, buf.capacity())) &#123; throw new IndexOutOfBoundsException( &quot;expected: &quot; + &quot;0 &lt;= offset(&quot; + offset + &quot;) &lt;= offset + length(&quot; + length + &quot;) &lt;= &quot; + &quot;buf.capacity(&quot; + buf.capacity() + &#x27;)&#x27;); &#125; if (length == 0) &#123; return; &#125; dump.append( &quot; +-------------------------------------------------+&quot; + NEWLINE + &quot; | 0 1 2 3 4 5 6 7 8 9 a b c d e f |&quot; + NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;); final int startIndex = offset; final int fullRows = length &gt;&gt;&gt; 4; final int remainder = length &amp; 0xF; // Dump the rows which have 16 bytes. for (int row = 0; row &lt; fullRows; row++) &#123; int rowStartIndex = (row &lt;&lt; 4) + startIndex; // Per-row prefix. appendHexDumpRowPrefix(dump, row, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + 16; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) &#123; dump.append(BYTE2HEX[getUnsignedByte(buf, j)]); &#125; dump.append(&quot; |&quot;); // ASCII dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) &#123; dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]); &#125; dump.append(&#x27;|&#x27;); &#125; // Dump the last row which has less than 16 bytes. if (remainder != 0) &#123; int rowStartIndex = (fullRows &lt;&lt; 4) + startIndex; appendHexDumpRowPrefix(dump, fullRows, rowStartIndex); // Hex dump int rowEndIndex = rowStartIndex + remainder; for (int j = rowStartIndex; j &lt; rowEndIndex; j++) &#123; dump.append(BYTE2HEX[getUnsignedByte(buf, j)]); &#125; dump.append(HEXPADDING[remainder]); dump.append(&quot; |&quot;); // Ascii dump for (int j = rowStartIndex; j &lt; rowEndIndex; j++) &#123; dump.append(BYTE2CHAR[getUnsignedByte(buf, j)]); &#125; dump.append(BYTEPADDING[remainder]); dump.append(&#x27;|&#x27;); &#125; dump.append(NEWLINE + &quot;+--------+-------------------------------------------------+----------------+&quot;); &#125; private static void appendHexDumpRowPrefix(StringBuilder dump, int row, int rowStartIndex) &#123; if (row &lt; HEXDUMP_ROWPREFIXES.length) &#123; dump.append(HEXDUMP_ROWPREFIXES[row]); &#125; else &#123; dump.append(NEWLINE); dump.append(Long.toHexString(rowStartIndex &amp; 0xFFFFFFFFL | 0x100000000L)); dump.setCharAt(dump.length() - 9, &#x27;|&#x27;); dump.append(&#x27;|&#x27;); &#125; &#125; public static short getUnsignedByte(ByteBuffer buffer, int index) &#123; return (short) (buffer.get(index) &amp; 0xFF); &#125;&#125; 2.3 ByteBuffer 常见方法分配空间可以使用 allocate 方法为 ByteBuffer 分配空间，其它 buffer 类也有该方法 1234567891011121314151617package com.hongliang.netty.c1;import java.nio.ByteBuffer;/** * @author Hongliang Zhu * @create 2021-08-22 0:06 */public class AllocateByteBufferTest &#123; public static void main(String[] args) &#123; System.out.println(ByteBuffer.allocate(16).getClass()); System.out.println(ByteBuffer.allocateDirect(16).getClass()); &#125;&#125; class java.nio.HeapByteBuffer : 堆中分配， 受到GC影响，读写效率低下 class java.nio.DirectByteBuffer： 直接内存， 读写效率高（少一次复制）， 不会受GC影响，分配效率低（需要调用OS系统函数分配）。 向 buffer 写入数据有两种办法 调用 channel 的 read 方法 调用 buffer 自己的 put 方法 1int readBytes = channel.read(buf); 和 1buf.put((byte)127); 从 buffer 读取数据同样有两种办法 调用 channel 的 write 方法 调用 buffer 自己的 get 方法 1int writeBytes = channel.write(buf); 和 1byte b = buf.get(); get 方法会让 position 读指针向后走，如果想重复读取数据 可以调用 rewind 方法将 position 重新置为 0 或者调用 get(int i) 方法获取索引 i 的内容，它不会移动读指针 mark 和 resetmark 是在读取时，做一个标记，即使 position 改变，只要调用 reset 就能回到 mark 的位置 注意 rewind 和 flip 都会清除 mark 位置 字符串与 ByteBuffer 互转123456789ByteBuffer buffer1 = StandardCharsets.UTF_8.encode(&quot;你好&quot;);ByteBuffer buffer2 = Charset.forName(&quot;utf-8&quot;).encode(&quot;你好&quot;);debug(buffer1);debug(buffer2);CharBuffer buffer3 = StandardCharsets.UTF_8.decode(buffer1);System.out.println(buffer3.getClass());System.out.println(buffer3.toString()); 输出 123456789101112 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| e4 bd a0 e5 a5 bd |...... |+--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| e4 bd a0 e5 a5 bd |...... |+--------+-------------------------------------------------+----------------+class java.nio.HeapCharBuffer你好 ⚠️ Buffer 的线程安全 Buffer 是非线程安全的 2.4 Scattering Reads分散读取，有一个文本文件 3parts.txt 1onetwothree 使用如下方式读取，可以将数据填充至多个 buffer 123456789101112131415try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) &#123; FileChannel channel = file.getChannel(); ByteBuffer a = ByteBuffer.allocate(3); ByteBuffer b = ByteBuffer.allocate(3); ByteBuffer c = ByteBuffer.allocate(5); channel.read(new ByteBuffer[]&#123;a, b, c&#125;); a.flip(); b.flip(); c.flip(); debug(a); debug(b); debug(c);&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 结果 123456789101112131415 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 6f 6e 65 |one |+--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 74 77 6f |two |+--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 74 68 72 65 65 |three |+--------+-------------------------------------------------+----------------+ 2.5 Gathering Writes使用如下方式写入，可以将多个 buffer 的数据填充至 channel 12345678910111213141516try (RandomAccessFile file = new RandomAccessFile(&quot;helloword/3parts.txt&quot;, &quot;rw&quot;)) &#123; FileChannel channel = file.getChannel(); ByteBuffer d = ByteBuffer.allocate(4); ByteBuffer e = ByteBuffer.allocate(4); channel.position(11); d.put(new byte[]&#123;&#x27;f&#x27;, &#x27;o&#x27;, &#x27;u&#x27;, &#x27;r&#x27;&#125;); e.put(new byte[]&#123;&#x27;f&#x27;, &#x27;i&#x27;, &#x27;v&#x27;, &#x27;e&#x27;&#125;); d.flip(); e.flip(); debug(d); debug(e); channel.write(new ByteBuffer[]&#123;d, e&#125;);&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 输出 12345678910 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 66 6f 75 72 |four |+--------+-------------------------------------------------+----------------+ +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 66 69 76 65 |five |+--------+-------------------------------------------------+----------------+ 文件内容 1onetwothreefourfive 2.6 练习网络上有多条数据发送给服务端，数据之间使用 \\n 进行分隔但由于某种原因这些数据在接收时，被进行了重新组合，例如原始数据有3条为 Hello,world\\n I’m zhangsan\\n How are you?\\n 变成了下面的两个 byteBuffer (黏包，半包) Hello,world\\nI’m zhangsan\\nHo w are you?\\n 现在要求你编写程序，将错乱的数据恢复成原始的按 \\n 分隔的数据 1234567891011121314151617181920212223242526public static void main(String[] args) &#123; ByteBuffer source = ByteBuffer.allocate(32); // 11 24 source.put(&quot;Hello,world\\nI&#x27;m zhangsan\\nHo&quot;.getBytes()); split(source); source.put(&quot;w are you?\\nhaha!\\n&quot;.getBytes()); split(source);&#125;private static void split(ByteBuffer source) &#123; source.flip(); int oldLimit = source.limit(); for (int i = 0; i &lt; oldLimit; i++) &#123; if (source.get(i) == &#x27;\\n&#x27;) &#123; System.out.println(i); ByteBuffer target = ByteBuffer.allocate(i + 1 - source.position()); // 0 ~ limit source.limit(i + 1); target.put(source); // 从source 读，向 target 写 debugAll(target); source.limit(oldLimit); &#125; &#125; source.compact();&#125; 3. 文件编程3.1 FileChannel⚠️ FileChannel 工作模式 FileChannel 只能工作在阻塞模式下 获取不能直接打开 FileChannel，必须通过 FileInputStream、FileOutputStream 或者 RandomAccessFile 来获取 FileChannel，它们都有 getChannel 方法 通过 FileInputStream 获取的 channel 只能读 通过 FileOutputStream 获取的 channel 只能写 通过 RandomAccessFile 是否能读写根据构造 RandomAccessFile 时的读写模式决定 读取会从 channel 读取数据填充 ByteBuffer，返回值表示读到了多少字节，-1 表示到达了文件的末尾 1int readBytes = channel.read(buffer); 写入写入的正确姿势如下， SocketChannel 1234567ByteBuffer buffer = ...;buffer.put(...); // 存入数据buffer.flip(); // 切换读模式while(buffer.hasRemaining()) &#123; channel.write(buffer);&#125; 在 while 中调用 channel.write 是因为 write 方法并不能保证一次将 buffer 中的内容全部写入 channel 关闭channel 必须关闭，不过调用了 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 close 方法会间接地调用 channel 的 close 方法 位置获取当前位置 1long pos = channel.position(); 设置当前位置 12long newPos = ...;channel.position(newPos); 设置当前位置时，如果设置为文件的末尾 这时读取会返回 -1 这时写入，会追加内容，但要注意如果 position 超过了文件末尾，再写入时在新内容和原末尾之间会有空洞（00） 大小使用 size 方法获取文件的大小 强制写入操作系统出于性能的考虑，会将数据缓存，不是立刻写入磁盘。可以调用 force(true) 方法将文件内容和元数据（文件的权限等信息）立刻写入磁盘 3.2 两个 Channel 传输数据123456789101112String FROM = &quot;helloword/data.txt&quot;;String TO = &quot;helloword/to.txt&quot;;long start = System.nanoTime();try (FileChannel from = new FileInputStream(FROM).getChannel(); FileChannel to = new FileOutputStream(TO).getChannel(); ) &#123; from.transferTo(0, from.size(), to);&#125; catch (IOException e) &#123; e.printStackTrace();&#125;long end = System.nanoTime();System.out.println(&quot;transferTo 用时：&quot; + (end - start) / 1000_000.0); 输出 1transferTo 用时：8.2011 超过 2g 大小的文件传输 123456789101112131415161718public class TestFileChannelTransferTo &#123; public static void main(String[] args) &#123; try ( FileChannel from = new FileInputStream(&quot;data.txt&quot;).getChannel(); FileChannel to = new FileOutputStream(&quot;to.txt&quot;).getChannel(); ) &#123; // 效率高，底层会利用操作系统的零拷贝进行优化 long size = from.size(); // left 变量代表还剩余多少字节 for (long left = size; left &gt; 0; ) &#123; System.out.println(&quot;position:&quot; + (size - left) + &quot; left:&quot; + left); left -= from.transferTo((size - left), left, to); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 实际传输一个超大文件 1234position:0 left:7769948160position:2147483647 left:5622464513position:4294967294 left:3474980866position:6442450941 left:1327497219 3.3 Pathjdk7 引入了 Path 和 Paths 类 Path 用来表示文件路径 Paths 是工具类，用来获取 Path 实例 1234567Path source = Paths.get(&quot;1.txt&quot;); // 相对路径 使用 user.dir 环境变量来定位 1.txtPath source = Paths.get(&quot;d:\\\\1.txt&quot;); // 绝对路径 代表了 d:\\1.txtPath source = Paths.get(&quot;d:/1.txt&quot;); // 绝对路径 同样代表了 d:\\1.txtPath projects = Paths.get(&quot;d:\\\\data&quot;, &quot;projects&quot;); // 代表了 d:\\data\\projects . 代表了当前路径 .. 代表了上一级路径 例如目录结构如下 12345d: |- data |- projects |- a |- b 代码 123Path path = Paths.get(&quot;d:\\\\data\\\\projects\\\\a\\\\..\\\\b&quot;);System.out.println(path);System.out.println(path.normalize()); // 正常化路径 会输出 12d:\\data\\projects\\a\\..\\bd:\\data\\projects\\b 3.4 Files检查文件是否存在 12Path path = Paths.get(&quot;helloword/data.txt&quot;);System.out.println(Files.exists(path)); 创建一级目录 12Path path = Paths.get(&quot;helloword/d1&quot;);Files.createDirectory(path); 如果目录已存在，会抛异常 FileAlreadyExistsException 不能一次创建多级目录，否则会抛异常 NoSuchFileException 创建多级目录用 12Path path = Paths.get(&quot;helloword/d1/d2&quot;);Files.createDirectories(path); 拷贝文件 1234Path source = Paths.get(&quot;helloword/data.txt&quot;);Path target = Paths.get(&quot;helloword/target.txt&quot;);Files.copy(source, target); 如果文件已存在，会抛异常 FileAlreadyExistsException 如果希望用 source 覆盖掉 target，需要用 StandardCopyOption 来控制 1Files.copy(source, target, StandardCopyOption.REPLACE_EXISTING); 移动文件 1234Path source = Paths.get(&quot;helloword/data.txt&quot;);Path target = Paths.get(&quot;helloword/data.txt&quot;);Files.move(source, target, StandardCopyOption.ATOMIC_MOVE); StandardCopyOption.ATOMIC_MOVE 保证文件移动的原子性 删除文件 123Path target = Paths.get(&quot;helloword/target.txt&quot;);Files.delete(target); 如果文件不存在，会抛异常 NoSuchFileException 删除目录 123Path target = Paths.get(&quot;helloword/d1&quot;);Files.delete(target); 如果目录还有内容，会抛异常 DirectoryNotEmptyException 遍历目录文件 123456789101112131415161718192021222324public static void main(String[] args) throws IOException &#123; Path path = Paths.get(&quot;C:\\\\Program Files\\\\Java\\\\jdk1.8.0_91&quot;); AtomicInteger dirCount = new AtomicInteger(); AtomicInteger fileCount = new AtomicInteger(); Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;()&#123; @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException &#123; System.out.println(dir); dirCount.incrementAndGet(); return super.preVisitDirectory(dir, attrs); &#125; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; System.out.println(file); fileCount.incrementAndGet(); return super.visitFile(file, attrs); &#125; &#125;); System.out.println(dirCount); // 133 System.out.println(fileCount); // 1479&#125; 统计 jar 的数目 12345678910111213Path path = Paths.get(&quot;C:\\\\Program Files\\\\Java\\\\jdk1.8.0_91&quot;);AtomicInteger fileCount = new AtomicInteger();Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;()&#123; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; if (file.toFile().getName().endsWith(&quot;.jar&quot;)) &#123; fileCount.incrementAndGet(); &#125; return super.visitFile(file, attrs); &#125;&#125;);System.out.println(fileCount); // 724 删除多级目录 12345678910111213141516Path path = Paths.get(&quot;d:\\\\a&quot;);Files.walkFileTree(path, new SimpleFileVisitor&lt;Path&gt;()&#123; @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException &#123; Files.delete(file); return super.visitFile(file, attrs); &#125; @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException &#123; Files.delete(dir); return super.postVisitDirectory(dir, exc); &#125;&#125;); ⚠️ 删除很危险 删除是危险操作，确保要递归删除的文件夹没有重要内容 拷贝多级目录 123456789101112131415161718192021long start = System.currentTimeMillis();String source = &quot;D:\\\\Snipaste-1.16.2-x64&quot;;String target = &quot;D:\\\\Snipaste-1.16.2-x64aaa&quot;;Files.walk(Paths.get(source)).forEach(path -&gt; &#123; try &#123; String targetName = path.toString().replace(source, target); // 是目录 if (Files.isDirectory(path)) &#123; Files.createDirectory(Paths.get(targetName)); &#125; // 是普通文件 else if (Files.isRegularFile(path)) &#123; Files.copy(path, Paths.get(targetName)); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125;);long end = System.currentTimeMillis();System.out.println(end - start); 4. 网络编程4.1 非阻塞 vs 阻塞阻塞 阻塞模式下，相关方法都会导致线程暂停 ServerSocketChannel.accept 会在没有连接建立时让线程暂停 SocketChannel.read 会在没有数据可读时让线程暂停 阻塞的表现其实就是线程暂停了，暂停期间不会占用 cpu，但线程相当于闲置 单线程下，阻塞方法之间相互影响，几乎不能正常工作，需要多线程支持 但多线程下，有新的问题，体现在以下方面 32 位 jvm 一个线程 320k，64 位 jvm 一个线程 1024k，如果连接数过多，必然导致 OOM，并且线程太多，反而会因为频繁上下文切换导致性能降低 可以采用线程池技术来减少线程数和线程上下文切换，但治标不治本，如果有很多连接建立，但长时间 inactive，会阻塞线程池中所有线程，因此不适合长连接，只适合短连接 服务器端 123456789101112131415161718192021222324252627// 使用 nio 来理解阻塞模式, 单线程// 0. ByteBufferByteBuffer buffer = ByteBuffer.allocate(16);// 1. 创建了服务器ServerSocketChannel ssc = ServerSocketChannel.open();// 2. 绑定监听端口ssc.bind(new InetSocketAddress(8080));// 3. 连接集合List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();while (true) &#123; // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信 log.debug(&quot;connecting...&quot;); SocketChannel sc = ssc.accept(); // 阻塞方法，线程停止运行 log.debug(&quot;connected... &#123;&#125;&quot;, sc); channels.add(sc); for (SocketChannel channel : channels) &#123; // 5. 接收客户端发送的数据 log.debug(&quot;before read... &#123;&#125;&quot;, channel); channel.read(buffer); // 阻塞方法，线程停止运行 buffer.flip(); debugRead(buffer); buffer.clear(); log.debug(&quot;after read...&#123;&#125;&quot;, channel); &#125;&#125; 客户端 123SocketChannel sc = SocketChannel.open();sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));System.out.println(&quot;waiting...&quot;); 非阻塞 非阻塞模式下，相关方法都会不会让线程暂停 在 ServerSocketChannel.accept 在没有连接建立时，会返回 null，继续运行 SocketChannel.read 在没有数据可读时，会返回 0，但线程不必阻塞，可以去执行其它 SocketChannel 的 read 或是去执行 ServerSocketChannel.accept 写数据时，线程只是等待数据写入 Channel 即可，无需等 Channel 通过网络把数据发送出去 但非阻塞模式下，即使没有连接建立，和可读数据，线程仍然在不断运行，白白浪费了 cpu 数据复制过程中，线程实际还是阻塞的（AIO 改进的地方） 服务器端，客户端代码不变 1234567891011121314151617181920212223242526272829// 使用 nio 来理解非阻塞模式, 单线程// 0. ByteBufferByteBuffer buffer = ByteBuffer.allocate(16);// 1. 创建了服务器ServerSocketChannel ssc = ServerSocketChannel.open();ssc.configureBlocking(false); // 非阻塞模式// 2. 绑定监听端口ssc.bind(new InetSocketAddress(8080));// 3. 连接集合List&lt;SocketChannel&gt; channels = new ArrayList&lt;&gt;();while (true) &#123; // 4. accept 建立与客户端连接， SocketChannel 用来与客户端之间通信 SocketChannel sc = ssc.accept(); // 非阻塞，线程还会继续运行，如果没有连接建立，但sc是null if (sc != null) &#123; log.debug(&quot;connected... &#123;&#125;&quot;, sc); sc.configureBlocking(false); // 非阻塞模式 channels.add(sc); &#125; for (SocketChannel channel : channels) &#123; // 5. 接收客户端发送的数据 int read = channel.read(buffer);// 非阻塞，线程仍然会继续运行，如果没有读到数据，read 返回 0 if (read &gt; 0) &#123; buffer.flip(); debugRead(buffer); buffer.clear(); log.debug(&quot;after read...&#123;&#125;&quot;, channel); &#125; &#125;&#125; 多路复用单线程可以配合 Selector 完成对多个 Channel 可读写事件的监控，这称之为多路复用 多路复用仅针对网络 IO、普通文件 IO 没法利用多路复用 如果不用 Selector 的非阻塞模式，线程大部分时间都在做无用功，而 Selector 能够保证 有可连接事件时才去连接 有可读事件才去读取 有可写事件才去写入 限于网络传输能力，Channel 未必时时可写，一旦 Channel 可写，会触发 Selector 的可写事件 4.2 Selector1234567graph TDsubgraph selector 版thread --&gt; selectorselector --&gt; c1(channel)selector --&gt; c2(channel)selector --&gt; c3(channel)end 好处 一个线程配合 selector 就可以监控多个 channel 的事件，事件发生线程才去处理。避免非阻塞模式下所做无用功 让这个线程能够被充分利用 节约了线程的数量 减少了线程上下文切换 创建1Selector selector = Selector.open(); 绑定 Channel 事件也称之为注册事件，绑定的事件 selector 才会关心 12channel.configureBlocking(false);SelectionKey key = channel.register(selector, 绑定事件); channel 必须工作在非阻塞模式 FileChannel 没有非阻塞模式，因此不能配合 selector 一起使用 绑定的事件类型可以有 connect - 客户端连接成功时触发 accept - 服务器端成功接受连接时触发 read - 数据可读入时触发，有因为接收能力弱，数据暂不能读入的情况 write - 数据可写出时触发，有因为发送能力弱，数据暂不能写出的情况 监听 Channel 事件可以通过下面三种方法来监听是否有事件发生，方法的返回值代表有多少 channel 发生了事件 方法1，阻塞直到绑定事件发生 1int count = selector.select(); 方法2，阻塞直到绑定事件发生，或是超时（时间单位为 ms） 1int count = selector.select(long timeout); 方法3，不会阻塞，也就是不管有没有事件，立刻返回，自己根据返回值检查是否有事件 1int count = selector.selectNow(); 💡 select 何时不阻塞 事件发生时 客户端发起连接请求，会触发 accept 事件 客户端发送数据过来，客户端正常、异常关闭时，都会触发 read 事件，另外如果发送的数据大于 buffer 缓冲区，会触发多次读取事件 channel 可写，会触发 write 事件 在 linux 下 nio bug 发生时 调用 selector.wakeup() 调用 selector.close() selector 所在线程 interrupt 4.3 处理 accept 事件客户端代码为 1234567891011public class Client &#123; public static void main(String[] args) &#123; try (Socket socket = new Socket(&quot;localhost&quot;, 8080)) &#123; System.out.println(socket); socket.getOutputStream().write(&quot;world&quot;.getBytes()); System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 服务器端代码为 1234567891011121314151617181920212223242526272829303132333435363738394041@Slf4jpublic class ChannelDemo6 &#123; public static void main(String[] args) &#123; try (ServerSocketChannel channel = ServerSocketChannel.open()) &#123; channel.bind(new InetSocketAddress(8080)); System.out.println(channel); Selector selector = Selector.open(); channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; int count = selector.select();// int count = selector.selectNow(); log.debug(&quot;select count: &#123;&#125;&quot;, count);// if(count &lt;= 0) &#123;// continue;// &#125; // 获取所有事件 Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); // 遍历所有事件，逐一处理 Iterator&lt;SelectionKey&gt; iter = keys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); // 判断事件类型 if (key.isAcceptable()) &#123; ServerSocketChannel c = (ServerSocketChannel) key.channel(); // 必须处理 SocketChannel sc = c.accept(); log.debug(&quot;&#123;&#125;&quot;, sc); &#125; // 处理完毕，必须将事件移除 iter.remove(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 💡 事件发生后能否不处理 事件发生后，要么处理，要么取消（cancel），不能什么都不做，否则下次该事件仍会触发，这是因为 nio 底层使用的是水平触发 4.4 处理 read 事件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4jpublic class ChannelDemo6 &#123; public static void main(String[] args) &#123; try (ServerSocketChannel channel = ServerSocketChannel.open()) &#123; channel.bind(new InetSocketAddress(8080)); System.out.println(channel); Selector selector = Selector.open(); channel.configureBlocking(false); channel.register(selector, SelectionKey.OP_ACCEPT); while (true) &#123; int count = selector.select();// int count = selector.selectNow(); log.debug(&quot;select count: &#123;&#125;&quot;, count);// if(count &lt;= 0) &#123;// continue;// &#125; // 获取所有事件 Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); // 遍历所有事件，逐一处理 Iterator&lt;SelectionKey&gt; iter = keys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); // 判断事件类型 if (key.isAcceptable()) &#123; ServerSocketChannel c = (ServerSocketChannel) key.channel(); // 必须处理 SocketChannel sc = c.accept(); sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_READ); log.debug(&quot;连接已建立: &#123;&#125;&quot;, sc); &#125; else if (key.isReadable()) &#123; SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); int read = sc.read(buffer); if(read == -1) &#123; key.cancel(); sc.close(); &#125; else &#123; buffer.flip(); debug(buffer); &#125; &#125; // 处理完毕，必须将事件移除 iter.remove(); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 开启两个客户端，修改一下发送文字，输出 1234567891011121314151617sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:8080]21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 121:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60367]21:16:39 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 121:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - 连接已建立: java.nio.channels.SocketChannel[connected local=/127.0.0.1:8080 remote=/127.0.0.1:60378]21:16:59 [DEBUG] [main] c.i.n.ChannelDemo6 - select count: 1 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 77 6f 72 6c 64 |world |+--------+-------------------------------------------------+----------------+ 💡 为何要 iter.remove() 因为 select 在事件发生后，就会将相关的 key 放入 selectedKeys 集合，但不会在处理完后从 selectedKeys 集合中移除，需要我们自己编码删除。例如 第一次触发了 ssckey 上的 accept 事件，没有移除 ssckey 第二次触发了 sckey 上的 read 事件，但这时 selectedKeys 中还有上次的 ssckey ，在处理时因为没有真正的 serverSocket 连上了，就会导致空指针异常 💡 cancel 的作用 cancel 会取消注册在 selector 上的 channel，并从 keys 集合中删除 key 后续不会再监听事件 客户端断开后会触发read事件, 需要将key取消（从selector的keys集合中真正删除 key） 不论是异常断开还是正常断开（sc.close()）,都会触发读事件。 1234int read = channel.read(buffer); // 正常断开， read 为-1if(read == -1)&#123; key.cancel();&#125; ⚠️ 不处理边界的问题以前有同学写过这样的代码，思考注释中两个问题，以 bio 为例，其实 nio 道理是一样的 12345678910111213141516171819public class Server &#123; public static void main(String[] args) throws IOException &#123; ServerSocket ss=new ServerSocket(9000); while (true) &#123; Socket s = ss.accept(); InputStream in = s.getInputStream(); // 这里这么写，有没有问题 byte[] arr = new byte[4]; while(true) &#123; int read = in.read(arr); // 这里这么写，有没有问题 if(read == -1) &#123; break; &#125; System.out.println(new String(arr, 0, read)); &#125; &#125; &#125;&#125; 客户端 12345678910public class Client &#123; public static void main(String[] args) throws IOException &#123; Socket max = new Socket(&quot;localhost&quot;, 9000); OutputStream out = max.getOutputStream(); out.write(&quot;hello&quot;.getBytes()); out.write(&quot;world&quot;.getBytes()); out.write(&quot;你好&quot;.getBytes()); max.close(); &#125;&#125; 输出 12345helloworld��好 为什么？ 处理消息的边界 一种思路是固定消息长度，数据包大小一样，服务器按预定长度读取，缺点是浪费带宽 另一种思路是按分隔符拆分，缺点是效率低 TLV 格式，即 Type 类型、Length 长度、Value 数据，类型和长度已知的情况下，就可以方便获取消息大小，分配合适的 buffer，缺点是 buffer 需要提前分配，如果内容过大，则影响 server 吞吐量 Http 1.1 是 TLV 格式 Http 2.0 是 LTV 格式 1234567891011sequenceDiagram participant c1 as 客户端1participant s as 服务器participant b1 as ByteBuffer1participant b2 as ByteBuffer2c1 -&gt;&gt; s: 发送 01234567890abcdef3333\\rs -&gt;&gt; b1: 第一次 read 存入 01234567890abcdefs -&gt;&gt; b2: 扩容b1 -&gt;&gt; b2: 拷贝 01234567890abcdefs -&gt;&gt; b2: 第二次 read 存入 3333\\rb2 -&gt;&gt; b2: 01234567890abcdef3333\\r 服务器端 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879private static void split(ByteBuffer source) &#123; source.flip(); for (int i = 0; i &lt; source.limit(); i++) &#123; // 找到一条完整消息 if (source.get(i) == &#x27;\\n&#x27;) &#123; int length = i + 1 - source.position(); // 把这条完整消息存入新的 ByteBuffer ByteBuffer target = ByteBuffer.allocate(length); // 从 source 读，向 target 写 for (int j = 0; j &lt; length; j++) &#123; target.put(source.get()); &#125; debugAll(target); &#125; &#125; source.compact(); // 0123456789abcdef position 16 limit 16&#125;public static void main(String[] args) throws IOException &#123; // 1. 创建 selector, 管理多个 channel Selector selector = Selector.open(); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); // 2. 建立 selector 和 channel 的联系（注册） // SelectionKey 就是将来事件发生后，通过它可以知道事件和哪个channel的事件 SelectionKey sscKey = ssc.register(selector, 0, null); // key 只关注 accept 事件 sscKey.interestOps(SelectionKey.OP_ACCEPT); log.debug(&quot;sscKey:&#123;&#125;&quot;, sscKey); ssc.bind(new InetSocketAddress(8080)); while (true) &#123; // 3. select 方法, 没有事件发生，线程阻塞，有事件，线程才会恢复运行 // select 在事件未处理时，它不会阻塞, 事件发生后要么处理，要么取消，不能置之不理 selector.select(); // 4. 处理事件, selectedKeys 内部包含了所有发生的事件 Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); // accept, read while (iter.hasNext()) &#123; SelectionKey key = iter.next(); // 处理key 时，要从 selectedKeys 集合中删除，否则下次处理就会有问题 iter.remove(); log.debug(&quot;key: &#123;&#125;&quot;, key); // 5. 区分事件类型 if (key.isAcceptable()) &#123; // 如果是 accept ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel sc = channel.accept(); sc.configureBlocking(false); ByteBuffer buffer = ByteBuffer.allocate(16); // attachment // 将一个 byteBuffer 作为附件关联到 selectionKey 上 SelectionKey scKey = sc.register(selector, 0, buffer); scKey.interestOps(SelectionKey.OP_READ); log.debug(&quot;&#123;&#125;&quot;, sc); log.debug(&quot;scKey:&#123;&#125;&quot;, scKey); &#125; else if (key.isReadable()) &#123; // 如果是 read try &#123; SocketChannel channel = (SocketChannel) key.channel(); // 拿到触发事件的channel // 获取 selectionKey 上关联的附件 ByteBuffer buffer = (ByteBuffer) key.attachment(); int read = channel.read(buffer); // 如果是正常断开，read 的方法的返回值是 -1 if(read == -1) &#123; key.cancel(); &#125; else &#123; split(buffer); // 需要扩容 if (buffer.position() == buffer.limit()) &#123; ByteBuffer newBuffer = ByteBuffer.allocate(buffer.capacity() * 2); buffer.flip(); newBuffer.put(buffer); // 0123456789abcdef3333\\n key.attach(newBuffer); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); key.cancel(); // 因为客户端断开了,因此需要将 key 取消（从 selector 的 keys 集合中真正删除 key） &#125; &#125; &#125; &#125;&#125; 客户端 1234567SocketChannel sc = SocketChannel.open();sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080));SocketAddress address = sc.getLocalAddress();// sc.write(Charset.defaultCharset().encode(&quot;hello\\nworld\\n&quot;));sc.write(Charset.defaultCharset().encode(&quot;0123\\n456789abcdef&quot;));sc.write(Charset.defaultCharset().encode(&quot;0123456789abcdef3333\\n&quot;));System.in.read(); ByteBuffer 大小分配 每个 channel 都需要记录可能被切分的消息，因为 ByteBuffer 不能被多个 channel 共同使用，因此需要为每个 channel 维护一个独立的 ByteBuffer ByteBuffer 不能太大，比如一个 ByteBuffer 1Mb 的话，要支持百万连接就要 1Tb 内存，因此需要设计大小可变的 ByteBuffer 一种思路是首先分配一个较小的 buffer，例如 4k，如果发现数据不够，再分配 8k 的 buffer，将 4k buffer 内容拷贝至 8k buffer，优点是消息连续容易处理，缺点是数据拷贝耗费性能，参考实现 http://tutorials.jenkov.com/java-performance/resizable-array.html 另一种思路是用多个数组组成 buffer，一个数组不够，把多出来的内容写入新的数组，与前面的区别是消息存储不连续解析复杂，优点是避免了拷贝引起的性能损耗 4.5 处理 write 事件一次无法写完例子 非阻塞模式下，无法保证把 buffer 中所有数据都写入 channel，因此需要追踪 write 方法的返回值（代表实际写入字节数） 用 selector 监听所有 channel 的可写事件，每个 channel 都需要一个 key 来跟踪 buffer，但这样又会导致占用内存过多，就有两阶段策略 当消息处理器第一次写入消息时，才将 channel 注册到 selector 上 selector 检查 channel 上的可写事件，如果所有的数据写完了，就取消 channel 的注册 如果不取消，会每次可写均会触发 write 事件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class WriteServer &#123; public static void main(String[] args) throws IOException &#123; ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.configureBlocking(false); ssc.bind(new InetSocketAddress(8080)); Selector selector = Selector.open(); ssc.register(selector, SelectionKey.OP_ACCEPT); while(true) &#123; selector.select(); Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); if (key.isAcceptable()) &#123; SocketChannel sc = ssc.accept(); sc.configureBlocking(false); SelectionKey sckey = sc.register(selector, SelectionKey.OP_READ); // 1. 向客户端发送内容 StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; 3000000; i++) &#123; sb.append(&quot;a&quot;); &#125; ByteBuffer buffer = Charset.defaultCharset().encode(sb.toString()); int write = sc.write(buffer); // 3. write 表示实际写了多少字节 System.out.println(&quot;实际写入字节:&quot; + write); // 4. 如果有剩余未读字节，才需要关注写事件 if (buffer.hasRemaining()) &#123; // read 1 write 4 // 在原有关注事件的基础上，多关注 写事件 sckey.interestOps(sckey.interestOps() + SelectionKey.OP_WRITE); // 把 buffer 作为附件加入 sckey sckey.attach(buffer); &#125; &#125; else if (key.isWritable()) &#123; ByteBuffer buffer = (ByteBuffer) key.attachment(); SocketChannel sc = (SocketChannel) key.channel(); int write = sc.write(buffer); System.out.println(&quot;实际写入字节:&quot; + write); if (!buffer.hasRemaining()) &#123; // 写完了 key.interestOps(key.interestOps() - SelectionKey.OP_WRITE); key.attach(null); &#125; &#125; &#125; &#125; &#125;&#125; 客户端 1234567891011121314151617181920212223242526public class WriteClient &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); SocketChannel sc = SocketChannel.open(); sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_CONNECT | SelectionKey.OP_READ); sc.connect(new InetSocketAddress(&quot;localhost&quot;, 8080)); int count = 0; while (true) &#123; selector.select(); Iterator&lt;SelectionKey&gt; iter = selector.selectedKeys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); if (key.isConnectable()) &#123; System.out.println(sc.finishConnect()); &#125; else if (key.isReadable()) &#123; ByteBuffer buffer = ByteBuffer.allocate(1024 * 1024); count += sc.read(buffer); buffer.clear(); System.out.println(count); &#125; &#125; &#125; &#125;&#125; 💡 write 为何要取消只要向 channel 发送数据时，socket 缓冲可写，这个事件会频繁触发，因此应当只在 socket 缓冲区写不下时再关注可写事件，数据写完之后再取消关注 4.6 更进一步💡 利用多线程优化 现在都是多核 cpu，设计时要充分考虑别让 cpu 的力量被白白浪费 前面的代码只有一个选择器，没有充分利用多核 cpu，如何改进呢？ 分两组选择器 单线程配一个选择器，专门处理 accept 事件 创建 cpu 核心数的线程，每个线程配一个选择器，轮流处理 read 事件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132public class ChannelDemo7 &#123; public static void main(String[] args) throws IOException &#123; new BossEventLoop().register(); &#125; @Slf4j static class BossEventLoop implements Runnable &#123; private Selector boss; private WorkerEventLoop[] workers; private volatile boolean start = false; AtomicInteger index = new AtomicInteger(); public void register() throws IOException &#123; if (!start) &#123; ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(8080)); ssc.configureBlocking(false); boss = Selector.open(); SelectionKey ssckey = ssc.register(boss, 0, null); ssckey.interestOps(SelectionKey.OP_ACCEPT); workers = initEventLoops(); new Thread(this, &quot;boss&quot;).start(); log.debug(&quot;boss start...&quot;); start = true; &#125; &#125; public WorkerEventLoop[] initEventLoops() &#123;// EventLoop[] eventLoops = new EventLoop[Runtime.getRuntime().availableProcessors()]; WorkerEventLoop[] workerEventLoops = new WorkerEventLoop[2]; for (int i = 0; i &lt; workerEventLoops.length; i++) &#123; workerEventLoops[i] = new WorkerEventLoop(i); &#125; return workerEventLoops; &#125; @Override public void run() &#123; while (true) &#123; try &#123; boss.select(); Iterator&lt;SelectionKey&gt; iter = boss.selectedKeys().iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); iter.remove(); if (key.isAcceptable()) &#123; ServerSocketChannel c = (ServerSocketChannel) key.channel(); SocketChannel sc = c.accept(); sc.configureBlocking(false); log.debug(&quot;&#123;&#125; connected&quot;, sc.getRemoteAddress()); workers[index.getAndIncrement() % workers.length].register(sc); &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; @Slf4j static class WorkerEventLoop implements Runnable &#123; private Selector worker; private volatile boolean start = false; private int index; private final ConcurrentLinkedQueue&lt;Runnable&gt; tasks = new ConcurrentLinkedQueue&lt;&gt;(); public WorkerEventLoop(int index) &#123; this.index = index; &#125; public void register(SocketChannel sc) throws IOException &#123; if (!start) &#123; worker = Selector.open(); new Thread(this, &quot;worker-&quot; + index).start(); start = true; &#125; tasks.add(() -&gt; &#123; try &#123; SelectionKey sckey = sc.register(worker, 0, null); sckey.interestOps(SelectionKey.OP_READ); worker.selectNow(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;); worker.wakeup(); &#125; @Override public void run() &#123; while (true) &#123; try &#123; worker.select(); Runnable task = tasks.poll(); if (task != null) &#123; task.run(); &#125; Set&lt;SelectionKey&gt; keys = worker.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = keys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); if (key.isReadable()) &#123; SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer buffer = ByteBuffer.allocate(128); try &#123; int read = sc.read(buffer); if (read == -1) &#123; key.cancel(); sc.close(); &#125; else &#123; buffer.flip(); log.debug(&quot;&#123;&#125; message:&quot;, sc.getRemoteAddress()); debugAll(buffer); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); key.cancel(); sc.close(); &#125; &#125; iter.remove(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 💡 如何拿到 cpu 个数 Runtime.getRuntime().availableProcessors() 如果工作在 docker 容器下，因为容器不是物理隔离的，会拿到物理 cpu 个数，而不是容器申请时的个数 这个问题直到 jdk 10 才修复，使用 jvm 参数 UseContainerSupport 配置， 默认开启 4.7 UDP UDP 是无连接的，client 发送数据不会管 server 是否开启 server 这边的 receive 方法会将接收到的数据存入 byte buffer，但如果数据报文超过 buffer 大小，多出来的数据会被默默抛弃 首先启动服务器端 1234567891011121314public class UdpServer &#123; public static void main(String[] args) &#123; try (DatagramChannel channel = DatagramChannel.open()) &#123; channel.socket().bind(new InetSocketAddress(9999)); System.out.println(&quot;waiting...&quot;); ByteBuffer buffer = ByteBuffer.allocate(32); channel.receive(buffer); buffer.flip(); debug(buffer); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出 1waiting... 运行客户端 1234567891011public class UdpClient &#123; public static void main(String[] args) &#123; try (DatagramChannel channel = DatagramChannel.open()) &#123; ByteBuffer buffer = StandardCharsets.UTF_8.encode(&quot;hello&quot;); InetSocketAddress address = new InetSocketAddress(&quot;localhost&quot;, 9999); channel.send(buffer, address); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 接下来服务器端输出 12345 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 68 65 6c 6c 6f |hello |+--------+-------------------------------------------------+----------------+ 5. NIO vs BIO5.1 stream vs channel stream 不会自动缓冲数据，channel 会利用系统提供的发送缓冲区、接收缓冲区（更为底层） stream 仅支持阻塞 API，channel 同时支持阻塞、非阻塞 API，网络 channel 可配合 selector 实现多路复用 二者均为全双工，即读写可以同时进行 5.2 IO 模型同步阻塞、同步非阻塞、同步多路复用、异步阻塞（没有此情况）、异步非阻塞 同步：线程自己去获取结果（一个线程） 异步：线程自己不去获取结果，而是由其它线程送结果（至少两个线程） 当调用一次 channel.read 或 stream.read 后，会切换至操作系统内核态来完成真正数据读取，而读取又分为两个阶段，分别为： 等待数据阶段 复制数据阶段 阻塞 IO 非阻塞 IO 多路复用 信号驱动 异步 IO 阻塞 IO vs 多路复用 🔖 参考UNIX 网络编程 - 卷 I 5.3 零拷贝传统 IO 问题传统的 IO 将一个文件通过 socket 写出 12345678File f = new File(&quot;helloword/data.txt&quot;);RandomAccessFile file = new RandomAccessFile(file, &quot;r&quot;);byte[] buf = new byte[(int)f.length()];file.read(buf);Socket socket = ...;socket.getOutputStream().write(buf); 内部工作流程是这样的： java 本身并不具备 IO 读写能力，因此 read 方法调用后，要从 java 程序的用户态切换至内核态，去调用操作系统（Kernel）的读能力，将数据读入内核缓冲区。这期间用户线程阻塞，操作系统使用 DMA（Direct Memory Access）来实现文件读，其间也不会使用 cpu DMA 也可以理解为硬件单元，用来解放 cpu 完成文件 IO 从内核态切换回用户态，将数据从内核缓冲区读入用户缓冲区（即 byte[] buf），这期间 cpu 会参与拷贝，无法利用 DMA 调用 write 方法，这时将数据从用户缓冲区（byte[] buf）写入 socket 缓冲区，cpu 会参与拷贝 接下来要向网卡写数据，这项能力 java 又不具备，因此又得从用户态切换至内核态，调用操作系统的写能力，使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu 可以看到中间环节较多，java 的 IO 实际不是物理设备级别的读写，而是缓存的复制，底层的真正读写是操作系统来完成的 用户态与内核态的切换发生了 3 次，这个操作比较重量级 数据拷贝了共 4 次 NIO 优化通过 DirectByteBuf ByteBuffer.allocate(10) HeapByteBuffer 使用的还是 java 内存 ByteBuffer.allocateDirect(10) DirectByteBuffer 使用的是操作系统内存 大部分步骤与优化前相同，不再赘述。唯有一点：java 可以使用 DirectByteBuf 将堆外内存映射到 jvm 内存中来直接访问使用 这块内存不受 jvm 垃圾回收的影响，因此内存地址固定，有助于 IO 读写 java 中的 DirectByteBuf 对象仅维护了此内存的虚引用，内存回收分成两步 DirectByteBuf 对象被垃圾回收，将虚引用加入引用队列 通过专门线程访问引用队列，根据虚引用释放堆外内存 减少了一次数据拷贝，用户态与内核态的切换次数没有减少 进一步优化（底层采用了 linux 2.1 后提供的 sendFile 方法），java 中对应着两个 channel 调用 transferTo/transferFrom 方法拷贝数据 java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 cpu 数据从内核缓冲区传输到 socket 缓冲区，cpu 会参与拷贝 最后使用 DMA 将 socket 缓冲区的数据写入网卡，不会使用 cpu 可以看到 只发生了一次用户态与内核态的切换 数据拷贝了 3 次 进一步优化（linux 2.4） java 调用 transferTo 方法后，要从 java 程序的用户态切换至内核态，使用 DMA将数据读入内核缓冲区，不会使用 cpu 只会将一些 offset 和 length 信息拷入 socket 缓冲区，几乎无消耗 使用 DMA 将 内核缓冲区的数据写入网卡，不会使用 cpu 整个过程仅只发生了一次用户态与内核态的切换，数据拷贝了 2 次。所谓的【零拷贝】，并不是真正无拷贝，而是在不会拷贝重复数据到 jvm 内存中，零拷贝的优点有 更少的用户态与内核态的切换 不利用 cpu 计算，减少 cpu 缓存伪共享 零拷贝适合小文件传输 5.3 AIOAIO 用来解决数据复制阶段的阻塞问题 同步意味着，在进行读写操作时，线程需要等待结果，还是相当于闲置 异步意味着，在进行读写操作时，线程不必等待结果，而是将来由操作系统来通过回调方式由另外的线程来获得结果 异步模型需要底层操作系统（Kernel）提供支持 Windows 系统通过 IOCP 实现了真正的异步 IO Linux 系统异步 IO 在 2.6 版本引入，但其底层实现还是用多路复用模拟了异步 IO，性能没有优势 文件 AIO先来看看 AsynchronousFileChannel 123456789101112131415161718192021222324252627282930@Slf4jpublic class AioDemo1 &#123; public static void main(String[] args) throws IOException &#123; try&#123; AsynchronousFileChannel s = AsynchronousFileChannel.open( Paths.get(&quot;1.txt&quot;), StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(2); log.debug(&quot;begin...&quot;); s.read(buffer, 0, null, new CompletionHandler&lt;Integer, ByteBuffer&gt;() &#123; @Override public void completed(Integer result, ByteBuffer attachment) &#123; log.debug(&quot;read completed...&#123;&#125;&quot;, result); buffer.flip(); debug(buffer); &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; log.debug(&quot;read failed...&quot;); &#125; &#125;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; log.debug(&quot;do other things...&quot;); System.in.read(); &#125;&#125; 输出 1234567813:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - begin...13:44:56 [DEBUG] [main] c.i.aio.AioDemo1 - do other things...13:44:56 [DEBUG] [Thread-5] c.i.aio.AioDemo1 - read completed...2 +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f |+--------+-------------------------------------------------+----------------+|00000000| 61 0d |a. |+--------+-------------------------------------------------+----------------+ 可以看到 响应文件读取成功的是另一个线程 Thread-5 主线程并没有 IO 操作阻塞 💡 守护线程默认文件 AIO 使用的线程都是守护线程，所以最后要执行 System.in.read() 以避免守护线程意外结束 网络 AIO123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100public class AioServer &#123; public static void main(String[] args) throws IOException &#123; AsynchronousServerSocketChannel ssc = AsynchronousServerSocketChannel.open(); ssc.bind(new InetSocketAddress(8080)); ssc.accept(null, new AcceptHandler(ssc)); System.in.read(); &#125; private static void closeChannel(AsynchronousSocketChannel sc) &#123; try &#123; System.out.printf(&quot;[%s] %s close\\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress()); sc.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static class ReadHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private final AsynchronousSocketChannel sc; public ReadHandler(AsynchronousSocketChannel sc) &#123; this.sc = sc; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; try &#123; if (result == -1) &#123; closeChannel(sc); return; &#125; System.out.printf(&quot;[%s] %s read\\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress()); attachment.flip(); System.out.println(Charset.defaultCharset().decode(attachment)); attachment.clear(); // 处理完第一个 read 时，需要再次调用 read 方法来处理下一个 read 事件 sc.read(attachment, attachment, this); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; closeChannel(sc); exc.printStackTrace(); &#125; &#125; private static class WriteHandler implements CompletionHandler&lt;Integer, ByteBuffer&gt; &#123; private final AsynchronousSocketChannel sc; private WriteHandler(AsynchronousSocketChannel sc) &#123; this.sc = sc; &#125; @Override public void completed(Integer result, ByteBuffer attachment) &#123; // 如果作为附件的 buffer 还有内容，需要再次 write 写出剩余内容 if (attachment.hasRemaining()) &#123; sc.write(attachment); &#125; &#125; @Override public void failed(Throwable exc, ByteBuffer attachment) &#123; exc.printStackTrace(); closeChannel(sc); &#125; &#125; private static class AcceptHandler implements CompletionHandler&lt;AsynchronousSocketChannel, Object&gt; &#123; private final AsynchronousServerSocketChannel ssc; public AcceptHandler(AsynchronousServerSocketChannel ssc) &#123; this.ssc = ssc; &#125; @Override public void completed(AsynchronousSocketChannel sc, Object attachment) &#123; try &#123; System.out.printf(&quot;[%s] %s connected\\n&quot;, Thread.currentThread().getName(), sc.getRemoteAddress()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; ByteBuffer buffer = ByteBuffer.allocate(16); // 读事件由 ReadHandler 处理 sc.read(buffer, buffer, new ReadHandler(sc)); // 写事件由 WriteHandler 处理 sc.write(Charset.defaultCharset().encode(&quot;server hello!&quot;), ByteBuffer.allocate(16), new WriteHandler(sc)); // 处理完第一个 accpet 时，需要再次调用 accept 方法来处理下一个 accept 事件 ssc.accept(null, this); &#125; @Override public void failed(Throwable exc, Object attachment) &#123; exc.printStackTrace(); &#125; &#125;&#125;","path":"2021/08/22/Netty01-nio/","date":"08-22","excerpt":"","tags":[{"name":"NIO","slug":"NIO","permalink":"https://castile.github.io/tags/NIO/"},{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"}]},{"title":"ZooKeeper集群安装","text":"ZooKeeper的集群安装集群规划 需要三台服务器，至少三台吧。在三台节点上都部署zookeeper zookeeper安装包 三个节点的ip分别为：192.168.175.130、192.168.175.129、192.168.175.128 安装部署zookeeper安装将zookeeper安装包都复制到对应节点的/opt/目录下: 使用scp命令用于给远程服务器传输数据。 12scp apache-zookeeper-3.5.7-bin.tar.gz root@192.168.175.128:/opt/scp apache-zookeeper-3.5.7-bin.tar.gz root@192.168.175.129:/opt/ 配置服务器编号 在/opt/zookeeper-3.5.7/这个目录下创建 zkData 1mkdir zkData 然后在zkData里面创建一个myid文件，文件名称必须是myid。 在文件中添加与 server 对应的编号（注意：上下不要有空行，左右不要有空格） 注意：添加 myid 文件，一定要在 Linux 里面创建，在 notepad++里面很可能乱码 在其他的节点上也做这样的配置（可以复制过去）。 配置zoo.cfg文件 注意其他节点也需要修改对应的conf目录下的zoo.cfg配置中dataDir为zkData。 增加如下配置 1234#######################cluster########################## server.2=192.168.175.130:2888:3888 server.3=192.168.175.128:2888:3888 server.4=192.168.175.129:2888:3888 配置参数解读 server.A=B:C:D: A 是一个数字，表示这个是第几号服务器； 集群模式下配置一个文件 myid，这个文件在 dataDir 目录下，这个文件里面有一个数据 就是 A 的值，Zookeeper 启动时读取此文件，拿到里面的数据与 zoo.cfg 里面的配置信息比较从而判断到底是哪个 server。 B 是这个服务器的地址； C 是这个服务器 Follower 与集群中的 Leader 服务器交换信息的端口； D 是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 注意：这个zoo.cfg文件里面千万不能有空格！！！！！！！！！！！不然启动报错。。。 查看日志说是配置文件的问题： 修改后可以顺利启动。 同步zoo.cfg配置文件 ​ xsync zoo.cfg 上述命令需要配置集群，修改hostname 已经hosts文件。暂未配置。 这一步骤将zoo.cfg同步到其他节点中。 集群操作 分别在三个节点上启动 zookeeper 1bin/zkServer.sh start 查看各个节点的状态 1bin/zkServer.sh status 192.168.175.128：follower 192.168.175.129：leader 192.168.175.130：follower 至此，三个节点搭建完毕。 修改主机名ip地址可以更换，配置。 每次都需要输入ip地址来连接很麻烦，我们为三台虚拟机的主机重命名为castile、castile2、castile3 修改/etc/sysconf/network 12345vim /etc/sysconfig/network添加：NETWORKING=yesHOSTNAME=castile2 修改hosts文件 1vim /etc/hosts 也可以将其他两台机器的ip和hostname进行配置。 重启网卡 1sevice network restart 设置主机名 1hostnamectl set-hostname castile2 重启即可 集群ssh免密登录集群之间操作登录其他虚拟机的时候需要输入密码，非常麻烦，可以设置ssh免密登录。 在主要操作的机器中使用ssh-keygen生成公钥和私钥 1ssh-keygen -t rsa 一路回车即可，秘钥保存在~/.ssh/ 中，其中id_rsa为私钥，id_rsa.pub为公钥。 将公钥的内容复制到authorized_keys里面 12cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyscat authorized_keys 在另外两台虚拟机进行同样的操作，并将他们的公钥内容复制到主机器的authorized_keys中，然后将这个authorized_keys复制到其他两台机器中~/.ssh/中。 12345678910111213141516171819[root@castile .ssh]# cat ~/.ssh/id2.pub &gt;&gt; ~/.ssh/authorized_keys[root@castile .ssh]# cat ~/.ssh/id3.pub &gt;&gt; ~/.ssh/authorized_keys[root@castile .ssh]# cat authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCkWhPVxk5SoFeQ1KX4Haxvhhrwai3w3A8MhVqoq3aS/shiMrxbGNLcN9O0s7KgULKt1N4vB0zM2LHuNTj8hfleyuM26tNHvZ4hj6w91AoNtrdpWc7NyuYXrVZUe/EEmr+r7OG30eR1mVvP5zXH0a5RMhF8FWa/FBeMKqFJicf9NVAo3r9h0ly9MnYP6D6E7ZRzqWSmZb0ifssyU4lSVC+wKtSEo32YGVegPMeEJQN5XPIdKy04C/7r6IfaKGxQ9B6HMLZ0y3ACFecivV36YYSOpffN6Ihvw6Aj0v1QM0C3jyRFDFryVj4Km2SE+CSJqHFjCKssFGv/AEpWA2XE9XIv root@castile.comssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDk6hJBiXtUNi5RY+iDuzYrsg4fg5aLDnluecSXbGyzK+qb5p2xyKmh7dvVOFBer4EgzIm0uj84csvmnP03jtq+4iVDmqy01AE7VQKm11bTiK861FnPoeIeuITk+/YFvVA8zVMWdMpd1R7ZDAFUHKaIPHKKpk7z94SM9j62GDPg8E6Am0rozSAAeRZA09/uDHqCZ4nsK5CyL6Ycg/ZIyIEfHMesnsWUMTMUdRMIACLMYxDrbki30Zt6qZmTsqEFeRDD0URQ2jwUFynlWe8hhXQgT4R0GJQwZDvQ5TksqP6cON0KBcyQH+SVw4oJgJlDeYsEU0WgYTeQoMFdfn8JBCXT root@castile2ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDNgPj2aqwx2fXCWvEdf0lgf3AZPD7CDNiZiB5XlLiLzoUxDp/+graEr28ORY2/pDDTRGqge+UwJj+7/foCfyp662dceW9et5gnGE2HdmBGjo+ASdgSNu677cOx81E9iGjjLQTsp4GCGoFPEY8coYnR9S7MIb96BXLG7Ai0WzHocPETLUypFwnRDrc116+QO751fsmXL1R9s+ScbJj3AJVJ1Ef0aMG/VTpVHBj8bej67mKcV8A5rNCX1eVwh3XEqpGcvSymWXRAWat2fbiT3kKq4F4yg+4mm0qjKpXIYKyGmgvsHJ1LI2PIyes/fbLEVJPzaclh3I93SeXuE5jydRVx root@castile3[root@castile .ssh]# scp -r authorized_keys root@192.168.160.201:~/.ssh/root@192.168.160.201&#x27;s password:authorized_keys 100% 1188 529.8KB/s 00:00[root@castile .ssh]# scp -r authorized_keys root@192.168.160.203:~/.ssh/root@192.168.160.203&#x27;s password:authorized_keys 100% 1188 200.3KB/s 00:00[root@castile .ssh]# ssh castile2ssh: Could not resolve hostname castile2: Name or service not known[root@castile .ssh]# ssh 192.168.160.203Last login: Sun Aug 8 13:22:27 2021 from 192.168.160.1 ZK 集群启动停止脚本1vim zk.sh 12345678910111213141516171819202122232425262728#!/bin/bashcase $1 in &quot;start&quot; )&#123; for i in castile castile2 castile3; do #statements echo --------------zookeeper $i start --------------- ssh $i &quot;/opt/zookeeper-3.5.7/bin/zkServer.sh start&quot; done &#125;;; &quot;stop&quot; )&#123; for i in castile castile2 castile3; do #statements echo --------------zookeeper $i stop --------------- ssh $i &quot;/opt/zookeeper-3.5.7/bin/zkServer.sh stop&quot; done &#125;;; &quot;status&quot; )&#123; for i in castile castile2 castile3; do #statements echo --------------zookeeper $i status --------------- ssh $i &quot;/opt/zookeeper-3.5.7/bin/zkServer.sh status&quot; done &#125;;;esac","path":"2021/08/08/ZooKeeper集群安装/","date":"08-08","excerpt":"","tags":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://castile.github.io/tags/ZooKeeper/"},{"name":"hosts","slug":"hosts","permalink":"https://castile.github.io/tags/hosts/"},{"name":"ssh免密","slug":"ssh免密","permalink":"https://castile.github.io/tags/ssh%E5%85%8D%E5%AF%86/"}]},{"title":"Centos7防火墙问题:Unit iptables.service could not be found.","text":"Centos7防火墙问题:Unit iptables.service could not be found.问题在搭建zookeeper集群的时候出错，查看防火墙状态发现： 1234[root@castile zookeeper-3.5.7]# service iptables statusRedirecting to /bin/systemctl status iptables.serviceUnit iptables.service could not be found. 解决 安装iptables-services 1yum install iptables-services 启动iptables 并查看状态 其他： service iptables stop ： 关闭防火墙 chkconfig iptables off","path":"2021/08/05/centos防火墙问题/","date":"08-05","excerpt":"","tags":[{"name":"linux","slug":"linux","permalink":"https://castile.github.io/tags/linux/"},{"name":"centos","slug":"centos","permalink":"https://castile.github.io/tags/centos/"}]},{"title":"ZooKeeper的安装及其配置参数","text":"ZooKeeper的安装及其配置参数ZooKeeper下载:https://zookeeper.apache.org/releases.html Zookeeper 是一个开源的分布式的，为分布式框架提供协调服务的 Apache 项目。 ZooKeeper安装 首先将下载的tar包上传到服务器中 apache-zookeeper-3.5.7-bin.tar.gz 在/opt/下面解压出来, 并改名 12tar -zxvf apache-zookeeper-3.5.7-bin.tar.gzmv apache-zookeeper-3.5.7-bin zookeeper-3.5.7 修改配置文件： 将/opt/zookeeper-3.5.7/conf 这个路径下的 zoo_sample.cfg 修改为 zoo.cfg； 1cp zoo_sample.cfg zoo.cfg 打开 zoo.cfg 文件，修改 dataDir 路径： 因为dataDir是存放节点数据，默认 放在/tmp目录下，但是tmp是临时目录，linux会定期删除，所以我们 需要另外指定目录。 12345678910111213141516171819202122232425262728# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/opt/zookeeper-3.5.7/zkData# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 启动zookeeper, 使用jps命令查看zookeeper进程QuorumPeerMain 12345678./bin/zkServer.sh start[root@castile zookeeper-3.5.7]# ./bin/zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.5.7/bin/../conf/zoo.cfgStarting zookeeper ... STARTED[root@castile zookeeper-3.5.7]# jps50058 QuorumPeerMain50077 Jps 客户端连接 1./bin/zkCli.sh 停止ZooKeeper 1bin/zkServer.sh stop 配置参数解读 Zookeeper中的配置文件zoo.cfg中参数含义解读如下 ： tickTime = 2000：通信心跳时间，Zookeeper服务器与客户端心跳时间，单位毫秒。 initLimit = 10：LF初始通信时限。 Leader和Follower初始连接时能容忍的最多心跳数。也就是初始化集群时集群节点同步超时时间为20s。 syncLimit = 5：LF同步通信时限。 Leader和Follower之间通信时间如果超过syncLimit * tickTime，Leader认为Follwer死 掉，从服务器列表中删除Follwer。 即集群在运行过程中同步数据超时时间为10s。 dataDir：保存Zookeeper中的数据。 注意：默认的tmp目录，容易被Linux系统定期删除，所以一般不用默认的tmp目录。 clientPort = 2181：客户端连接端口，服务监听的端口号。通常不做修改。 maxClientCnxns=60: 线程池数量为60个。","path":"2021/08/01/ZooKeeper1/","date":"08-01","excerpt":"","tags":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://castile.github.io/tags/ZooKeeper/"}]},{"title":"阿里巴巴开源的Java性能诊断工具Arthas详解","text":"一、ArthasArthas 是Alibaba开源的Java诊断工具，深受开发者喜爱。 当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 怎么快速定位应用的热点，生成火焰图？ 怎样直接从JVM内查找某个类的实例？ Arthas支持JDK6+，支持Linux/Mac/Windows，采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。 二、安装使用arthas-boot（推荐）下载arthas-boot.jar，然后用java -jar的方式启动： 12curl -O https://arthas.aliyun.com/arthas-boot.jarjava -jar arthas-boot.jar 打印帮助信息： 1java -jar arthas-boot.jar -h 如果下载速度比较慢，可以使用aliyun的镜像： 1java -jar arthas-boot.jar --repo-mirror aliyun --use-http 使用as.shArthas 支持在 Linux/Unix/Mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可： 1curl -L https://arthas.aliyun.com/install.sh | sh 上述命令会下载启动脚本文件 as.sh 到当前目录，你可以放在任何地方或将其加入到 $PATH 中。 直接在shell下面执行./as.sh，就会进入交互界面。 也可以执行./as.sh -h来获取更多参数信息。 全量安装最新版本，点击下载： 解压后，在文件夹里有arthas-boot.jar，直接用java -jar的方式启动： 1java -jar arthas-boot.jar 三、快速使用1. 启动math-game12curl -O https://arthas.aliyun.com/math-game.jarjava -jar math-game.jar math-game是一个简单的程序，每隔一秒生成一个随机数，再执行质因数分解，并打印出分解结果。 math-game源代码：查看 2. 启动arthas在命令行下面执行（使用和目标进程一致的用户启动，否则可能attach失败）： 12curl -O https://arthas.aliyun.com/arthas-boot.jarjava -jar arthas-boot.jar 执行该程序的用户需要和目标进程具有相同的权限。比如以admin用户来执行：sudo su admin &amp;&amp; java -jar arthas-boot.jar 或 sudo -u admin -EH java -jar arthas-boot.jar。 如果attach不上目标进程，可以查看~/logs/arthas/ 目录下的日志。 如果下载速度比较慢，可以使用aliyun的镜像：java -jar arthas-boot.jar --repo-mirror aliyun --use-http java -jar arthas-boot.jar -h 打印更多参数信息。 选择应用java进程： 123$ $ java -jar arthas-boot.jar* [1]: 35542 [2]: 71560 math-game.jar math-game进程是第2个，则输入2，再输入回车/enter。Arthas会attach到目标进程上，并输出日志 四、常用命令 dashboard仪表盘 通过thread命令来获取到arthas-demo进程的Main Class 通过jad反编译Main Class watch 命令介绍1. dashboard仪表盘 输入dashboard，按回车/enter，会展示当前进程的信息，按ctrl+c可以中断执行。 第一部分是显示JVM中运行的所有线程：所在的线程组，优先级，线程的状态，CPU的利用率，是否是后台进程等。 第二部分显示的是JVM内存的使用情况等 第三部分是操作系统的一些信息和Java版本号 ID: Java级别的线程ID，注意这个ID不能跟jstack中的nativeID一一对应。 NAME: 线程名 GROUP: 线程组名 PRIORITY: 线程优先级, 1~10之间的数字，越大表示优先级越高 STATE: 线程的状态 CPU%: 线程的cpu使用率。比如采样间隔1000ms，某个线程的增量cpu时间为100ms，则cpu使用率=100/1000=10% DELTA_TIME: 上次采样之后线程运行增量CPU时间，数据格式为秒 TIME: 线程运行总CPU时间，数据格式为分:秒 INTERRUPTED: 线程当前的中断位状态 DAEMON: 是否是daemon线程 2. 通过thread命令来获取到arthas-demo进程的Main Class获取到arthas-demo进程的Main Class thread 1 会打印线程ID为1 的栈信息，通常是main函数的线程 12345678910111213141516171819202122232425262728Threads Total: 24, NEW: 0, RUNNABLE: 7, BLOCKED: 0, WAITING: 4, TIMED_WAITING: 3, TERMINATED: 0, Internal threads: 10ID NAME GROUP PRIORITY STATE %CPU DELTA_TIME TIME INTERRUPTED DAEMON-1 VM Periodic Task Thread - -1 - 0.13 0.000 0:0.804 false true22 arthas-command-execute system 5 RUNNABLE 0.09 0.000 0:0.004 false true-1 C1 CompilerThread2 - -1 - 0.06 0.000 0:0.587 false true2 Reference Handler system 10 WAITING 0.0 0.000 0:0.001 false true3 Finalizer system 8 WAITING 0.0 0.000 0:0.004 false true4 Signal Dispatcher system 9 RUNNABLE 0.0 0.000 0:0.000 false true9 Attach Listener system 9 RUNNABLE 0.0 0.000 0:0.010 false true11 arthas-timer system 9 WAITING 0.0 0.000 0:0.000 false true14 arthas-NettyHttpTelnetBootstrap-3-1 system 5 RUNNABLE 0.0 0.000 0:0.020 false true15 arthas-NettyWebsocketTtyBootstrap-4-1 system 5 RUNNABLE 0.0 0.000 0:0.001 false true16 arthas-NettyWebsocketTtyBootstrap-4-2 system 5 RUNNABLE 0.0 0.000 0:0.002 false true17 arthas-shell-server system 9 TIMED_WAITING 0.0 0.000 0:0.002 false true18 arthas-session-manager system 9 TIMED_WAITING 0.0 0.000 0:0.001 false true19 arthas-UserStat system 9 WAITING 0.0 0.000 0:0.000 false true21 arthas-NettyHttpTelnetBootstrap-3-2 system 5 RUNNABLE 0.0 0.000 0:0.200 false true1 main main 5 TIMED_WAITING 0.0 0.000 0:0.230 false false-1 GC task thread#1 (ParallelGC) - -1 - 0.0 0.000 0:0.030 false true-1 VM Thread - -1 - 0.0 0.000 0:0.152 false true-1 GC task thread#2 (ParallelGC) - -1 - 0.0 0.000 0:0.031 false true-1 GC task thread#3 (ParallelGC) - -1 - 0.0 0.000 0:0.030 false true-1 GC task thread#0 (ParallelGC) - -1 - 0.0 0.000 0:0.028 false true-1 C2 CompilerThread0 - -1 - 0.0 0.000 0:0.704 false true-1 Service Thread - -1 - 0.0 0.000 0:0.000 false true-1 C2 CompilerThread1 - -1 - 0.0 0.000 0:0.535 false true 1thread 1 3. 通过jad反编译Main Class1jad demo.MathGame 4. watch监视 （debug）通过watch命令来查看demo.MathGame#primeFactors 函数的返回值 12watch demo.MathGame primeFactors returnObj 包名+类名 函数名 ongl表达式 1234567891011121314151617181920212223242526[arthas@29058]$ watch demo.MathGame primeFactors returnObjPress Q or Ctrl+C to abort.Affect(class count: 1 , method count: 1) cost in 77 ms, listenerId: 1method=demo.MathGame.primeFactors location=AtExceptionExitts=2021-07-17 15:22:29; [cost=0.58359ms] result=nullmethod=demo.MathGame.primeFactors location=AtExitts=2021-07-17 15:22:30; [cost=0.09676ms] result=@ArrayList[ @Integer[2], # 第一个整数 @Integer[7], @Integer[11], @Integer[557],]method=demo.MathGame.primeFactors location=AtExitts=2021-07-17 15:22:31; [cost=0.03972ms] result=@ArrayList[ @Integer[2], @Integer[3], @Integer[17], @Integer[1151],]method=demo.MathGame.primeFactors location=AtExceptionExitts=2021-07-17 15:22:32; [cost=0.049295ms] result=null # 不能分解method=demo.MathGame.primeFactors location=AtExitts=2021-07-17 15:22:33; [cost=0.763201ms] result=@ArrayList[ @Integer[65809],] 5. 退出arthas如果只是退出当前的连接，可以用quit或者exit命令。Attach到目标进程上的arthas还会继续运行，端口会保持开放，下次连接时可以直接连接上。 如果想完全退出arthas，可以执行stop命令。 五、基础命令 help——查看命令帮助信息 cat——打印文件内容，和linux里的cat命令类似 echo–打印参数，和linux里的echo命令类似 grep——匹配查找，和linux里的grep命令类似 但是它只能用于管道命令 语法： 参数列表 作用 -n 显示行号 -i 忽略大小写查找 -m 行数 最大显示行数，要与查询字符串一起使用 -e “正则表达式” 使用正则表达式查找 如： 只显示包含java字符串的行系统属性 1sysprop | grep java 只显示10行，并显示出行号 1sysprop | grep java -n -m10 base64——base64编码转换，和linux里的base64命令类似 tee——复制标准输入到标准输出和指定的文件，和linux里的tee命令类似 tee指令会从标准输入设备读取数据，将其内容输出到标准输出设备，同时保存成文件。 123EXAMPLES: sysprop | tee /path/to/logfile | grep java sysprop | tee -a /path/to/logfile | grep java -a 参数是追加到文件 pwd——返回当前的工作目录，和linux命令类似 cls——清空当前屏幕区域 session——查看当前会话的信息 12345Name Value-------------------------------------------------- JAVA_PID 29058 SESSION_ID dfad3e36-c62f-49b4-906f-494f030a5c50 reset——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类。 Arthas在 watch/trace 等命令时，实际上是修改了应用的字节码，插入增强的代码。显式执行 reset 命令，可以清除掉这些增强代码。 语法： 1、 还原指定类：reset Test 2、还原所有以List结尾的类：reset *List 3、还原所有的类：reset version——输出当前目标 Java 进程所加载的 Arthas 版本号 12[arthas@29058]$ version3.5.2 history——打印命令历史 quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响 stop——关闭 Arthas 服务端，所有 Arthas 客户端全部退出 keymap——Arthas快捷键列表及自定义快捷键 快捷键 快捷键说明 命令名称 命令说明 &quot;\\C-a&quot; ctrl + a beginning-of-line 跳到行首 &quot;\\C-e&quot; ctrl + e end-of-line 跳到行尾 &quot;\\C-f&quot; ctrl + f forward-word 向前移动一个单词 &quot;\\C-b&quot; ctrl + b backward-word 向后移动一个单词 &quot;\\e[D&quot; 键盘左方向键 backward-char 光标向前移动一个字符 &quot;\\e[C&quot; 键盘右方向键 forward-char 光标向后移动一个字符 &quot;\\e[B&quot; 键盘下方向键 next-history 下翻显示下一个命令 &quot;\\e[A&quot; 键盘上方向键 previous-history 上翻显示上一个命令 &quot;\\C-h&quot; ctrl + h backward-delete-char 向后删除一个字符 &quot;\\C-?&quot; ctrl + shift + / backward-delete-char 向后删除一个字符 &quot;\\C-u&quot; ctrl + u undo 撤销上一个命令，相当于清空当前行 &quot;\\C-d&quot; ctrl + d delete-char 删除当前光标所在字符 &quot;\\C-k&quot; ctrl + k kill-line 删除当前光标到行尾的所有字符 &quot;\\C-i&quot; ctrl + i complete 自动补全，相当于敲TAB &quot;\\C-j&quot; ctrl + j accept-line 结束当前行，相当于敲回车 &quot;\\C-m&quot; ctrl + m accept-line 结束当前行，相当于敲回车 &quot;\\C-w&quot; backward-delete-word &quot;\\C-x\\e[3~&quot; backward-kill-line &quot;\\e\\C-?&quot; backward-kill-word 任何时候 tab 键，会根据当前的输入给出提示 命令后敲 - 或 -- ，然后按 tab 键，可以展示出此命令具体的选项 中文版：供参考 六、JVM相关命令目标 dashboard 仪表板 thread 线程相关 jvm虚拟机相关 sysprop 系统属性相关 sysenv 查看jvm环境信息 1. dashboard 数据说明 ID: Java级别的线程ID，注意这个ID不能跟jstack中的nativeID一一对应。 NAME: 线程名 GROUP: 线程组名 PRIORITY: 线程优先级, 1~10之间的数字，越大表示优先级越高 STATE: 线程的状态 CPU%: 线程的cpu使用率。比如采样间隔1000ms，某个线程的增量cpu时间为100ms，则cpu使用率=100/1000=10% DELTA_TIME: 上次采样之后线程运行增量CPU时间，数据格式为秒 TIME: 线程运行总CPU时间，数据格式为分:秒 INTERRUPTED: 线程当前的中断位状态 DAEMON: 是否是daemon线程 JVM内部线程Java 8之后支持获取JVM内部线程CPU时间，这些线程只有名称和CPU时间，没有ID及状态等信息（显示ID为-1）。 通过内部线程可以观测到JVM活动，如GC、JIT编译等占用CPU情况，方便了解JVM整体运行状况。 当JVM 堆(heap)/元数据(metaspace)空间不足或OOM时，可以看到GC线程的CPU占用率明显高于其他的线程。 当执行trace/watch/tt/redefine等命令后，可以看到JIT线程活动变得更频繁。因为JVM热更新class字节码时清除了此class相关的JIT编译结果，需要重新编译。 JVM内部线程包括下面几种： JIT编译线程: 如 C1 CompilerThread0, C2 CompilerThread0 GC线程: 如GC Thread0, G1 Young RemSet Sampling 其它内部线程: 如VM Periodic Task Thread, VM Thread, Service Thread JIT即时编译 JIT是just in time的缩写，也就是即时编译。通过JIT技术，能够做到Java程序执行速度的加速。 注： JIT即时编译： https://blog.csdn.net/qq_34902684/article/details/85538895 2. thread查看当前JVM的线程堆栈信息（ 查看当前线程信息，查看线程的堆栈 ） 参数说明： 参数名称 参数说明 id 线程id [n:] 指定最忙的前N个线程并打印堆栈 [b] 找出当前阻塞其他线程的线程 [i ] 指定cpu占比统计的采样间隔，单位为毫秒指定cpu使用率统计的采样间隔，，默认值为200 [–all] 显示所有匹配的线程 cpu使用率是如何统计出来的？这里的cpu使用率与linux 命令top -H -p 的线程%CPU类似，一段采样间隔时间内，当前JVM里各个线程的增量cpu时间与采样间隔时间的比例。 工作原理说明： 首先第一次采样，获取所有线程的CPU时间(调用的是java.lang.management.ThreadMXBean#getThreadCpuTime()及sun.management.HotspotThreadMBean.getInternalThreadCpuTimes()接口) 然后睡眠等待一个间隔时间（默认为200ms，可以通过-i指定间隔时间） 再次第二次采样，获取所有线程的CPU时间，对比两次采样数据，计算出每个线程的增量CPU时间 线程CPU使用率 = 线程增量CPU时间 / 采样间隔时间 * 100% 注意： 这个统计也会产生一定的开销（JDK这个接口本身开销比较大），因此会看到as的线程占用一定的百分比，为了降低统计自身的开销带来的影响，可以把采样间隔拉长一些，比如5000毫秒。 另外一种查看Java进程的线程cpu使用率方法：可以使用show-busy-java-threads这个脚本 举例如： 显示当前最忙的前3个线程并打印堆栈信息： 1thread -n 3 没有线程ID，包含[Internal]表示为JVM内部线程，参考dashboard命令的介绍。 cpuUsage为采样间隔时间内线程的CPU使用率，与dashboard命令的数据一致。 deltaTime为采样间隔时间内线程的增量CPU时间，小于1ms时被取整显示为0ms。 time 线程运行总CPU时间。 当没有参数时，显示第一页线程信息默认按照CPU增量时间降序排列，只显示第一页数据，避免滚屏。 thread –all, 显示所有匹配的线程显示所有匹配线程信息，有时需要获取全部JVM的线程数据进行分析。 thread id， 显示指定线程的运行堆栈查看线程ID 1的栈： 1thread 1 thread -i, 指定采样时间间隔 thread -i 1000 : 统计最近1000ms内的线程CPU时间。 thread -n 3 -i 1000 : 列出1000ms内最忙的3个线程栈 thread –state ，查看指定状态的线程1thread --state WAITING thread -b, 找出当前阻塞其他线程的线程有时候我们发现应用卡住了， 通常是由于某个线程拿住了某个锁， 并且其他线程都在等待这把锁造成的。 为了排查这类问题， arthas提供了thread -b， 一键找出那个罪魁祸首。 注意， 目前只支持找出synchronized关键字阻塞住的线程， 如果是java.util.concurrent.Lock， 目前还不支持。 写一个死锁程序： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.hongliang;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @create 2021-07-17 17:48 */public class Main &#123; public static void main(String[] args) &#123; DinnerLockThread thread = new DinnerLockThread(); new Thread(thread, &quot;Jack&quot;).start(); new Thread(thread, &quot;Rose&quot;).start(); &#125;&#125;class DinnerLockThread implements Runnable&#123; String lock1 = &quot;第一根筷子&quot;; String lock2 = &quot;第二根筷子&quot;; public void run() &#123; if (&quot;Jack&quot;.equals(Thread.currentThread().getName()))&#123; synchronized (lock1)&#123; System.out.println(&quot;Jack 拿到了&quot;+lock1); synchronized (lock2)&#123; System.out.println(&quot;Jack 拿到了&quot;+lock2); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;else &#123; synchronized (lock2)&#123; System.out.println(&quot;Rose 拿到了&quot;+lock2); synchronized (lock1)&#123; System.out.println(&quot;Rose 拿到了&quot;+lock1); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;&#125; 运行： 1234[root@castile arthas]# java -cp demo-arthas-deadlock-1.0-SNAPSHOT.jar com.hongliang.MainJack 拿到了第一根筷子Rose 拿到了第二根筷子... 出现死锁了... 可以看到上面的Jack和Rose的线程已经Blocked 接下来使用arthas来诊断具体那个线程造成的死锁： 3. jvm 查看当前JVM信息 查看当前JVM信息 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100 RUNTIME---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- MACHINE-NAME 31604@castile.com JVM-START-TIME 2021-07-17 17:59:24 MANAGEMENT-SPEC-VERSION 1.2 SPEC-NAME Java Virtual Machine Specification SPEC-VENDOR Oracle Corporation SPEC-VERSION 1.8 VM-NAME Java HotSpot(TM) 64-Bit Server VM VM-VENDOR Oracle Corporation VM-VERSION 25.251-b08 INPUT-ARGUMENTS [] CLASS-PATH demo-arthas-deadlock-1.0-SNAPSHOT.jar BOOT-CLASS-PATH /usr/jdk/jdk1.8.0_251/jre/lib/resources.jar:/usr/jdk/jdk1.8.0_251/jre/lib/rt.jar:/usr/jdk/jdk1.8.0_251/jre/lib/sunrsasign.jar:/usr/jdk/jdk1.8.0_251 /jre/lib/jsse.jar:/usr/jdk/jdk1.8.0_251/jre/lib/jce.jar:/usr/jdk/jdk1.8.0_251/jre/lib/charsets.jar:/usr/jdk/jdk1.8.0_251/jre/lib/jfr.jar:/usr/jdk/j dk1.8.0_251/jre/classes LIBRARY-PATH /usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- CLASS-LOADING---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- LOADED-CLASS-COUNT 3457 TOTAL-LOADED-CLASS-COUNT 3457 UNLOADED-CLASS-COUNT 0 IS-VERBOSE false---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- COMPILATION---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- NAME HotSpot 64-Bit Tiered Compilers TOTAL-COMPILE-TIME 804 [time (ms)]---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- GARBAGE-COLLECTORS---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- PS Scavenge name : PS Scavenge [count/time (ms)] collectionCount : 6 collectionTime : 31 PS MarkSweep name : PS MarkSweep [count/time (ms)] collectionCount : 1 collectionTime : 31---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- MEMORY-MANAGERS---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- CodeCacheManager Code Cache Metaspace Manager Metaspace Compressed Class Space PS Scavenge PS Eden Space PS Survivor Space PS MarkSweep PS Eden Space PS Survivor Space PS Old Gen---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- MEMORY # 内存相关---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- HEAP-MEMORY-USAGE init : 31457280(30.0 MiB) [memory in bytes] used : 23836240(22.7 MiB) committed : 66060288(63.0 MiB) max : 425197568(405.5 MiB) NO-HEAP-MEMORY-USAGE init : 2555904(2.4 MiB) [memory in bytes] used : 27348920(26.1 MiB) committed : 28573696(27.3 MiB) max : -1(-1 B) PENDING-FINALIZE-COUNT 0---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- OPERATING-SYSTEM#系统相关---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- OS Linux ARCH amd64 PROCESSORS-COUNT 4 LOAD-AVERAGE 0.0 VERSION 3.10.0-1127.el7.x86_64---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- THREAD---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- COUNT 16 DAEMON-COUNT 13 PEAK-COUNT 17 STARTED-COUNT 20 DEADLOCK-COUNT 2---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- FILE-DESCRIPTOR # 文件描述符---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- MAX-FILE-DESCRIPTOR-COUNT 4096 OPEN-FILE-DESCRIPTOR-COUNT 103 THREAD相关 COUNT: JVM当前活跃的线程数 DAEMON-COUNT: JVM当前活跃的守护线程数 PEAK-COUNT: 从JVM启动开始曾经活着的最大线程数 STARTED-COUNT: 从JVM启动开始总共启动过的线程次数 DEADLOCK-COUNT: JVM当前死锁的线程数 文件描述符相关 MAX-FILE-DESCRIPTOR-COUNT：JVM进程最大可以打开的文件描述符数 OPEN-FILE-DESCRIPTOR-COUNT：JVM当前打开的文件描述符数 4. sysprop 系统属性相关查看单个属性12$ sysprop java.versionjava.version=1.8.0_51 修改单个属性12345$ sysprop user.countryuser.country=US$ sysprop user.country CNSuccessfully changed the system property.user.country=CN 5. sysenv 查看jvm环境信息 也可以只看其中一个环境变量 123[arthas@31604]$ sysenv JAVA_HOME KEY VALUE JAVA_HOME /usr/jdk/jdk1.8.0_251 123[arthas@31604]$ sysenv CLASSPATH KEY VALUE CLASSPATH .:/usr/jdk/jdk1.8.0_251/lib.tools.jar 6. vmoption查看，更新VM诊断相关的参数 查看，更新VM诊断相关的参数 vmoption : 查看所有的option vmoption PrintGCDetails : 查看指定的option 1234arthas@31604]$ vmoption PrintGCDetails KEY VALUE ORIGIN WRITEABLE PrintGCDetails false DEFAULT true vmoption PrintGCDetails true ： 更新指定的option 7. getstatic查看类的静态属性 通过getstatic命令可以方便的查看类的静态属性。使用方法为getstatic class_name field_name 123456789101112131415161718192021[arthas@34093]$ getstatic demo.MathGame random # 查看MathGame里面的random字段field: random # 字段@Random[ serialVersionUID=@Long[3905348978240129619], seed=@AtomicLong[144884610029513], multiplier=@Long[25214903917], addend=@Long[11], mask=@Long[281474976710655], DOUBLE_UNIT=@Double[1.1102230246251565E-16], BadBound=@String[bound must be positive], BadRange=@String[bound must be greater than origin], BadSize=@String[size must be non-negative], seedUniquifier=@AtomicLong[3620162808252824828], nextNextGaussian=@Double[0.0], haveNextNextGaussian=@Boolean[false], serialPersistentFields=@ObjectStreamField[][isEmpty=false;size=3], unsafe=@Unsafe[sun.misc.Unsafe@2b0f66cd], seedOffset=@Long[24],]Affect(row-cnt:1) cost in 10 ms. 推荐直接使用ognl命令，更加灵活 。 express 执行的表达式 [c:] 执行表达式的 ClassLoader 的 hashcode，默认值是SystemClassLoader [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [x] 结果对象的展开层次，默认值1 调用静态函数： 12$ ognl &#x27;@java.lang.System@out.println(&quot;hello&quot;)&#x27;返回null 获取静态类的静态字段： 123456789101112131415161718$ ognl &#x27;@demo.MathGame@random&#x27;@Random[ serialVersionUID=@Long[3905348978240129619], seed=@AtomicLong[125451474443703], multiplier=@Long[25214903917], addend=@Long[11], mask=@Long[281474976710655], DOUBLE_UNIT=@Double[1.1102230246251565E-16], BadBound=@String[bound must be positive], BadRange=@String[bound must be greater than origin], BadSize=@String[size must be non-negative], seedUniquifier=@AtomicLong[-3282039941672302964], nextNextGaussian=@Double[0.0], haveNextNextGaussian=@Boolean[false], serialPersistentFields=@ObjectStreamField[][isEmpty=false;size=3], unsafe=@Unsafe[sun.misc.Unsafe@28ea5898], seedOffset=@Long[24],] 执行多行表达式，赋值给临时变量，返回一个List： 123456 ognl &#x27;#value1=@System@getProperty(&quot;java.home&quot;), #value2=@System@getProperty(&quot;java.runtime.name&quot;), &#123;#value1, #value2&#125;&#x27; @ArrayList[ @String[/opt/java/8.0.181-zulu/jre], @String[OpenJDK Runtime Environment],] OGNL特殊用法请参考：https://github.com/alibaba/arthas/issues/71 OGNL表达式官方指南：https://commons.apache.org/proper/commons-ognl/language-guide.html 八、Class/ClassLoader相关命令目标 sc： Search-Class 。查看JVM已加载的类信息 sm： Search-Method 。 查看已加载类的方法信息 jad: 把字节码反编译成源代码 1. sc查看JVM已加载的类信息 Search-Class” 的简写，这个命令能搜索出所有已经加载到 JVM 中的 Class 信息，这个命令支持的参数有 [d]、[E]、[f] 和 [x:]。 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 [d] 输出当前类的详细信息，包括这个类所加载的原始文件来源、类的声明、加载的ClassLoader等详细信息。 如果一个类被多个ClassLoader所加载，则会出现多次 [E] 开启正则表达式匹配，默认为通配符匹配 [f] 输出当前类的成员变量信息（需要配合参数-d一起使用） [x:] 指定输出静态变量时属性的遍历深度，默认为 0，即直接使用 toString 输出 [c:] 指定class的 ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [n:] 具有详细信息的匹配类的最大数量（默认为100） 1sc com.hongliang.DinnerLockThread -d 1sc com.hongliang.DinnerLockThread -df sc 默认开启了子类匹配功能，也就是说所有当前类的子类也会被搜索出来，想要精确的匹配，请打开options disable-sub-class true开关 2. sm查看已加载类的方法信息 “Search-Method” 的简写，这个命令能搜索出所有已经加载了 Class 信息的方法信息。 sm 命令只能看到由当前类所声明 (declaring) 的方法，父类则无法看到。 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 [d] 展示每个方法的详细信息 [E] 开启正则表达式匹配，默认为通配符匹配 [c:] 指定class的 ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [n:] 具有详细信息的匹配类的最大数量（默认为100） 3. jad: 把字节码反编译成源代码jad 命令将 JVM 中实际运行的 class 的 byte code 反编译成 java 代码，便于你理解业务逻辑； 在 Arthas Console 上，反编译出来的源码是带语法高亮的，阅读更方便 当然，反编译出来的 java 代码可能会存在语法错误，但不影响你进行阅读理解 参数名称 参数说明 class-pattern 类名表达式匹配 [c:] 类所属 ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [E] 开启正则表达式匹配，默认为通配符匹配 反编译java.lang.String 反编译时只显示源代码 默认情况下，反编译结果里会带有ClassLoader信息，通过--source-only选项，可以只打印源代码。方便和mc/retransform命令结合使用。 1jad --source-only demo.MathGame 反编译时指定ClassLoader 当有多个 ClassLoader 都加载了这个类时，jad 命令会输出对应 ClassLoader 实例的 hashcode，然后你只需要重新执行 jad 命令，并使用参数 -c 就可以反编译指定 ClassLoader 加载的那个类了； 反编译指定的函数1jad demo.MathGame main 4. mc内存编译 Memory Compiler/内存编译器，编译.java文件生成.class。 可以通过-d命令指定输出目录： 1mc -d /tmp/output /tmp/ClassA.java /tmp/ClassB.java 编译生成.class文件之后，可以结合retransform命令实现热更新代码。 注意，mc命令有可能失败。如果编译失败可以在本地编译好.class文件，再上传到服务器。具体参考retransform命令说明。 可以通过-c参数指定classloader： 1mc -c 327a647b /tmp/Test.java 5. redefine 加载外部的.class文件，redefine jvm已加载的类。 常见问题 redefine的class不能修改、添加、删除类的field和method，包括方法参数、方法名称及返回值 如果mc失败，可以在本地开发环境编译好class文件，上传到目标系统，使用redefine热加载class 目前redefine 和watch/trace/jad/tt等命令冲突，以后重新实现redefine功能会解决此问题 注意， redefine后的原来的类不能恢复，redefine有可能失败（比如增加了新的field），参考jdk本身的文档。 reset命令对redefine的类无效。如果想重置，需要redefine原始的字节码。 redefine命令和jad/watch/trace/monitor/tt等命令会冲突。执行完redefine之后，如果再执行上面提到的命令，则会把redefine的字节码重置。 原因是jdk本身redefine和Retransform是不同的机制，同时使用两种机制来更新字节码，只有最后修改的会生效。 redefine的限制 不允许新增加field/method 正在跑的函数，没有退出不能生效。 举例热更新代码源码准备123456789101112131415161718192021222324252627package com.hongliang;import java.util.concurrent.TimeUnit;/** * @author Hongliang Zhu * @create 2021-07-17 23:36 */public class PrintNum &#123; public static void main(String[] args) throws InterruptedException &#123; int i = 1; PrintNum p = new PrintNum(); while (true)&#123; TimeUnit.SECONDS.sleep(1L);// System.out.println(&quot;我是在main中新增的代码&quot;); p.run(i); i++; &#125; &#125; public void run(int i) &#123;// System.out.println(&quot;在run中新增的代码&quot;); System.out.println(&quot;run--&gt;&quot;+i); &#125;&#125; 其中注释的是要即将修改的代码！！！ jad反编译1jad --source-only com.hongliang.PrintNum &gt; /tmp/PrintNum.java sc查找加载PrintNum的ClassLoader12[arthas@35673]$ sc -d com.hongliang.PrintNum | grep classLoaderHash classLoaderHash 7852e922 mc编译保存好/tmp/PrintNum.java之后，使用mc(Memory Compiler)命令来编译，并且通过-c参数指定ClassLoader的hash 1234[arthas@35673]$ mc -c 7852e922 /tmp/PrintNum.java -d /tmp/Memory compiler output:/tmp/com/hongliang/PrintNum.classAffect(row-cnt:1) cost in 831 ms. redefine再使用redefine命令重新加载新编译好的PrintNum.class： 123[arthas@35673]$ redefine /tmp/com/hongliang/PrintNum.classredefine success, size: 1, classes:com.hongliang.PrintNum 注：使用jad等命令导致重置1jad com.hongliang.PrintNum 6. dump将已经加载类的字节码文件保存到特定目录： logs/arthas/classdump/ 参数名称 参数说明 class-pattern 类名表达式匹配 [c:] 类所属 ClassLoader 的 hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [d:] 设置类文件的目标目录 [E] 开启正则表达式匹配，默认为通配符匹配 123456dump -d /tmp/output java.lang.String # String类的字节码文件放到指定目录中dump demo.* # HASHCODE CLASSLOADER LOCATION 3d4eac69 +-sun.misc.Launcher$AppClassLoader@3d4eac69 /Users/admin/logs/arthas/classdump/sun.misc.Launcher$AppClassLoader-3d4eac69/demo/MathGame.class +-sun.misc.Launcher$ExtClassLoader@66350f69Affect(row-cnt:1) cost in 39 ms. 7. classloader 查看classloader的继承树，urls，类加载信息 classloader 命令将 JVM 中所有的classloader的信息统计出来，并可以展示继承树，urls等。 可以让指定的classloader去getResources，打印出所有查找到的resources的url。对于ResourceNotFoundException比较有用。 参数名称 参数说明 [l] 按类加载实例进行统计 [t] 打印所有ClassLoader的继承树 [a] 列出所有ClassLoader加载的类，请谨慎使用 [c:] ClassLoader的hashcode [classLoaderClass:] 指定执行表达式的 ClassLoader 的 class name [c: r:] 用ClassLoader去查找resource [c: load:] 用ClassLoader去加载指定的类 显示所有类加载器的信息 获取某个类加载器所在的jar包 获取某个资源在哪个jar包中 加载某个类 九、增强命令目标 monitor 方法执行监控 watch方法执行数据观测 trace 输出当前方法的调用路径 tt 方法执行数据的时空隧道 profiler 火焰图 1. monitor方法执行监控对匹配 class-pattern／method-pattern的类、方法的调用进行监控。 monitor 命令是一个非实时返回命令. 实时返回命令是输入之后立即返回，而非实时返回的命令，则是不断的等待目标 Java 进程返回信息，直到用户输入 Ctrl+C 为止。 服务端是以任务的形式在后台跑任务，植入的代码随着任务的中止而不会被执行，所以任务关闭后，不会对原有性能产生太大影响，而且原则上，任何Arthas命令不会引起原有业务逻辑的改变。 监控的维度说明 监控项 说明 timestamp 时间戳 class Java类 method 方法（构造方法、普通方法） total 调用次数 success 成功次数 fail 失败次数 rt 平均RT(平均耗时) fail-rate 失败率 方法拥有一个命名参数 [c:]，意思是统计周期（cycle of output），拥有一个整型的参数值 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 [E] 开启正则表达式匹配，默认为通配符匹配 [c:] 统计周期，默认值为120秒 每5s监控一次，类demo.MathGame中的primeFactors方法 1monitor -c 5 demo.MathGame primeFactors 2. watch 方法执行数据观测 让你能方便的观察到指定方法的调用情况。能观察到的范围为：返回值、抛出异常、入参，通过编写 OGNL 表达式进行对应变量的查看。 参数说明watch 的参数比较多，主要是因为它能在 4 个不同的场景观察对象 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 express 观察表达式 condition-express 条件表达式 [b] 在方法调用之前观察 [e] 在方法异常之后观察 [s] 在方法返回之后观察 [f] 在方法结束之后(正常返回和异常返回)观察 [E] 开启正则表达式匹配，默认为通配符匹配 [x:] 指定输出结果的属性遍历深度，默认为 1 这里重点要说明的是观察表达式，观察表达式的构成主要由 ognl 表达式组成，所以你可以这样写&quot;&#123;params,returnObj&#125;&quot;，只要是一个合法的 ognl 表达式，都能被正常支持。 观察的维度也比较多，主要体现在参数 advice 的数据结构上。Advice 参数最主要是封装了通知节点的所有信息。请参考表达式核心变量中关于该节点的描述。 特殊用法请参考：https://github.com/alibaba/arthas/issues/71 OGNL表达式官网：https://commons.apache.org/proper/commons-ognl/language-guide.html 特别说明： watch 命令定义了4个观察事件点，即 -b 方法调用前，-e 方法异常后，-s 方法返回后，-f 方法结束后 4个观察事件点 -b、-e、-s 默认关闭，-f 默认打开，当指定观察点被打开后，在相应事件点会对观察表达式进行求值并输出 这里要注意方法入参和方法出参的区别，有可能在中间被修改导致前后不一致，除了 -b 事件点 params 代表方法入参外，其余事件都代表方法出参 当使用 -b 时，由于观察事件点是在方法调用前，此时返回值或异常均不存在 举例 观察demo.MathGame类中primeFactors方法出参和返回值，结果属性遍历深度为2 1watch demo.MathGame primeFactors &quot;&#123;params,returnObj&#125;&quot; -x 2 观察方法的入参 1watch demo.MathGame primeFactors &quot;&#123;params,returnObj&#125;&quot; -x 2 -b 对比前一个例子，返回值为空（事件点为方法执行前，因此获取不到返回值） 观察当前对象中的属性，如果想查看方法运行前后当前对象中的属性，可以使用target关键字代表当前对象。 1watch demo.MathGame primeFactors &quot;&#123;params,target,returnObj&#125;&quot; -x 2 -b -s -n 2 参数里-n 2，表示只执行两次 这里输出结果中，第一次输出的是方法调用前的观察表达式的结果，第二次输出的是方法返回后的表达式的结果 结果的输出顺序和事件发生的先后顺序一致，和命令中 -s -b 的顺序无关 调整-x的值，观察具体的方法参数值 1watch demo.MathGame primeFactors &quot;&#123;params,target&#125;&quot; -x 3 -x表示遍历深度，可以调整来打印具体的参数和结果内容，默认值是1。 条件表达式 1watch demo.MathGame primeFactors &quot;&#123;params[0],target&#125;&quot; &quot;params[0]&lt;0&quot; 只有满足条件的调用，才会有响应。 watch-express 单个值可以不加’{}’，多个值需要加’{a,b,c}’。 condition-express 不能加’{}’，可以使用逗号分隔子表达式，取表达式最后一个值来判断。 如果watch的方法存在同名的其它重载方法，可以通过下面的办法进行过滤： 根据参数类型进行过滤 watch demo.MathGame primeFactors &#39;&#123;params, params[0].class.name&#125;&#39; &#39;params[0].class.name == &quot;java.lang.Integer&quot;&#39; 根据参数个数进行过滤 watch demo.MathGame primeFactors &#39;&#123;params, params.length&#125;&#39; &#39;params.length==1&#39; 观察异常信息 1watch demo.MathGame primeFactors &quot;&#123;params[0],throwExp&#125;&quot; -e -x 2 -e表示抛出异常时才触发 express中，表示异常信息的变量是throwExp 根据异常类型或者message进行过滤： 1watch demo.MathGame primeFactors &#x27;&#123;params, throwExp&#125;&#x27; &#x27;#msg=throwExp.toString(), #msg.contains(&quot;IllegalArgumentException&quot;)&#x27; -e -x 2 观察当前对象中的属性 1watch demo.MathGame primeFactors &#x27;target&#x27; 如果想查看方法运行前后，当前对象中的属性，可以使用target关键字，代表当前对象 . 然后使用target.field_name访问当前对象的某个属性 。 1watch demo.MathGame primeFactors &#x27;target.illegalArgumentCount&#x27; 3. trace 方法内部调用路径追踪方法内部调用路径，并输出方法路径上的每个节点上耗时。 trace 命令能主动搜索 class-pattern／method-pattern 对应的方法调用路径，渲染和统计整个调用链路上的所有性能开销和追踪调用链路。 参数说明 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 condition-express 条件表达式 [E] 开启正则表达式匹配，默认为通配符匹配 [n:] 命令执行次数 #cost 方法执行耗时 观察的维度也比较多，主要体现在参数 advice 的数据结构上。Advice 参数最主要是封装了通知节点的所有信息。 很多时候我们只想看到某个方法的rt大于某个时间之后的trace结果，现在Arthas可以按照方法执行的耗时来进行过滤了，例如trace *StringUtils isBlank &#39;#cost&gt;100&#39;表示当执行时间超过100ms的时候，才会输出trace的结果。 watch/stack/trace这个三个命令都支持#cost trace 能方便的帮助你定位和发现因 RT 高而导致的性能问题缺陷，但其每次只能跟踪一级方法的调用链路。 参考：Trace命令的实现原理 3.3.0 版本后，可以使用动态Trace功能，不断增加新的匹配类，参考下面的示例。 举例 trace函数 1trace demo.MathGame run trace次数限制 1trace demo.MathGame run -n 1 包含jdk的函数 1trace --skipJDKMethod false demo.MathGame run 默认情况下，trace不会包含jdk里的函数调用，如果希望trace jdk里的函数，需要显式设置--skipJDKMethod false。 根据调用耗时来过滤 1trace demo.MathGame run &#x27;#cost &gt; 10&#x27; 只会展示耗时大于10ms的调用路径，有助于在排查问题的时候，只关注异常情况 4. stack输出当前方法的调用路径很多时候我们都知道一个方法被执行，但这个方法被执行的路径非常多，或者你根本就不知道这个方法是从那里被执行了，此时你需要的是 stack 命令。 参数说明 参数名称 参数说明 class-pattern 类名表达式匹配 method-pattern 方法名表达式匹配 condition-express 条件表达式 [E] 开启正则表达式匹配，默认为通配符匹配 [n:] 执行次数限制 举例 展示primeFactors的调用路径 1stack demo.MathGame primeFactors 参数小于0的，执行两次 1stack demo.MathGame primeFactors &#x27;params[0]&lt;0&#x27; -n 2 根据执行时间过滤。大于0.5ms的 1stack demo.MathGame primeFactors &#x27;#cost&gt;0.5&#x27; 5. tt 方法执行数据的时空隧道 方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 watch 虽然很方便和灵活，但需要提前想清楚观察表达式的拼写，这对排查问题而言要求太高，因为很多时候我们并不清楚问题出自于何方，只能靠蛛丝马迹进行猜测。 这个时候如果能记录下当时方法调用的所有入参和返回值、抛出的异常会对整个问题的思考与判断非常有帮助。 于是乎，TimeTunnel 命令就诞生了。 举例 记录下当前方法的每次调用环境现场 1tt -t demo.MathGame primeFactors 命令参数解析 -t tt 命令有很多个主参数，-t 就是其中之一。这个参数的表明希望记录下类 *Test 的 print 方法的每次执行情况。 -n 3 当你执行一个调用量不高的方法时可能你还能有足够的时间用 CTRL+C 中断 tt 命令记录的过程，但如果遇到调用量非常大的方法，瞬间就能将你的 JVM 内存撑爆。 此时你可以通过 -n 参数指定你需要记录的次数，当达到记录次数时 Arthas 会主动中断tt命令的记录过程，避免人工操作无法停止的情况。 表格字段 字段解释 INDEX 时间片段记录编号，每一个编号代表着一次调用，后续tt还有很多命令都是基于此编号指定记录操作，非常重要。 TIMESTAMP 方法执行的本机时间，记录了这个时间片段所发生的本机时间 COST(ms) 方法执行的耗时 IS-RET 方法是否以正常返回的形式结束 IS-EXP 方法是否以抛异常的形式结束 OBJECT 执行对象的hashCode()，注意，曾经有人误认为是对象在JVM中的内存地址，但很遗憾他不是。但他能帮助你简单的标记当前执行方法的类实体 CLASS 执行的类名 METHOD 执行的方法名 条件表达式 不知道大家是否有在使用过程中遇到以下困惑 Arthas 似乎很难区分出重载的方法 我只需要观察特定参数，但是 tt 却全部都给我记录了下来 条件表达式也是用 \bOGNL 来编写，核心的判断对象依然是 Advice 对象。除了 tt 命令之外，watch、trace、stack 命令也都支持条件表达式。 解决方法重载 tt -t *Test print params.length==1 通过制定参数个数的形式解决不同的方法签名，如果参数个数一样，你还可以这样写 tt -t *Test print &#39;params[1] instanceof Integer&#39; 解决指定参数 tt -t *Test print params[0].mobile==&quot;13989838402&quot; 检索调用记录 当你用 tt 记录了一大片的时间片段之后，你希望能从中筛选出自己需要的时间片段，这个时候你就需要对现有记录进行检索。 假设我们有这些记录: tt -l 我需要筛选出 primeFactors 方法的调用信息 1tt -s &#x27;method.name==&quot;primeFactors&quot;&#x27; 你需要一个 -s 参数。同样的，搜索表达式的核心对象依旧是 Advice 对象。 查看调用信息 对于具体一个时间片的信息而言，你可以通过 -i 参数后边跟着对应的 INDEX 编号查看到他的详细信息。 1tt -i 1003 重新做一次调用 当你稍稍做了一些调整之后，你可能需要前端系统重新触发一次你的调用，此时得求爷爷告奶奶的需要前端配合联调的同学再次发起一次调用。而有些场景下，这个调用不是这么好触发的。 tt 命令由于保存了当时调用的所有现场信息，所以我们可以自己主动对一个 INDEX 编号的时间片自主发起一次调用，从而解放你的沟通成本。此时你需要 -p 参数。通过 --replay-times 指定 调用次数，通过 --replay-interval 指定多次调用间隔(单位ms, 默认1000ms) 1tt -i 1004 -p 你会发现结果虽然一样，但调用的路径发生了变化，由原来的程序发起变成了 Arthas 自己的内部线程发起的调用了。 需要强调的点 ThreadLocal 信息丢失 很多框架偷偷的将一些环境变量信息塞到了发起调用线程的 ThreadLocal 中，由于调用线程发生了变化，这些 ThreadLocal 线程信息无法通过 Arthas 保存，所以这些信息将会丢失。 一些常见的 CASE 比如：鹰眼的 TraceId 等。 引用的对象 需要强调的是，tt 命令是将当前环境的对象引用保存起来，但仅仅也只能保存一个引用而已。如果方法内部对入参进行了变更，或者返回的对象经过了后续的处理，那么在 tt 查看的时候将无法看到当时最准确的值。这也是为什么 watch 命令存在的意义。 6. profiler profiler 命令支持生成应用热点的火焰图。本质上是通过不断的采样，然后把收集到的采样结果生成火焰图。 profiler 命令基本运行结构是 profiler action [actionArg] 参数说明 参数名称 参数说明 action 要执行的操作 actionArg 属性名模式 [i:] 采样间隔（单位：ns）（默认值：10’000’000，即10 ms） [f:] 将输出转储到指定路径 [d:] 运行评测指定秒 [e:] 要跟踪哪个事件（cpu, alloc, lock, cache-misses等），默认是cpu 开始采样123profiler start[arthas@46284]$ profiler startStarted [cpu] profiling 获取已采集的sample的数量123profiler getSamples$ profiler getSamples23 查看profiler状态123profiler status$ profiler status[itimer] profiling is running for 4 seconds 可以查看当前profiler在采样哪种event和采样时间。 停止profiler生成svg格式结果123profiler stopprofiler output file: /tmp/demo/arthas-output/20191125-135546.svgOK 默认情况下，生成的结果保存到应用的工作目录下的arthas-output目录。可以通过 --file参数来指定输出结果路径。比如： 1234profiler stop --file /tmp/output.svg$ profiler stop --file /tmp/output.svgprofiler output file: /tmp/output.svgOK 生成html格式结果默认情况下，结果文件是svg格式，如果想生成html格式，可以用--format参数指定： 1234profiler stop --format html$ profiler stop --format htmlprofiler output file: /tmp/test/arthas-output/20191125-143329.htmlOK 或者在--file参数里用文件名指名格式。比如--file /tmp/result.html 。 1profiler stop --file /tmp/result.html 火焰图的含义火焰图是基于pref结果产生的SVG图片，用来展示CPU的调用栈。 y轴表示调用栈，每一层都是一个函数。调用栈越深，火焰就越高，顶部就是正在执行的函数，下方都是它的父函数。 x轴表示抽样数，如果一个函数在x轴占据的宽度越宽，就表示它被抽到的次数越多，即执行时间长。注意，x轴不代表时间，而是所有调用栈合并后，按照字母顺序排列的。 火焰图就是看顶层的哪个函数占据的宽度最大。只要有“平顶”(plateaus)，就表示该函数可能存在性能问题。颜色没有特殊含义，以为火焰图表示的是CPU的繁忙程度，所以一般选择暖色调。","path":"2021/07/25/阿里巴巴开源的Java性能诊断工具Arthas详解/","date":"07-25","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"CVPR2017:Learning Video Object Segmentation with Visual Memory","text":"Learning Video Object Segmentation with Visual Memory此论文也是旨在解决运动目标分割任务。引入two-stream网络，同时带有一个memory module。Memory module用来捕获视频中目标的演化，由convolutional gated recurrent units（ConvGRU）构成。Two stream包括appearance stream和temporal stream。 网络的两个流分别在视频序列中学习空间和时序特征。 使用双流网络的思路是利用外观和运动的互补性来构建随着时间推移而发展的对象的强大表示。例如，当一个物体在场景中移动时，外观和运动网络都是同样有效的，但是一旦它变成静止的，运动网络就不能像外观网络一样估计这个物体。 Contributions present an approach for moving object segmentation in unconstrained videos that does not require any manually-annotated frames in the input video。网络结构包含 memory unit，this is the first recurrent network based approach to accomplish the video segmentation task。 在DAVIS和Freiburg-Berkeley两个数据集上得到state-of-the-art的结果。 Networks Appearance stream：采用DeepLab网络，在PASCAL VOC上预训练过。取视频的一帧作为输入,输出一个大小为 128 x w/8 x h/8的预测特征。deeplab网络的aspp模块使得特征保持了一个相对较高的特征空间分辨率，并且在每个像素的表示中包含上下文信息。 使用fc6层，每个像素的特征维度为1024， 然后经过两个1x1的卷积层，tanh非线性操作，将通道降至128维。这些层和ConvGRU一起训练。 Temporal stream：是一个motion prediction network，网络采用MPNet（作者之前的工作），在FlyingThings3D 上预训练过。光流作为motion network的输入，产生一个w/4 x h/4 的运动预测， 其中每个值表示对应像素运动的可能性。 Memory module：由convolutional gated units (ConvGRU)构成。两条分支的输出结果concat在一起，作为Conv GRU的输入。 Bidirectional processing：考虑到视频存在这样的情况：目标前几帧是静止的，后面才开始移动。作者的方法前向处理不能分割好初始帧的目标，因为缺少prior memory representation of the object in the first frame。所以采取双向处理的方式。 Visual memory module ConvGRU模块的关键部分是是状态矩阵h ，对于帧 $ t $ , ConvGRU使用双流网络中融合后的特征 $x_t$ 和 前一个状态 $h_{t-1} $ 来计算新的状态 $ h_t $。 通过一个更新门 $z_t$ 和遗忘门 $r_t$ 来进行动态的计算。这些状态和门都是3D的张量，可以刻画视频序列中的时空特征，有效的记忆运动的目标个目标的位置。公式如下： 更新门 $z_t$ 决定将多少记忆合并到新状态 ，遗忘门 $r_t$ 控制前一个状态的影响。 也就是说有多少先前的状态被允许进入候选记忆。 如果$r_t$接近于零，则该单元将忘记先前计算的状态 $ h_{t-1}$ 一个像素的视觉记忆表示不仅取决于输入和该像素处的前一状态，还取决于它的局部邻域。增加卷积内核的大小允许模型处理更大运动的时空模式。 综上所述，该模型学习将当前帧的外观特征与记忆的视频表示相结合，以细化运动预测，甚至在运动对象变为静止时的情况下，他可以完全恢复之前的观察结果到的状态。 Bidirectional processing 考虑这样一个例子:一个物体在视频序列的开始是静止的，然后在后面的帧中开始移动。 前面描述的方法，即按顺序处理视频帧(正向)，不能在初始帧中分割对象。这是因为在第一帧中缺少对象的预先记忆表示。受双向循环模型在语音领域的应用启发，我们使用双向处理步骤来改进我们的框架。 由两个并行的ConvGRU，第一个从第一帧开始前向处理，第二个从最后一帧开始后向处理。 为了生成一个128 x w/8 x h/8 的输出，在每一个时间步将来自两个方向的激活输出被串接起来。然后通过一个3x3的卷积操作，产生一个64 x w/8 x h/8 的特征图，最后连接一个1x1的卷积层和softmax分类层得到最终的二值分割掩码。这个双向的ConvGRU在训练和测试中均会用到。这考虑了整个视频序列的信息。【ps: 但是对于场景发生变化的情况下，这样的似乎不太合理。。。】 在实验部分展示了双向处理能够带来将近3%的提升（在DAVIS数据集上）， 双向处理对FBMS数据集的影响更为突出，在FBMS数据集中，前景目标在视频开始时可以是静态的，比单向处理改进了5% 。 Training一个ConvGRU 模型有6个卷积层，视频序列长度为n，一共需要6n个卷积层，双向的话，就需要12n个卷积层。 这种内存需求使得端到端训练整个模型(包括外观和运动流)变得不可行。我们求助于使用预先训练过的外观和运动网络，并对ConvGRU进行训练。 使用DAVIS数据集的训练集来学习ConvGRU权重 ，Davis数据集中视频序列的每一帧都是运动的， 这使记忆模块倾向于不间断运动流的存在。 当一个对象在测试序列中停止移动时， 这导致了ConvGRU从失败的数据中学到的教训 。 我们增加了训练数据来模拟这种走走停停的场景，从而为真实的视频学习一个更健壮的模型。 创建一个新的训练序列，最后5帧是重复的，用来模拟目标停止运动，其他帧的ground-truth不变， 最后五帧没有使用任何运动输入。这些收工处理的数据以一个固定比例的迭代代替常规的样本。 鉴于ground truth segmentation决定了训练的损失，即，它用于所有的帧，ConvGRU显式地记忆序列的初始部分的移动对象，然后在运动缺失的帧分割它。 我们通过在批处理中复制前五帧来进行类似的训练集扩展，以模拟在视频开始时对象是静态的情况。 其他训练细节 loss： binary cross entropy optimzier： RMSProp lr : 1e-4 weight decay:0.005 所有卷积层(ConvGRU内部的层除外)的初始化都是使用标准的xavier方法完成的. 在每次更新参数之前，进行梯度裁剪，使其位于预定义的范围内，以避免数值问题 。 数据： 随机选择一个视频序列，选择连续的14帧作为一个batch 7 × 7 convolutions in all the ConvGRU operations 对模型进行30000次迭代训练，并将含有附加序列的批次比例设置为20%。 使用一个完全连接的CRF来在后处理步骤中细化边界。 Ablation Study在Davis数据集中不同的组件的影响： ResultsOn Davis2016 On FBMS","path":"2021/07/23/lvo/","date":"07-23","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"}]},{"title":"MySQL语句执行过程","text":"查询语句执行过程分析MySQL基础架构 大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。 Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。 1. MySQL的框架有几个组件, 各是什么作用?连接器：负责跟客户端建立连接、获取权限、维持和管理连接。 查询缓存：查询请求先访问缓存(key 是查询的语句，value 是查询的结果)。命中直接返回。不推荐使用缓存，更新会把缓存清除(关闭缓存：参数 query_cache_type 设置成 DEMAND)。 分析器：对 SQL 语句做解析，判断sql是否正确。 优化器：决定使用哪个索引，多表关联（join）的时候，决定各个表的连接顺序。 执行器：执行语句，先判断用户有无查询权限，使用表定义的存储引擎。 2. 使用查询缓存就一定好么？大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利 查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。 需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。分析器 3. Server层和存储引擎层各是什么作用?Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。 存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。 3. you have an error in your SQL syntax 这个保存是在词法分析里还是在语法分析里报错?语法分析 4. 对于表的操作权限验证在哪里进行?执行器 5. 执行器的执行查询语句的流程是什么样的?1select * from T where ID=10; 先判断是否有该表的操作权限，有则进行下面的操作，没有则报错 1）调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中； 2)调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。 3）执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端 问题如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？ 答案： 分析器。 有人回答执行器，原因是这个时候才打开表获取数据，但是表的字段不是数据啊，是事先定义好的，所以可以直接读取的，不需要打开表。 那么，分析器的作用就是就是对你输入的sql字符串进行词法分析，这时候会检查你的表名，列名等。在Oracle数据库中会在分析阶段判断语句是否正确，表是否存在，列是否存在，mysql也借鉴了其设计思想。","path":"2021/07/23/mysql语句执行过程/","date":"07-23","excerpt":"","tags":[{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"}]},{"title":"区间调度算法","text":"区间调度算法区间调度问题是一个很经典的贪心算法问题。 贪⼼算法可以认为是动态规划算法的⼀个特例， 相⽐动态规划， 使⽤贪⼼算法需要满⾜更多的条件（贪⼼选择性质），但是效率⽐动态规划要⾼ 。 leetcode435. 无重叠区间给定一个区间的集合，找到需要移除区间的最小数量，使剩余区间互不重叠。 注意: 可以认为区间的终点总是大于它的起点。 区间 [1,2] 和 [2,3] 的边界相互“接触”，但没有相互重叠。示例 1: 输入: [ [1,2], [2,3], [3,4], [1,3] ] 输出: 1 解释: 移除 [1,3] 后，剩下的区间没有重叠。示例 2: 输入: [ [1,2], [1,2], [1,2] ] 输出: 2 解释: 你需要移除两个 [1,2] 来使剩下的区间没有重叠。示例 3: 输入: [ [1,2], [2,3] ] 输出: 0 解释: 你不需要移除任何区间，因为它们已经是无重叠的了 这个问题有许多看起来不错的贪⼼思路， 却都不能得到正确答案。 ⽐如说：也许我们可以每次选择可选区间中开始最早的那个？ 但是可能存在某些区间开始很早， 但是很⻓， 使得我们错误地错过了⼀些短的区间。 或者我们每次选择可选区间中最短的那个？ 或者选择出现冲突最少的那个区间？ 这些⽅案都能很容易举出反例， 不是正确的⽅案。 正确的思路其实很简单， 可以分为以下三步： 从区间集合 intvs 中选择⼀个区间 x， 这个 x 是在当前所有区间中结束早的（end 最⼩） 把所有与 x 区间相交的区间从区间集合 intvs 中删除。 重复步骤 1 和 2， 直到 intvs 为空为⽌。 之前选出的那些 x 就是最⼤不相交⼦集。 123456789101112131415161718class Solution &#123; public int eraseOverlapIntervals(int[][] intervals) &#123; if(intervals.length == 1)&#123; return 0; &#125; Arrays.sort(intervals, (a, b)-&gt; a[1]-b[1]); int count = 0; int x_end = Integer.MIN_VALUE; for(int[] a: intervals)&#123; if(a[0] &lt; x_end )&#123; count++; &#125;else&#123; x_end = a[1]; &#125; &#125; return count; &#125;&#125; leetcode452. 用最少数量的箭引爆气球在二维空间中有许多球形的气球。对于每个气球，提供的输入是水平方向上，气球直径的开始和结束坐标。由于它是水平的，所以y坐标并不重要，因此只要知道开始和结束的x坐标就足够了。开始坐标总是小于结束坐标。平面内最多存在10^4个气球。 一支弓箭可以沿着x轴从不同点完全垂直地射出。在坐标x处射出一支箭，若有一个气球的直径的开始和结束坐标为 xstart，xend， 且满足 xstart ≤ x ≤ xend，则该气球会被引爆。可以射出的弓箭的数量没有限制。 弓箭一旦被射出之后，可以无限地前进。我们想找到使得所有气球全部被引爆，所需的弓箭的最小数量。 Example: 12345678输入:[[10,16], [2,8], [1,6], [7,12]]输出:2解释:对于该样例，我们可以在x = 6（射爆[2,8],[1,6]两个气球）和 x = 11（射爆另外两个气球）。 这个问题和区间调度算法⼀模⼀样！ 如果最多有 n 个不重叠的区间， 那么就⾄少需要 n 个箭头穿透所有区间。只是有⼀点不⼀样， 在 intervalSchedule 算法中， 如果两个区间的边界触碰， 不算重叠； ⽽按照这道题⽬的描述， 箭头如果碰到⽓球的边界⽓球也会爆炸， 所以说相当于区间的边界触碰也算重叠。 在上道题目的基础上稍微修改即可： 123456789101112131415161718192021class Solution &#123; public int findMinArrowShots(int[][] points) &#123; // 无重叠的+1 if(points.length == 1)&#123; return 1; &#125; Arrays.sort(points, (a, b)-&gt; a[1]-b[1]); int count = 0; int x_end = Integer.MIN_VALUE; for(int[] a: points)&#123; if(a[0] &gt; x_end )&#123; count++; x_end = a[1]; &#125; &#125; return count; &#125;&#125; 区间调度问题之区间合并leetcode56. 合并区间给出一个区间的集合，请合并所有重叠的区间。 示例 1: 123输入: intervals = [[1,3],[2,6],[8,10],[15,18]]输出: [[1,6],[8,10],[15,18]]解释: 区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2: 123输入: intervals = [[1,4],[4,5]]输出: [[1,5]]解释: 区间 [1,4] 和 [4,5] 可被视为重叠区间。 ⼀个区间可以表⽰为 [start, end] ， 前⽂聊的区间调度问题， 需要按 end排序， 以便满⾜贪⼼选择性质。 ⽽对于区间合并问题， 其实按 end 和start 排序都可以， 不过为了清晰起⻅， 我们选择按 start 排序。 显然， 对于⼏个相交区间合并后的结果区间 x ， x.start ⼀定是这些相交区间中 start 最⼩的， x.end ⼀定是这些相交区间中 end 最⼤的。 1234567891011121314151617181920212223242526class Solution &#123; public int[][] merge(int[][] intervals) &#123; if (intervals.length == 0) &#123; return new int[0][2]; &#125; int m = intervals.length; int n = intervals[0].length; List&lt;int[] &gt; res = new ArrayList&lt;&gt;(); Arrays.sort(intervals, (a, b)-&gt;a[0]-b[0]); res.add(intervals[0]); for(int i = 0; i &lt; m; i++)&#123; int[] curr = intervals[i]; int[] last = res.get(res.size()-1); // 注意这里是引用 if(curr[0] &lt;= last[1])&#123; // 找到最大的end last[1] = Math.max(last[1], curr[1]); // 会修改list中值 &#125;else&#123; res.add(curr); &#125; &#125; return res.toArray(new int[res.size()][]); &#125;&#125; 区间交集问题leetcode986. 区间列表的交集给定两个由一些 闭区间 组成的列表，每个区间列表都是成对不相交的，并且已经排序。 返回这两个区间列表的交集。 （形式上，闭区间 [a, b]（其中 a &lt;= b）表示实数 x 的集合，而 a &lt;= x &lt;= b。两个闭区间的交集是一组实数，要么为空集，要么为闭区间。例如，[1, 3] 和 [2, 4] 的交集为 [2, 3]。） 输入：A = [[0,2],[5,10],[13,23],[24,25]], B = [[1,5],[8,12],[15,24],[25,26]] 输出：[[1,2],[5,5],[8,10],[15,23],[24,24],[25,25]] 画图可知规律。 123456789101112131415161718192021222324class Solution &#123; public int[][] intervalIntersection(int[][] A, int[][] B) &#123; List&lt;int[] &gt; res = new ArrayList&lt;&gt;(); int i =0, j = 0; while( i &lt; A.length &amp;&amp; j &lt; B.length)&#123; int a1 = A[i][0]; int a2 = A[i][1]; int b1 = B[j][0]; int b2 = B[j][1]; if(b2 &gt;= a1 &amp;&amp; a2 &gt;= b1)&#123; res.add(new int[]&#123;Math.max(a1,b1), Math.min(a2, b2)&#125;); &#125; if(b2 &lt; a2)&#123; j++; &#125;else&#123; i++; &#125; &#125; return res.toArray(new int[res.size()][]); &#125;&#125; 参考 https://labuladong.gitbook.io/algo/suan-fa-si-wei-xi-lie/qu-jian-jiao-ji-wen-ti","path":"2020/10/05/区间调度算法/","date":"10-05","excerpt":"","tags":[{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"贪心","slug":"贪心","permalink":"https://castile.github.io/tags/%E8%B4%AA%E5%BF%83/"}]},{"title":"leetcode42接雨水","text":"描述给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。 上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水） 示例: 输入: [0,1,0,2,1,0,1,3,2,1,2,1] 输出: 6 题解对于每一个位置，该位置能装最大的雨水与两边中最大高度中的最小值有关系。 即要先求出min{lmax， rmax}。我们只需要找到左边的最大和右边的最大高度就行。 该位置能接到的雨水就是其高度差。 注意： 第一个格子和最后一个格子不能接到雨水。 暴力解法时间复杂度为O(N^2) 1234567891011121314151617181920212223242526class Solution &#123; public int trap(int[] height) &#123; int n = height.length; int res = 0; for(int i = 1; i &lt; n -1; i++)&#123; int lmax = 0; int rmax = 0; //找右边的 for(int j = i; j &lt; n; j++)&#123; rmax = Math.max(rmax, height[j]); &#125; // 左边的 for(int j = i; j &gt;= 0; j--)&#123; lmax = Math.max(lmax, height[j]); &#125; res += Math.min(lmax, rmax)- height[i]; &#125; return res; &#125;&#125; 这种太暴力了，每次都得重新计算当前位置的左边最大和右边最大，不如先将每个位置的左边最大和右边最大都保存下来啊，这样就不用每次重新计算了，可能降低时间复杂度。 1234567891011121314151617181920212223242526272829class Solution &#123; public int trap(int[] height) &#123; if(height == null || height.length == 0)&#123; return 0; &#125; int n = height.length; int[] lmax = new int[n]; int[] rmax = new int[n]; lmax[0] = height[0]; rmax[n-1] = height[n-1]; // 从左往右计算lmax for(int i = 1; i &lt; n; i++)&#123; lmax[i] = Math.max(height[i], lmax[i-1]); &#125; // 从右往左计算右边最大 for(int i = n-2; i &gt;= 0; i--)&#123; rmax[i] = Math.max(height[i], rmax[i+1]); &#125; int res = 0; // 计算 for(int i = 1; i &lt; n -1; i++)&#123; res += Math.min(lmax[i], rmax[i])- height[i]; &#125; return res; &#125;&#125; 双指针使用双指针边走边算，减少空间 复杂度。 123456789101112131415161718192021222324class Solution &#123; public int trap(int[] height) &#123; if(height.length == 0) return 0; int n = height.length; int left = 0; int right = n-1; int l_max=height[0], r_max = height[n-1]; int ans = 0; while(left &lt;= right)&#123; l_max = Math.max(l_max, height[left]); r_max = Math.max(r_max, height[right]); if(l_max &lt; r_max)&#123; ans += l_max - height[left]; left++; &#125;else&#123; ans += r_max - height[right]; right--; &#125; &#125; return ans; &#125;&#125;","path":"2020/10/04/leetcode42接雨水/","date":"10-04","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"}]},{"title":"算法题解之单调栈和单调队列","text":"单调栈栈是很简单的⼀种数据结构， 先进后出的逻辑顺序， 符合某些问题的特点， ⽐如说函数调⽤栈。 单调栈实际上就是栈， 只是利⽤了⼀些巧妙的逻辑， 使得每次新元素⼊栈后， 栈内的元素都保持有序（单调递增或单调递减） 。 leetcode有一些题目可以使用单调栈来解决。 leetcode496. 下一个更大元素 I给定两个没有重复元素 的数组 nums1 和 nums2 ，其中nums1 是 nums2 的子集。找到 nums1 中每个元素在 nums2 中的下一个比其大的值。 nums1 中数字 x 的下一个更大元素是指 x 在 nums2 中对应位置的右边的第一个比 x 大的元素。如果不存在，对应位置输出 -1 。 示例 1: 输入: nums1 = [4,1,2], nums2 = [1,3,4,2]. 输出: [-1,3,-1] 解释: 对于num1中的数字4，你无法在第二个数组中找到下一个更大的数字，因此输出 -1。 对于num1中的数字1，第二个数组中数字1右边的下一个较大数字是 3。 对于num1中的数字2，第二个数组中没有下一个更大的数字，因此输出 -1。 示例 2: 输入: nums1 = [2,4], nums2 = [1,2,3,4]. 输出: [3,-1] 解释: 对于 num1 中的数字 2 ，第二个数组中的下一个较大数字是 3 。 对于 num1 中的数字 4 ，第二个数组中没有下一个更大的数字，因此输出 -1 。 1234567891011121314151617181920212223class Solution &#123; public int[] nextGreaterElement(int[] nums1, int[] nums2) &#123; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int[] ans = new int[nums2.length]; int[] res = new int[nums1.length]; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for(int i = nums2.length-1; i &gt;= 0; i--)&#123; while(!stack.isEmpty() &amp;&amp; nums2[i] &gt;= stack.peek())&#123; stack.pop(); &#125; int tmp = stack.isEmpty()? -1 : stack.peek(); map.put(nums2[i], tmp ); stack.push(nums2[i]); &#125; for(int i = 0; i &lt; nums1.length; i++)&#123; res[i] = map.get(nums1[i]); &#125; return res; &#125;&#125; leetcode739. 每日温度请根据每日气温列表，重新生成一个列表。对应位置的输出为：要想观测到更高的气温，至少需要等待的天数。如果气温在这之后都不会升高，请在该位置用 0 来代替。 例如，给定一个列表 temperatures = [73, 74, 75, 71, 69, 72, 76, 73]，你的输出应该是 [1, 1, 4, 2, 1, 1, 0, 0]。 提示：气温 列表长度的范围是 [1, 30000]。每个气温的值的均为华氏度，都是在 [30, 100] 范围内的整数。 这个问题本质上也是找 Next Greater Number， 只不过现在不是问你 Next Greater Number 是多少， ⽽是问你当前距离 Next Greater Number 的距离⽽已。 123456789101112131415class Solution &#123; public int[] dailyTemperatures(int[] T) &#123; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); int[] res = new int[T.length]; for(int i = T.length-1; i &gt;= 0; i--)&#123; while( !stack.isEmpty() &amp;&amp; T[stack.peek()] &lt;= T[i])&#123; stack.pop(); &#125; res[i] = stack.isEmpty()? 0 : stack.peek()-i; stack.push(i); &#125; return res; &#125;&#125; 如何处理「循环数组」同样是 Next Greater Number， 现在假设给你的数组是个环形的， 如何处理？ 503. 下一个更大元素 II给定一个循环数组（最后一个元素的下一个元素是数组的第一个元素），输出每个元素的下一个更大元素。数字 x 的下一个更大的元素是按数组遍历顺序，这个数字之后的第一个比它更大的数，这意味着你应该循环地搜索它的下一个更大的数。如果不存在，则输出 -1。 示例 1: 输入: [1,2,1] 输出: [2,-1,2] 解释: 第一个 1 的下一个更大的数是 2； 数字 2 找不到下一个更大的数； 第二个 1 的下一个最大的数需要循环搜索，结果也是 2。 注意: 输入数组的长度不会超过 10000。 12345678910111213141516class Solution &#123; public int[] nextGreaterElements(int[] nums) &#123; int[] res = new int[nums.length]; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for(int i = 2 * nums.length - 1; i &gt;= 0 ; i--)&#123; while( !stack.isEmpty() &amp;&amp; stack.peek() &lt;= nums[i % nums.length])&#123; stack.pop(); &#125; res[i % nums.length] = stack.isEmpty() ? -1: stack.peek() ; stack.push(nums[i % nums.length]); &#125; return res; &#125;&#125; 或者开辟一个新数组，将原数组复制两份。 1234567891011121314151617181920class Solution &#123; public int[] nextGreaterElements(int[] nums) &#123; int[] arr = new int[2*nums.length]; for(int i = 0; i &lt; arr.length; i++)&#123; arr[i] = nums[i % nums.length]; &#125; int[] res = new int[nums.length]; Deque&lt;Integer&gt; stack = new ArrayDeque&lt;&gt;(); for(int i = arr.length-1; i &gt;= 0; i--)&#123; while(!stack.isEmpty() &amp;&amp; arr[i] &gt;= stack.peek())&#123; stack.pop(); &#125; res[i % nums.length ] = stack.isEmpty()?-1: stack.peek(); stack.push(arr[i]); &#125; return res; &#125;&#125; 腾讯笔面试题：逛街2021校招亲身经历的面试题，可惜了，当时没做出来 小Q在周末的时候和他的小伙伴来到大城市逛街，一条步行街上有很多高楼，共有n座高楼排成一行。 小Q从第一栋一直走到了最后一栋，小Q从来都没有见到这么多的楼，所以他想知道他在每栋楼的位置处能看到多少栋楼呢？（当前面的楼的高度大于等于后面的楼时，后面的楼将被挡住） 输入描述:1输入第一行将包含一个数字n，代表楼的栋数，接下来的一行将包含n个数字wi(1&lt;=i&lt;=n)，代表每一栋楼的高度。1&lt;=n&lt;=100000;1&lt;=wi&lt;=100000; 输出描述:1输出一行，包含空格分割的n个数字vi，分别代表小Q在第i栋楼时能看到的楼的数量。 输入例子1:1265 3 8 3 2 5 输出例子1:13 3 5 4 4 4 例子说明1:1当小Q处于位置3时，他可以向前看到位置2,1处的楼，向后看到位置4,6处的楼，加上第3栋楼，共可看到5栋楼。当小Q处于位置4时，他可以向前看到位置3处的楼，向后看到位置5,6处的楼，加上第4栋楼，共可看到4栋楼。 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.Scanner;import java.util.Stack;public class Main&#123; public static int[] MaxBuilding(int[] arr)&#123; if(arr == null || arr.length &lt; 0) return null; int[] res = new int[arr.length]; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); // 从前向后遍历，维持一个递减栈 for(int i = 0;i &lt; arr.length;i++)&#123; res[i] = stack.size(); //前面能看到的数量 while(!stack.isEmpty() &amp;&amp; arr[i] &gt;= arr[stack.peek()])&#123; stack.pop(); &#125; stack.push(i); &#125; stack.clear(); // 从后向前遍历，同样维持递减栈 for(int i = arr.length - 1;i &gt;=0;i--) &#123; res[i] = res[i] + 1 + stack.size();;//后面能看到的数量 + 自己 while (!stack.isEmpty() &amp;&amp; arr[i] &gt;= arr[stack.peek()]) &#123; stack.pop(); &#125; stack.push(i); &#125; return res; &#125; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int len = sc.nextInt(); int[] arr = new int[len]; for(int i = 0 ; i &lt; len ; i++)&#123; arr[i] = sc.nextInt(); &#125; int[] res = MaxBuilding(arr); for (int i = 0; i &lt; res.length; i++) &#123; System.out.print(res[i] + &quot; &quot;); &#125; &#125;&#125; 单调队列所谓单调队列，就是在保持原始队列的先进先出的特性外，添加一个新方法getMax(), 可以以O(1)的时间复杂度获取当前队列的最大值。 字节亲身经历的面试题！！！可惜了 请定义一个队列并实现函数 max_value 得到队列里的最大值，要求函数max_value、push_back 和 pop_front 的均摊时间复杂度都是O(1)。 若队列为空，pop_front 和 max_value 需要返回 -1 123456789101112131415161718192021222324252627282930313233343536373839404142434445class MaxQueue &#123; Deque&lt;Integer&gt; data = null; Deque&lt;Integer&gt; maxQ = null; public MaxQueue() &#123; data = new ArrayDeque&lt;&gt;(); maxQ = new ArrayDeque&lt;&gt;(); &#125; public int max_value() &#123; if(!maxQ.isEmpty())&#123; return maxQ.peek(); &#125; return -1; &#125; public void push_back(int value) &#123; while(!maxQ.isEmpty() &amp;&amp; maxQ.peekLast() &lt; value)&#123; maxQ.pollLast(); // 从后面出队列 &#125; maxQ.offerLast(value); data.offer(value); &#125; public int pop_front() &#123; if(data.isEmpty())&#123; return -1; &#125; int poll = data.peek(); if(poll == maxQ.peek())&#123; maxQ.poll(); &#125; data.poll(); return poll; &#125;&#125;/** * Your MaxQueue object will be instantiated and called as such: * MaxQueue obj = new MaxQueue(); * int param_1 = obj.max_value(); * obj.push_back(value); * int param_3 = obj.pop_front(); */ leetcode239. 滑动窗口最大值给定一个数组 nums，有一个大小为 k 的滑动窗口从数组的最左侧移动到数组的最右侧。你只可以看到在滑动窗口内的 k 个数字。滑动窗口每次只向右移动一位。 返回滑动窗口中的最大值。 示例: 输入: nums = [1,3,-1,-3,5,3,6,7], 和 k = 3 输出: [3,3,5,5,6,7] 解释: 滑动窗口的位置 最大值 [1 3 -1] -3 5 3 6 7 3 1 [3 -1 -3] 5 3 6 7 3 1 3 [-1 -3 5] 3 6 7 5 1 3 -1 [-3 5 3] 6 7 5 1 3 -1 -3 [5 3 6] 7 6 1 3 -1 -3 5 [3 6 7] 7 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; class MonotonicQueue&#123; private Deque&lt;Integer&gt; q; public MonotonicQueue()&#123; q = new ArrayDeque&lt;&gt;(); &#125; private int max()&#123; return q.peek(); &#125; private void push(int value)&#123; while(!q.isEmpty() &amp;&amp; value &gt; q.getLast())&#123; q.pollLast(); &#125; q.offer(value); &#125; private void pop(int value)&#123; if(!q.isEmpty() &amp;&amp; q.peek() == value)&#123; q.pollFirst(); &#125; &#125; &#125; public int[] maxSlidingWindow(int[] nums, int k) &#123; if(k == 0) return new int[]&#123;&#125;; MonotonicQueue q = new MonotonicQueue(); int[] res = new int[nums.length - k + 1]; int j = 0; for(int i = 0; i &lt; nums.length; i++)&#123; if( i &lt; k -1)&#123; q.push(nums[i]); &#125;else&#123; // 窗口滑动 q.push(nums[i]); res[j++] = q.max(); q.pop(nums[i- k + 1]); // 移除窗口的最后一个元素 &#125; &#125; return res; &#125;&#125;","path":"2020/10/02/单调栈和单调队列的应用/","date":"10-02","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"Redis的持久化","text":"Redis 的持久化Redis是一个基于内存的数据库，这就体现了其易失性。内存中的数据当机器断电的时候就会消失，所以，持久化机制对于数据的完整性使至关重要的。 Redis提供了两种持久化机制，分别是分别是RDB(Redis DataBase)和AOF(Append Only File)。 Redis在以前的版本中是单线程的，而在6.0后对Redis的io模型做了优化，io Thread为多线程的，但是worker Thread仍然是单线程。 在Redis启动的时候就会去加载持久化的文件，如果没有就直接启动，在启动后的某一时刻继续持久化内存中产生的数据。 RDB持久化机制RDB持久化就是将当前进程的数据以生成快照的形式持久化到磁盘中。 它恢复时是将快照文件直接读到内存里。 RDB持久化的时候会单独fork一个与当前进程一摸一样的子进程来进行持久化，因此RDB持久化有如下特点： 开机恢复数据快。 写入持久化文件快。 Redis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失 Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 RDB的持久化也是Redis默认的持久化机制，它会把内存中的数据以快照的形式写入默认文件名为dump.rdb中保存。 文件名可以咋Redis的配置文件redis.conf中进行配置。dafilename就是配置rdb的持久化文件名。 RDB 的触发 save命令 save命令不会fork子进程，通过阻塞当前Redis服务器，直到RDB完成为止，所以该命令在生产中一般不会使用。 可以配置redis.conf文件中的dir，表示rdb持久化后生成的rdb二进制文件所在的位置。 bgsave命令 Redis会在后台异步进行快照操作， 命令会在后台fork一个与Redis主线程一摸一样的子线程，由子线程负责内存中的数据持久化。 快照同时还可以响应客户端请求。可以通过lastsave命令获取最后一次成功执行快照的时间。 自动化 除了上面在命令行使用save和bgsave命令触发持久化，也可以在redis.conf配置文件中，完成配置。 123save 900 1save 300 10save 60 100000 在新安装的redis中由默认的以上三个save配置，save 900 1表示900秒内如果至少有1个key值变化，则进行持久化保存数据； save 300 10则表示300秒内如果至少有10个key值发生变化，则进行持久化，save 60 10000以此类推。 save和bgsave的对比 save是同步持久化数据，而bgsave是异步持久化数据。 save不会fork子进程，通过主进程持久化数据，会阻塞处理客户端的请求，而bgsave会fork子进程持久化数据，同时还可以处理客户端请求，高效。 save不会消耗内存，而bgsave会消耗内存。因为会fork新进程。 RDB优势和劣势 缺点： RDB持久化后的文件是紧凑的二进制文件，适合于备份、全量复制、大规模数据恢复的场景，对数据完整性和一致性要求不高，RDB会丢失最后一次快照的数据。也即在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改。而且如果使用的bgsave的话，Fork的时候，内存中的数据被克隆了一份，大致2倍的膨胀性需要考虑。 优点： 开机的恢复数据快，写入持久化文件快。 AOF持久化机制AOF持久化机制是以日志的形式记录Redis中的每一次的增删改操作，不会记录查询操作，以文本的形式记录，打开记录的日志文件就可以查看操作记录。只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 AOF默认不开启，开启需要配置redis.conf中的 appendonly no 修改为 appendonly yes， 也可以配置文件名，通过appendonly.aof， 当然，也可以配置dir。 AOF触发机制AOF带来的持久化更加安全可靠，默认提供三种触发机制，如下所示： no：表示等操作系统等数据缓存同步到磁盘中（快、持久化没保证）。 always：同步持久化，每次发生数据变更时，就会立即记录到磁盘中（慢，安全）。 everysec：表示每秒同步一次（默认值，很快，但是会丢失一秒内的数据）。 AOF中每秒同步也是异步完成的，效率是非常高的，由于该机制对日志文件的写入操作是采用append的形式。 在redis中配置 appendfsync always。在写入的过程即使宕机，也不会丢失已经存入日志文件的数据，数据的完整性是非常高的。 AOF的重写机制AOF采用文件追加方式，文件会越来越大为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。 导致aof文件增大的无效的操作有很多， 举个例子，比如某一时刻对一个k++，然后后面的某一时刻k–，这样k的值是保持不变的，那么这两次的操作就是无效的。 如果像这样的无效操作很多，记录的文件臃肿，就浪费了资源空间，所以在Redis中出现了rewrite机制。 redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。 重写AOF的日志文件不是读取旧的日志文件瘦身，而是将内存中的数据用命令的方式重写一个AOF文件，重新保存替换原来旧的日志文件，因此内存中的数据才是最新的。 重写操作也会fork一个子进程来处理重写操作，重写以内存中的数据作为重写的源，避免了操作的冗余性，保证了数据的最新。 执行set k1 1的命令，此命令映射到文件中的命令如下： 1234567*3 //表示该命令有三组 set为一组 k1为一组 1为一组$3 // 表示 set 有三个字符set // 表示执行了set命令$2 // 表示k1有两个字符k1 // key值$1 // 便是value值的字符长度为11 // value值 当AOF的日志文件增长到一定大小的时候Redis就能够bgrewriteaof对日志文件进行重写瘦身。当AOF配置文件大于改配置项时自动开启重写（这里指超过原大小的100%）。 该配置可以通过如下的配置项进行配置： 12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64m Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时触发。 AOF的优缺点每修改同步：appendfsync always 同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好 每秒同步：appendfsync everysec 异步操作，每秒记录 如果一秒内宕机，有数据丢失 不同步：appendfsync no 从不同步 优点： AOF更好保证数据不会被丢失，最多只丢失一秒内的数据，通过fork一个子进程处理持久化操作，保证了主进程不会进程io操作，能高效的处理客户端的请求。 另外重写操作保证了数据的有效性，即使日志文件过大也会进行重写。 AOF的日志文件的记录可读性非常的高，即使某一时刻有人执行flushall清空了所有数据，只需要拿到aof的日志文件，然后把最后一条的flushall给删除掉，就可以恢复数据。 缺点： 对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。AOF在运行效率上往往会慢于RDB。 混合持久化在redis4.0后混合持久化（RDB+AOF）对重写的优化，4.0版本的混合持久化默认是关闭的，可以通过以下的配置开启混合持久化： 1aof-use-rdb-preamble no 混合持久化也是通过bgrewriteaof来完成的，不同的是当开启混合持久化时，fork出的子进程先将共享内存的数据以RDB方式写入aof文件中，然后再将重写缓冲区的增量命令以AOF方式写入文件中。 写入完成后通知主进程统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。简单的说：新的AOF文件前半段是以RDB格式的全量数据后半段是AOF格式的增量数据。 优点： 混合持久化结合RDB持久化和AOF持久化的优点，由于绝大部分的格式是RDB格式，加载速度快，增量数据以AOF方式保存，数据更少的丢失。 总结 RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储 AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据。AOF命令以Redis协议追加保存每次写的操作到文件末尾。Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大。 只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式。 如果同时开启两种持久化方式，在这种情况下，当redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？作者建议不要，因为RDB更适合用于备份数据库(AOF在不断变化不好备份)，快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。 性能建议因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果Enalbe AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价一是带来了持续的IO，二是AOF rewrite的最后将rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。默认超过原大小100%大小时重写可以改到适当的数值。 如果不Enable AOF ，仅靠Master-Slave Replication 实现高可用性也可以。能省掉一大笔IO也减少了rewrite时带来的系统波动。代价是如果Master/Slave同时倒掉，会丢失十几分钟的数据，启动脚本也要比较两个Master/Slave中的RDB文件，载入较新的那个。新浪微博就选用了这种架构。 Redis是怎么持久化的？服务主从数据怎么交互的？RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。 不过Redis本身的机制是 AOF持久化开启且存在AOF文件时，优先加载AOF文件；AOF关闭或者AOF文件不存在时，加载RDB文件；加载AOF/RDB文件完成后，Redis启动成功；AOF/RDB文件存在错误时，Redis启动失败并打印错误信息 如果突然机器掉电会怎样？取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。 参考 一不小心肝出了4W字的Redis面试教程","path":"2020/09/14/Redis的持久化/","date":"09-14","excerpt":"","tags":[{"name":"redis","slug":"redis","permalink":"https://castile.github.io/tags/redis/"}]},{"title":"Redis的Value类型及其应用场景","text":"String数据类型字符串类型，也可以进行数值计算，bitmap也属于String。 1234127.0.0.1:6379&gt; set a helloOK127.0.0.1:6379&gt; get a&quot;hello&quot; String类型的数据结构存储方式有三种int、raw、embstr。那么这三种存储方式有什么区别 123456789127.0.0.1:6379&gt; set k1 345OK127.0.0.1:6379&gt; object encoding k1&quot;int&quot;127.0.0.1:6379&gt; set k2 3.2000OK127.0.0.1:6379&gt; object encoding k2&quot;embstr&quot;127.0.0.1:6379&gt; Redis中规定假如存储的是整数型值，比如set num 123这样的类型，就会使用 int的存储方式进行存储，在redisObject的ptr属性中就会保存该值。 假如存储的字符串是一个字符串值并且长度大于32个字节就会使用SDS（simple dynamic string）方式进行存储，并且encoding设置为raw；若是字符串长度小于等于32个字节就会将encoding改为embstr来保存字符串. SDS称为简单动态字符串，对于SDS中的定义在Redis的源码中有的三个属性int len、int free、char buf[]。 len保存了字符串的长度，free表示buf数组中未使用的字节数量，buf数组则是保存字符串的每一个字符元素。 SDS与C语言字符串有什么区别呢？ Redis没有使用C语言的字符串，而是自己定义和设计了自己的字符串类型，具有很多优势、 C语言的字符串类型没有len属性，如果要获得字符串的长度只能遍历一遍去统计，时间复杂度为O(n)。而Redis中的SDS有len这个属性，直接返回len值就行，时复为O(1)。 C语言两个字符串拼接如果没有分配足够长度的空间的话，会出现缓冲区溢出的情况。而redis会先根据 len的属性判断空间是否满足要求，空间不够时会相应扩展，不会缓冲区溢出。 具体的空间预分配原则是：当修改字符串后的长度len小于1MB，就会预分配和len一样长度的空间，即len=free；若是len大于1MB，free分配的空间大小就为1MB。 SDS有空间预分配和惰性空间释放两种策略。在为字符串分配空间的时候，分配的空间比实际要多。能减少连续的执行字符串增长带来内存重新分配的次数 。 当字符串被缩短的时候，SDS也不会立即回收不适用的空间，而是通过free属性将不使用的空间记录下来，等后面使用的时候再释放。 SDS是二进制安全的，除了可以储存字符串以外还可以储存二进制文件（如图片、音频，视频等文件的二进制数据）；而c语言中的字符串是以空字符串作为结束符，一些图片中含有结束符，因此不是二进制安全的。 c语言字符串 SDS 获取长度的时间复杂度为O(n) 获取长度的时间复杂度为O(1) 不是二进制安全的 是二进制安全的 只能保存字符串 还可以保存二进制数据 n次增长字符串必然会带来n次的内存分配 n次增长字符串内存分配的次数&lt;=n VFS 虚拟文件系统12345127.0.0.1:6379&gt; set /root/user/video a.ma4OK127.0.0.1:6379&gt; get /root/user/video&quot;a.ma4&quot; 数值计算12345678910127.0.0.1:6379&gt; set k1 4OK127.0.0.1:6379&gt; DECR k1(integer) 3127.0.0.1:6379&gt; get k1&quot;3&quot;127.0.0.1:6379&gt; INCRBY k1 5(integer) 8127.0.0.1:6379&gt; get k1&quot;8&quot; strlen 计算的是字节数1234567891011121314151617127.0.0.1:6379&gt; set k1 aOK127.0.0.1:6379&gt; STRLEN a(integer) 0127.0.0.1:6379&gt; STRLEN k1(integer) 1127.0.0.1:6379&gt; APPEND k1 xxoo(integer) 5127.0.0.1:6379&gt; STRLEN k1(integer) 5127.0.0.1:6379&gt; APPEND k1 朱(integer) 8127.0.0.1:6379&gt; get k1&quot;axxoo\\xe6\\x9c\\xb1&quot;127.0.0.1:6379&gt; strlen k1(integer) 8 bitmap是一个二进制位 1234127.0.0.1:6379&gt; SETBIT k1 1 1 # 0 1 0 0 0 0 0 0(integer) 0127.0.0.1:6379&gt; get k1&quot;@&quot; # 表示是ASCII码 1234567891011127.0.0.1:6379&gt; SETBIT k1 7 1 # 0 1 0 0 0 0 0 1(integer) 0127.0.0.1:6379&gt; get k1&quot;A&quot;127.0.0.1:6379&gt; SETBIT k2 1 1(integer) 0127.0.0.1:6379&gt; SETBIT k2 6 1(integer) 0127.0.0.1:6379&gt; get k2&quot;B&quot; 与或操作12345678910111213127.0.0.1:6379&gt; BITOP and andkey k1 k2(integer) 1127.0.0.1:6379&gt; get andkey&quot;@&quot;# 0 1 0 0 0 0 0 1 # 0 1 0 0 0 0 1 0 # --&gt; 0 1 0 0 0 0 0 0 @ 127.0.0.1:6379&gt; BITOP or orkey k1 k2(integer) 1127.0.0.1:6379&gt; get orkey&quot;C&quot; 如果设置的位数很大，会自动进行字节拓宽 123456127.0.0.1:6379&gt; SETBIT k1 9999 1(integer) 0127.0.0.1:6379&gt; STRLEN k1(integer) 1250127.0.0.1:6379&gt; bitcount统计1的个数1234127.0.0.1:6379&gt; BITCOUNT k1 0 0(integer) 2127.0.0.1:6379&gt; BITCOUNT k1 0 -1(integer) 3 bitmap的应用场景用户统计需求： 统计任意时间窗 统计用户的登录天数 使用bitmap来做。 比如统计一年内用户的登录天数，可以创建一个365位的bitmap，用户在哪一天登陆了，就将对应的位置为1，然后使用bitcount来统计1的个数，即为用户的登录总天数。 1234567127.0.0.1:6379&gt; SETBIT hongliang 2 1(integer) 0127.0.0.1:6379&gt; SETBIT hongliang 364 1(integer) 0127.0.0.1:6379&gt; BITCOUNT hongliang 0 -1(integer) 2 # 两天 12127.0.0.1:6379&gt; STRLEN hongliang(integer) 46 # 只消耗了46个字节就能存储一年的时间 京东618只要用户登录就送一个礼物假设京东有2个亿个用户，那么我们需要准备多少份礼物。 用户分为活跃用户和僵尸用户，我们应该为活跃用户准备礼物。 123456127.0.0.1:6379&gt; SETBIT 20200101 2 1 # 2020年1月1日，用户3登陆了(integer) 0127.0.0.1:6379&gt; SETBIT 20200101 6 1 # 2020年1月1日，用户7登陆了(integer) 0127.0.0.1:6379&gt; SETBIT 20200102 6 1 # 2020年1月2日，用户7登陆了(integer) 0 这样设计，我们可以看出， 1月1日和1月2日两天只有两个用户登陆了，我们可以使用或运算来得出2. 1234127.0.0.1:6379&gt; BITOP or res 20200101 20200102(integer) 1127.0.0.1:6379&gt; BITCOUNT res 0 -1(integer) 2 1230612306买票问题 将座位的情况缓存到redis中，每一个站的座位情况使用bitmap来处理。 假如客户P买了从A-B的车票，客户Q想买A-D的车票，那么只需要将ABCD四个站的bitmap进行或运算即可，为0的那个座位才能买。 linux权限管理chmod 777 rwx rwx rwx 持有者 持有组 其他人 任何人都有权限 三个位分别表示421 000 = 0 111= 7 List Redis中的列表在3.2之前的版本是使用ziplist和linkedlist进行实现的。在3.2之后的版本就是引入了quicklist。 linkedlist是一个双向链表。quicklist底层也是采用链表实现的。 Redis中链表的特性： 每一个节点都有指向前一个节点和后一个节点的指针。 头节点和尾节点的prev和next指针指向为null，所以链表是无环的。 链表有自己长度的信息，获取长度的时间复杂度为O(1)。 数据结构使用lpush 队列 rpop 栈 LinkedList 双向链表 lindex 数组 1234567891011121314151617181920212223127.0.0.1:6379&gt; LPUSH k1 a b c d e(integer) 5127.0.0.1:6379&gt; LRANGE k1 0 -11) &quot;e&quot;2) &quot;d&quot;3) &quot;c&quot;4) &quot;b&quot;5) &quot;a&quot;127.0.0.1:6379&gt; LINDEX k1 2&quot;c&quot;127.0.0.1:6379&gt; rpush k1 x y z(integer) 8127.0.0.1:6379&gt; LRANGE k1 0 -11) &quot;e&quot;2) &quot;d&quot;3) &quot;c&quot;4) &quot;b&quot;5) &quot;a&quot;6) &quot;x&quot;7) &quot;y&quot;8) &quot;z&quot;127.0.0.1:6379&gt; rpop k1&quot;z&quot; ltrim 保留数据 12345678910111213141516171819127.0.0.1:6379&gt; LRANGE k1 0 -11) &quot;e&quot;2) &quot;d&quot;3) &quot;c&quot;4) &quot;b&quot;5) &quot;a&quot;6) &quot;x&quot;7) &quot;y&quot;8) &quot;z&quot;127.0.0.1:6379&gt; rpop k1&quot;z&quot;127.0.0.1:6379&gt; LTRIM k1 0 3 # 保留0-3的数据，其他的都删除OK127.0.0.1:6379&gt; LRANGE k1 0 -11) &quot;e&quot;2) &quot;d&quot;3) &quot;c&quot;4) &quot;b&quot; 应用场景阻塞队列 结合lpush和brpop命令就可以实现。生产者使用lupsh从列表的左侧插入元素，消费者使用brpop命令从队列的右侧获取元素进行消费。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package cn.hongliang.redismessage.config;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisStandaloneConfiguration;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;import redis.clients.jedis.JedisPoolConfig;/** * @author Hongliang Zhu * @create 2020-09-12 15:44 */@Configurationpublic class RedisConfig &#123; @Value(&quot;$&#123;spring.redis.host&#125;&quot;) private String host; @Value(&quot;$&#123;spring.redis.port&#125;&quot;) private int port; @Value(&quot;$&#123;spring.redis.pool.max-active&#125;&quot;) private int maxActive; @Value(&quot;$&#123;spring.redis.pool.max-idle&#125;&quot;) private int maxIdle; @Value(&quot;$&#123;spring.redis.pool.min-idle&#125;&quot;) private int minIdle; @Value(&quot;$&#123;spring.redis.pool.max-wait&#125;&quot;) private int maxWait; @Value(&quot;$&#123;spring.redis.database&#125;&quot;) private int database; @Value(&quot;$&#123;spring.redis.timeout&#125;&quot;) private int timeout; @Bean public JedisPoolConfig getRedisConfiguration()&#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(maxActive); jedisPoolConfig.setMaxIdle(maxIdle); jedisPoolConfig.setMaxWaitMillis(maxWait); return jedisPoolConfig; &#125; @Bean public JedisConnectionFactory getRedisConnectionFactory() &#123; RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(); redisStandaloneConfiguration.setHostName(host); redisStandaloneConfiguration.setPort(port); redisStandaloneConfiguration.setDatabase(database); JedisPoolConfig jedisPoolConfig= getRedisConfiguration();// redisStandaloneConfiguration.setPoolConfig(jedisPoolConfig); JedisConnectionFactory factory = new JedisConnectionFactory(redisStandaloneConfiguration); factory.setPoolConfig(jedisPoolConfig); return factory; &#125; @Bean public RedisTemplate&lt;?, ?&gt; getRedisTemplate() &#123; JedisConnectionFactory factory = getRedisConnectionFactory(); RedisTemplate&lt;?, ?&gt; redisTemplate = new StringRedisTemplate(factory); return redisTemplate; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package cn.hongliang.utils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.stereotype.Component;import java.util.List;/** * @author Hongliang Zhu * @create 2020-09-12 15:59 */@Componentpublic class RedisUtil &#123; @Autowired private RedisTemplate&lt;String, Object&gt; redisTemplate; /** * 存消息到消息队列中 * @param key 键 * @param value 值 * @return */ public boolean lPushMessage(String key, Object value) &#123; try &#123; redisTemplate.opsForList().leftPush(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 从消息队列中弹出消息 - &lt;rpop：非阻塞式&gt; * @param key 键 * @return */ public Object rPopMessage(String key) &#123; try &#123; return redisTemplate.opsForList().rightPop(key); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; /** * 查看消息 * @param key 键 * @param start 开始 * @param end 结束 0 到 -1代表所有值 * @return */ public List&lt;Object&gt; getMessage(String key, long start, long end) &#123; try &#123; return redisTemplate.opsForList().range(key, start, end); &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125;&#125; HashHash对象的实现方式有两种，分别是ziplist、hashtable； ziplist压缩列表（ziplist）是一组连续内存块组成的顺序的数据结构，压缩列表能够节省空间，压缩列表中使用多个节点来存储数据。 压缩列表是列表键和哈希键底层实现的原理之一，压缩列表并不是以某种压缩算法进行压缩存储数据，而是它表示一组连续的内存空间的使用，节省空间，压缩列表的内存结构图如下： 压缩列表中每一个节点表示的含义如下所示： zlbytes：4个字节的大小，记录压缩列表占用内存的字节数。 zltail：4个字节大小，记录表尾节点距离起始地址的偏移量，用于快速定位到尾节点的地址。 zllen：2个字节的大小，记录压缩列表中的节点数。 entry：表示列表中的每一个节点。 zlend：表示压缩列表的特殊结束符号&#39;0xFF&#39;。 再压缩列表中每一个entry节点又有三部分组成，包括previous_entry_ength、encoding、content。 previous_entry_ength表示前一个节点entry的长度，可用于计算前一个节点的其实地址，因为他们的地址是连续的。 encoding：这里保存的是content的内容类型和长度。 content：content保存的是每一个节点的内容。 用法类似HashMap类似HashMap， 用法如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162help @hash HDEL key field [field ...] summary: Delete one or more hash fields since: 2.0.0 HEXISTS key field summary: Determine if a hash field exists since: 2.0.0 HGET key field summary: Get the value of a hash field since: 2.0.0 HGETALL key summary: Get all the fields and values in a hash since: 2.0.0 HINCRBY key field increment summary: Increment the integer value of a hash field by the given number since: 2.0.0 HINCRBYFLOAT key field increment summary: Increment the float value of a hash field by the given amount since: 2.6.0 HKEYS key summary: Get all the fields in a hash since: 2.0.0 HLEN key summary: Get the number of fields in a hash since: 2.0.0 HMGET key field [field ...] summary: Get the values of all the given hash fields since: 2.0.0 HMSET key field value [field value ...] summary: Set multiple hash fields to multiple values since: 2.0.0 HSCAN key cursor [MATCH pattern] [COUNT count] summary: Incrementally iterate hash fields and associated values since: 2.8.0 HSET key field value summary: Set the string value of a hash field since: 2.0.0 HSETNX key field value summary: Set the value of a hash field, only if the field does not exist since: 2.0.0 HSTRLEN key field summary: Get the length of the value of a hash field since: 3.2.0 HVALS key summary: Get all the values in a hash since: 2.0.0 设置和获取数据 1234567891011121314151617181920212223127.0.0.1:6379&gt; hset k1 name tom(integer) 1127.0.0.1:6379&gt; HSET k1 age 12(integer) 1127.0.0.1:6379&gt; keys *1) &quot;k1&quot;127.0.0.1:6379&gt; HVALS k1 # 获取value1) &quot;tom&quot;2) &quot;12&quot;127.0.0.1:6379&gt; HKEYS k1 # 获取key1) &quot;name&quot;2) &quot;age&quot;127.0.0.1:6379&gt; HGET k1 name # 获取指定key的value值&quot;tom&quot;127.0.0.1:6379&gt; HGET k1 age&quot;12&quot;127.0.0.1:6379&gt; HINCRBY k1 age 3 # 数值计算(integer) 15127.0.0.1:6379&gt; HVALS k11) &quot;tom&quot;2) &quot;15&quot; 应用场景 商品详情页 聚合场景 用户数据管理 存储用户的信息： 用户id作为key，其他信息作为value hash也可以用作高并发场景下使用Redis生成唯一的id。 1234567891011121314151617// offset表示的是id的递增梯度值 public Long getId(String key,String hashKey,Long offset) throws BusinessException&#123; try &#123; if (null == offset) &#123; offset=1L; &#125; // 生成唯一id return redisUtil.increment(key, hashKey, offset); &#125; catch (Exception e) &#123; //若是出现异常就是用uuid来生成唯一的id值 int randNo=UUID.randomUUID().toString().hashCode(); if (randNo &lt; 0) &#123; randNo=-randNo; &#125; return Long.valueOf(String.format(&quot;%16d&quot;, randNo)); &#125; &#125; Set是一个无序的集合，不允许添加重复元素。 Set的底层实现是ht和intset，ht（哈希表）前面已经详细了解过，下面我们来看看intset类型的存储结构。 intset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存int16_t、int32_t 或者int64_t 的整数值。 在整数集合中，有三个属性值encoding、length、contents[]，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。 在整数集合新增元素的时候，若是超出了原集合的长度大小，就会对集合进行升级，具体的升级过程如下： 首先扩展底层数组的大小，并且数组的类型为新元素的类型。 然后将原来的数组中的元素转为新元素的类型，并放到扩展后数组对应的位置。 整数集合升级后就不会再降级，编码会一直保持升级后的状态。 无序去重12345678127.0.0.1:6379&gt; sadd k1 a b c d a c(integer) 4127.0.0.1:6379&gt; SMEMBERS k11) &quot;a&quot;2) &quot;c&quot;3) &quot;b&quot;4) &quot;d&quot;127.0.0.1:6379&gt; SRANDMEMBER随机返回元素12345678127.0.0.1:6379&gt; SRANDMEMBER k1 21) &quot;b&quot;2) &quot;c&quot;127.0.0.1:6379&gt; SRANDMEMBER k1 41) &quot;d&quot;2) &quot;a&quot;3) &quot;b&quot;4) &quot;c&quot; 返回的是一个集合，如果是正数，则返回的是一个不重复的集合，如果是负数，则可能会返回重复的集合。 123456789101112131415161718192021222324252627127.0.0.1:6379&gt; SRANDMEMBER k1 -31) &quot;b&quot;2) &quot;c&quot;3) &quot;b&quot;127.0.0.1:6379&gt; SRANDMEMBER k1 -31) &quot;d&quot;2) &quot;b&quot;3) &quot;d&quot;127.0.0.1:6379&gt; SRANDMEMBER k1 -31) &quot;b&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; SRANDMEMBER k1 -31) &quot;d&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; SRANDMEMBER k1 -8 # 负数的话会有重复数据1) &quot;c&quot;2) &quot;a&quot;3) &quot;b&quot;4) &quot;d&quot;5) &quot;b&quot;6) &quot;d&quot;7) &quot;a&quot;8) &quot;d&quot; 应用场景 抽奖 随机事件 并查集（共同好友） 推荐系统 123456789101112131415161718192021222324252627127.0.0.1:6379&gt; SADD k1 a b c d e(integer) 5127.0.0.1:6379&gt; SADD k2 b f c d r(integer) 5127.0.0.1:6379&gt; SUNION k1 k2 # 并集1) &quot;r&quot;2) &quot;c&quot;3) &quot;b&quot;4) &quot;d&quot;5) &quot;f&quot;6) &quot;a&quot;7) &quot;e&quot;127.0.0.1:6379&gt; SINTER k1 k2 # 交集 （共同好友）1) &quot;d&quot;2) &quot;c&quot;3) &quot;b&quot;# 差集127.0.0.1:6379&gt; SDIFF k1 k2 # k1-k2 (减去k2中之后的)1) &quot;a&quot;2) &quot;e&quot;127.0.0.1:6379&gt; SDIFF k2 k1 # k2-k11) &quot;f&quot;2) &quot;r&quot; Zset有序集合，通过score来排序。 ZSet的底层实现是ziplist和skiplist skiplist也叫做跳跃表，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100BZPOPMAX key [key ...] timeout summary: Remove and return the member with the highest score from one or more sorted sets, or block until one is available since: 5.0.0 BZPOPMIN key [key ...] timeout summary: Remove and return the member with the lowest score from one or more sorted sets, or block until one is available since: 5.0.0 ZADD key [NX|XX] [CH] [INCR] score member [score member ...] summary: Add one or more members to a sorted set, or update its score if it already exists since: 1.2.0 ZCARD key summary: Get the number of members in a sorted set since: 1.2.0 ZCOUNT key min max summary: Count the members in a sorted set with scores within the given values since: 2.0.0 ZINCRBY key increment member summary: Increment the score of a member in a sorted set since: 1.2.0 ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] summary: Intersect multiple sorted sets and store the resulting sorted set in a new key since: 2.0.0 ZLEXCOUNT key min max summary: Count the number of members in a sorted set between a given lexicographical range since: 2.8.9 ZPOPMAX key [count] summary: Remove and return members with the highest scores in a sorted set since: 5.0.0 ZPOPMIN key [count] summary: Remove and return members with the lowest scores in a sorted set since: 5.0.0 ZRANGE key start stop [WITHSCORES] summary: Return a range of members in a sorted set, by index since: 1.2.0 ZRANGEBYLEX key min max [LIMIT offset count] summary: Return a range of members in a sorted set, by lexicographical range since: 2.8.9 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] summary: Return a range of members in a sorted set, by score since: 1.0.5 ZRANK key member summary: Determine the index of a member in a sorted set since: 2.0.0 ZREM key member [member ...] summary: Remove one or more members from a sorted set since: 1.2.0 ZREMRANGEBYLEX key min max summary: Remove all members in a sorted set between the given lexicographical range since: 2.8.9 ZREMRANGEBYRANK key start stop summary: Remove all members in a sorted set within the given indexes since: 2.0.0 ZREMRANGEBYSCORE key min max summary: Remove all members in a sorted set within the given scores since: 1.2.0 ZREVRANGE key start stop [WITHSCORES] summary: Return a range of members in a sorted set, by index, with scores ordered from high to low since: 1.2.0 ZREVRANGEBYLEX key max min [LIMIT offset count] summary: Return a range of members in a sorted set, by lexicographical range, ordered from higher to lower strings. since: 2.8.9 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] summary: Return a range of members in a sorted set, by score, with scores ordered from high to low since: 2.2.0 ZREVRANK key member summary: Determine the index of a member in a sorted set, with scores ordered from high to low since: 2.0.0 ZSCAN key cursor [MATCH pattern] [COUNT count] summary: Incrementally iterate sorted sets elements and associated scores since: 2.8.0 ZSCORE key member summary: Get the score associated with the given member in a sorted set since: 1.2.0 ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] summary: Add multiple sorted sets and store the resulting sorted set in a new key since: 2.0.0 1234567891011121314127.0.0.1:6379&gt; ZADD k1 4 apple 3.2 banana 1.6 orange(integer) 3127.0.0.1:6379&gt; ZRANGE k1 0 -1 withscores1) &quot;orange&quot;2) &quot;1.6000000000000001&quot;3) &quot;banana&quot;4) &quot;3.2000000000000002&quot;5) &quot;apple&quot;6) &quot;4&quot;127.0.0.1:6379&gt; ZRANGE k1 0 -11) &quot;orange&quot;2) &quot;banana&quot;3) &quot;apple&quot; 排序1234567127.0.0.1:6379&gt; ZREVRANGE k1 0 -1 withscores # 反转排序1) &quot;apple&quot;2) &quot;4&quot;3) &quot;banana&quot;4) &quot;3.2000000000000002&quot;5) &quot;orange&quot;6) &quot;1.600000000000000 场景排行榜动态的排行榜。 有序事件评论+分页底层结构跳跃表 1234127.0.0.1:6379&gt; type k1zset127.0.0.1:6379&gt; OBJECT encoding k1&quot;ziplist&quot; 可以看到并不是我们所说的跳表，而是一个list，这是因为我们的元素比较少。 如果我们的元素数量很多或者某个元素的值很大的话，则会使用跳表。 123456127.0.0.1:6379&gt; ZADD k1 99 saddddddddkakjfhkashfkaskfhkahsfkjahkjfawoiffahkfnakshfakkshfffffffffffffffffffffffffffffffaoifafskaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa(integer) 1127.0.0.1:6379&gt; OBJECT encoding k1&quot;skiplist&quot; # 跳表 参考 一不小心肝出了4W字的Redis面试教程","path":"2020/09/13/redis的Value类型及其应用场景/","date":"09-13","excerpt":"","tags":[{"name":"redis","slug":"redis","permalink":"https://castile.github.io/tags/redis/"}]},{"title":"新一代垃圾收集器G1","text":"Java GC介绍 GC是垃圾搜集的意思，是jvm的一个重要部分。 怎么算是垃圾 废弃的对象 任何时候都不再使用的对象 怎么判断是否是垃圾 引用计数法：会有循环引用的问题 GC roots搜索： 可达性分析算法（JVM使用的） 垃圾收集器 以上是 HotSpot 虚拟机中的垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 垃圾收集算法 mark-sweep： 有内存碎片问题，有些对象分配不到空间 mark-sweep-compact： 内存整理，解决了内存碎片问题 mark-copy：存活的对象复制到另外一块内存中。内存消耗大。 怎么优化？ GC分代假设堆分为新生代和老年代，一般创建的对象是在新生代创建，新生代创建的对象大多数都是朝生夕死的，GC也主要发生在新生代，在新生代会会回收大量的垃圾。经过几次新生代的GC后还存活下来的对象会被送入到老年代中。这个是有一个阈值来设置的。 在新生代和老年代分别使用不同的垃圾收集算法。 古典时期的GC算法 Serial 年轻代Serial ⽼年代SerialOld Parallel ParNew 年轻代Parallel Scavenge ⽼年代Parallel Old Serial Serial 收集器为单线程环境设计，并只使用一个线程进行垃圾回收。 在回收时，会暂停用户线程，并不适用于并发环境。 Serial 收集器采用复制算法 ParallelParNew 它是 Serial 收集器的多线程版本。 它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。 Parallel Scavenge 收集器 其它收集器目标是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，因此它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户程序的时间占总时间的比值。 Parallel Old 收集器 是 Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 中古时代的GC算法CMS： Concurrent Mark Sweep Stop The World：当进行垃圾收集的时候，必须暂停所有的用户线程。这种现象叫做Stop The World 分为以下四个流程： 初始标记：仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记：进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记：为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除：不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 具有以下缺点： 吞吐量低：低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 以前的垃圾收集算法想Serial是串行的，垃圾收集的时候必须暂停用户线程，后来有了Parallel的垃圾收集器，目的是降低用户线程等待的时间，所以引入了多线程的垃圾收集器，垃圾收集是并行的多个线程处理。但是感觉还是比较慢，所以有了CMS，搞一个可以让用户线程和垃圾收集线程齐头并进的收集器，用户线程可以和垃圾收集线程并发执行。 CMS有以下特点： 低延时的系统 不进行Compact，使用的sweep，可能会产生内存碎片 这是老年代的垃圾收集器 可以配合Serial/ParNew 使用 removed in JEP363 为什么新生代不使用 CMS新生代使用的copying算法，因为新生代的对象一般是朝生夕死的。复制算法的代价最小。 现代的垃圾收集器G1G1垃圾收集其实jdk9 的默认垃圾收集器 软实时、低延时、可设定目标（可以设定最大STW的停顿时间） -XX：MaxGCPauseMillis=N 250 by default JDK9+默认的GC (JEP248) 适用于较大的堆（&gt; 4 ~ 6G ） 可用于替代CMS G1（Garbage-First），它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。 -XXG1HeapRegionSize=N 2048 by fefault G1 把堆划分成多个大小相等的独立区域（Region），新生代和老年代不再物理隔离。 G1垃圾收集器利用分而治之的思想将堆进行分区，划分为一个个的区域。每次收集的时候，只收集其中几个区域，以此来控制垃圾回收产生的STW G1和其他GC算法最大的区别是弱化分代概念，引入分区思想！！！ 为什么会有G1因为并发、并行和CMS垃圾收集器都有2个共同的问题： 老年代收集器大部分操作都必须扫描整个老年代空间（标记，清除和压缩）。这就导致了GC随着Java堆空间而线性增加或减少 年轻代和老年代是独立的连续内存块，所以要先决定年轻代和年老代放在虚拟地址空间的位置 跨代/跨Region引用老年代对象可能持有年轻代的引⽤（跨代引⽤），不同的Region间互相引⽤，怎么处理这样的现象呢？ G1引入了两种数据结构，一个叫做Remembered Set(RS) 和 Card Table。 Card Table ：表中的每个entry覆盖512Byte的内存空间 ，当对应的内存空间发⽣改变时，标记为dirty。也就是说，当我们写代码的时候，通过一个引用赋值操作，将某个对象指向其引用的时候，将这个对象所在的card置为dirty 比如一个Region有1M，那么每512个字节就有一个Card， 那么这一个Region就有2000个Card。 RememberedSet： 指向Card Table中的对应entry ，可找到具体内存区域 。引入RS的通就是避免大范围的扫描，避免全堆扫描。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如上图，一个区域region1，分成若干个卡片，假如其中某个卡片里面的对象引用了其他region里面的对象的话，这个卡片的位置会被记入region2中的RS中，等Region2的对象回收的时候，根据RS去查询那个对象还在引用我，这样就避免了全堆扫描。 这是一个典型的空间换时间的操作。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间（这两个值是通过过去回收的经验获得），并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤： 初始标记 并发标记 最终标记：为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收：首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点： 空间整合：整体来看是基于“标记 - 整理”算法实现的收集器，从局部（两个 Region 之间）上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿：能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 Write barrier当一个对象引用了另一个对象是怎么记录下来的呢？ 他有事怎么知道有对象引用了它呢？使用的是Write barrier，写屏障来维护卡表和RS的。 写屏障可以看作在JVM层面上对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环绕通知，供程序执行额外的动作，也就是说赋值前后都在写屏障的覆盖范畴内。 Write barrier其实是 JVM注⼊的⼀⼩段代码，⽤于记录指针变化 1object.field = &lt;reference&gt; (putfield) 当更新指针时,标记Card为Dirty , 将Card存⼊Dirty Card Queue, 这个队由 ⽩/绿/⻩/红四个颜⾊。 更新Remembered SetBy concurrent refinement threads White： 天下太平，⽆事发⽣ Green zone (-XX:G1ConcRefinementGreenZone=N) ： Refinement线程开始被激活，开始更新RS Yellow zone (-XX:G1ConcRefinementYellowZone=N) ： 全部Refinement线程开始激活 Red zone (-XX:G1ConcRefinementRedZone=N) ： 应⽤线程也参与排空队列的⼯作 Fully young GC STW (Evacuation Pause) 分散 构建CS (Eden+Survivor) 扫描GC Roots Update RS：排空Dirty ard Queue Process RS：找到被哪些那些⽼年代对象所引⽤ Object Copy Reference Processing 记录每个阶段的时间，⽤于⾃动调优 记录Eden/Survivor的数量和GC时间 根据暂停⽬标⾃动调整Region的数量 暂停⽬标越短，Eden数量越少 吞吐量下降 -XX:+PrintAdaptiveSizePolicy -XX:+PrintTenuringDistribution Old GC当堆⽤量达到⼀定程度时触发 -XX:InitiatingHeapOccupancyPercent=N 45 by default Old GC是并发(concurrent)进⾏的 、 三⾊标记算法：不暂停应⽤线程的情况下进⾏标记 三⾊标记算法黑色：表示对象以及被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色就代表对象以及扫描过了，他是安全存活的对象。 灰色：表示对象以及被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过 白色： 表示对象还没有被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，表示 Mixed GC不⼀定⽴即发⽣ 选择若⼲个Region进⾏ ​ 默认1/8的Old Region ： -XX:G1MixedGCCountTarget=N ​ Eden+Survivor Region ​ STW, Parallel, Copying 根据暂停⽬标，选择垃圾最多的Old Region优先进⾏ ​ -XX:G1MixedGCLiveThresholdPercent=N (default 85) ​ -XX:G1HeapWastePercent=N 未来：ZGC/Shenandoah 令⼈恐怖的极低延时，使用了染色指针和多重映射 参考 https://www.bilibili.com/video/BV1D741177rV?p=2 https://cyc2018.github.io/CS-Notes/#/notes/Java%20%E8%99%9A%E6%8B%9F%E6%9C%BA?id=_7-g1-%e6%94%b6%e9%9b%86%e5%99%a8 https://www.cnblogs.com/GrimMjx/p/12234564.html","path":"2020/09/08/新一代垃圾收集器G1/","date":"09-08","excerpt":"","tags":[{"name":"gc","slug":"gc","permalink":"https://castile.github.io/tags/gc/"},{"name":"JVM","slug":"JVM","permalink":"https://castile.github.io/tags/JVM/"}]},{"title":"算法模板之滑动窗口系列","text":"最小覆盖子串难度:困难 给你一个字符串 S、一个字符串 T 。请你设计一种算法，可以在 O(n) 的时间复杂度内，从字符串 S 里面找出：包含 T 所有字符的最小子串。 滑动窗⼝算法的思路是这样：1、 我们在字符串 S 中使⽤双指针中的左右指针技巧， 初始化 left = right =0， 把索引闭区间 [left, right] 称为⼀个「窗⼝」 。2、 我们先不断地增加 right 指针扩⼤窗⼝ [left, right]， 直到窗⼝中的字符串符合要求（包含了 T 中的所有字符） 。3、 此时， 我们停⽌增加 right， 转⽽不断增加 left 指针缩⼩窗⼝ [left,right]， 直到窗⼝中的字符串不再符合要求（不包含 T 中的所有字符了） 。同时， 每次增加 left， 我们都要更新⼀轮结果。4、 重复第 2 和第 3 步， 直到 right 到达字符串 S 的尽头。 123456789101112131415161718192021222324252627282930313233343536373839404142public String minWindow(String s, String t) &#123; Map&lt;Character, Integer&gt; needs = new HashMap&lt;&gt;(), window = new HashMap&lt;&gt;(); for(int i = 0; i &lt; t.length(); i++)&#123; needs.put(t.charAt(i), needs.getOrDefault(t.charAt(i), 0) + 1); &#125; int left = 0, right = 0; int start = 0; // 最小覆盖子串的起始下标 int len = Integer.MAX_VALUE; // 最小覆盖子串的长度 int valid = 0; // 统计有多少字符满足了覆盖的要求 while(right &lt; s.length())&#123; // 当前要加入窗口的字符 char c = s.charAt(right); right++; // 右指针++ if(needs.containsKey(c))&#123; window.put(c, window.getOrDefault(c, 0) + 1); // 看看字符数量是否达到要求 if(window.get(c).equals(needs.get(c))) valid++; // 千万注意别用 == 判断... &#125; // 看看是否满足要求 while(valid == needs.size())&#123; // 在这里更新最小覆盖子串 if(right - left &lt; len)&#123; start = left; len = right - left; &#125; char lc = s.charAt(left); left++; // 左指针++ if(needs.containsKey(lc))&#123; // 看看字符数量是否达到要求 if(window.get(lc).equals(needs.get(lc))) valid--; window.put(lc, window.getOrDefault(lc, 0) - 1); &#125; &#125; &#125; // 返回最小覆盖子串 return len == Integer.MAX_VALUE ? &quot;&quot; : s.substring(start, start+len);// s.substring() &#125; 找到字符串中所有字母异位词leetcode438, 难度: 中等 给定一个字符串 s 和一个非空字符串 p，找到 s 中所有是 p 的字母异位词的子串，返回这些子串的起始索引。 字符串只包含小写英文字母，并且字符串 s 和 p 的长度都不超过 20100。 说明： 字母异位词指字母相同，但排列不同的字符串。 不考虑答案输出的顺序。 示例 1: 输入:s: “cbaebabacd” p: “abc” 输出:[0, 6] 解释:起始索引等于 0 的子串是 “cba”, 它是 “abc” 的字母异位词。起始索引等于 6 的子串是 “bac”, 它是 “abc” 的字母异位词。 示例 2: 输入:s: “abab” p: “ab” 输出:[0, 1, 2] 解释:起始索引等于 0 的子串是 “ab”, 它是 “ab” 的字母异位词。起始索引等于 1 的子串是 “ba”, 它是 “ab” 的字母异位词。起始索引等于 2 的子串是 “ab”, 它是 “ab” 的字母异位词。 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public List&lt;Integer&gt; findAnagrams(String s, String t) &#123; Map&lt;Character, Integer&gt; needs = new HashMap&lt;&gt;(), window = new HashMap&lt;&gt;(); for(int i = 0; i &lt; t.length(); i++)&#123; needs.put(t.charAt(i), needs.getOrDefault(t.charAt(i), 0) + 1); &#125; int left = 0, right = 0; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); int valid = 0; // 统计有多少字符满足了覆盖的要求 while(right &lt; s.length())&#123; // 当前要加入窗口的字符 char c = s.charAt(right); right++; // 右指针++ if(needs.containsKey(c))&#123; window.put(c, window.getOrDefault(c, 0) + 1); // 看看字符数量是否达到要求 if(window.get(c).equals(needs.get(c))) valid++; &#125; // 看看是否满足要求 while(right - left &gt;= t.length())&#123; if(valid == needs.size())&#123; res.add(left); &#125; char lc = s.charAt(left); left++; // 左指针++ if(needs.containsKey(lc))&#123; // 看看字符数量是否达到要求 if(window.get(lc).equals(needs.get(lc))) valid--; window.put(lc, window.getOrDefault(lc, 0) - 1); &#125; &#125; &#125; return res; &#125;&#125; 无重复字符的最长子串难度中等,leetcode3 给定一个字符串，请你找出其中不含有重复字符的 最长子串 的长度。 方法一示例 1: 123输入: &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。 示例 2: 123输入: &quot;bbbbb&quot;输出: 1解释: 因为无重复字符的最长子串是 &quot;b&quot;，所以其长度为 1。 示例 3: 1234输入: &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。 12345678910111213141516171819public int lengthOfLongestSubstring(String s) &#123; Map&lt;Character, Integer&gt; window = new HashMap&lt;&gt;(); int left = 0, right = 0; int res = Integer.MIN_VALUE; while( right &lt; s.length())&#123; char c = s.charAt(right); right++; window.put(c, window.getOrDefault(c, 0) + 1); while( window.get(c).compareTo(1) &gt; 0)&#123; // 有重复 需要缩小窗口 char l = s.charAt(left); window.put(l, window.get(l) - 1); left++; &#125; res = Math.max(res, right - left); &#125; return res == Integer.MIN_VALUE ? 0 : res; &#125; 方法二123456789101112131415161718class Solution &#123; public int lengthOfLongestSubstring(String s) &#123; int[] charIndex = new int[256]; int res = 0; int len = s.length(); for(int left = 0, right = 0; right &lt; len; right++)&#123; char c = s.charAt(right); left = Math.max(left, charIndex[c]); res = Math.max(res, right - left + 1); charIndex[c] = right+1; &#125; return res; &#125; &#125; 剑指 Offer 57 - II. 和为s的连续正数序列难度：简单 输入一个正整数 target ，输出所有和为 target 的连续正整数序列（至少含有两个数）。 序列内的数字由小到大排列，不同序列按照首个数字从小到大排列。 法一超时。 123456789101112131415161718192021222324public int[][] findContinuousSequence(int target) &#123; List&lt;int[]&gt; res = new ArrayList&lt;&gt;(); int len = (int)Math.ceil(target/2.0); for(int i = 1; i &lt;= len;i++)&#123; List&lt;Integer&gt; ans = new ArrayList&lt;&gt;(); int sum = 0; boolean flag = false; for(int j = i; j &lt;= len; j++)&#123; sum+= j; ans.add(j); if(sum == target)&#123; flag = true; break; &#125; &#125; if(flag)&#123; int[] a = ans.stream().mapToInt(Integer::valueOf).toArray(); res.add(a); &#125; &#125; return res.toArray(new int[res.size()][]);&#125; 法二滑动窗口 123456789101112131415161718192021222324252627282930313233// 滑动窗口 public int[][] findContinuousSequence(int target) &#123; List&lt;int[]&gt; res = new ArrayList&lt;&gt;(); int l = 1; int r = 1; int sum = 0; while(r &lt;= target/2+1)&#123; // 求和 int[] a = new int[r-l+1]; for(int i = l ; i &lt;= r; i++)&#123; sum+=i; &#125; if(sum &gt; target)&#123; l++; &#125;else if(sum &lt; target)&#123; r++; &#125;else&#123; int k = 0; for(int i = l ; i &lt;= r; i++)&#123; a[k++] = i; &#125; res.add(a); l++; &#125; sum = 0; &#125; return res.toArray(new int[res.size()][]);&#125;","path":"2020/09/07/算法模板之滑动窗口系列/","date":"09-07","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"模板","slug":"模板","permalink":"https://castile.github.io/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"topK问题","text":"leetcode上有不少topK的问题，而且topK问题也是面试必问的，所以在此做一个总结。 347. 前 K 个高频元素给定一个非空的整数数组，返回其中出现频率前 k 高的元素。 示例 1: 输入: nums = [1,1,1,2,2,3], k = 2 输出: [1,2] 示例 2: 输入: nums = [1], k = 1 输出: [1] 要求时间复杂度为O(nlogn) 堆排序思想先统计每一个数字出现的次数，然后维护一个大小为k的小根堆，小根堆按照数字出现 的频率排序，当堆中元素小于k时，加入小根堆当中，如果小根堆元素=k，则比较堆顶与当前元素的频率，如果比堆顶小，说明，当前堆中已经有k个元素出现的频率比这个数大；如果堆顶元素的频率比当前元素出现的频率小的话，则堆顶弹出，新元素进堆。 123456789101112131415161718192021222324252627public int[] topKFrequent(int[] nums, int k) &#123;// Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); // 统计每个数字出现的次数 Map&lt;Integer, Integer&gt; map = IntStream.of(nums).boxed().collect(Collectors.toMap(e -&gt; e, e -&gt; 1, Integer::sum)); PriorityQueue&lt;Integer&gt; q = new PriorityQueue&lt;&gt;((a, b)-&gt;map.get(a) - map.get(b)); // 小根堆 Set&lt;Integer&gt; integers = map.keySet(); for(int num: integers)&#123; if(q.size() &lt; k)&#123; q.offer(num); &#125;else&#123; if( map.get(q.peek()) &lt; map.get(num))&#123; q.poll(); q.offer(num); &#125; &#125; &#125; int i = 0; int[] res = new int[k]; while (!q.isEmpty())&#123; res[i++] = q.poll(); &#125; return res; &#125; 基于二叉搜索树12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; public int[] topKFrequent(int[] nums, int k) &#123; // 统计每个数字出现的次数 Map&lt;Integer, Integer&gt; counterMap = IntStream.of(nums).boxed().collect(Collectors.toMap(e -&gt; e, e -&gt; 1, Integer::sum)); // 定义二叉搜索树：key 是数字出现的次数，value 是出现了key次的数字列表。 TreeMap&lt;Integer, List&lt;Integer&gt;&gt; treeMap = new TreeMap&lt;&gt;(); // 维护一个有 k 个数字的二叉搜索树： // 不足 k 个直接将当前数字加入到树中；否则判断当前树中的最小次数是否小于当前数字的出现次数，若是，则删掉树中出现次数最少的一个数字，将当前数字加入树中。 int count = 0; for(Map.Entry&lt;Integer, Integer&gt; entry: counterMap.entrySet()) &#123; int num = entry.getKey(); int cnt = entry.getValue(); if (count &lt; k) &#123; treeMap.computeIfAbsent(cnt, ArrayList::new).add(num); count++; &#125; else &#123; Map.Entry&lt;Integer, List&lt;Integer&gt;&gt; firstEntry = treeMap.firstEntry(); if (cnt &gt; firstEntry.getKey()) &#123; treeMap.computeIfAbsent(cnt, ArrayList::new).add(num); List&lt;Integer&gt; list = firstEntry.getValue(); if (list.size() == 1) &#123; treeMap.pollFirstEntry(); &#125; else &#123; list.remove(list.size() - 1); &#125; &#125; &#125; &#125; // 构造返回结果 int[] res = new int[k]; int idx = 0; for (List&lt;Integer&gt; list: treeMap.values()) &#123; for (int num: list) &#123; res[idx++] = num; &#125; &#125; return res; &#125;&#125; 基于桶排序1234567891011121314151617181920212223242526272829 public int[] topKFrequent1(int[] nums, int k) &#123; Map&lt;Integer, Integer&gt; map = IntStream.of(nums).boxed().collect(Collectors.toMap(e -&gt; e, e -&gt; 1, Integer::sum)); // 每个桶 存放当前频率的元素 List&lt;Integer&gt;[] bucket = new ArrayList[nums.length+1];// Arrays.fill(bucket, new ArrayList()); for(int i = 0; i&lt; bucket.length; i++)&#123; bucket[i] = new ArrayList&lt;&gt;(); &#125; map.forEach((key, count)-&gt;&#123; bucket[count].add(key); &#125;); int[] res = new int[k]; int n = 0; // 从后往前遍历 for(int i = bucket.length-1; i &gt; 0; i--)&#123; for(int num : bucket[i])&#123; res[n++] = num; if(n == k)&#123; return res; &#125; &#125; &#125; return res; &#125; 基于快速选择算法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * 基于快速排序 * @param nums * @param k * @return */ public int[] topKFrequent2(int[] nums, int k) &#123; // 统计每个数字出现的次数 Map&lt;Integer, Integer&gt; map = IntStream.of(nums).boxed().collect(Collectors.toMap(e -&gt; e, e -&gt; 1, Integer::sum)); Pair[] p = new Pair[nums.length]; Pair[] pairs = IntStream.of(nums).distinct().boxed().map(num -&gt; new Pair(num, map.get(num))).toArray(Pair[]::new); Pair[] ans = qselect(pairs, 0, pairs.length-1, k-1); // 下标为k-1 int[] res = new int[k]; int i = 0; for(Pair pair: ans)&#123; res[i++] = pair.key; &#125; return res; &#125; private Pair[] qselect(Pair[] pairs, int l, int r, int aux) &#123; if( l &lt;= r)&#123; int p = partition(pairs, l, r); if( p == aux)&#123; return Arrays.copyOf(pairs, aux+1); // 包头不包尾 &#125;else if(p &lt; aux)&#123; // 答案在其右边 return qselect(pairs, p+1, r, aux); &#125;else &#123; return qselect(pairs, l, p-1, aux); &#125; &#125; return new Pair[0]; &#125; private int partition(Pair[] pairs, int l, int r) &#123; int i = l; int j = r; int p = l; while (i &lt; j)&#123; while (pairs[i].count &gt; pairs[p].count &amp;&amp; i &lt; j)&#123; i++; &#125; while (pairs[j].count &lt;= pairs[p].count &amp;&amp; i &lt; j)&#123; j--; &#125; swap(pairs, i ,j); &#125; swap(pairs, p, i); return i; &#125; private void swap(Pair[] pairs, int l, int r)&#123; Pair t = pairs[l]; pairs[l] = pairs[r]; pairs[r] = t; &#125; class Pair &#123; int key; int count; public Pair(int key, int count) &#123; this.key = key; this.count = count; &#125; &#125; 剑指 Offer 40. 最小的k个数基于快排123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution &#123; public int[] getLeastNumbers(int[] arr, int k) &#123; if (k == 0 || arr.length == 0) &#123; return new int[0]; &#125; return QuickSort(arr, 0, arr.length-1, k); &#125; private int[] QuickSort(int[] arr, int low, int high, int k)&#123; int partition = partition(arr, low, high); if(partition == k-1)&#123; return Arrays.copyOf(arr, partition+1); &#125; if(partition &gt; k-1)&#123; return QuickSort(arr, low, partition-1, k); &#125; else&#123; return QuickSort(arr, partition+1, high, k); &#125; &#125; private int partition(int[] arr, int low, int high)&#123; int p = arr[low]; int i = low; while(low &lt; high)&#123; while(arr[high] &gt; p &amp;&amp; low &lt; high) high--; while(arr[low] &lt;= p &amp;&amp; low &lt; high) low++; swap(arr, low, high); &#125; arr[i] = arr[low]; arr[low] = p; return low; &#125; private void swap(int[]arr, int i, int j)&#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t; &#125;&#125; 直接排序1234567891011class Solution &#123; public int[] getLeastNumbers(int[] arr, int k) &#123; Arrays.sort(arr); int []res = new int[k]; int i = 0; for(int j = 0; j &lt; k; j++)&#123; res[i++] = arr[j]; &#125; return res; &#125;&#125; 基于堆123456789101112131415161718192021222324252627public int[] getLeastNumbers(int[] arr, int k) &#123; PriorityQueue&lt;Integer&gt; q = new PriorityQueue&lt;&gt;((a,b)-&gt;b-a); // 大根堆 int[] res = new int[k]; if(k == 0)&#123; // 避免空指针异常 return res; &#125; for(int num: arr)&#123; if(q.size() &lt; k)&#123; q.offer(num); &#125;else&#123; if( q.peek() &gt; num)&#123; q.poll(); q.offer(num); &#125; &#125; &#125; int i = 0; for(int num: q)&#123; res[i++] = num; &#125; return res; &#125; 参考 https://leetcode-cn.com/problems/top-k-frequent-elements/solution/4-chong-fang-fa-miao-sha-topkji-shu-pai-xu-kuai-pa/","path":"2020/09/07/topK问题/","date":"09-07","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"topK","slug":"topK","permalink":"https://castile.github.io/tags/topK/"}]},{"title":"字符串的统计字符串","text":"链接：https://www.nowcoder.com/questionTerminal/e8b97a6d64ae4304b6f0ff4ecae1589d?orderByHotValue=1&amp;page=1&amp;onlyReference=false来源：牛客网 给定一个字符串str，返回str的统计字符串。例如“aaabbbbcccd”的统计字符串为“a_3_b_4_c_3_d_1”。 输入1offerofferzainaliiiiii 输出1o_1_f_2_e_1_r_1_o_1_f_2_e_1_r_1_z_1_a_1_i_1_n_1_a_1_l_1_i_6 示例2 输入1hhhaaa 输出1h_3_a_3 备注:1时间复杂度O（n） 空间复杂度O（n） Java代码1234567891011121314151617181920import java.util.*;public class Main&#123; public static void main(String[] args)&#123; Scanner sc = new Scanner(System.in); String s = sc.next(); int n = 1; for(int i = 1;i &lt; s.length(); i++)&#123; if(s.charAt(i) == s.charAt(i-1))&#123; n++; &#125;else&#123; System.out.print(s.charAt(i-1)+&quot;_&quot;+n+&quot;_&quot;); n = 1; &#125; &#125; System.out.println(s.charAt(s.length()-1)+&quot;_&quot;+n); &#125; &#125;","path":"2020/09/07/字符串的统计字符串/","date":"09-07","excerpt":"","tags":[{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"字符串","slug":"字符串","permalink":"https://castile.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"Redis缓存问题：缓存穿透、缓存击穿、缓存雪崩、分布式锁、一致性hash算法","text":"缓存穿透缓存穿透的概念很简单。用户想要查询一个数据。发现redis内存数据库中没有，也就是缓存没有命中。于是向持久层数据库查询，发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中，于是都去请求了持久层数据库，这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。 黑客： id=-1，id = -2 … 访问请求。这些id在redis中找不到，在数据库中也找不到。解决办法就是将找不到的id号在redis中存为null值，但是由于大量的id都找不到，而redis有内存淘汰策略，会将有效的数据淘汰掉，redis里面会有大量无效的数据。 缓存空对象 缓存空对象是指当一个请求过来缓存中和数据库中都不存在该请求的数据，第一次请求就会跳过缓存进行数据库的访问，并且访问数据库后返回为空，此时也将该空对象进行缓存。 1234567891011121314151617181920212223242526272829public class UserServiceImpl &#123; @Autowired UserDAO userDAO; @Autowired RedisCache redisCache; public User findUser(Integer id) &#123; Object object = redisCache.get(Integer.toString(id)); // 缓存中存在，直接返回 if(object != null) &#123; // 检验该对象是否为缓存空对象，是则直接返回null if(object instanceof NullValueResultDO) &#123; return null; &#125; return (User)object; &#125; else &#123; // 缓存中不存在，查询数据库 User user = userDAO.getUser(id); // 存入缓存 if(user != null) &#123; redisCache.put(Integer.toString(id),user); &#125; else &#123; // 将空对象存进缓存 redisCache.put(Integer.toString(id), new NullValueResultDO()); &#125; return user; &#125; &#125; &#125; 若是再次进行访问该空对象的时候，就会直接击中缓存，而不是再次数据库， 但是缓存空对象会带来比较大的问题，就是缓存中会存在很多空对象，占用内存的空间，浪费资源，一个解决的办法就是设置空对象的较短的过期时间，代码如下： 12// 再缓存的时候，添加多一个该空对象的过期时间60秒redisCache.put(Integer.toString(id), new NullValueResultDO(),60); 终极解决方案：在redis与mysql中间加一个过滤器，过滤器中需要保存未来可能查询的字段值。 过滤器不能重量级，当查询的字段多样化的时候，可能会导致内存紧张，导致过滤效率降低。布隆过滤器登场 布隆算法我们希望过滤器不能占用太多的内存，是一个轻量级的过滤器。 布隆过滤器是一种基于概率的数据结构，主要用来判断某个元素是否在集合内，它具有运行速度快（时间效率），占用内存小的优点（空间效率），但是有一定的误识别率和删除困难的问题。它只能告诉你某个元素一定不在集合内或可能在集合内。 布隆过滤器的特点如下： 一个非常大的二进制位数组 （数组里只有0和1） 若干个哈希函数 空间效率和查询效率高 不存在漏报（False Negative）：某个元素在某个集合中，肯定能报出来。 可能存在误报（False Positive）：某个元素不在某个集合中，可能也被爆出来。 不提供删除方法，代码维护困难。 位数组初始化都为0，它不存元素的具体值，当元素经过哈希函数哈希后的值（也就是数组下标）对应的数组位置值改为1。 布隆算法：通过错误率来换取空间的算法。是一个数据标识算法，内部是一个二进制位数组（bitmap） 布隆过滤器会有一定的错误率，但是这个错误率在实际情况下影响并不大。如果它告诉你存在这个id值，但其实并不在，我们允许他去查询数据库，这点压力mysql还是可以承受得住的，不至于这么脆弱。 但是我们还是希望错误率越低越好，那么，错误率是什么引起的。刚刚说的hash碰撞，与数组的大小、hash函数有关系。 当数组越长，hash碰撞的概率就低。 还与hash函数的个数有关系，hash函数映射不同的hash值。 只有当三个hash函数的值都相同的时候，才会发生hash碰撞。 并不是hash函数越多越好，很多hash函数的话，可能会导致不管传入的什么值，都会返回“存在”，这样的话错误率是越来越高的。所以要把握度。 如果未来客户端往是数据库中中提交信息，也是通过上面的流程，我们是在插入数据的时候在过滤器中标志数据还是先插入到数据库中，然后返回来标识呢？ 我们可以先插入到数据库中，然后通过异步的方式，设置一个时间，将新数据在过滤器上标识。 那么为什么不能删除元素呢？ 原因很简单，因为删除元素后，将对应元素的下标设置为零，可能别的元素的下标也引用改下标，这样别的元素的判断就会收到影响，原理图如下： 当你删除z元素之后，将对应的下标10和13设置为0，这样导致x和y元素的下标受到影响，导致数据的判断不准确，所以直接不提供删除元素的api。 手写一个布隆过滤器以上说的都是布隆过滤器的原理，只有理解了原理，在实际的运用才能如鱼得水，下面就来实操代码，手写一个简单的布隆过滤器。 对于要手写一个布隆过滤器，首先要明确布隆过滤器的核心： 若干哈希函数 存值得Api 判断值得Api 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import java.util.BitSet;/** * @author Hongliang Zhu * @create 2020-09-13 12:18 * * 手写一个简单的布隆过滤器 */public class BloomFilter &#123; // 布隆过滤器的 的长度 private static final int SIZE = 2 &lt;&lt; 10; // 模拟实现不同的hash函数 private static final int[] num = new int[]&#123;5, 19, 23, 31, 47, 71&#125;; // 初始化位数组 private BitSet bits = new BitSet(SIZE); // 用于存储Hash函数 private MyHash[] hashFunc = new MyHash[num.length]; // 初始化hash函数 private BloomFilter()&#123; for(int i = 0; i &lt; num.length; i++)&#123; hashFunc[i] = new MyHash(SIZE, num[i]); &#125; &#125; // 存入 public void add(String value)&#123; // hash计算 for(MyHash func : hashFunc)&#123; // 将为数组对应的哈希下标得位置得值改为1 bits.set(func.hash(value), true); &#125; &#125; // 判断是否存在 public boolean contains(String value)&#123; if(value == null)&#123; return false; &#125; boolean res = true; for(MyHash func : hashFunc)&#123; res = res &amp;&amp; bits.get(func.hash(value)); &#125; return res; &#125; public static void main(String[] args) &#123; BloomFilter filter = new BloomFilter(); String value = &quot;4243212355312&quot;; System.out.println(filter.contains(value)); filter.add(value); System.out.println(filter.contains(value)); &#125;&#125;class MyHash&#123; private int cap; private int seed; public MyHash(int cap, int seed) &#123; this.cap = cap; this.seed = seed; &#125; public int hash(String value)&#123; int res = 0; int len = value.length(); for(int i = 0;i &lt; len; i++)&#123; res = seed * res + value.charAt(i); &#125; return (cap-1) &amp; res; &#125;&#125; false true 在实际项目中可以使用别人已经写好的布隆过滤器，比如谷歌的 Google Guava，只需要在项目中引入一下依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;27.0.1-jre&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314public static void MyBloomFilterSysConfig &#123; @Autowired OrderMapper orderMapper // 1.创建布隆过滤器 第二个参数为预期数据量10000000，第三个参数为错误率0.00001 BloomFilter&lt;CharSequence&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charset.forName(&quot;utf-8&quot;)),10000000, 0.00001); // 2.获取所有的订单，并将订单的id放进布隆过滤器里面 List&lt;Order&gt; orderList = orderMapper.findAll() for (Order order;orderList ) &#123; Long id = order.getId(); bloomFilter.put(&quot;&quot; + id); &#125;&#125; 在实际项目中会启动一个系统任务或者定时任务，来初始化布隆过滤器，将热点查询数据的id放进布隆过滤器里面，当用户再次请求的时候，使用布隆过滤器进行判断该订单的id是否在布隆过滤器中存在，不存在直接返回null，具体操作代码： 12// 判断订单id是否在布隆过滤器中存在bloomFilter.mightContain(&quot;&quot; + id) 布隆过滤器的缺点就是要维持容器中的数据，因为订单数据肯定是频繁变化的，实时的要更新布隆过滤器中的数据为最新。 缓存击穿 这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。 缓存击穿这里强调的是并发，造成缓存击穿的原因有以下两个： 该数据没有人查询过 ，第一次就大并发的访问。（冷门数据） 添加到了缓存，reids有设置数据失效的时间 ，这条数据刚好失效，大并发访问（热点数据） 缓存击穿的话，设置热点数据永远不过期。或者使用分布式锁解决。 但是是对于一般的场景来说，缓存击穿不需要去解决。因为mysql可以承受。 当用户出现大并发访问的时候，在查询缓存的时候和查询数据库的过程加锁，只能第一个进来的请求进行执行，当第一个请求把该数据放进缓存中，接下来的访问就会直接集中缓存，防止了缓存击穿。 业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中load数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。这里要注意，分布式环境中要使用分布式锁，单机的话用普通的锁（synchronized、Lock）就够了。 单机版的锁： 123456789101112131415161718192021// 获取库存数量public String getProduceNum(String key) &#123; try &#123; synchronized (this) &#123; //加锁 // 缓存中取数据，并存入缓存中 int num= Integer.parseInt(redisTemplate.opsForValue().get(key)); if (num&gt; 0) &#123; //没查一次库存-1 redisTemplate.opsForValue().set(key, (num- 1) + &quot;&quot;); System.out.println(&quot;剩余的库存为num：&quot; + (num- 1)); &#125; else &#123; System.out.println(&quot;库存为0&quot;); &#125; &#125; &#125; catch (NumberFormatException e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; return &quot;OK&quot;;&#125; 分布式锁可以使用Redisson来实现。 1234567891011121314151617181920212223public String getProduceNum(String key) &#123; // 获取分布式锁 RLock lock = redissonClient.getLock(key); try &#123; // 获取库存数 int num= Integer.parseInt(redisTemplate.opsForValue().get(key)); // 上锁 lock.lock(); if (num&gt; 0) &#123; //减少库存，并存入缓存中 redisTemplate.opsForValue().set(key, (num - 1) + &quot;&quot;); System.out.println(&quot;剩余库存为num：&quot; + (num- 1)); &#125; else &#123; System.out.println(&quot;库存已经为0&quot;); &#125; &#125; catch (NumberFormatException e) &#123; e.printStackTrace(); &#125; finally &#123; //解锁 lock.unlock(); &#125; return &quot;OK&quot;;&#125; 分布式锁需要加锁的条件 共享资源 共享资源互斥 多任务环境 缺一不可。 但是设置“保安”也可能会发生死锁，因为保安可能会挂。 考虑另一个场景，加入现在JVM1抢到了锁，可以去买票了，但是在买票的过程中，JVM1出现了GC，我们知道，GC的话用户线程会挂起，所以买票会休眠，如果GC时间大于“保安JVM”设置的时间，那么到时会收回锁，这时其他的JVM都可以获取锁，那么就可能出现两个JVM一起来买票。这样的话很可能出现一票多卖的问题。 那么，我们应该给“保安JVM”的超时时间多长合适呢？我们并不知道JVM休眠的时间多少，加入设置超时时间为1小时，那么在买票的第一秒钟宕机了的话，需要等待59分59秒才能获取锁，这样就无法在单位时间内卖出更多的票了。如果超时时间设置的比较短，那么可能会出现上面所说的JVM乱入的现象。所以超时时间的设置是比较重要的。 使用redis分布式锁的原因是redis天生具有有效期这个特性，就不用“保安JVM”了。但是基于redis来做的话还是会出现这个度的问题，超时时间。【后期看看redission框架】 我们一般使用zookeeper来设置分布式锁。 zookeeper是一个分布式的一致性服务。 总结一下分布式锁的解决思路： 发生缓存击穿的时候，多个请求一起打在mysql，如果需要访问myslq的话，必须先获得分布式锁，先获取分布式锁的那个client先去mysql查询数据，然后缓存在redis中，之后的client就不需要再次抢分布式锁了，直接在redis缓存中去查询即可。这就是分布式锁解决缓存击穿的原理。 缓存雪崩 同一时间缓存大面积失效，那一瞬间Redis跟没有一样，那这个数量级别的请求直接打到数据库几乎是灾难性的。 导致缓存雪崩的原因： 缓存数据的有效期是一致的， 造成缓存大面积失效 Redis宕机 对于缓存雪崩的解决方案有以下两种： 搭建高可用的集群，防止单机的redis宕机。 设置不同的过期时间，防止同意之间内大量的key失效。 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效，我相信，Redis这点流量还是顶得住的。 如果Redis挂了，那么可以设置Redis集群。 Redis集群有切片集群和主从复制 切片集群就是将热点数据分散放在各个服务器上 主从复制的话就是每台服务器存放相同的数据 一致性Hash算法上面说的切片集群，当数据量很大的时候，建议这么做。但是我们不能做到每一台服务器上的数据都是平均的，可能会发生数据倾斜。假如现在新增一台服务器，我们需要从其他的服务器复制一部分数据给新的服务器，这样会发生大量的复制，在复制的过程中，redis服务器是无法提供服务的？？？（不能fork子进程去复制吗），那么就又会发生缓存雪崩的现象。 那么一致性Hash算法就可以解决集群动态扩展问题。内部是通过哈希环来实现的。 在实现分布式缓存的时候，我们怎么讲数据平均地去分配到redis服务器中？ 加入现在redis集群中只有两台数据库。如下所示分配原理。 假如新增一台服务器，hash函数应该%3 ，这时候需要将原来的数据的重新分配。这样会导致大量的数据迁移。原来能找的数据现在找不到了，导致大量的缓存失效，出现缓存雪崩的现象。那么可以使用一致性hash算法来解决。内部是通过哈希环来实现的。 hash环 将数据和redis都映射到一个hash环上面，数据顺时针去寻找要存储的redis。 这样可以避免大量数据的迁移。但是还是可能会发生数据倾斜。 解决方法就是设置虚拟节点。 我们理想的环境是，让数据均匀地覆盖到每一台服务器上，但是使用一致性hash算法映射到hash环中很有可能是倾斜的。 这样会导致大量的数据都缓存在redis1中，导致分局分布极度不均匀，机器没有平均地被使用。要想数据均匀分布到服务器上，很直观的想法就是让服务器的数量尽量多，且均匀地出现在hash环上面。 我们可以给每一个服务器设置许多虚拟节点。 虚拟节点越多，就更有概率使其均匀分布在hash环上面。 具体缓存读写的时候先找到虚拟节点，然后在从虚拟节点找到真实redis服务器实现读写。这样就解决了数据倾斜的问题。 最后，解决几个问题。 一致性hash的性质平衡性也就是hash的结果应该尽可能分散，避免出现过多的hash碰撞。 单调性所谓单调性也就是指，当有新的节点增加的时候，旧数据的寻找方式应该一致，即按照原来的方式找到数据所对应的服务器，而新数据可以按照新的散列算法找到服务器。 如果不单调的话，当新的节点 增加的时候，导致所有的数据都需要重新计算，这样会有大量的数据迁移，开销很大。 分散性在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 平滑性(Smoothness)平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。 hash环上是怎么定位所在的服务器的定位数据存储在哪台服务器的方法为：将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器 可以为这些服务器维护一条二分查找树，定位服务器的过程就是在二分查找树中找刚好比其大的节点。 如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 假如出现数据倾斜怎么办当服务节点太少的话，很容易因为节点分布不均匀而造成数据倾斜问题。 一致性hash算法引入了虚拟节点机制。 即对每一个服务节点计算多个哈希（可以用原节点key+”##xxxk”作为每个虚拟节点的key，然后求hashcode）， 每个计算结果位置都放置一个此服务节点，称为虚拟节点。 具体做法可以在服务器ip或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3”的哈希值，于是形成六个虚拟节点。 数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到“Node A#1”、“Node A#2”、“Node A#3”三个虚拟节点的数据均定位到Node A上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为32甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。 一致性hash算法在分布式环境中应用的很广，只要是涉及到分布式存储的负载均衡问题，一致性hash都是很好的解决的方案。 Hash环是一个什么数据结构我们知道，一致性hash算法是基于hash环来实现的，怎么构造一个$ 2^{32}$ 的整数环？然后根据节点名称的hash值将服务器节点放置在这个hash环中。应该选用什么样的数据结构，才能使得时间复杂度最低？ 最直观的考虑，是使用一个list，而且是有序的。每次按照顺序去找数据所对应的服务节点。时间复杂度为O(N)。 如果采用二叉查找树，查找的时间复杂度可以为O(logN）。但是不能简单使用一般的二叉树，因为在最坏的情况下，可能会链化。时间复杂度退化为O(N)。 我们可以使用AVL树或者红黑树。 使用红黑树的原因如下： 因为红黑树本身主要的作用就是存储有序的数据，这其实和第一种方案想一块去了，但是效率比使用list效率快多了。 JDK中提供了红黑树的数据结构代码实现 TreeMap和TreeSet。 以TreeMap为例，TreeMap本身提供了一个tailMap(K fromKey)方法，支持从红黑树中查找比fromKey大的值的集合，但并不需要遍历整个数据结构，然后再从集合中取第一个即可，更方便的TreeMap提供了higherKey(k key)，可以直接获取第一个比参数key大的对象，这里要注意的是，如果tailMap.isEmpty()==true或higherkey返回null，代表数据在环的末端，这时应该取tailMap中最小的元素作为存储服务器，即tailMap.firstKey()。 虚拟节点是怎么和物理节点对应的加入节点A的key为keyA，我们可以循环生成若干个虚拟节点，key分别为keyA##VN0、keyA##VN1、keyA##VN2…..keyA##VNn。然后采用上面的hash算法分别求这些虚拟节点的hashcode，然后放入hash环中（即TreeMap中），定位数据所属的服务器节点时，假设返回keyA##VNk，则通过截取可以获取物理节点keyA。 参考 一不小心肝出了4W字的Redis面试教程 https://blog.csdn.net/wudiyong22/article/details/78687246","path":"2020/09/06/redis深入/","date":"09-06","excerpt":"","tags":[{"name":"redis","slug":"redis","permalink":"https://castile.github.io/tags/redis/"}]},{"title":"leetcode287_寻找重复数字","text":"寻找重复数字给定一个包含 n + 1 个整数的数组 nums，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。假设只有一个重复的整数，找出这个重复的数。 示例 1: 输入: [1,3,4,2,2]输出: 2示例 2: 输入: [3,1,3,4,2]输出: 3 解决思路使用环形链表II的方法解题（142.环形链表II），使用 142 题的思想来解决此题的关键是要理解如何将输入的数组看作为链表。 首先明确前提，整数的数组 nums 中的数字范围是 [1,n]。考虑一下两种情况： 如果数组中没有重复的数，以数组 [1,3,4,2]为例，我们将数组下标 n 和数 nums[n] 建立一个映射关系 f(n)f(n)f(n)，其映射关系 n-&gt;f(n)为：0-&gt;11-&gt;32-&gt;43-&gt;2我们从下标为 0 出发，根据 f(n)f(n)f(n) 计算出一个值，以这个值为新的下标，再用这个函数计算，以此类推，直到下标超界。这样可以产生一个类似链表一样的序列。0-&gt;1-&gt;3-&gt;2-&gt;4-&gt;null 如果数组中有重复的数，以数组 [1,3,4,2,2] 为例,我们将数组下标 n 和数 nums[n] 建立一个映射关系 f(n)f(n)f(n)，其映射关系 n-&gt;f(n) 为：0-&gt;11-&gt;32-&gt;43-&gt;24-&gt;2同样的，我们从下标为 0 出发，根据 f(n)计算出一个值，以这个值为新的下标，再用这个函数计算，以此类推产生一个类似链表一样的序列。0-&gt;1-&gt;3-&gt;2-&gt;4-&gt;2-&gt;4-&gt;2-&gt;…… 从理论上讲，数组中如果有重复的数，那么就会产生多对一的映射，这样，形成的链表就一定会有环路了。 综上: 1.数组中有一个重复的整数-&gt;链表中存在环 2.找到数组中的重复整数 -&gt;找到链表的环入口 至此，问题转换为 142 题。那么针对此题，快、慢指针该如何走呢。根据上述数组转链表的映射关系，可推出142 题中慢指针走一步 slow = slow.next ==&gt; 本题 slow = nums[slow]142 题中快指针走两步 fast = fast.next.next ==&gt; 本题 fast = nums[nums[fast]] 12345678910111213141516171819202122class Solution &#123; public int findDuplicate(int[] nums) &#123; int slow = 0; int fast = 0; slow = nums[slow]; fast = nums[nums[fast]]; while(slow != fast)&#123; slow = nums[slow]; fast = nums[nums[fast]]; &#125; int p = slow; int q = 0; while(p != q)&#123; p = nums[p]; q = nums[q]; &#125; return q; &#125;&#125; 二分法二分法的思路是先猜一个数（有效范围 [left, right]里的中间数 mid），然后统计原始数组中小于等于这个中间数的元素的个数 cnt，如果 cnt 严格大于 mid，（注意我加了着重号的部分「小于等于」、「严格大于」）。根据抽屉原理，重复元素就在区间 [left, mid] 里； 以 [2, 4, 5, 2, 3, 1, 6, 7] 为例，一共 8 个数，n + 1 = 8，n = 7，根据题目意思，每个数都在 1 和 7 之间。 例如：区间[1,7]的中位数是 4，遍历整个数组，统计小于等于 4 的整数的个数，如果不存在重复元素，最多为 4 个。等于 4 的时候区间 [1,4] 内也可能有重复元素。但是，如果整个数组里小于等于 4 的整数的个数严格大于 4 的时候，就可以说明重复的数存在于区间[1,4]。 12345678910111213141516171819202122232425262728293031public class Solution &#123; public int findDuplicate(int[] nums) &#123; int len = nums.length; int left = 1; int right = len - 1; while (left &lt; right) &#123;// 在 Java 里可以这么用，当 left + right 溢出的时候，无符号右移保证结果依然正确 int mid = (left + right) &gt;&gt;&gt; 1; int cnt = 0; for (int num : nums) &#123; if (num &lt;= mid) &#123; cnt += 1; &#125; &#125; // 根据抽屉原理，小于等于 4 的个数如果严格大于 4 个 // 此时重复元素一定出现在 [1, 4] 区间里 if (cnt &gt; mid) &#123; // 重复元素位于区间 [left, mid] right = mid; &#125; else &#123; // if 分析正确了以后，else 搜索的区间就是 if 的反面 // [mid + 1, right] left = mid + 1; &#125; &#125; return left; &#125;&#125; 参考 https://leetcode-cn.com/problems/find-the-duplicate-number/solution/287xun-zhao-zhong-fu-shu-by-kirsche/ https://leetcode-cn.com/problems/find-the-duplicate-number/solution/er-fen-fa-si-lu-ji-dai-ma-python-by-liweiwei1419/","path":"2020/09/02/leetcode287-寻找重复数字/","date":"09-02","excerpt":"","tags":[{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"腾讯","slug":"腾讯","permalink":"https://castile.github.io/tags/%E8%85%BE%E8%AE%AF/"}]},{"title":"博弈游戏算法","text":"leetcode486. 预测赢家给定一个表示分数的非负整数数组。 玩家 1 从数组任意一端拿取一个分数，随后玩家 2 继续从剩余数组任意一端拿取分数，然后玩家 1 拿，…… 。每次一个玩家只能拿取一个分数，分数被拿取之后不再可取。直到没有剩余分数可取时游戏结束。最终获得分数总和最多的玩家获胜。 给定一个表示分数的数组，预测玩家1是否会成为赢家。你可以假设每个玩家的玩法都会使他的分数最大化。 示例 1： 输入：[1, 5, 2]输出：False解释：一开始，玩家1可以从1和2中进行选择。如果他选择 2（或者 1 ），那么玩家 2 可以从 1（或者 2 ）和 5 中进行选择。如果玩家 2 选择了 5 ，那么玩家 1 则只剩下 1（或者 2 ）可选。所以，玩家 1 的最终分数为 1 + 2 = 3，而玩家 2 为 5 。因此，玩家 1 永远不会成为赢家，返回 False 。示例 2： 输入：[1, 5, 233, 7]输出：True解释：玩家 1 一开始选择 1 。然后玩家 2 必须从 5 和 7 中进行选择。无论玩家 2 选择了哪个，玩家 1 都可以选择 233 。 最终，玩家 1（234 分）比玩家 2（12 分）获得更多的分数，所以返回 True，表示玩家 1 可以成为赢家。 提示： 1 &lt;= 给定的数组长度 &lt;= 20.数组里所有分数都为非负数且不会大于 10000000 。如果最终两个玩家的分数相等，那么玩家 1 仍为赢家。 解题思路123456789class Pairs&#123; int first; // 先手 int second; // 后手 public Pairs(int first, int second) &#123; this.first = first; this.second = second; &#125;&#125; 定义一个类first表示先手，second表示后手 1Pairs[][] dp = new Pairs[n][n]; dp[i][j] 表示 面对nums[i … j] , 两个选手的所能得到的最高分数 则： dp[i][j].first = max(nums[i] + dp[i+1][j].second, nums[j] + dp[i][j-1].second) dp[i][j].first = max( 选择最左边的⽯头堆 , 选择最右边的⽯头堆 ) 解释： 我作为先⼿， ⾯对 nums[i…j] 时， 有两种选择： 要么我选择最左边的那⼀堆⽯头， 然后⾯对 nums[i+1…j] 但是此时轮到对⽅， 相当于我变成了后⼿； 要么我选择最右边的那⼀堆⽯头， 然后⾯对 nums[i…j-1] 但是此时轮到对⽅， 相当于我变成了后⼿。 此时，如果 先⼿选择左边: dp[i][j].second = dp[i+1][j].fir if 先⼿选择右边: dp[i][j].sec = dp[i][j-1].fir 解释： 我作为后⼿， 要等先⼿先选择， 有两种情况： 如果先⼿选择了最左边那堆， 给我剩下了 piles[i+1…j] 此时轮到我， 我变成了先⼿； 如果先⼿选择了最右边那堆， 给我剩下了 piles[i…j-1] 此时轮到我， 我变成了先⼿。 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class Pairs&#123; int first; int second; public Pairs(int first, int second) &#123; this.first = first; this.second = second; &#125;&#125;class Solution &#123; public boolean PredictTheWinner(int[] nums) &#123; int n = nums.length; if(n == 1) return true; Pairs[][] dp = new Pairs[n][n]; for (int i = 0; i &lt; n; i++)&#123; for(int j = 0; j &lt;n; j++)&#123; dp[i][j] = new Pairs(0,0); &#125; &#125; // 初始化 base case for (int i = 0; i &lt; n; i++) &#123; // 只有一堆 // 先手拿到的分数， 后手肯定为0， dp[i][i].first = nums[i]; dp[i][i].second = 0; &#125; /// 斜着遍历 for (int r = 2; r &lt;= n; r++) &#123; //对角线 for (int i = 0; i &lt; n - r + 1; i++) &#123; // 行控制 int j = r + i - 1; // 列 // 选择拿左边的还是右边的 int left = dp[i+1][j].second + nums[i]; int right = dp[i][j-1].second+ nums[j]; if(left &gt; right)&#123; // 选择左边 dp[i][j].first = left; dp[i][j].second = dp[i+1][j].first; &#125;else&#123; dp[i][j].first = right; dp[i][j].second = dp[i][j-1].first; &#125; &#125; &#125; return dp[0][n-1].first &gt;= dp[0][n-1].second; &#125;&#125; leetcode 877. 石子游戏亚历克斯和李用几堆石子在做游戏。偶数堆石子排成一行，每堆都有正整数颗石子 piles[i] 。 游戏以谁手中的石子最多来决出胜负。石子的总数是奇数，所以没有平局。 亚历克斯和李轮流进行，亚历克斯先开始。 每回合，玩家从行的开始或结束处取走整堆石头。 这种情况一直持续到没有更多的石子堆为止，此时手中石子最多的玩家获胜。 假设亚历克斯和李都发挥出最佳水平，当亚历克斯赢得比赛时返回 true ，当李赢得比赛时返回 false 。 示例： 输入：[5,3,4,5] 输出：true解释：亚历克斯先开始，只能拿前 5 颗或后 5 颗石子 。假设他取了前 5 颗，这一行就变成了 [3,4,5] 。如果李拿走前 3 颗，那么剩下的是 [4,5]，亚历克斯拿走后 5 颗赢得 10 分。如果李拿走后 5 颗，那么剩下的是 [3,4]，亚历克斯拿走后 4 颗赢得 9 分。这表明，取前 5 颗石子对亚历克斯来说是一个胜利的举动，所以我们返回 true 。 提示： 2 &lt;= piles.length &lt;= 500 piles.length 是偶数。 1 &lt;= piles[i] &lt;= 500 sum(piles) 是奇数。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/stone-game著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 解法一和上面一样的题目。 解法二12345class Solution &#123; public boolean stoneGame(int[] nums) &#123; return true; &#125;&#125; 擦…总是会赢。 这是为什么呢， 因为题⽬有两个条件很重要： ⼀是⽯头总共有偶数堆， ⽯头的总数是奇数。 这两个看似增加游戏公平性的条件， 反⽽使该游戏成为了⼀个割⾲菜游戏。 我们以 piles=[2, 1, 9, 5] 讲解， 假设这四堆⽯头从左到右的索引分别是 1， 2， 3， 4。 如果我们把这四堆⽯头按索引的奇偶分为两组， 即第 1、 3 堆和第 2、 4 堆，那么这两组⽯头的数量⼀定不同， 也就是说⼀堆多⼀堆少。 因为⽯头的总数是奇数， 不能被平分。 ⽽作为第⼀个拿⽯头的⼈， 你可以控制⾃⼰拿到所有偶数堆， 或者所有的奇数堆。你最开始可以选择第 1 堆或第 4 堆。 如果你想要偶数堆， 你就拿第 4 堆， 这样留给对⼿的选择只有第 1、 3 堆， 他不管怎么拿， 第 2 堆⼜会暴露出来，你就可以拿。 同理， 如果你想拿奇数堆， 你就拿第 1 堆， 留给对⼿的只有第2、 4 堆， 他不管怎么拿， 第 3 堆⼜给你暴露出来了。也就是说， 你可以在第⼀步就观察好， 奇数堆的⽯头总数多， 还是偶数堆的⽯头总数多， 然后步步为营， 就⼀切尽在掌控之中了。 leetcode292. Nim 游戏这是一道简单题？？？？？？？？？？ 你和你的朋友，两个人一起玩 Nim 游戏：桌子上有一堆石头，每次你们轮流拿掉 1 - 3 块石头。 拿掉最后一块石头的人就是获胜者。你作为先手。 你们是聪明人，每一步都是最优解。 编写一个函数，来判断你是否可以在给定石头数量的情况下赢得游戏。 示例: 输入: 4输出: false解释: 如果堆中有 4 块石头，那么你永远不会赢得比赛；因为无论你拿走 1 块、2 块 还是 3 块石头，最后一块石头总是会被你的朋友拿走。 递归解法当没有石子的话，也就意味着最后的石子被对方拿走了，也就是你输了。 当石子数剩下 1, 2, 3 个的时候，你可以一次性都拿走，也就是你赢了。 然后我们考虑所有的情况。 你拿走 1 个石子，然后不论对方从剩下的石子中拿走 1 个，2 个，还是 3 个，判断一下剩下的石子你是不是有稳赢的策略。 如果上边不行的话，你就拿走 2 个石子，然后再判断不论对方从剩下的石子拿走 1 个，2 个，还是3 个，剩下的石子你是不是都有稳赢的策略。 如果上边还不行的话，你就拿走 3 个石子，然后再判断不论对方从剩下的石子拿走 1 个，2 个，还是3 个，剩下的石子你是不是都有稳赢的策略。 如果上边通通不行，那就是你输了 1234567891011121314151617class Solution &#123; public boolean canWinNim(int n) &#123; if(n == 0) return false; if( n &lt; 4)&#123; return true; &#125; for(int i = 1; i &lt;= 3; i++)&#123; if(canWinNim(n-1-i) &amp;&amp; canWinNim(n-2-i) &amp;&amp; canWinNim(n-3-i) )&#123; return true; &#125; &#125; return false; &#125;&#125; 超时时间限制 使用备忘录的方法 1234567891011121314151617181920212223class Solution &#123; Map&lt;Integer, Boolean&gt; map = new HashMap&lt;&gt;(); public boolean canWinNim(int n) &#123; if(map.containsKey(n))&#123; return map.get(n); &#125; if(n &lt;= 0) return false; if( n &lt; 4)&#123; return true; &#125; for(int i = 1; i &lt;= 3; i++)&#123; if(canWinNim(n-1-i) &amp;&amp; canWinNim(n-2-i) &amp;&amp; canWinNim(n-3-i) )&#123; map.put(n, true); return true; &#125; &#125; map.put(n, false); return false; &#125;&#125; Stack Overflow 。。。 数学推导先说结论： 我们解决这种问题的思路⼀般都是反着思考： 如果我能赢， 那么最后轮到我取⽯⼦的时候必须要剩下 1~3 颗⽯⼦， 这样我才能⼀把拿完。如何营造这样的⼀个局⾯呢？ 显然， 如果对⼿拿的时候只剩 4 颗⽯⼦， 那么⽆论他怎么拿， 总会剩下 13 颗⽯⼦， 我就能赢。如何逼迫对⼿⾯对 4 颗⽯⼦呢？ 要想办法， 让我选择的时候还有 57 颗⽯⼦， 这样的话我就有把握让对⽅不得不⾯对 4 颗⽯⼦。 如何营造 57 颗⽯⼦的局⾯呢？ 让对⼿⾯对 8 颗⽯⼦， ⽆论他怎么拿， 都会给我剩下 57 颗， 我就能赢。这样⼀直循环下去， 我们发现只要踩到 4 的倍数， 就落⼊了圈套， 永远逃不出 4 的倍数， ⽽且⼀定会输。 所以这道题的解法⾮常简单： 123// 如果上来就踩到 4 的倍数， 那就认输吧// 否则， 可以把对⽅控制在 4 的倍数， 必胜return n % 4 != 0; 电灯开关问题这个问题是这样描述的： 有 n 盏电灯， 最开始时都是关着的。 现在要进⾏ n轮操作： 第 1 轮操作是把每⼀盏电灯的开关按⼀下（全部打开） 。 第 2 轮操作是把每两盏灯的开关按⼀下（就是按第 2， 4， 6… 盏灯的开关，它们被关闭） 。 第 3 轮操作是把每三盏灯的开关按⼀下（就是按第 3， 6， 9… 盏灯的开关，有的被关闭， ⽐如3， 有的被打开， ⽐如 6） … 如此往复， 直到第 n 轮， 即只按⼀下第 n 盏灯的开关。现在给你输⼊⼀个正整数 n 代表电灯的个数， 问你经过 n 轮操作后， 这些电灯有多少盏是亮的？ 布尔数组统计使用一个布尔数组去模拟上述操作 1234567891011121314151617181920public int isLight(int n)&#123; boolean[] flag = new boolean[n+1]; for(int i = 1; i &lt;= n; i++)&#123; for(int j = i; j &lt;= n; j+=i)&#123; flag[j] = !flag[j]; &#125; &#125; // 统计 int count = 0; for(int i = 1; i &lt;= n; i++)&#123; if(flag[i])&#123; count++; &#125; &#125; return count; &#125; 妙解123public int isLight(int n) &#123; return (int)Math.sqrt(n);&#125; ⾸先， 因为电灯⼀开始都是关闭的， 所以某⼀盏灯最后如果是点亮的， 必然要被按奇数次开关。 我们假设只有 6 盏灯， ⽽且我们只看第 6 盏灯。 需要进⾏ 6 轮操作对吧， 请问对于第 6 盏灯，会被按下⼏次开关呢？ 这不难得出， 第 1 轮会被按， 第 2轮， 第 3 轮， 第 6 轮都会被按。 为什么第 1、 2、 3、 6 轮会被按呢？ 因为 6=16=23 。 ⼀般情况下， 因⼦都是成对出现的， 也就是说开关被按的次数⼀般是偶数次。 但是有特殊情况，⽐如说总共有 16 盏灯， 那么第 16 盏灯会被按⼏次? 16=1*16=2*8=4*4 其中因⼦ 4 重复出现， 所以第 16 盏灯会被按 5 次， 奇数次。 现在你应该理解这个问题为什么和平⽅根有关了吧？不过， 我们不是要算最后有⼏盏灯亮着吗， 这样直接平⽅根⼀下是啥意思呢？ 稍微思考⼀下就能理解了。 就假设现在总共有 16 盏灯， 我们求 16 的平⽅根， 等于 4， 这就说明最后会有 4 盏灯亮着， 它们分别是第 1*1=1 盏、 第 2*2=4 盏、 第 3*3=9 盏和第4*4=16 盏。 就算有的 n 平⽅根结果是⼩数， 强转成 int 型， 也相当于⼀个最⼤整数上界， ⽐这个上界⼩的所有整数， 平⽅后的索引都是最后亮着的灯的索引。 所以说我们直接把平⽅根转成整数， 就是这个问题的答案。 参考 https://leetcode-cn.com/problems/nim-game/solution/xiang-xi-tong-su-de-si-lu-fen-xi-duo-jie-fa-by-54/ https://labuladong.gitbook.io/algo","path":"2020/09/01/博弈游戏算法/","date":"09-01","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"2020年8月31日-58同城2021校园招聘后台开发笔试","text":"选择题22题，一道多选题，3道把编程题，时间挺紧张的。。。 编程题1：找出共有字符串就是给几个存放字符串的列表，找出他们的公共的字符串。也就是都出现过的，这题a了80 % 没有去重复… 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package wubatongcheng;import cn.hongliang.singleton.Father;import com.sun.org.apache.regexp.internal.RE;import java.util.*;/** * @author Hongliang Zhu * @create 2020-08-31 20:39 */public class FindCommonString &#123; public static ArrayList&lt;String&gt; findCommonString (List&lt;List&lt;String&gt;&gt; values) &#123; // write code here ArrayList&lt;String&gt; res = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; values.get(0).size(); j++) &#123; String s = values.get(0).get(j); boolean flag = true; for (int i = 1; i &lt; values.size(); i++) &#123; flag |= values.get(i).contains(s); &#125; if (flag) &#123; if (!res.contains(s)) &#123; // 去重 res.add(s); &#125; &#125; &#125; return res; &#125; public static void main(String[] args) &#123; List&lt;String&gt; list = Arrays.asList(&quot;a&quot;, &quot;a&quot;, &quot;hnf&quot;, &quot;uhg&quot;, &quot;hnf&quot;); List&lt;String&gt; list2 = Arrays.asList(&quot;a&quot;, &quot;a&quot;, &quot;ass&quot;, &quot;ggg&quot;, &quot;hnf&quot;); List&lt;List&lt;String&gt;&gt; values = Arrays.asList(list, list2); ArrayList&lt;String&gt; commonString = findCommonString(values); System.out.println(commonString); &#125;&#125; 编程题2：500以内的整数k一个500以内的整数k， 加上a之后变成一个完全平方数，再加上b后也变成一个完全平方数，求这个k。 暴力枚举即可，找到k+a 和 k+a+b他们是否能完全开平方。但是我只过了20% 。。。为啥 原来来理解错了题意… 应该比较 a+k 和 k+b…. 1234567891011121314151617181920212223242526272829303132333435363738394041424344 /** * * @param a int整型 * @param b int整型 * @return int整型 */ public int question (int a, int b) &#123; // write code here for (int k = 0; k &lt;= 500; k++)&#123;// double sqrt = Math.sqrt(k + a);// double sqrt1 = Math.sqrt(k + a + b); boolean f = false; for(int i = 0; i &lt;= k+a; i++)&#123; if(i * i == k+a)&#123; f = true; break; &#125; &#125; boolean g = false; for(int i = 0; i &lt;= k+a+b; i++)&#123; if(i * i == k+b)&#123; g = true; break; &#125; &#125; if( f &amp;&amp; g)&#123; return k; &#125;// int aa = (int)sqrt;// int bb = (int)sqrt1;// if((aa-sqrt) == 0 &amp;&amp; (bb-sqrt1) == 0)&#123;// return k;// &#125; &#125; return 0; &#125; 编程题3： 敌军破译密码leetcode: https://leetcode-cn.com/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/ dp[i] 表示以字符i结尾的字符串的翻译种数。 如果第i位和第i-1位数字可以翻译，则dp[i] = dp[i-1]+dp[i-2]; 否则dp[i] = dp[i-1]; 123456789101112131415161718class Solution &#123; public int translateNum(int num) &#123; String s = String.valueOf(num); int n = s.length(); int[] dp = new int[n+1]; dp[0] = 1; dp[1] = 1; for(int i = 2; i &lt;= n;i++)&#123; if(Integer.valueOf(s.substring(i-2,i)) &gt;= 10 &amp;&amp; Integer.valueOf(s.substring(i-2,i)) &lt;= 25 )&#123; dp[i] = dp[i-1]+ dp[i-2]; &#125;else&#123; dp[i] = dp[i-1]; &#125; &#125; return dp[n]; &#125;&#125;","path":"2020/08/31/58笔试/","date":"08-31","excerpt":"","tags":[{"name":"笔试","slug":"笔试","permalink":"https://castile.github.io/tags/%E7%AC%94%E8%AF%95/"},{"name":"校招","slug":"校招","permalink":"https://castile.github.io/tags/%E6%A0%A1%E6%8B%9B/"}]},{"title":"面试题-翻转整数","text":"给出一个 32 位的有符号整数，你需要将这个整数中每位上的数字进行反转。 示例 1: 12输入: 123输出: 321 示例 2: 12输入: -123输出: -321 示例 3: 12输入: 120输出: 2 如果num小于0， 则需要添加一个-号 1234567891011121314151617181920212223242526272829303132/** * @author Hongliang Zhu * @create 2020-08-31 22:43 * * 翻转整数 */public class reverseInteger &#123; private static int reverseInteger(int num)&#123; int res = 0; StringBuilder s = new StringBuilder(); // 处理小于0的情况 if(num &lt; 0)&#123; s.append(&quot;-&quot;); num = -num; &#125; while (num != 0)&#123; s.append(num % 10); num /=10; &#125; res = Integer.valueOf(s.toString()); return res; &#125; public static void main(String[] args) &#123; int num = -1234; System.out.println(reverseInteger(num)); // -4321 &#125;&#125;","path":"2020/08/31/面试题-翻转整数/","date":"08-31","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"POI及easyExcel操作Excel表格","text":"应用场景​ 最近的一个项目需要使用到excel导入功能。比如测试用例，根据里面的案例生成自动化测试脚本文件。那么，首先就要将excel读取程序当中。 ​ 目前操作excel比较流行的就是Apache POI和阿里巴巴的easyexcel。 Apache POI​ 官网： http://poi.apache.org/ ​ POI，全称Apache POI，使用Java编写的免费开源的跨平台的Java API。 是创建和维护操作各种符合 Office Open XML（OOXML）标准和微软的 OLE 2 复合文档格式（OLE2）的 Java API。用它可以使用 Java 读取和创建, 修改 MS Excel 文件。而且，还可以使用 Java 读取和创建 MS Word 和 MSPowerPoint 文件。Apache POI 提供 Java 操作 Excel 解决方案（适用于 Excel97-2008）。 POI-Excel写 创建项目、导入依赖 1234567891011121314151617181920212223242526272829&lt;dependencies&gt;&lt;!-- xls(03)--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.11&lt;/version&gt; &lt;/dependency&gt;&lt;!-- xls(07)--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.11&lt;/version&gt; &lt;/dependency&gt;&lt;!-- 日期自动化工具--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.10.1&lt;/version&gt; &lt;/dependency&gt;&lt;!-- junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 03版本与07版本的区别：03版是以xls结尾， 07版以xlsx结尾。而且03班最多支持65536行数据，而07版没有限制。 在一个excel文件里面，有工作表、工作簿、行、列。 所以我们只需要找到这几个对象就可以开始操作excel了！ 03版 123456789101112131415161718192021222324252627282930313233343536String Path = &quot;F:\\\\java\\\\excel\\\\poiexcel&quot;; @Test public void testWrite03() throws Exception &#123; // 创建一个工作簿 Workbook workbook = new HSSFWorkbook(); // 创建一个工作表 Sheet sheet = workbook.createSheet(&quot;测试案例&quot;); // 创建一行 第一个单元格 Row row1 = sheet.createRow(0); Cell cell11 = row1.createCell(0); cell11.setCellValue(&quot;案例描述&quot;); Cell cell12 = row1.createCell(1); cell12.setCellValue(&quot;案例名称&quot;); Cell cell13 = row1.createCell(2); cell13.setCellValue(&quot;预期结果&quot;); Cell cell14 = row1.createCell(3); cell14.setCellValue(&quot;GIVEN&quot;); Cell cell15 = row1.createCell(4); cell15.setCellValue(&quot;WHEN&quot;); Cell cell16 = row1.createCell(5); cell16.setCellValue(&quot;THEN&quot;); // 生成表 FileOutputStream fileOutputStream = new FileOutputStream(Path+&quot;测试案例.xls&quot;); //输出 workbook.write(fileOutputStream); fileOutputStream.close(); System.out.println(&quot;生成成功！&quot;); &#125; 对于07版本的，只要在上面的代码，将下面代码 12// 创建一个工作簿Workbook workbook = new HSSFWorkbook(); 改为 12// 创建一个工作簿Workbook workbook = new XSSFWorkbook(); 然后文件的后缀是xlsx。 大文件写入 03版： 大文件写HSSF 缺点：最多只能处理65536行数据。否则会抛出异常。 优点： 过程中写入缓存，不操作磁盘，最后一次性写入磁盘，速度比较快。 12345678910111213141516171819202122232425262728@Test public void testWrite03BigData() throws Exception &#123; // 创建工作簿 Workbook workbook = new HSSFWorkbook(); Sheet sheet = workbook.createSheet(&quot;bigdata03&quot;); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; 65536; i++) &#123; // 创建一行 Row row = sheet.createRow(i); for(int j = 0; j &lt; 10; j++)&#123; Cell cell = row.createCell(j); cell.setCellValue(&quot;a&quot;+j); &#125; &#125; FileOutputStream fileOutputStream = new FileOutputStream(Path+&quot;bigdata03.xls&quot;); workbook.write(fileOutputStream); fileOutputStream.close(); long end = System.currentTimeMillis(); System.out.println((double)(end-begin)/1000); System.out.println(&quot;成功！&quot;); &#125; 1.577成功！ 将65536 改为65537， 报异常 07版： 大文件写XSSF 缺点：写数据时速度非常慢，非常耗内存，也会发生内存溢出。如一百万条。 优点：可以写较大的数据量。比如说20万条。 123456789101112131415161718192021222324252627@Test public void testWrite07BigData() throws Exception &#123; // 创建工作簿 Workbook workbook = new XSSFWorkbook(); Sheet sheet = workbook.createSheet(&quot;bigdata07&quot;); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; 65536; i++) &#123; // 创建一行 Row row = sheet.createRow(i); for(int j = 0; j &lt; 10; j++)&#123; Cell cell = row.createCell(j); cell.setCellValue(&quot;a&quot;+j); &#125; &#125; FileOutputStream fileOutputStream = new FileOutputStream(Path+&quot;bigdata07.xlsx&quot;); workbook.write(fileOutputStream); fileOutputStream.close(); long end = System.currentTimeMillis(); System.out.println((double)(end-begin)/1000); System.out.println(&quot;成功！&quot;); &#125; 12.815成功！ 他可以写大量的数据，没有65536 的限制，比如写100000行数据 17.968成功！ 可以看到XSSF的速度极慢！下面可以改进，通过SXSSF 大文件写SXSSF 优点： 可以写非常大的数据量，如一百万条，甚至更多条。写数据速度快，占用更少的内存。 但是在过程中会产生临时文件，需要清理临时文件。默认由100条记录被保存到内存中。如果超过这数量，则最前面的数据被写入临时文件。如果想自定义内存中数据的数量，可以使用new SXSSFWorkbook(数量)。 1234567891011121314151617181920212223242526272829@Test public void testWrite07BigDataS() throws Exception &#123; // 创建工作簿 SXSSFWorkbook workbook = new SXSSFWorkbook(); Sheet sheet = workbook.createSheet(&quot;bigdataSSS07&quot;); long begin = System.currentTimeMillis(); for (int i = 0; i &lt; 65536; i++) &#123; // 创建一行 Row row = sheet.createRow(i); for(int j = 0; j &lt; 10; j++)&#123; Cell cell = row.createCell(j); cell.setCellValue(&quot;a&quot;+j); &#125; &#125; FileOutputStream fileOutputStream = new FileOutputStream(Path+&quot;bigdata07S.xlsx&quot;); workbook.write(fileOutputStream); fileOutputStream.close(); // 清除临时文件 workbook.dispose(); long end = System.currentTimeMillis(); System.out.println((double)(end-begin)/1000); System.out.println(&quot;成功！&quot;); &#125; 1.17成功！ 即使写入100000条记录 1.719成功！ ​ 官方解释。实现big green demo策略的流逝版本，这允许写入非常大的文件，而不会耗尽内存，因为任何时候只有可配置的行部分。被保存在内存中。请注意。仍然可能会消耗大量内存。这些内存基于您正在使用的功能，例如合并区域、注释…….仍然只存在内存中。因此，如果广泛使用，可能需要大量内存。 POI 读取Excel123456789101112131415161718192021public class excelReadTest &#123; String Path = &quot;F:\\\\java\\\\excel\\\\poiexcel&quot;; @Test public void testRead() throws Exception &#123; FileInputStream in = new FileInputStream(Path+&quot;测试案例.xls&quot;); // 创建工作簿 Workbook workbook = new HSSFWorkbook(in); Sheet sheet = workbook.getSheetAt(0); // 获取行 Row row = sheet.getRow(0); for(int i = 0; i &lt; 6; i++)&#123; Cell cell = row.getCell(i); String stringCellValue = cell.getStringCellValue(); System.out.println(stringCellValue); &#125; &#125;&#125; 案例描述案例名称预期结果GIVENWHENTHEN 读取不同的数据类型 里面包含了字符串、数字、日期等数据类型。 看几个API 方法 描述 Row.java –&gt; int getPhysicalNumberOfCells(); 获取当前行的单元格数量 Cell.java –&gt; int getCellType(); 获取当前单元格的类型，是一个枚举类型。 CELL_TYPE_BLANK CELL_TYPE_NUMERIC CELL_TYPE_STRING CELL_TYPE_FORMULA CELL_TYPE_BOOLEAN CELL_TYPE_ERROR Sheet.java – &gt; int getPhysicalNumberOfRows(); 获取工作表中的行数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081 @Test public void testRead07() throws Exception &#123; FileInputStream in = new FileInputStream(Path+&quot;明细.xlsx&quot;); // 创建工作簿 Workbook workbook = new XSSFWorkbook(in); Sheet sheet = workbook.getSheetAt(0); // // 获取标题内容 Row rowTitle = sheet.getRow(0); if(rowTitle != null)&#123; int cells = rowTitle.getPhysicalNumberOfCells(); for (int i = 0; i &lt; cells; i++) &#123; Cell cell = rowTitle.getCell(i); if(cell != null)&#123; int cellType = cell.getCellType(); // 获取类型 String stringCellValue = cell.getStringCellValue(); System.out.print(stringCellValue + &quot; | &quot;); &#125; &#125; System.out.println(); &#125; // 获取表中的内容 int rows = sheet.getPhysicalNumberOfRows(); for (int i = 1; i &lt; rows; i++) &#123; Row rowData = sheet.getRow(i); if(rowData != null)&#123; //读取列 int cells = rowData.getPhysicalNumberOfCells(); for (int j = 0; j &lt; cells; j++) &#123; Cell cell = rowData.getCell(j); if(cell != null)&#123; int cellType = cell.getCellType(); String cellValue = null; // 匹配列的数据类型 switch (cellType)&#123; case XSSFCell.CELL_TYPE_STRING: // 字符串// System.out.println(&quot;【String】&quot;); cellValue = cell.getStringCellValue(); break; case XSSFCell.CELL_TYPE_BOOLEAN:// System.out.println(&quot;【Boolean】&quot;); cellValue = String.valueOf(cell.getBooleanCellValue()); break; case XSSFCell.CELL_TYPE_NUMERIC:// System.out.println(&quot;【Num】&quot;); if(HSSFDateUtil.isCellDateFormatted(cell))&#123; // 日期 Date date = cell.getDateCellValue(); cellValue = new DateTime(date).toString(&quot;yyyy-MM-dd&quot;); &#125;else&#123; cell.setCellType(XSSFCell.CELL_TYPE_STRING); cellValue = cell.getStringCellValue() ; &#125; break; case XSSFCell.CELL_TYPE_BLANK:// System.out.println(&quot;【BLANK】&quot;); break; case XSSFCell.CELL_TYPE_ERROR: break; &#125; System.out.print(cellValue+&quot; &quot;); &#125; &#125; &#125; System.out.println(); &#125; in.close(); &#125; PIO 这个框架比较原生，用起来比较麻烦，而且在文件很大的时候可能会出现OOM异常，因为它导入是将整个文档全部导入到内存中。 所以， easye小说xcel就出现了，它解决了POI的问题，而且使用起来也非常方便。 easyExcel官网： https://www.yuque.com/easyexcel/doc/easyexcel github： https://github.com/alibaba/easyexcel easyexcel是阿里巴巴开源的一个Excel处理框架。以使用简单，节省内存著称。 Easy Excel能大大减少占用内存的主要原因是在解析Excel时，没有将文件数据一次性全部加载到内存中。而是在磁盘上一行行读取逐个解析。 easyexcel 是一个 JAVA 解析 Excel 工具。Java 解析、生成 Excel 比较有名的框架有 Apache poi、jxl 。但他们都存在一个严重的问题就是非常的耗内存，poi 有一套 SAX 模式的 API 可以一定程度的解决一些内存溢出的问题，但 POI 还是有一些缺陷，比如 07 版 Excel 解压缩以及解压后存储都是在内存中完成的，内存消耗依然很大。easyexcel 重写了 poi 对 07 版 Excel 的解析，能够原本一个 3M 的 excel 用 POI sax 依然需要 100M 左右内存降低到 KB 级别，并且再大的 excel 不会出现内存溢出，03 版依赖 POI 的 sax 模式。在上层做了模型转换的封装，让使用者更加简单方便。 导入依赖1234567&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;2.2.6&lt;/version&gt;&lt;/dependency&gt; 实体类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package cn.hongliang;import com.alibaba.excel.annotation.ExcelIgnore;import com.alibaba.excel.annotation.ExcelProperty;import lombok.Data;import java.util.Date;/** * @author Hongliang Zhu * @create 2020-08-04 11:11 */@Datapublic class EquivalenceImportEntity &#123; @ExcelProperty(&quot;案例描述&quot;) private String caseDescription; @ExcelProperty(&quot;案例名称&quot;) private String caseName; @ExcelProperty(&quot;预期结果&quot;) private String expectedResult; @ExcelProperty(&quot;GIVEN&quot;) private String given; @ExcelProperty(&quot;WHEN&quot;) private String when; @ExcelProperty(&quot;THEN&quot;) private String then; /** * 忽略字段 */ /** * 文件包名 */ @ExcelIgnore private String packageDir; /** * 文件名 */ @ExcelIgnore private String classFileName; /** * 创建时间 */ // @ExcelIgnore @ExcelProperty(&quot;创建时间&quot;) private Date createDateTime;&#125; 写Excel通用数据生成123456789101112131415private List&lt;EquivalenceImportEntity&gt; data() &#123; List&lt;EquivalenceImportEntity&gt; list = new ArrayList&lt;EquivalenceImportEntity&gt;(); for (int i = 0; i &lt; 10; i++) &#123; EquivalenceImportEntity data = new EquivalenceImportEntity(); data.setCaseDescription(&quot;用于测试easyExcel的案例&quot; + i); data.setCaseName(&quot;写excel&quot; + i); data.setGiven(&quot;我付款1000RMB预定了一个3周后从成都飞往三亚的航班。&quot; + i); data.setWhen(&quot;在航班起飞前一周“我”取消了该行程&quot;); data.setThen(&quot;我应该得到预定机票半价的退款（500RMB)&quot; + i); data.setExpectedResult(&quot;返回500元 &quot; + i); data.setCreateDateTime(new Date()); list.add(data); &#125; return list; &#125; 写入123456789101112131415/** * 最简单的写 * &lt;p&gt;1. 创建excel对应的实体对象 参照&#123;@link EquivalenceImportEntity&#125; * &lt;p&gt;2. 直接写即可 */ @Test public void simpleWrite() &#123; // 写法1 String fileName = Path + System.currentTimeMillis() + &quot;.xlsx&quot;; // 这里 需要指定写用哪个class去写，然后写到第一个sheet，名字为模板 然后文件流会自动关闭 EasyExcel.write(fileName, EquivalenceImportEntity.class).sheet(&quot;User&quot;).doWrite(data()); &#125; 也可以排除指定的列去写入，将排除的列存入一个set中，然后write的时候传入set就行了。具体可参照官网 https://www.yuque.com/easyexcel/doc/write 读取Excel还是上面那个对象 监听器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package cn.hongliang;import com.alibaba.excel.context.AnalysisContext;import com.alibaba.excel.event.AnalysisEventListener;import com.alibaba.fastjson.JSON;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;/** * @author Hongliang Zhu * @create 2020-08-04 11:48 * * // 有个很重要的点 CaseDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去 */public class CaseDataListener extends AnalysisEventListener&lt;EquivalenceImportEntity&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(CaseDataListener.class); /** * 每隔5条存储数据库，实际使用中可以3000条，然后清理list ，方便内存回收 */ private static final int BATCH_COUNT = 5; List&lt;EquivalenceImportEntity&gt; list = new ArrayList&lt;EquivalenceImportEntity&gt;(); public CaseDataListener() &#123; &#125; /** * 这个每一条数据解析都会来调用 * * @param data one row value. Is is same as &#123;@link AnalysisContext#readRowHolder()&#125; * @param context 分析上下文 */ @Override public void invoke(EquivalenceImportEntity data, AnalysisContext context) &#123; LOGGER.info(&quot;解析到一条数据:&#123;&#125;&quot;, JSON.toJSONString(data)); list.add(data); // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM if (list.size() &gt;= BATCH_COUNT) &#123; saveData(); // 持久化 // 存储完成清理 list list.clear(); &#125; &#125; /** * 所有数据解析完成了 都会来调用 * * @param context */ @Override public void doAfterAllAnalysed(AnalysisContext context) &#123; // 这里也要保存数据，确保最后遗留的数据也存储到数据库 saveData(); LOGGER.info(&quot;所有数据解析完成！&quot;); &#125; /** * 加上存储数据库 */ private void saveData() &#123; LOGGER.info(&quot;&#123;&#125;条数据，开始存储数据库！&quot;, list.size());// demoDAO.save(list); LOGGER.info(&quot;存储数据库成功！&quot;); &#125;&#125; 读取123456789101112131415/** * 最简单的读 * &lt;p&gt;1. 创建excel对应的实体对象 参照&#123;@link EquivalenceImportEntity&#125; * &lt;p&gt;2. 由于默认一行行的读取excel，所以需要创建excel一行一行的回调监听器，参照&#123;@link CaseDataListener&#125; * &lt;p&gt;3. 直接读即可 */ @Test public void simpleRead() &#123; // 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去 // 写法1： String fileName = Path+ &quot;1596512468069.xlsx&quot;; // 这里 需要指定读用哪个class去读，然后读取第一个sheet 文件流会自动关闭 EasyExcel.read(fileName, EquivalenceImportEntity.class, new CaseDataListener()).sheet().doRead(); &#125; 这样就把Excel文件的内容读取到了！！！","path":"2020/08/04/easyexcel/","date":"08-04","excerpt":"","tags":[{"name":"excel","slug":"excel","permalink":"https://castile.github.io/tags/excel/"},{"name":"tools","slug":"tools","permalink":"https://castile.github.io/tags/tools/"}]},{"title":"MySQL中的连接查询","text":"MySQL中的连接查询一共有7大连接查询，如下图所示 通过举例来理解吧。 建库建表12345678910111213141516171819202122232425262728293031323334353637383940USE test;CREATE TABLE `t_dept` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `deptName` VARCHAR(30) DEFAULT NULL, `address` VARCHAR(40) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; CREATE TABLE `t_emp` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `name` VARCHAR(20) DEFAULT NULL, `age` INT(3) DEFAULT NULL, `deptId` INT(11) DEFAULT NULL,empno INT NOT NULL, PRIMARY KEY (`id`), KEY `idx_dept_id` (`deptId`) #CONSTRAINT `fk_dept_id` FOREIGN KEY (`deptId`) REFERENCES `t_dept` (`id`)) ENGINE=INNODB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; INSERT INTO t_dept(deptName,address) VALUES(&#x27;华山&#x27;,&#x27;华山&#x27;);INSERT INTO t_dept(deptName,address) VALUES(&#x27;丐帮&#x27;,&#x27;洛阳&#x27;);INSERT INTO t_dept(deptName,address) VALUES(&#x27;峨眉&#x27;,&#x27;峨眉山&#x27;);INSERT INTO t_dept(deptName,address) VALUES(&#x27;武当&#x27;,&#x27;武当山&#x27;);INSERT INTO t_dept(deptName,address) VALUES(&#x27;明教&#x27;,&#x27;光明顶&#x27;); INSERT INTO t_dept(deptName,address) VALUES(&#x27;少林&#x27;,&#x27;少林寺&#x27;); INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;风清扬&#x27;,90,1,100001);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;岳不群&#x27;,50,1,100002);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;令狐冲&#x27;,24,1,100003); INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;洪七公&#x27;,70,2,100004);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;乔峰&#x27;,35,2,100005);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;灭绝师太&#x27;,70,3,100006);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;周芷若&#x27;,20,3,100007);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;张三丰&#x27;,100,4,100008);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;张无忌&#x27;,25,5,100009);INSERT INTO t_emp(NAME,age,deptId,empno) VALUES(&#x27;韦小宝&#x27;,18,NULL,100010); 1SELECT * FROM t_emp; # 10 一共有10条记录。 1SELECT * FROM t_dept; # 6 部门有6条记录，表示六大门派 七大连接查询AB共同即查询两张表中共同的部分，即上图的交集。 查询所有 有门派的人员信息： 1SELECT * FROM t_emp a INNER JOIN t_dept b ON a.`deptId` = b.`id`; 从结果中发现，门派表中的“少林”与员工表的“韦小宝”不在查询结果中。只查询了两表的交集部分。因为韦小宝不属于任何门派，而员工表中没有少林派的人员。 A的全集 列出所有用户，并显示其机构信息： 1SELECT * FROM t_emp a LEFT JOIN t_dept b ON a.`deptId` = b.`id`; 要求列出所有的用户，应该使用左连接， 员工表为主表，将主表 中的数据全部查询出来，从表是部门表，与员工表不对应的部分查询为NULL。 B的全集 列出所有门派 ： 1SELECT * FROM t_emp a RIGHT JOIN t_dept b ON a.`deptId` = b.`id`; 上述结果中，将所有的门派查询出来了，右边的表为主表，而左边的员工表中，有匹配的就查询，无匹配的就填充NULL。 A的独有所谓A的独占就是说查询出来的结果中只在A表中出现的记录，B表中无匹配。 相当于A的全集中将中间的“抠掉”, 也就是说将两表的公共部分去掉。其标准查询模板是： 1Select &lt;select list&gt; from A left join B on a.key = b.key where b.key IS NULL; 如： 查询所有不入门派的人员, 我们需要做的就是将上面红框部分的去掉，获取剩下的蓝色框部分。 1SELECT * FROM t_emp a LEFT JOIN t_dept b ON a.`deptId` = b.`id` WHERE b.`id` IS NULL; B的独有 同上的分析。相当于B的全集中将中间的“抠掉”, 也就是说将两表的公共部分去掉，或者说我要去的B的独有部分，A 就没啥事情了，将B全集中结果去掉A的那部分就是B的独有了。其标准查询模板是： 1Select &lt;select list&gt; from A right join B on a.key = b.key where a.key IS NULL; 查询所有没人入的门派： 1SELECT * FROM t_emp a RIGHT JOIN t_dept b ON a.`deptId` = b.`id` WHERE a.`deptId` IS NULL; 查出来的是少林派，的确是少林派没有人加入。 AB全有 其标准查询模板是： 1select &lt;select list &gt; from A FULL OUTER JOIN B ON A.key = B.key; 列出所有人员和门派的对应关系： 1SELECT * FROM t_emp a FULL OUTER JOIN t_dept b ON a.`deptId` = b.`id`; 保存如下： 这是因为MYSQL不支持FULL JOIN。 可以使用UNION， 可以去重 123SELECT * FROM t_emp a LEFT JOIN t_dept b ON a.`deptId` = b.`id`UNIONSELECT * FROM t_emp a RIGHT JOIN t_dept b ON a.`deptId` = b.`id`; 分析一下, 一目了然，就是三个的并集： A的独有+B的独有 列出所有没入派的人员和没人入的门派 没入派的就是韦小宝，没人入的门派是少林派 和上面一样，就是A的独有并上B的独有，也可以使用UNION关键字 1234# 7. 列出所有没入派的人员和没人入的门派SELECT * FROM t_emp a LEFT JOIN t_dept b ON a.`deptId` = b.`id` WHERE b.`id` IS NULL UNIONSELECT * FROM t_emp a RIGHT JOIN t_dept b ON a.`deptId` = b.`id` WHERE a.`deptId` IS NULL; 进阶如果在上面的部门表上加上对应的门派掌门字段 12345678ALTER TABLE t_dept ADD CEO INT(11);UPDATE t_dept SET CEO=2 WHERE id=1;UPDATE t_dept SET CEO=4 WHERE id=2;UPDATE t_dept SET CEO=6 WHERE id=3;UPDATE t_dept SET CEO=8 WHERE id=4;UPDATE t_dept SET CEO=9 WHERE id=5;SELECT * FROM t_dept; 求各个门派对应的掌门人名称: 1SELECT * FROM t_dept b LEFT JOIN t_emp a ON a.`id`= b.`CEO`; 求所有当上掌门人的平均年龄: 1SELECT AVG(a.`age`) FROM t_emp a INNER JOIN t_dept b ON a.`id` = b.`CEO`; 求所有人物对应的掌门名称: 123SELECT c.`name` NAME, ab.name ceoName FROM t_emp c LEFT JOIN (SELECT b.`id`, a.`name` FROM t_dept b LEFT JOIN t_emp a ON a.`id`= b.`CEO`) abON c.`deptId`= ab.id; 这里涉及到了三表连接。在第一题中我们已经查询到了每一个门派的掌门姓名，然后我们需要查询每一个人对应的掌门姓名，可以利用第一题查询 到的结果作为另一张表，然后使用员工表去左连接查询。","path":"2020/07/27/mysql连接查询/","date":"07-27","excerpt":"","tags":[{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"}]},{"title":"最短路径算法","text":"最短路径算法整理于网络 单源最短路不带负权边：Dijkstra带负权边：Bellman−Ford、SPFA 多源最短路：Floyd Dijkstra 假设图中顶点V个，边E条，有如下结论 这是求解单元最短路径的经典算法，非常重要 其本质是贪心+BFS Dijkstra算法更适合稠密图（边多的） 无论图有没有环，Dijkstra 算法都是可以用的，它只是不能处理负权边，因为它本质上是贪心策略，每个点选择之后就不再更新，如果碰到了负边的存在就会破坏这个贪心的策略就无法处理了。 堆优化+邻接矩阵是常用的解法 例题leetcode-743 网络延迟时间 有 N 个网络节点，标记为 1 到 N。 给定一个列表 times，表示信号经过有向边的传递时间。 times[i] = (u, v, w)，其中 u 是源节点，v 是目标节点， w 是一个信号从源节点传递到目标节点的时间。 现在，我们从某个节点 K 发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回 -1。 12输入：times = [[2,1,1],[2,3,1],[3,4,1]], N = 4, K = 2输出：2 堆优化的Dijkstra算法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import javafx.util.Pair;import java.util.*;/** * leetcode-743 网络延迟时间 * * @author Hongliang Zhu * @create 2020-07-26 11:03 */public class NetworkDelayTime &#123; public int networkDelayTime(int[][] times, int N, int K) &#123; int res = 0; // 建图 , 每个times就是一条边， 每条边包括起始点和终点已经这条边对应的权重 Map&lt;Integer, List&lt;int[]&gt;&gt; Graph = new HashMap&lt;&gt;(); for (int[] time : times) &#123; Graph.computeIfAbsent(time[0], k -&gt; new ArrayList&lt;&gt;()).add(new int[]&#123;time[1], time[2]&#125;); &#125; Set&lt;Integer&gt; visited = new HashSet&lt;&gt;(); // 优先级队列，小根堆 PriorityQueue&lt;Pair&lt;Integer, Integer&gt;&gt; q = new PriorityQueue&lt;&gt;(Comparator.comparingInt(Pair::getValue)); // 将源点加入 q.offer(new Pair&lt;&gt;(K, 0)); while (!q.isEmpty()) &#123; Pair&lt;Integer, Integer&gt; cur = q.poll(); if (visited.contains(cur.getKey())) &#123; // 已经访问过了 continue; &#125; visited.add(cur.getKey()); res = Math.max(res, cur.getValue()); // 将其相邻的边遍历 for (int[] next : Graph.getOrDefault(cur.getKey(), new ArrayList&lt;&gt;())) &#123; if (visited.contains(next[0])) &#123; continue; &#125; q.offer(new Pair&lt;&gt;(next[0], next[1] + cur.getValue())); &#125; &#125; return visited.size() == N ? res : -1; &#125; public static void main(String[] args) &#123; NetworkDelayTime solution = new NetworkDelayTime(); int[][] times = &#123;&#123;2, 1, 1&#125;, &#123;2, 3, 1&#125;, &#123;3, 4, 1&#125;&#125;; int result = solution.networkDelayTime(times, 4, 2); System.out.println(result); &#125;&#125; Bellman-Ford什么是BF算法 BF这个算法也是求单源最短路径的一个算法，算法非常简洁。但是他并不是一个最优的一个方法，他的时间复杂度大于迪杰斯特拉算法。事实上，BF算法的时间复杂度正比于结点的个数和边个数的乘积，即O(V*E)。而迪杰斯特拉算法可以使用一个小根堆来实现，复杂度更小，是O(E+V)log(V)。 我们使用BF算法，是因为有时候迪杰斯特拉他算法在某些情况下不适用，也就是说图中会有负边权。当图中存在着负边时候，就有可能导致negative cycle。这种情况下，我们需要把它检测出来。如果使用迪杰斯特拉算法的话，会陷入一个循环之中，因为算法总能找到一个更短的路径。 红色的节点表示负环， 经过负环的节点的权重都会是负无穷， 黄色的节点。 BF算法的步骤E: 边数 V:顶点数 S:开始节点 D：开始节点到其他节点的单源最短路径，是一个大小为V的数组 将每个每个节点到开始节点的最短路径设为﹢无穷 set D[S] = 0, 开始节点到自己为0； 对每一条边进行V-1次松弛操作 松弛操作： 对于任意一条边 (u -&gt; v)，取出他们存储好的权重 w( u -&gt; v ). 如果 u.distance + w &lt; v.distance，那么做两个赋值操作：v.distance = u.distance + w，v.previous = u；这一步是松弛操作的核心。 如果上面的判断不成立，什么都不做 问题来了，为啥是V-1次循环呢？ 做 n - 1 次已经足够了。算法导论上有证明： 从原点开始走，到第 x 个节点，这中间只有 x - 1 条边（不考虑环路） 如果一个图有 n 个节点，那么即使用最啰嗦的走法，到达一个点顶多需要走 n - 1 条边（不考虑环路）。也就是顶多把所有的节点都经过一遍。 在第一轮对所有的边进行松弛的时候，被松弛的点其实只有从原点可以一步到达的点。其他的点所在的边 Edge( u -&gt; v ) 中，u.distance 都是 ∞，v 无法被松弛。只有 start_point.distance 为 0，Edge( start_point -&gt; v ) 中的 v 才可能被松弛。 以此类推，在第 i 轮中，被松弛的点只可能是距离原点 i 步的点。他们利用到的边是 Edge( vi - 1 -&gt; vi)，其中 vi - 1 在上一轮松弛的过程中已经被松弛过，如果他能到达原点的话，vi - 1.distance 就不会是 ∞。 有些点可能有多种不同的到达方式，并且在第 i 步之前也松弛过。这其实没关系。如果第 i 步是最后一次到达他，所有能用来到达这个点的边都已经被计算机探索过（不然这就不是最后一次到达），所以这次松弛也将是它最后一次被松弛，之后到达他的 distance 就已经是最终结果值了。 根据上面提到的 2，不可能有节点出现 n - 1 步还到达不了的地方，即使一个点有多条路径可以到达（除非这个点真的无法到达），他的最多步数路径上的边也都被计算机探索过了。也就是说，他的最后一次被访问已经发生过，他的 distance 肯定已经是最终结果值了。没有任何一个点可以例外。 所以 n - 1 次循环已经足够。 第一次迭代在对所有的边进行松弛之后，得到的是从起点”只能经过一条边“到达其余各顶点的最短路径长度…第k轮迭代得到的就是起始点”最多经过k条边“到达其他各顶点的最短路径长度。 迭代的时候使用边进行松弛的顺序比较随机。在最差情况下，导致第一次迭代后，只更新了从起点出发通过一条边到达的部分顶点的最短路径长度。而没有更新不能通过一条边到达的顶点的最短路径长度，长度还是保持正无穷。 所以，可以将leetcode-743使用FB算法。 1234567891011121314151617181920212223242526272829303132333435363738class Solution &#123; public int networkDelayTime(int[][] times, int N, int K) &#123; int[] dist = new int[N+1]; Arrays.fill(dist, Integer.MAX_VALUE/2); dist[K] = 0; boolean flag = false; //循环N-1次 for(int i = 0; i &lt; N-1; i++)&#123; flag = false; for(int j = 0; j &lt; times.length; j++)&#123; int[] t = times[j]; int u = t[0]; int v = t[1]; int w = t[2]; if(dist[u] + w &lt; dist[v])&#123; dist[v] = dist[u] + w ; flag = true; &#125; &#125; if(!flag) break; &#125; int res = -1; for(int i = 1; i &lt;= N; i++)&#123; if(dist[i] == Integer.MAX_VALUE/2)&#123; return -1; &#125; res = Math.max(res, dist[i]); &#125; return res; &#125; &#125; 注意上面的flag操作，可以剪枝不必要的循环。 leetcode-787. K 站中转内最便宜的航班 有 n 个城市通过 m 个航班连接。每个航班都从城市 u 开始，以价格 w 抵达 v。 现在给定所有的城市和航班，以及出发城市 src 和目的地 dst，你的任务是找到从 src 到 dst 最多经过 k 站中转的最便宜的价格。 如果没有这样的路线，则输出 -1。 解法一： 12345678910111213141516171819class Solution &#123; public int findCheapestPrice(int n, int[][] flights, int src, int dst, int K) &#123; int[][] dist = new int[K+2][n]; int INF= Integer.MAX_VALUE/2; for(int i = 0; i &lt; K+2; i++)&#123; Arrays.fill(dist[i], INF); &#125; dist[0][src] = 0; // 经过0个节点到src的距离是0 int res = INF; for(int i =1 ; i &lt; K+2; i++)&#123; for(int[] next: flights)&#123; dist[i][next[1]] = Math.min(dist[i][next[1]], dist[i-1][next[0]] + next[2]); &#125; res = Math.min(res, dist[i][dst]); &#125; return res == INF ? -1: res; &#125;&#125; 解法二： 123456789101112131415161718192021222324252627class Solution &#123; public int findCheapestPrice(int n, int[][] flights, int src, int dst, int K) &#123; int[] dist = new int[n]; int[] back = new int[n]; int INF = Integer.MAX_VALUE/2; Arrays.fill(dist, INF ); Arrays.fill(back, INF ); // 防止串联？？？ dist[src] = 0; for(int i = 0; i &lt;= K; i++)&#123; for(int m = 0; m &lt; n; m++)&#123; back[m] = dist[m]; &#125; for(int[] next: flights)&#123; // 对每条边遍历 // if(dist[next[0]] + next[2] &lt; dist[next[1]] )&#123; // dist[next[1]] = dist[next[0]] + next[2]; // &#125; dist[next[1]] = Math.min(dist[next[1]],back[next[0]] + next[2] ); &#125; &#125; return dist[dst] == INF ? -1 : dist[dst]; &#125;&#125; SPFAFB对边的松弛操作是盲目的，每次循环都将所有的边拿出来看一下。其实，只有当前节点更新了，以他为起点的终点节点才会被更新，不然是无效的。 SPFA 是 Bellman−Ford 的队列优化，但是算法时间效率不稳定，时间复杂度为 O(E)，最好情况下，每个节点只入队一次，就是 BFS，最坏情况下，每一个节点都要入队 V−1 次，这时候就退化成 Bellman−Ford了。SPFA 时间复杂度某种情况下略高于 Dijkstra， 适合稀疏图。 SPFA 是可以用于带有负权图的，在 SPFA 中每一个点松弛过后说明这个点距离更近了，所以有可能通过这个点会再次优化其他点，所以它的策略是将 vis 位置为 false，把这个点入队再判断一次！这就和 Dijkstra 的贪心策略不同了。 SPFA 还有个用处是可以判断图是否存在负环，我们只要用一个 cnt[x] 数组来存放经过这个点的次数，上面提到过，最坏情况下每个节点入队 V−1 次，如果cnt[x] 为 V的个数，那就说明存在负环了。 【算法思想】 初始时，只有把起点放入队列中。 遍历与起点相连的边，如果可以松弛就更新距离dis[]，然后判断如果这个点没有在队列中就入队标记。 出队队首，取消标记，循环2-3步，直至队为空。 所有能更新的点都更新完毕，dis[]数组中的距离就是起点到其他点的最短距离。 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public int networkDelayTime(int[][] times, int N, int K) &#123; // 建图 Map&lt;Integer, List&lt;int[]&gt;&gt; map = new HashMap&lt;&gt;(); int[] dist = new int[N+1]; Arrays.fill(dist, Integer.MAX_VALUE / 2); dist[K] = 0; for(int[] time: times)&#123; map.computeIfAbsent(time[0], k -&gt; new ArrayList&lt;&gt;()).add(new int[]&#123;time[1], time[2]&#125;); &#125; boolean[] vis = new boolean[N+1]; Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;(); q.offer(K); while(!q.isEmpty())&#123; int cur = q.poll(); vis[cur] = false; // 可以再次入队 for(int[] next: map.getOrDefault(cur, new ArrayList&lt;&gt;()))&#123; if(dist[cur]+next[1] &lt; dist[next[0]])&#123; dist[next[0]] = dist[cur]+next[1]; // 将这次更新过的节点入队 if(!vis[next[0]]) &#123; q.offer(next[0]); vis[next[0]] = true; &#125; &#125; &#125; &#125; // 找最大 int res = -1; for(int i = 1; i &lt;=N; i++)&#123; if(dist[i] == Integer.MAX_VALUE / 2)&#123; return -1; &#125; res = Math.max(res, dist[i]); &#125; return res; &#125;&#125; Floyd算法本质是动态规划，能解决任意两点间的最短路径，时间复杂度O*(V3) 。 Floyd它是可以判断有没有负权边环的，走N−1 步，如果再走一步，更短了，那么就说明有环。另外 Floyd 是不能处理带有负权的最短路的，因为本质是一个动态规划算法，有了负边，最优子结构的性质就不满足了。由此可见，它能够判断是否存在负环，但是不能够处理带有负权的最短路径。 Floyd 有个神奇的特性，这个是其他算法没有的， Floyd第 k 轮算的结果，是每个源点到每个汇点经过前 k 个点的最短路，这一点可以出题。 对于上题，由于是动态规划，所以都是用邻接矩阵，并且它是不用 dis 数组和 vis 数组的这边注意，初始化邻接矩阵的时候，如果两个顶点没有边，最好初始化为INF，别初始化为-1，上面说过Floyd是不能处理负权边的，只能判断有没有负环！ 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public int networkDelayTime(int[][] times, int N, int K) &#123; // 邻接矩阵 int[][] g = new int[N+1][N+1]; int INF = 0x3f3f3f3f; // 初始化图,注意,一开始距离是初始化为INF的，而不是像 spfa初始化成-1 // spfa初始化成-1只是为了判断是否为邻居，这里初始化为INF是因为要取min的 for (int i = 1; i &lt;= N; i++) &#123; for (int j = 1; j &lt;= N; j++) &#123; g[i][j] = i == j ? 0 : 0x3f3f3f3f; &#125; &#125; for(int[] time: times)&#123; g[time[0]][time[1]]= time[2]; &#125; for(int k = 1; k &lt;= N; k++)&#123; for(int i = 1; i &lt;= N; i++)&#123; for(int j = 1; j &lt;= N; j++)&#123; g[i][j] = Math.min(g[i][k] + g[k][j], g[i][j]); &#125; &#125; &#125; // g[a][b]表示a到b的最短距离 // 拿结果 int res = 0; for (int distance : g[K]) &#123; res = Math.max(res, distance); &#125; return res == INF ? -1 : res; &#125;&#125; 参考 https://www.dazhuanlan.com/2019/12/08/5dec8b7394f9b/ https://www.bilibili.com/video/BV11b411S79w?from=search&amp;seid=8294149097754810253 https://www.bilibili.com/video/BV1gb41137u4?from=search&amp;seid=14565420049859812931 https://www.bilibili.com/video/BV1Yx411a7HX?p=2 https://blog.csdn.net/qq_24884193/article/details/104357889","path":"2020/07/26/最短路径算法/","date":"07-26","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"fastNote插件开发","text":"开发笔记插件需求分析在阅读源码的时候，我们是不是看完后面的就忘记了前面的了。。。所以决定开发一个插件，用于记录我们阅读源码或者开发的过程，最后可以生成一个md格式的笔记，方便我们后面复习查阅。 功能：点击右键之后在菜单中有插件的工具，选中代码片段之后可以生成对应的笔记，而且具有导出md的功能。 如何添加一个右键点击之后的子菜单 如何获取编辑器中已经选择的文本 如何弹出对话框，获取用户编辑的笔记内容 如何使用ToolWindow展示笔记列表 如何在ToolWindow中添加表格 如何让用户选择文档生成的目录 如何将笔记列表静态化生成文档 代码编写创建工程首先创建一个工程，完成plugin.xml 1234567891011121314151617181920212223242526272829303132333435&lt;idea-plugin&gt; &lt;id&gt;cn.hongliang.fastNote.id&lt;/id&gt; &lt;name&gt;FastNote&lt;/name&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;vendor email=&quot;zhl396740445@163.com&quot; url=&quot;https://hongliangzhu.cn&quot;&gt;Castile&lt;/vendor&gt; &lt;description&gt;&lt;![CDATA[ This is a notebook for development when you start a project or read source code to record ypur steps, and can generate a md document.&lt;br&gt; &lt;em&gt;MarkDown Doc&lt;/em&gt; ]]&gt;&lt;/description&gt; &lt;change-notes&gt;&lt;![CDATA[ version 1.0: Add a note and main function .&lt;br&gt; &lt;em&gt;Only support md doc&lt;/em&gt; ]]&gt; &lt;/change-notes&gt; &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/build_number_ranges.html for description --&gt; &lt;idea-version since-build=&quot;173.0&quot;/&gt; &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/plugin_compatibility.html on how to target different products --&gt; &lt;!-- uncomment to enable plugin in all products &lt;depends&gt;com.intellij.modules.lang&lt;/depends&gt; --&gt; &lt;extensions defaultExtensionNs=&quot;com.intellij&quot;&gt; &lt;!-- Add your extensions here --&gt; &lt;/extensions&gt; &lt;actions&gt; &lt;!-- Add your actions here --&gt; &lt;/actions&gt;&lt;/idea-plugin&gt; 创建一个Action创建一个Action，用于右键弹出一个子菜单 12345678910111213141516171819202122232425262728293031323334353637package cn.hongliang.fastNote.action;import cn.hongliang.fastNote.data.DataCenter;import cn.hongliang.fastNote.dialog.AddNoteDialog;import com.intellij.openapi.actionSystem.AnAction;import com.intellij.openapi.actionSystem.AnActionEvent;import com.intellij.openapi.actionSystem.CommonDataKeys;import com.intellij.openapi.editor.Editor;import com.intellij.openapi.editor.SelectionModel;/** * @author Hongliang Zhu * @create 2020-07-22 18:39 */public class PopUpAction extends AnAction &#123; @Override public void actionPerformed(AnActionEvent e) &#123; // 首先获取编辑器对象 Editor editor = e.getRequiredData(CommonDataKeys.EDITOR); // 获取选择的文本 SelectionModel selectionModel = editor.getSelectionModel(); String selectedText = selectionModel.getSelectedText(); DataCenter.SELECTED_TEXT = selectedText; // 獲取文件的名稱 String fileName = e.getRequiredData(CommonDataKeys.PSI_FILE).getVirtualFile().getName(); DataCenter.FILE_NAME = fileName; AddNoteDialog addNoteDialog = new AddNoteDialog(); addNoteDialog.show();// System.out.println(selectedText); &#125;&#125; 创建添加笔记的对话框创建一个对话框，添加笔记的对话框 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package cn.hongliang.fastNote.dialog;import cn.hongliang.fastNote.data.DataCenter;import cn.hongliang.fastNote.data.NoteData;import com.intellij.openapi.ui.DialogWrapper;import com.intellij.ui.EditorTextField;import org.jetbrains.annotations.Nullable;import javax.swing.*;import java.awt.*;/** * @author Hongliang Zhu * @create 2020-07-22 18:51 */public class AddNoteDialog extends DialogWrapper &#123; private EditorTextField noteTitle; private EditorTextField noteContent; public AddNoteDialog() &#123; super(true); setTitle(&quot;添加笔记注释&quot;); init(); &#125; @Nullable @Override protected JComponent createCenterPanel() &#123; JPanel panel = new JPanel(new BorderLayout()); noteTitle = new EditorTextField(&quot;笔记标题&quot;); noteContent = new EditorTextField(&quot;笔记内容&quot;); // 设置文本框的大小 noteContent.setPreferredSize(new Dimension(200, 100)); panel.add(noteTitle, BorderLayout.NORTH); panel.add(noteContent, BorderLayout.CENTER); return panel; &#125; @Override protected JComponent createSouthPanel() &#123; JPanel panel = new JPanel(); JButton button = new JButton(&quot;添加笔记到列表&quot;); // 按钮事件 button.addActionListener(e -&gt; &#123; String noteTitleText = noteTitle.getText(); String noteContentText = noteContent.getText(); String fileType = DataCenter.FILE_NAME.substring(DataCenter.FILE_NAME.lastIndexOf(&quot;.&quot;) + 1); NoteData noteData = new NoteData(noteTitleText, noteContentText, DataCenter.SELECTED_TEXT, DataCenter.FILE_NAME, fileType); DataCenter.NOTE_LIST.add(noteData); System.out.println(DataCenter.NOTE_LIST); &#125;); panel.add(button); return panel; &#125;&#125; NoteData类存储一条笔记的内容上面用到了一个NoteData类，里面封装了一个笔记所包含的内容，包括标题、选中的代码，内容，文件名以及文件格式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package cn.hongliang.fastNote.data;/** * @author Hongliang Zhu * @create 2020-07-22 19:47 */public class NoteData &#123; private String title; private String mark; private String content; private String fileName; private String fileType; public NoteData(String title, String mark, String content, String fileName, String fileType) &#123; this.title = title; this.mark = mark; this.content = content; this.fileName = fileName; this.fileType = fileType; &#125; public String getTitle() &#123; return title; &#125; public void setTitle(String title) &#123; this.title = title; &#125; public String getMark() &#123; return mark; &#125; public void setMark(String mark) &#123; this.mark = mark; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public String getFileName() &#123; return fileName; &#125; public void setFileName(String fileName) &#123; this.fileName = fileName; &#125; public String getFileType() &#123; return fileType; &#125; public void setFileType(String fileType) &#123; this.fileType = fileType; &#125; @Override public String toString() &#123; return &quot;NoteData&#123;&quot; + &quot;title=&#x27;&quot; + title + &#x27;\\&#x27;&#x27; + &quot;, mark=&#x27;&quot; + mark + &#x27;\\&#x27;&#x27; + &quot;, content=&#x27;&quot; + content + &#x27;\\&#x27;&#x27; + &quot;, fileName=&#x27;&quot; + fileName + &#x27;\\&#x27;&#x27; + &quot;, fileType=&#x27;&quot; + fileType + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 还有一个数据中心DataCenter。用于存取笔记。 1234567891011121314package cn.hongliang.fastNote.data;import java.util.LinkedList;import java.util.List;/** * @author Hongliang Zhu * @create 2020-07-22 20:13 */public class DataCenter &#123; public static String SELECTED_TEXT; // 选中的代码块 public static String FILE_NAME; // 文件名 public static List&lt;NoteData&gt; NOTE_LIST = new LinkedList&lt;&gt;(); // 笔记内容&#125; 一切准备就绪，运行一下。 工具窗口创建一个GUI Form 然后添加一些组件，拖动布局。用于我们展示笔记列表。 更改上述控件的filedName后，在目录下会生成一个java文件。这些空间就对象。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package cn.hongliang.fastNote.window;import javax.swing.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;/** * @author Hongliang Zhu * @create 2020-07-22 22:52 */public class NoteListWindow &#123; /** * main panel */ private JPanel contentPanel; /** * 文档标题 */ private JTextField tfTopic; /** * 三个按钮 */ private JButton btnCreate; private JButton btnClear; private JButton btnClose; /** * 笔记列表 */ private JScrollPane tabContent; public NoteListWindow() &#123; btnCreate.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; &#125; &#125;); btnClear.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; &#125; &#125;); btnClose.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; &#125; &#125;); &#125; public JPanel getContentPanel() &#123; return contentPanel; &#125;&#125; 先把这个工具视窗显示出来，创建一个NoteListWindowFactory实现ToolWindowFactory接口 123456789101112131415161718192021222324252627282930package cn.hongliang.fastNote.window;import b.e.P;import com.intellij.openapi.project.Project;import com.intellij.openapi.wm.ToolWindow;import com.intellij.openapi.wm.ToolWindowFactory;import com.intellij.ui.content.Content;import com.intellij.ui.content.ContentFactory;import org.jetbrains.annotations.NotNull;/** * *工厂类 工具视窗 * @author Hongliang Zhu * @create 2020-07-22 23:09 */public class NoteListWindowFactory implements ToolWindowFactory &#123; @Override public void createToolWindowContent(@NotNull Project project, @NotNull ToolWindow toolWindow) &#123; // 创建NoteListWindow对象 NoteListWindow noteListWindow = new NoteListWindow(project, toolWindow); // 获取内容工厂的实例 ContentFactory contentFactory = ContentFactory.SERVICE.getInstance(); // 获取用于ToolWindow显示的内容 Content content = contentFactory.createContent(noteListWindow.getContentPanel(), &quot;&quot;, false); //给toolWindow设置内容 toolWindow.getContentManager().addContent(content); &#125;&#125; 然后需要在plugin.xml中的扩展extension加上我们创建的toolWindow。 1234&lt;extensions defaultExtensionNs=&quot;com.intellij&quot;&gt; &lt;!-- Add your extensions here --&gt; &lt;toolWindow id=&quot;noteListWindow&quot; factoryClass=&quot;cn.hongliang.fastNote.window.NoteListWindowFactory&quot; anchor=&quot;right&quot;&gt;&lt;/toolWindow&gt;&lt;/extensions&gt; 可以看到显示成功，但是缺少表格内容啊，下面完善这部分的功能 设置表头：在DataCenter里面添加 1234567891011public class DataCenter &#123; public static String SELECTED_TEXT; public static String FILE_NAME; public static List&lt;NoteData&gt; NOTE_LIST = new LinkedList&lt;&gt;(); public static String[] TABLE_HEADER = &#123;&quot;标题&quot;, &quot;备注&quot;, &quot;文件名&quot;, &quot;代码段&quot;&#125;; public static DefaultTableModel TABLEMODEL = new DefaultTableModel(null, TABLE_HEADER); &#125; 在初始化的工具视窗的时候将表格插入 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package cn.hongliang.fastNote.window;import cn.hongliang.fastNote.data.DataCenter;import com.intellij.openapi.project.Project;import com.intellij.openapi.wm.ToolWindow;import org.jetbrains.annotations.NotNull;import javax.swing.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;/** * @author Hongliang Zhu * @create 2020-07-22 22:52 */public class NoteListWindow &#123; /** * main panel */ private JPanel contentPanel; /** * 文档标题 */ private JTextField tfTopic; /** * 三个按钮 */ private JButton btnCreate; private JButton btnClear; private JButton btnClose; private JTable tabContent; //*******************设置表头************************* private void init()&#123; tabContent.setModel(DataCenter.TABLEMODEL); tabContent.setEnabled(true); &#125; // ****************************************** public NoteListWindow(Project project, ToolWindow toolWindow) &#123; init(); // 初始化表格 btnCreate.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; &#125; &#125;); btnClear.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; &#125; &#125;); btnClose.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; toolWindow.hide(null); &#125; &#125;); &#125; public JPanel getContentPanel() &#123; return contentPanel; &#125;&#125; 然后解决创建笔记部分，添加到表格中, 在AddNoteDialog.java类中。 12345678910111213141516@Override protected JComponent createSouthPanel() &#123; JPanel panel = new JPanel(); JButton button = new JButton(&quot;添加笔记到列表&quot;); button.addActionListener(e -&gt; &#123; String noteTitleText = noteTitle.getText(); String noteContentText = noteContent.getText(); String fileType = DataCenter.FILE_NAME.substring(DataCenter.FILE_NAME.lastIndexOf(&quot;.&quot;) + 1); NoteData noteData = new NoteData(noteTitleText, noteContentText, DataCenter.SELECTED_TEXT, DataCenter.FILE_NAME, fileType); DataCenter.NOTE_LIST.add(noteData); DataCenter.TABLEMODEL.addRow(DataConvert.convert(noteData)); &#125;); panel.add(button); return panel; &#125; 生成文档需求： 点击生成文档，如果用户没有输入文档的标题，将弹出一个对话框提示用户输入。然后选择保存的路径。生成md文档以特定的格式保存。 这里使用的是一个freeMarker的模板引擎。 下面是使用fastNote生成的MD笔记 [TOC] 定义一个接口Processor 此接口用于处理生成文档的功能，传入笔记的数据即可，可以通过其实现类具体生成各种文档 Processor.java 123public interface Processor &#123; void process(SourceNoteData sourceNoteData) throws IOException, TemplateException, Exception;&#125; 抽象类继承Processor 这是一个模板，所有文档的生成都需要经过里面的process方法。首先是获取数据，然后获取模板，最后指定写入的位置。 AbstractFreeMarkerProcessor.java 123456789101112131415161718192021222324252627282930313233/** * 使用FreeMarker生成 * @author Hongliang Zhu * @create 2020-07-23 8:54 * * 模板设计模式 */public abstract class AbstractFreeMarkerProcessor implements Processor&#123; /** * 处理流程 * @return */ protected abstract Object getModel(SourceNoteData sourceNoteData); // 获取数据 protected abstract Template getTemplate() throws IOException, Exception; // 获取模板 protected abstract Writer getWriter(SourceNoteData sourceNoteData) throws FileNotFoundException, Exception; // 写到哪里 /** * 子类实现上面三个方法，按照这个方法的流程进行（模板） * @param sourceNoteData * @throws Exception */ @Override public final void process(SourceNoteData sourceNoteData) throws Exception &#123; Template template = getTemplate(); Object model = getModel(sourceNoteData); Writer writer = getWriter(sourceNoteData); template.process(model, writer); &#125;&#125; MDFreeMarkerProcessor生成MD格式 这是抽象类的子类，具体生成md文档 MDFreeMarkerProcessor.java 1234567891011121314151617181920212223242526272829303132333435public class MDFreeMarkerProcessor extends AbstractFreeMarkerProcessor &#123; @Override protected Object getModel(SourceNoteData sourceNoteData) &#123; Map model = new HashMap(); model.put(&quot;topic&quot;, sourceNoteData.getTopic()); model.put(&quot;noteList&quot;, sourceNoteData.getNoteList()); return model; &#125; @Override protected Template getTemplate() throws Exception &#123; // 创建模板配置 Configuration configuration = new Configuration(Configuration.VERSION_2_3_30); // 加载模板字符串 String templateContent = UrlUtil.loadText(MDFreeMarkerProcessor.class.getResource(&quot;/template/md.ftl&quot;)); // 创建字符串模板导入器 StringTemplateLoader stringTemplateLoader = new StringTemplateLoader(); // 导入字符串模板 stringTemplateLoader.putTemplate(&quot;MDtemplate&quot;, templateContent); configuration.setTemplateLoader(stringTemplateLoader); // 获取模板 return configuration.getTemplate(&quot;MDtemplate&quot;); &#125; @Override protected Writer getWriter(SourceNoteData sourceNoteData) throws Exception &#123; String fileName = sourceNoteData.getFileName(); BufferedWriter bufferedWriter = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(new File(fileName)), &quot;utf-8&quot;)); return bufferedWriter; &#125;&#125; 文档模板 这是生成文档的模板，使用freemarker模板引擎填充数据 md.ftl 123456789## $&#123;topic&#125;[TOC]&lt;#list noteList as note&gt;### $&#123;note.title&#125;- $&#123;note.mark&#125;- $&#123;note.fileName&#125;​```$&#123;note.fileType&#125;$&#123;note.content&#125;&lt;/#list&gt; 至此，大功告成，希望这个插件可以大大提高我们的学习效率。","path":"2020/07/23/idea插件之笔记插件/","date":"07-23","excerpt":"","tags":[{"name":"plugin","slug":"plugin","permalink":"https://castile.github.io/tags/plugin/"},{"name":"插件","slug":"插件","permalink":"https://castile.github.io/tags/%E6%8F%92%E4%BB%B6/"}]},{"title":"idea插件开发之鸡血大师","text":"需求分析在idea启动，也就是要开启我们这一天苦逼充满激情的编码工作时候，展示一碗鸡汤，给你打鸡血，当点击再干一碗的时候可以切换下一条内容。 问题： 怎么抓住idea启动这个时间点 如何显示一个对话框 怎么添加按钮的点击事件 鸡血从何处来？？ 代码编写Components组件 组件类型 描述 接口 plugin.xml加载配置元素 ApplicationComponent 在IDEA启动的时候初始化。整个idea只有一个实例。 ApplicationComponent ProjectComponent Idea会为每个project实例创建对应级别的component。 ProjectComponent ModuleComponent Idea会为每一个已经加载的project中的每一个模块创建module级别的component。 ModuleComponent 先写一个类实现ApplicationComponent接口，整个idea只有一个实例。 12345678910111213141516171819202122package com.hongliang.cheer;import com.intellij.openapi.components.ApplicationComponent;/** * @author Hongliang Zhu * @create 2020-07-22 11:09 */public class MyApplicatioComponent implements ApplicationComponent &#123; @Override public void initComponent() &#123; System.out.println(&quot;InitComponnet&quot;); CheerUpDialog cheerUpDialog = new CheerUpDialog(); cheerUpDialog.show(); &#125; @Override public void disposeComponent() &#123; &#125;&#125; 然后写一个对话框出来，和JavaSwing编写的差不多 123456789101112131415161718192021222324252627282930313233343536373839404142package com.hongliang.cheer;import com.intellij.openapi.ui.DialogWrapper;import org.jetbrains.annotations.Nullable;import javax.swing.*;/** * @author Hongliang Zhu * @create 2020-07-22 11:13 */public class CheerUpDialog extends DialogWrapper &#123; private JLabel label; protected CheerUpDialog() &#123; super(true); setTitle(&quot;每天一碗毒鸡汤&quot;); init(); &#125; @Nullable @Override protected JComponent createCenterPanel() &#123; JPanel panel = new JPanel(); String contentAsString = ContentUtils.getContentAsString(); label = new JLabel(contentAsString); panel.add(label); return panel; &#125; @Override protected JComponent createSouthPanel() &#123; JPanel panel = new JPanel(); JButton btn = new JButton(); btn.setText(&quot;再干一碗&quot;); btn.addActionListener(e -&gt; &#123; String contentAsString = ContentUtils.getContentAsString(); label.setText(contentAsString); &#125;); panel.add(btn); return panel; &#125;&#125; 其中用到了一个ContentUtils工具类，用来获取得到的鸡汤 123456789101112131415161718192021222324252627282930313233343536373839package com.hongliang.cheer;import org.springframework.http.HttpStatus;import org.springframework.http.ResponseEntity;import org.springframework.web.client.RestClientException;import org.springframework.web.client.RestTemplate;import java.util.List;import java.util.Map;/** * @author Hongliang Zhu * @create 2020-07-22 13:06 */public class ContentUtils &#123; public static String getContentAsString()&#123; try &#123; String content = null; RestTemplate restTemplate = new RestTemplate(); ResponseEntity&lt;Map&gt; entity = restTemplate.getForEntity(&quot;https://api.nextrt.com/V1/Dutang&quot;, Map.class); HttpStatus statusCode = entity.getStatusCode(); if(statusCode.is2xxSuccessful())&#123; Map body = entity.getBody(); List data = (List) body.get(&quot;data&quot;); Map map = (Map) data.get(0); content = (String) map.get(&quot;content&quot;); return content; &#125; &#125; catch (RestClientException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 当然还需要去xml中配置 12345&lt;application-components&gt; &lt;component&gt; &lt;implementation-class&gt;com.hongliang.cheer.MyApplicatioComponent&lt;/implementation-class&gt; &lt;/component&gt; &lt;/application-components&gt; 安装运行","path":"2020/07/22/idea插件开发之鸡血大师/","date":"07-22","excerpt":"","tags":[{"name":"plugin","slug":"plugin","permalink":"https://castile.github.io/tags/plugin/"},{"name":"插件","slug":"插件","permalink":"https://castile.github.io/tags/%E6%8F%92%E4%BB%B6/"}]},{"title":"idea插件开发首次体验","text":"创建工程 创建的是一个插件工程，使用idea的SDK。 创建之后在目录下有一个文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;idea-plugin&gt;&lt;!-- 插件的id--&gt; &lt;id&gt;com.hongliang.first.id&lt;/id&gt;&lt;!-- 插件名称--&gt; &lt;name&gt;first Plugin&lt;/name&gt;&lt;!-- 版本号--&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;!-- 作者和提供方的信息--&gt; &lt;vendor email=&quot;zhl396740445@163.com&quot; url=&quot;http://hongliangzhu.cn&quot;&gt;Castile&lt;/vendor&gt;&lt;!-- 插件的描述--&gt; &lt;description&gt;&lt;![CDATA[ Enter short description for your ss plugin here.&lt;br&gt; &lt;em&gt;most HTML tags may be used&lt;/em&gt; ]]&gt;&lt;/description&gt;&lt;!-- 变更日志 --&gt; &lt;change-notes&gt;&lt;![CDATA[ Add change notes here.&lt;br&gt; &lt;em&gt;most HTML tags may be used&lt;/em&gt; ]]&gt; &lt;/change-notes&gt;&lt;!-- 插件支持的版本号--&gt; &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/build_number_ranges.html for description --&gt; &lt;idea-version since-build=&quot;173.0&quot;/&gt; &lt;!-- please see http://www.jetbrains.org/intellij/sdk/docs/basics/getting_started/plugin_compatibility.html on how to target different products --&gt; &lt;!-- uncomment to enable plugin in all products &lt;depends&gt;com.intellij.modules.lang&lt;/depends&gt; --&gt;&lt;!-- 相关的其他依赖--&gt; &lt;depends&gt;com.intellij.modules.lang&lt;/depends&gt;&lt;!-- 扩展内容--&gt; &lt;extensions defaultExtensionNs=&quot;com.intellij&quot;&gt; &lt;!-- Add your extensions here --&gt; &lt;/extensions&gt;&lt;!-- 菜单动作 --&gt; &lt;actions&gt; &lt;action id=&quot;firstPluginActionID&quot; class=&quot;com.hongliang.first.firstPluginAction&quot; text=&quot;测试&quot; description=&quot;测试描述&quot;&gt; &lt;add-to-group group-id=&quot;ToolsMenu&quot; anchor=&quot;first&quot;/&gt; &lt;keyboard-shortcut keymap=&quot;$default&quot; first-keystroke=&quot;ctrl I&quot;/&gt; &lt;/action&gt; &lt;/actions&gt;&lt;/idea-plugin&gt; 创建一个Action 我们创建一个在ToolsMenu的插件，在tools工具栏里面有一个“测试”的插件，点击之后在idea的右下角显示一个通知。 12345678910111213141516171819202122232425package com.hongliang.first;import com.intellij.notification.Notification;import com.intellij.notification.NotificationDisplayType;import com.intellij.notification.NotificationGroup;import com.intellij.notification.Notifications;import com.intellij.openapi.actionSystem.AnAction;import com.intellij.openapi.actionSystem.AnActionEvent;import com.intellij.openapi.ui.MessageType;/** * @author Hongliang Zhu * @create 2020-07-22 8:40 */public class firstPluginAction extends AnAction &#123; @Override public void actionPerformed(AnActionEvent e) &#123; // TODO: insert action logic here NotificationGroup notificationGroup = new NotificationGroup(&quot;我的第一个插件&quot;, NotificationDisplayType.BALLOON, true); Notification notification = notificationGroup.createNotification(&quot;点击测试&quot;, MessageType.INFO); Notifications.Bus.notify(notification); &#125;&#125; 点击运行，与普通的java类运行一样，但是插件运行的话会打开一个新的idea 可以看见在Tools工具栏里面有一个“测试”的插件，点击之后可以看到在右下角出现了一个通知 到此，一个简单的插件入门程序就完成了，接下来我们对插件进行打包。 打包发布 可以发现在项目目录下生成了一个jar包。 安装Files-&gt;plugin 然后重启idea 大功告成。但是，这只是初步涉猎，任重而道远。","path":"2020/07/22/idea插件开发/","date":"07-22","excerpt":"","tags":[{"name":"plugin","slug":"plugin","permalink":"https://castile.github.io/tags/plugin/"},{"name":"插件","slug":"插件","permalink":"https://castile.github.io/tags/%E6%8F%92%E4%BB%B6/"}]},{"title":"SpringBoot自动配置原理","text":"SpringBoot配置SpringBoot是Spring系列的延伸，Spring需要自己去配置各种属性。SpringBoot 的出现就是为了简化程序员的配置工作，所谓“约定大于配置”。 所以，自动配置是SpringBoot的核心。 SpringBoot能配置什么呢？ 查看文档common-application-properties . 创建SpringBoot项目项目目录结构： 自动配置原理首先我们知道SpringBoot有一个启动类，其实也是一个配置类，其有main方法，可以直接运行。使用@SpingBootApplication注解表示它是一个配置类。 @SpringBootApplication: Spring Boot应用标注在某个类上说明这个类是SpringBoot的主配置类，SpringBoot就应该运行这个类的main方法来启动SpringBoot应用； 1234567891011package com.hongliang.springboot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Springboot02AutoconfigApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(Springboot02AutoconfigApplication.class, args); &#125;&#125; 我们点击进去这个注解： 12345678@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration //开启自动配置功能@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; 我们可以看到有一个@EnableAutoConfiguration的注解，这个注解的作用就是开启自动配置功能。 发现里面有一个@Import(AutoConfigurationImportSelector.class)， 作用是给容器中带入一些组件，那么具体导入那些组件呢？我们继续查看AutoConfigurationImportSelector这个类。 12345678910111213141516171819202122232425262728293031323334public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123; private static final AutoConfigurationEntry EMPTY_ENTRY = new AutoConfigurationEntry(); @Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125; protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; &#125; selectImports方法选择组件进行导入，里面调用了getAutoConfigurationEntry方法来获取哪些配置，返回的是一个AutoConfigurationEntry类， 之后转成一个字符串数组 123456789101112131415161718192021222324protected static class AutoConfigurationEntry &#123; private final List&lt;String&gt; configurations; // 配置 private final Set&lt;String&gt; exclusions; // 排除配置 private AutoConfigurationEntry() &#123; // 初始化空集合 this.configurations = Collections.emptyList(); this.exclusions = Collections.emptySet(); &#125; AutoConfigurationEntry(Collection&lt;String&gt; configurations, Collection&lt;String&gt; exclusions) &#123; this.configurations = new ArrayList&lt;&gt;(configurations); this.exclusions = new HashSet&lt;&gt;(exclusions); &#125; public List&lt;String&gt; getConfigurations() &#123; return this.configurations; &#125; public Set&lt;String&gt; getExclusions() &#123; return this.exclusions; &#125;&#125; 我们再来看一下getAutoConfigurationEntry这个方法的具体操作：在AutoConfigurationImportSelector这个类里面 123456789101112131415protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125; 这个方法首先调用了getCandidateConfigurations获取候选配置，返回的是一个List集合，然后封装成AutoConfigurationEntry返回。 所以我们还需要看一下getCandidateConfigurations干了啥： 1234567891011protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; protected Class&lt;?&gt; getSpringFactoriesLoaderFactoryClass() &#123; return EnableAutoConfiguration.class; &#125; 首先调用SpringFactoriesLoader.loadFactoryNames（Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader）里面传入需要返回哪个自动配置类，这里调用了getSpringFactoriesLoaderFactoryClass， 返回的是EnableAutoConfiguration.class。 再看看SpringFactoriesLoader.loadFactoryName() 的具体细节：这个方法在SpringFactoriesLoader这个类里面， 123456789101112131415161718192021222324252627282930313233343536public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryClassName, factoryName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(&quot;Unable to load factories from location [&quot; + FACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex); &#125; &#125; 主要看这一段 首先会去加载一个配置文件，这个配置文件在类的开头声明了一个静态的常量： 1public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;; 看一下这个配置文件是什么内容： 看到这里应该对大致的流程有一个清晰的了解了，SpringFactoriesLoader.loadFactoryNames()扫描所有jar包类路径下 META-INF/spring.factories. 把扫描到的这些文件的内容包装成properties对象从properties中获取到EnableAutoConfiguration.class类（类名）对应的值，然后把他们添加在容器中，这些值就是上图中黄色字体部分的XXXAutoConfiguration。每一个自动配置类XXXAutoConfiguration 都是都是容器中的一个组件，都加入到容器中；用他们来做自动配置； 然后每一个自动配置类进行自动配置功能。 HttpEncodingAutoConfiguration以HttpEncodingAutoConfiguration为例解释自动配置原理 123456789101112131415161718192021222324252627282930313233@Configuration//表示这是一个配置类，以前编写的配置文件一样，也可以给容器中添加组件@EnableConfigurationProperties(HttpProperties.class)// 启动指定类的ConfigurationProperties功能； 将配置文件中对应的值和HttpEncodingProperties绑定起来；并把HttpEncordingProperties加入到ioc容器里面。// Spring底层@Conditional注解, 根据不同的条件。如果满足指定的条件，将整个配置类里面的配置生效； 判断当前应用是否是web应用，如果是，则配置类生效。@ConditionalOnWebApplication(type = ConditionalOnWebApplication.Type.SERVLET)// 判断当前项目有没有这个CharacterEncodingFilter类。（这是SpringMVC中进行乱码解决的类）@ConditionalOnClass(CharacterEncodingFilter.class)// 判断配置文件中是否存在摸个配置spring.http.encoding.enabled；如果不存在，判断也是成立的（matchIfMissing = true）@ConditionalOnProperty(prefix = &quot;spring.http.encoding&quot;, value = &quot;enabled&quot;, matchIfMissing = true)public class HttpEncodingAutoConfiguration &#123; // 已经和SpringBoot的配置文件映射了 private final HttpProperties.Encoding properties; // 只有一个有参构造函数的情况下， 参数的值就会从容器中拿。 public HttpEncodingAutoConfiguration(HttpProperties properties) &#123; this.properties = properties.getEncoding(); &#125; @Bean // 给容器中添加一个组件，这个组件的某些值需要从properties中去获取 @ConditionalOnMissingBean // //判断容器没有这个组件，没有这个才需要配置 public CharacterEncodingFilter characterEncodingFilter() &#123; CharacterEncodingFilter filter = new OrderedCharacterEncodingFilter(); filter.setEncoding(this.properties.getCharset().name()); filter.setForceRequestEncoding(this.properties.shouldForce(Type.REQUEST)); filter.setForceResponseEncoding(this.properties.shouldForce(Type.RESPONSE)); return filter; &#125; &#125; 可以看上面详细的注释理解每个注解的功能。 根据当前不同的条件判断，决定这个配置类是否生效？ 一但这个配置类生效；这个配置类就会给容器中添加各种组件；这些组件的属性是从对应的properties类中获取的，这些类里面的每一个属性又是和配置文件绑定的； 我们看一下properties类中内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122@ConfigurationProperties(prefix = &quot;spring.http&quot;)public class HttpProperties &#123; /** * Whether logging of (potentially sensitive) request details at DEBUG and TRACE level * is allowed. */ private boolean logRequestDetails; /** * HTTP encoding properties. */ private final Encoding encoding = new Encoding(); public boolean isLogRequestDetails() &#123; return this.logRequestDetails; &#125; public void setLogRequestDetails(boolean logRequestDetails) &#123; this.logRequestDetails = logRequestDetails; &#125; public Encoding getEncoding() &#123; return this.encoding; &#125; /** * Configuration properties for http encoding. */ public static class Encoding &#123; public static final Charset DEFAULT_CHARSET = StandardCharsets.UTF_8; /** * Charset of HTTP requests and responses. Added to the &quot;Content-Type&quot; header if * not set explicitly. */ private Charset charset = DEFAULT_CHARSET; /** * Whether to force the encoding to the configured charset on HTTP requests and * responses. */ private Boolean force; /** * Whether to force the encoding to the configured charset on HTTP requests. * Defaults to true when &quot;force&quot; has not been specified. */ private Boolean forceRequest; /** * Whether to force the encoding to the configured charset on HTTP responses. */ private Boolean forceResponse; /** * Locale in which to encode mapping. */ private Map&lt;Locale, Charset&gt; mapping; public Charset getCharset() &#123; return this.charset; &#125; public void setCharset(Charset charset) &#123; this.charset = charset; &#125; public boolean isForce() &#123; return Boolean.TRUE.equals(this.force); &#125; public void setForce(boolean force) &#123; this.force = force; &#125; public boolean isForceRequest() &#123; return Boolean.TRUE.equals(this.forceRequest); &#125; public void setForceRequest(boolean forceRequest) &#123; this.forceRequest = forceRequest; &#125; public boolean isForceResponse() &#123; return Boolean.TRUE.equals(this.forceResponse); &#125; public void setForceResponse(boolean forceResponse) &#123; this.forceResponse = forceResponse; &#125; public Map&lt;Locale, Charset&gt; getMapping() &#123; return this.mapping; &#125; public void setMapping(Map&lt;Locale, Charset&gt; mapping) &#123; this.mapping = mapping; &#125; public boolean shouldForce(Type type) &#123; Boolean force = (type != Type.REQUEST) ? this.forceResponse : this.forceRequest; if (force == null) &#123; force = this.force; &#125; if (force == null) &#123; force = (type == Type.REQUEST); &#125; return force; &#125; public enum Type &#123; REQUEST, RESPONSE &#125; &#125;&#125; 里面包括了可以配置的所有属性。 所有在配置文件中能配置的属性都是封装在xxxxProperties类中，配置文件能配置什么就可以参照某个功能对应的这个属性类。 @Conditional派生注解作用：必须是@Conditional指定的条件成立，才给容器中添加组件，配置配里面的所有内容才生效； @Conditional扩展注解 作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean 容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate 容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty 系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication 当前是web环境 @ConditionalOnNotWebApplication 当前不是web环境 @ConditionalOnJndi JNDI存在指定项 自动配置类必须在一定的条件下才能生效； 我们怎么知道哪些自动配置类生效； **==我们可以通过启用 debug=true属性；来让控制台打印自动配置报告==**，这样我们就可以很方便的知道哪些自动配置类生效； 总结​ 1）、SpringBoot启动会加载大量的自动配置类 ​ 2）、我们看我们需要的功能有没有SpringBoot默认写好的自动配置类； ​ 3）、我们再来看这个自动配置类中到底配置了哪些组件；（只要我们要用的组件有，我们就不需要再来配置了） ​ 4）、给容器中自动配置类添加组件的时候，会从properties类中获取某些属性。我们就可以在配置文件中指定这些属性的值； xxxxAutoConfigurartion：自动配置类； 给容器中添加组件 xxxxProperties:封装配置文件中相关属性； spring Boot启动的时候会通过@EnableAutoConfiguration注解找到META-INF/spring.factories配置文件中的所有自动配置类，并对其进行加载，而这些自动配置类都是以AutoConfiguration结尾来命名的，它实际上就是一个JavaConfig形式的Spring容器配置类，它能通过以Properties结尾命名的类中取得在全局配置文件中配置的属性如：server.port，而XxxxProperties类是通过@ConfigurationProperties注解与全局配置文件中对应的属性进行绑定的。","path":"2020/07/14/SpringBoot自动配置原理/","date":"07-14","excerpt":"","tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://castile.github.io/tags/SpringBoot/"}]},{"title":"Spring AOP面向切面编程？你懂了吗？","text":"AOP概述什么是aop(Aspect Oriented Programming ), 翻译过来就是“面向切面编程”， 你们估计听过OOP 面向对象编程，对这个已经很熟悉了，那么他们俩有什么关系呢？？？答案是： 没有啥关系。。。，非要说有啥关系，或许能说AOP是OOP的一种延伸吧，AOP可以做到OOP办不到的事情。 那，OOP不能做到的事情是什么呢？ 在面向对象编程思想中，我们认为世间万物一切皆对象，面向对象编程的思想就是我要做一件事情，我不需要自己去做，交给专业的人去做，让各个对象组合去帮我们做成一件事情。 在OOP中，我们是纵向编程， 纵向继承机制 。 AOP中是横向抽取机制。 我们一般写程序都是从上到下，需要什么就要创建什么，如果有多个相同的业务，每一业务都要做一些公共的验证或者处理，那么在每个业务中都需要写同样的代码，这样代码很多重复，繁琐。而AOP的作用就是将一些公共的代码或者功能抽取出来，生成一个切面（后面会说到），然后哪个地方需要验证，处理就在程序执行的过程中动态地去插入这些代码。这些代码可能在程序的执行前，方法执行后等等。。。，这就是AOP里面的连接点和通知了。这些稍后再讲。 AOP编程操作的主要对象是切面(aspect)，而切面用于模块化横切关注点（公共功能）。 简单来说aop的作用就是在程序运行期间，不修改源码对已有方法进行增强。 AOP 优点减少重复代码 提高开发效率 维护方便 AOP术语横切关注点从每个方法中抽取出来的同一类非核心业务。就是公共的功能代码 切面（Aspect）封装横切关注点信息的类，每个关注点体现为一个通知方法。 也就是把这些公共的代码或者功能抽取成为一个类，这个类，就是我们所说的切面。 通知（Advice）在切面中的横切关注点用在目标对象中的方法就是通知，通知包含：用在啥地方（执行前？执行后？），使用的是啥功能（验证？ 打印日志？）。 说白了就是切面必须要完成的各个具体工作。 通知的类型：前置通知,后置通知,异常通知,最终通知,环绕通知。 目标（Target）目标对象，很简单，就是你要增强的对象。 代理对象向目标对象应用通知之后创建的代理对象。一个类被 AOP 织入增强后，就产生一个结果代理类。 AOP中会通过代理的方式，对目标对象生成一个代理对象，代理对象中会加入需要增强功能，通过代理对象来间接的方式目标对象，起到增强目标对象的效果。 连接点（Join Point）横切关注点在程序代码中的具体体现，对应程序执行的某个特定位置。例如：类某个方法调用前、调用后、方法捕获到异常后等。 也就是说，所谓连接点是指那些被拦截到的点。在 spring 中,这些点指的是方法,因为 spring 只支持方法类型的连接点。 在应用程序中可以使用横纵两个坐标来定位一个具体的连接点： 切入点(pointcut)所谓切入点是指我们要对哪些 Joinpoint 进行拦截的定义。 切入点就是定位连接点的方式。每个类的方法中都包含多个连接点，所以连接点是类中客观存在的事物。如果把连接点看作数据库中的记录，那么切入点就是查询条件——AOP可以通过切入点定位到特定的连接点。切点通过org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件。 也就是说是用来指定需要将通知使用到哪些地方，比如需要用在哪些类的哪些方法上，切入点就是做这个配置的。 是要通过切入点表达式来 配置和指定。 AOP的实现AOP是通过动态代理的方式实现的。 动态代理的特点： 字节码随用随创建，随用随加载。 它与静态代理的区别也在于此。因为静态代理是字节码一上来就创建好，并完成加载。 装饰者模式就是静态代理的一种体现。 动态代理技术有两种，一种是基于接口的动态代理，另一种是基于子类的动态代理。 基于接口的动态代理由JDK 官方的 Proxy 类实现。 要求：被代理类最少实现一个接口。 在很久以前，演员和剧组都是直接见面联系的。没有中间人环节。 而随着时间的推移，产生了一个新兴职业：经纪人（中间人），这个时候剧组再想找演员就需要通过经纪 人来找了。下面我们就用代码演示出来。 1234567891011121314151617181920212223242526272829303132/** * 一个经纪公司的要求: * 能做基本的表演和危险的表演 */ public interface IActor &#123; /** * 基本演出 * @param money */ public void basicAct(float money); /** * 危险演出 * @param money */ public void dangerAct(float money); &#125;/** * 一个演员 */ //实现了接口，就表示具有接口中的方法实现。即：符合经纪公司的要求 public class Actor implements IActor&#123; public void basicAct(float money)&#123; System.out.println(&quot;拿到钱，开始基本的表演：&quot;+money); &#125; public void dangerAct(float money)&#123; System.out.println(&quot;拿到钱，开始危险的表演：&quot;+money); &#125; &#125; 使用代理来间接获取对象。要求被代理类至少实现一个接口。 创建的方式： Proxy.newProxyInstance(三个参数) 参数的含义： ClassLoader：和被代理对象使用相同的类加载器。 Interfaces：和被代理对象具有相同的行为。实现相同的接口。 InvocationHandler：如何代理。 123456789101112131415161718192021IActor proxyActor = (IActor) Proxy.newProxyInstance( actor.getClass().getClassLoader(), actor.getClass().getInterfaces(), new InvocationHandler()&#123; /** * 执行被代理对象的任何方法，都会经过该方法。 * 此方法有拦截的功能。 * * 参数： * proxy：代理对象的引用。不一定每次都用得到 * method：当前执行的方法对象 * args：执行方法所需的参数 * 返回值： * 当前执行方法的返回值 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable&#123; ... &#125; &#125;); 基于子类的动态代理使用CGLib的Enhancer类创建代理对象。 要求被代理的对象不能是最终类。 方法参数：Enhancer.create(Class, Callback) Class: 被代理对象的字节码 Callback：如何代理 12345678910111213141516171819Actor cglibActor = (Actor) Enhancer.create(actor.getClass(), new MethodInterceptor()&#123; /** * 执行被代理对象的任何方法，都会经过该方法。在此方法内部就可以对被代理对象的任何 方法进行增强。 * 参数： * 前三个和基于接口的动态代理是一样的。 * MethodProxy：当前执行方法的代理对象。 * 返回值： * 当前执行方法的返回值 */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; 。。。代理 &#125; &#125;); 关于代理的选择在 spring 中，框架会根据目标类是否实现了接口来决定采用哪种动态代理的方式。 AspectJAspectJ：Java社区里最完整最流行的AOP框架。 在Spring2.0以上版本中，可以使用基于AspectJ注解或基于XML配置的AOP。 在Spring中启用AspectJ注解支持1. 导包导入对应的jar包 2. 配置在bean.xml中配置aop. 当Spring IOC容器侦测到bean配置文件中的aop:aspectj-autoproxy元素时，会自动为 与AspectJ切面匹配的bean创建代理。 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;context:component-scan base-package=&quot;com.hongliang.aop&quot;&gt;&lt;/context:component-scan&gt;&lt;!-- 开启aspectJ的自动代理功能 --&gt; &lt;aop:aspectj-autoproxy /&gt;&lt;/beans&gt; 3. 编码举例： math的加减乘除，然后在执行过程中记录执行的方法，方法的参数，使用一个Logger类来作为切面。 MathI.java 接口 1234567891011121314151617181920package com.hongliang.aop;/** * @author Hongliang Zhu * @create 2020-06-21 14:30 */public interface MathI &#123; int add(int i, int j); int sub(int i, int j); int mul(int i, int j); int div(int i, int j);&#125; MathImpl.java 实现类 12345678910111213141516171819202122232425262728293031package com.hongliang.aop;import org.springframework.stereotype.Component;/** * @author Hongliang Zhu * @create 2020-06-21 14:31 */@Componentpublic class MathImpl implements MathI &#123; public int add(int i, int j) &#123; int result = i + j; return result; &#125; public int sub(int i, int j) &#123; int result = i - j; return result; &#125; public int mul(int i, int j) &#123; int result = i * j; return result; &#125; public int div(int i, int j) &#123; int result = i / j; return result; &#125;&#125; 4. 用AspectJ注解声明切面 要在Spring中声明AspectJ切面，只需要在IOC容器中将切面声明为bean实例。 当在Spring IOC容器中初始化AspectJ切面之后，Spring IOC容器就会为那些与 AspectJ切面相匹配的bean创建代理。 在AspectJ注解中，切面只是一个带有@Aspect注解的Java类，它往往要包含很多通知。 通知是标注有某种注解的简单的Java方法。 AspectJ支持5种类型的通知注解： ① @Before：前置通知，在方法执行之前执行 ② @After：后置通知，在方法执行之后执行 ③ @AfterRunning：返回通知，在方法返回结果之后执行 ④ @AfterThrowing：异常通知，在方法抛出异常之后执行 ⑥ @Around：环绕通知，围绕着方法执行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.hongliang.aop;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.stereotype.Component;import java.util.Arrays;/** * * // 切面： 用来存储横切关注点 * @author Hongliang Zhu * @create 2020-06-21 14:32 */@Component@Aspect //标注当前类是切面public class MyLoggerAspect &#123; /** * * 将方法指定为前置通知 value 为切入点表达式 */ @Before(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot;) public void beforeMethod(JoinPoint joinPoint)&#123; Object[] args = joinPoint.getArgs(); String methodName = joinPoint.getSignature().getName(); System.out.println(&quot;Method:&quot; + methodName+&quot;\\t arguments: &quot;+ Arrays.toString(args)); System.out.println(&quot;方法执行之前&quot;); &#125; /** * finally */ @After(&quot;execution(* com.hongliang.aop.*.*(..))&quot;) public void afterMethod()&#123; System.out.println(&quot;后置通知&quot;); &#125; @AfterReturning(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot; , returning = &quot;result&quot;) public void returning(JoinPoint joinPoint, Object result)&#123; System.out.println(joinPoint.getSignature().getName()+&quot;\\t&quot;+result); System.out.println(&quot;返回通知&quot;); &#125; @AfterThrowing(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot; , throwing = &quot;ex&quot;) public void afterThrowing(Exception ex)&#123; System.out.println(&quot;出了异常啊:&quot; +ex.getMessage()); &#125; @Around(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot;) public void aroundMethod()&#123; &#125;&#125; AOP细节1. 切入点表达式作用： 通过表达式的方式定位一个或多个具体的连接点。 切入点表达式的写法: 关键字：execution(表达式) 表达式： 访问修饰符 返回值 包名.包名.包名…类名.方法名(参数列表) 标准的表达式写法： public void com.hongliangng.service.impl.AccountServiceImpl.saveAccount() 访问修饰符可以省略 void com.hongliangng.service.impl.AccountServiceImpl.saveAccount() 返回值可以使用通配符，表示任意返回值 ​ * com.hongliangng.service.impl.AccountServiceImpl.saveAccount() 包名可以使用通配符，表示任意包。但是有几级包，就需要写几个 ​ *.* *.*.*.*.AccountServiceImpl.saveAccount()) 包名可以使用..表示当前包及其子包 * *..AccountServiceImpl.saveAccount() 类名和方法名都可以使用*来实现通配 ​ * *..*.*() 全通配写法： * *..*.*(..) 实际开发中切入点表达式的通常写法： 切到业务层实现类下的所有方法 * com.hongliangng.service.impl.*.*(..) 2. 当前连接点细节切入点表达式通常都会是从宏观上定位一组方法，和具体某个通知的注解结合起来就能够确定对应的连接点。那么就一个具体的连接点而言，我们可能会关心这个连接点的一些具体信息，例如：当前连接点所在方法的方法名、当前传入的参数值等等。这些信息都封装在JoinPoint接口的实例对象中。 JoinPoint 3. 通知 在具体的连接点上要执行的操作。 一个切面可以包括一个或者多个通知。 通知所使用的注解的值往往是切入点表达式。 前置通知前置通知：在方法执行之前执行的通知 使用@Before注解 后置通知后置通知：后置通知是在连接点完成之后执行的，即连接点返回结果或者抛出异常的时候 使用@After注解 无论连接点是正常返回还是抛出异常，后置通知都会执行 （finally） 返回通知 返回通知：无论连接点是正常返回还是抛出异常，后置通知都会执行。如果只想在连接点返回的时候记录日志，应使用返回通知代替后置通知。 使用@AfterReturning注解，在返回通知中访问连接点的返回值 ​ ①在返回通知中，只要将returning属性添加到@AfterReturning注解中，就可以访问连接点的返回值。该属性的值即为用来传入返回值的参数名称。 12345@AfterReturning(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot; , returning = &quot;result&quot;) public void returning(JoinPoint joinPoint, Object result)&#123; System.out.println(joinPoint.getSignature().getName()+&quot;\\t&quot;+result); System.out.println(&quot;返回通知&quot;); &#125; ​ ②必须在通知方法的签名中添加一个同名参数。在运行时Spring AOP会通过这个参数传递返回值 ​ ③原始的切点表达式需要出现在pointcut属性中 异常通知 异常通知：只在连接点抛出异常时才执行异常通知 将throwing属性添加到@AfterThrowing注解中，也可以访问连接点抛出的异常。Throwable是所有错误和异常类的顶级父类，所以在异常通知方法可以捕获到任何错误和异常。 如果只对某种特殊的异常类型感兴趣，可以将参数声明为其他异常的参数类型。然后通知就只在抛出这个类型及其子类的异常时才被执行 1234@AfterThrowing(value = &quot;execution(* com.hongliang.aop.*.*(..))&quot; , throwing = &quot;ex&quot;) public void afterThrowing(Exception ex)&#123; System.out.println(&quot;出了异常啊:&quot; +ex.getMessage()); &#125; 环绕通知 环绕通知是所有通知类型中功能最为强大的，能够全面地控制连接点，甚至可以控制是否执行连接点。 对于环绕通知来说，连接点的参数类型必须是ProceedingJoinPoint。它是 JoinPoint的子接口，允许控制何时执行，是否执行连接点。 在环绕通知中需要明确调用ProceedingJoinPoint的proceed()方法来执行被代理的方法。如果忘记这样做就会导致通知被执行了，但目标方法没有被执行。 注意：环绕通知的方法需要返回目标方法执行之后的结果，即调用 joinPoint.proceed();的返回值，否则会出现空指针异常。 123456789101112131415161718192021@Around(&quot;pt1()&quot;) // 切入点表达式引用 public Object aroundPrintLog(ProceedingJoinPoint proceedingJoinPoint)&#123; Object rtValue = null; try &#123; Object[] args = proceedingJoinPoint.getArgs(); System.out.println(&quot;前置： Logger类中的printLog方法开始记录日志了...&quot;); rtValue = proceedingJoinPoint.proceed(args); // System.out.println(&quot;后置： Logger类中的printLog方法开始记录日志了...&quot;); return rtValue; &#125; catch (Throwable throwable) &#123; throwable.printStackTrace(); System.out.println(&quot;异常： Logger类中的printLog方法开始记录日志了...&quot;); throw new RuntimeException(throwable); &#125;finally &#123; System.out.println(&quot;最终：Logger类中的printLog方法开始记录日志了...&quot;); &#125;// return rtValue; &#125; 4. 重用切入点定义 在编写AspectJ切面时，可以直接在通知注解中书写切入点表达式。但同一个切点表达式可能会在多个通知中重复出现。 在AspectJ切面中，可以通过@Pointcut注解将一个切入点声明成简单的方法。切入点的方法体通常是空的，因为将切入点定义与应用程序逻辑混在一起是不合理的。 切入点方法的访问控制符同时也控制着这个切入点的可见性。如果切入点要在多个切面中共用，最好将它们集中在一个公共的类中。在这种情况下，它们必须被声明为public。在引入这个切入点时，必须将类名也包括在内。如果类没有与这个切面放在同一个包中，还必须包含包名。 其他通知可以通过方法名称引入该切入点 1234@Pointcut(&quot;execution(* com.hongliang.service.impl.*.*(..))&quot;) public void pt1()&#123; &#125; 5. 指定切面的优先级 在同一个连接点上应用不止一个切面时，除非明确指定，否则它们的优先级是不确定的。 切面的优先级可以通过实现Ordered接口或利用@Order注解指定。 实现Ordered接口，getOrder()方法的返回值越小，优先级越高。 若使用@Order注解，序号出现在注解中。 123456789101112@Component@Aspect //标注当前类是切面@Order(0)public class MyLoggerAspect &#123;&#125;@Component@Aspect //标注当前类是切面@Order(1)public class MyLoggerAspect01 &#123; &#125; 基于XML的AOP配置 把通知Bean也交给spring来管理 使用aop:config标签表名开始AOP配置 使用aop:aspect标签表明配置切面 id属性：是给切面提供一个唯一标识 ref属性：是指定通知类bean的Id。 在aop:aspect标签的内部使用对应的标签来配置通知的类型 第一步：把通知类用 bean 标签配置起来通知类也就是切面 如果有注解的话，需要引入扫描包的标签 1&lt;context:component-scan base-package=&quot;com.hongliang.aop&quot;&gt;&lt;/context:component-scan&gt; 第二步：使用 aop:config 声明 aop 配置第三步：使用 aop:aspect 配置切面 第四步：使用 aop:pointcut 配置切入点表达式第五步：使用 aop:xxx 配置对应的通知类型12345&lt;aop:config&gt; &lt;aop:aspect ref=&quot;myLoggerAspect&quot;&gt; &lt;aop:before method=&quot;beforeMethod&quot; pointcut=&quot;execution(* com.hongliang.aop.*.*(..))&quot;&gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt; 12&lt;!-- 配置切入点表达式 : 所有切面可用 （但是必须放在配置切面之前 ）--&gt; &lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.hongliang.service.impl.*.*(..))&quot;&gt;&lt;/aop:pointcut&gt; 不使用 XML的配置方式在spring的配置类中引入 以下注解 12345@Configuration @ComponentScan(basePackages=&quot;com.hongliang&quot;) @EnableAspectJAutoProxy public class SpringConfiguration &#123; &#125;","path":"2020/06/26/spring02-aop/","date":"06-26","excerpt":"","tags":[{"name":"spring","slug":"spring","permalink":"https://castile.github.io/tags/spring/"},{"name":"aop","slug":"aop","permalink":"https://castile.github.io/tags/aop/"}]},{"title":"mybatis代理Dao的执行过程-源码分析","text":"代理Dao执行过程123456789// 读取配置文件，生成字节输入流 in = Resources.getResourceAsStream(&quot;SQLMapConfig.xml&quot;); //名字不区分大小写 // 构建SQLSessionfactory builder = new SqlSessionFactoryBuilder(); factory = builder.build(in); // 构建SQLSession sqlSession = factory.openSession(); dao = sqlSession.getMapper(UserDao.class); // 获取 代理Dao 首先进入DefaultSqlSession类里面的getMapper()f方法 1234@Override public &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return configuration.&lt;T&gt;getMapper(type, this); &#125; 进入到configuration类中去调用getMapper方法 123public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession);&#125; mapperRegistry.getMapper(type, sqlSession) 通过一个代理工厂返回一个代理对象。 来看看这个代理工厂内部做了啥子: MapperProxyFactory.java 123456789101112// 动态代理 @SuppressWarnings(&quot;unchecked&quot;) protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy); // mapperProxy代理的对象 &#125; public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;T&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); // 调用了上面的newInstance方法 &#125; MapperProxy实现了InvocationHandler接口。重写invoke方法，内部调用被代理类的对应方法。 最后执行这个方法的execute方法，看看这个方法： 可以看到会调用对应的CRUD操作。 调用Dao的findByName方法， 返回一个User对象，所以执行SelectOne方法 里面是调用SelectList方法，然后返回结果的第一个 完整过程图","path":"2020/06/20/mybatis代理dao/","date":"06-20","excerpt":"","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"}]},{"title":"mybatis缓存","text":"MyBatis缓存像大多数的持久化框架一样，Mybatis 也提供了缓存策略，通过缓存策略来减少数据库的查询次数，从而提 高性能。 Mybatis 中缓存分为一级缓存，二级缓存。 但是在默认的情况下， 只开启一级缓存 。 一级缓存一级缓存是 SqlSession 级别的缓存，只要 SqlSession 没有 flush 或 close，它就存在。 1. 证明一级缓存的存在首先在一个test里面重复两次相同的查询 1234567891011@Test public void test()&#123; System.out.println(&quot;第一次查询&quot;); User castille = dao.findByName(&quot;Castille&quot;); System.out.println(castille); System.out.println(&quot;第二次查询&quot;); User castille1 = dao.findByName(&quot;Castille&quot;); System.out.println(castille1); &#125; 然后执行查询，查看日志输出： 我们可以发现，虽然在上面的代码中我们查询了两次，但最后只执行了一次数据库操作，这就是 Mybatis 提 供给我们的一级缓存在起作用了。因为一级缓存的存在，导致第二次查询 name为castille 的记录时，并没有发出sql语句 从数据库中查询数据，而是从一级缓存中查询。 2. 一级缓存的分析一级缓存是 SqlSession 范围的缓存，当调用 SqlSession 的修改，添加，删除，commit()，close()等方法时，就会清空一级缓存。 第一次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，如果没有，从数据库查 询用户信息。 得到用户信息，将用户信息存储到一级缓存中。 如果 sqlSession 去执行 commit 操作（执行插入、更新、删除），清空 SqlSession 中的一级缓存，这样 做的目的为了让缓存中存储的是最新的信息，避免脏读。 第二次发起查询用户 id 为 1 的用户信息，先去找缓存中是否有 id 为 1 的用户信息，缓存中有，直接从缓存 中获取用户信息。 3. 测试一级缓存的清空使用 sqlSession.clearCache()清空缓存123456789101112 @Test public void test()&#123; System.out.println(&quot;第一次查询&quot;); User castille = dao.findByName(&quot;Castille&quot;); System.out.println(castille);// dao = sqlSession.getMapper(UserDao.class); // 重新获得SQLSession sqlSession.clearCache(); // 清空缓存 System.out.println(&quot;第二次查询&quot;); User castille1 = dao.findByName(&quot;Castille&quot;); System.out.println(castille1); 可以看到上述结果，执行了两次的sql语句的查询。因为一级缓存被清空了，所以第二次查询需要在数据库中查询。 做了更新操作123456789101112131415@Test public void testCache()&#123; System.out.println(&quot;第一次查询&quot;); User ke = dao.findByName(&quot;keke&quot;); System.out.println(ke); // 更新操作 dao.updateStatus(ke); System.out.println(&quot;第二次查询&quot;); User keke = dao.findByName(&quot;keke&quot;); System.out.println(keke); &#125; 不同的sqlSession12345678910111213141516 @Test public void testCache1()&#123; System.out.println(&quot;第一次查询&quot;); User ke = dao.findByName(&quot;keke&quot;); System.out.println(ke);// 再次获得sqlSession sqlSession = factory.openSession(); dao = sqlSession.getMapper(UserDao.class); System.out.println(&quot;第二次查询&quot;); User keke = dao.findByName(&quot;keke&quot;); System.out.println(keke); &#125; 二级缓存1. 二级缓存结构图 二级缓存是 mapper 映射级别的缓存，多个 SqlSession 去操作同一个 Mapper 映射的 sql 语句，多个 SqlSession 可以共用二级缓存，二级缓存是跨 SqlSession 的。或者说 二级缓存存在于 SqlSessionFactory 生命周期中。 首先开启 mybatis 的二级缓存。 sqlSession1去查询用户信息，查询到用户信息会将查询数据存储到二级缓存中。 如果 SqlSession3 去执行相同 mapper 映射下 sql，执行 commit 提交，将会清空该 mapper 映射下的二级缓存区域的数据。 sqlSession2 去查询与 sqlSession1 相同的用户信息，首先会去缓存中找是否存在数据，如果存在直接从 缓存中取出数据。 2. 二级缓存的开启与关闭 第一步：在 SqlMapConfig.xml 文件开启二级缓存 因为 cacheEnabled 的取值默认就为 true，所以这一步可以省略不配置。为 true 代表开启二级缓存；为 false 代表不开启二级缓存。 12&lt;settings&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt; 第二步：配置相关的 Mapper 映射文件 123456&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;cn.hongliang.dao.UserDao&quot;&gt; &lt;!-- 开启二级缓存的支持 --&gt; &lt;cache&gt;&lt;/cache&gt;&lt;/mapper 标签表示当前这个 mapper 映射将使用二级缓存，区分的标准就看 mapper 的 namespace 值。 第三步：配置 statement 上面的 useCache 属性 123&lt;select id=&quot;findByName&quot; resultType=&quot;cn.hongliang.beans.User&quot; useCache=&quot;true&quot;&gt; select * from tab_user where username = #&#123;username&#125; &lt;/select&gt; 将 UserDao.xml 映射文件中的标签中设置 useCache=”true”代表当前这个 statement 要使用 二级缓存，如果不使用二级缓存可以设置为 false 注意：针对每次查询都需要最新的数据 sql，要设置成 useCache=false，禁用二级缓存。 3. 二级缓存测试1234567891011121314151617181920 @Test public void testCachelevel2()&#123; System.out.println(&quot;第一次查询&quot;); User ke = dao.findByName(&quot;keke&quot;); System.out.println(ke); sqlSession.close(); // 一级缓存关闭// 再次获得sqlSession SqlSession sqlSession2 = factory.openSession(); dao = sqlSession2.getMapper(UserDao.class); System.out.println(&quot;第二次查询&quot;); User keke = dao.findByName(&quot;keke&quot;); System.out.println(keke); &#125; 经过上面的测试，我们发现执行了两次查询，并且在执行第一次查询后，我们关闭了一级缓存，再去执行第二 次查询时，我们发现并没有对数据库发出 sql 语句，所以此时的数据就只能是来自于我们所说的二级缓存。 123&lt;!-- 开启二级缓存--&gt; &lt;cache readOnly=&quot;true&quot;&gt;&lt;/cac 注意上面的readonly。readOnly 为只读属性， 默认为 false false: 可读写， 在创建对象时， 会通过反序列化得到缓存对象的拷贝。 因此在速度上会相对慢一点， 但重在安全。 true: 只读， 只读的缓存会给所有调用者返回缓存对象的相同实例。 因此性能很好， 但如果修改了对象， 有可能会导致程序出问题。 所以使用readOnly=true的话，返回的是同一个实例，如果为false的话，则会反序列一个新的实例，则是不同的对象。 注意：当我们在使用二级缓存时，所缓存的类一定要实现 java.io.Serializable 接口，这种就可以使用序列化 方式来保存对象。 4. 注意事项 由于在更新时会刷新缓存， 因此需要注意使用场合：查询频率很高， 更新频率很低时使用， 即经常使用 select, 相对较少使用delete, insert, update。 缓存是以 namespace 为单位的，不同 namespace 下的操作互不影响。但刷新缓存是刷新整个 namespace 的缓存， 也就是你 update 了一个， 则整个缓存都刷新了。 最好在 「只有单表操作」 的表的 namespace 使用缓存， 而且对该表的操作都在这个 namespace 中。 否则可能会出现数据不一致的情况。 参考 https://blog.csdn.net/weixin_37139197/article/details/82908377","path":"2020/06/20/mybatis缓存/","date":"06-20","excerpt":"","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"}]},{"title":"Spring01-对Ioc控制反转的理解","text":"IOC控制反转你如何理解IOC？ 这个问题首先要从程序的“高内聚、低耦合”开始说起。 那么，什么是程序的耦合？ 因为耦合这个概念在各个行业都有相关自己的概念，这里只从软件行业的角度来说说。简单说耦合就是多个程序的模块之间的依赖关系。好的程序应该有较低的耦合，耦合是无法消除的，完全没有任何耦合的程序是没有意义的。而高耦合就是说“牵一发而动全身”，这显然不是我们想看到的。各个模块应该要尽量独立，当某个模块出问题了就直接修改这一个模块就可以了，不要让程序大改。。。代价人工消耗。。 程序的耦合耦合有很多种， 它们之间的耦合度由高到低排列如下 ： 内容耦合。当一个模块直接修改或操作另一个模块的数据时，或一个模块不通过正常入口而转入另 一个模块时，这样的耦合被称为内容耦合。内容耦合是最高程度的耦合，应该避免使用之。 公共耦合。两个或两个以上的模块共同引用一个全局数据项，这种耦合被称为公共耦合。在具有大 量公共耦合的结构中，确定究竟是哪个模块给全局变量赋了一个特定的值是十分困难的。 外部耦合 。一组模块都访问同一全局简单变量而不是同一全局数据结构，而且不是通过参数表传 递该全局变量的信息，则称之为外部耦合。 控制耦合 。一个模块通过接口向另一个模块传递一个控制信号，接受信号的模块根据信号值而进 行适当的动作，这种耦合被称为控制耦合。 标记耦合 。若一个模块 A 通过接口向两个模块 B 和 C 传递一个公共参数，那么称模块 B 和 C 之间 存在一个标记耦合。 数据耦合。模块之间通过参数来传递数据，那么被称为数据耦合。数据耦合是最低的一种耦合形 式，系统中一般都存在这种类型的耦合，因为为了完成一些有意义的功能，往往需要将某些模块的输出数据作为另一些模块的输入数据。 非直接耦合 。两个模块之间没有直接关系，它们之间的联系完全是通过主模块的控制和调用来实 现的。 重点关注加粗部分的耦合，即内容耦合、公共耦合、控制耦合、数据耦合。 耦合是影响软件复杂程度和设计质量的一个重要因素，在设计上我们应采用以下原则：如果模块间必须 存在耦合，就尽量使用数据耦合，少用控制耦合，限制公共耦合的范围，尽量避免使用内容耦合。 高内聚那么，还有个“高内聚”，所谓高内聚是从模块的内部结构角度来观察的，就是说内聚表示了一个模块的内部各个元素彼此结合的紧密程度。内聚是从 功能角度来度量模块内的联系，一个好的内聚模块应当恰好做一件事。它描述的是模块内的功能联系。 高内聚简单来说就是自己尽量自己完成自己的事情，不要麻烦别人。自己得事情内部解决，对外只提供公共的接口来访问功能。 程序讲究的是低耦合，高内聚。就是同一个模块内的各个元素之间要高度紧密，但是各个模块之 间的相互依存度却不要那么紧密。 内聚和耦合是密切相关的，同其他模块存在高耦合的模块意味着低内聚，而高内聚的模块意味着该模块同其他模块之间是低耦合。在进行软件设计时，应力争做到高内聚，低耦合。 高耦合举例下面来举几个例子来说明一下。 在传统的基于MVC三层架构开发模式下，我们会写一个DAO接口，这是一个数据访问对象，用来作为持久层接口，还会写一个service来处理业务逻辑，表示业务层，但是业务层需要持久层接口来实现各种业务逻辑。就像下面这样： 1234public class UserServiceImpl implements UserService &#123; private UserDao dao = new UserDaoImpl();&#125; 业务层调用持久层，并且此时业务层在依赖持久层的接口和实现类。如果此时没有持久层实现类，编译将不能通过。这种编译期依赖关系，应该在我们开发中杜绝。我们需要优化代码解决。 这就是一个典型的耦合。 再来一个例子吧： JDBC都学过，使用JDBC来操作数据库的时候，我们首先需要加载驱动，然后创建连接，执行sql。。。， 注册驱动的时候我们可以通过DriverManager 的 register 方法来注册驱动，也可以使用Class.forName（Class…） 通过反射去加载驱动类完成注册。但是我们一般推荐使用Class.forName（）的方式，为啥呢？？？ 12345678910public static void main(String[] args) throws Exception &#123; //1.注册驱动 //riverManager.registerDriver(new com.mysql.jdbc.Driver()); Class.forName(&quot;com.mysql.jdbc.Driver&quot;); //2.获取连接 //3.获取预处理 sql 语句对象 //4.获取结果集 //5.遍历结果集 &#125; 我们知道JDBC 是 sun 公司提供一套用于数据库操作的接口。java 程序员只需要面向这套接口编程即可。不同的数据库厂商，需要针对这套接口，提供不同实现。不同的实现的集合，即为不同数据库的驱动。 java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口，每个厂商实现的方式不一样，在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类 (java.sql.DriverManager) 去调用这些 Driver 实现。 Oracle 的驱动：oracle.jdbc.driver.OracleDriver mySql 的驱动： com.mysql.jdbc.Driver 如果使用DriverManager.registerDriver方式会依赖某种具体的数据库(mysql)，需要在编译的时候就要导入对应的包，这样程序的耦合行较高。如果这时候更换了数据库品牌（比如 Oracle），需要 修改源码来重新数据库驱动。这显然不是我们想要的。 而采用Class.forName（）的方式是在运行时动态加载的。看如下源码 1234567891011121314public class Driver extends NonRegisteringDriver implements java.sql.Driver &#123; // ~ Static fields/initializers // --------------------------------------------- // // Register ourselves with the DriverManager // static &#123; try &#123; java.sql.DriverManager.registerDriver(new Driver()); &#125; catch (SQLException E) &#123; throw new RuntimeException(&quot;Can&#x27;t register driver!&quot;); &#125; &#125; 静态代码块的方式来注册驱动，也就是说通过class.forName的方式是通过直接加载字节码的。根据类加载原理，一个class加载进内存，连接，初始化，会先执行类的静态代码块和对静态变量的初始化操作，所以在加载的时候就可以注册数据库驱动。 好了，刚刚分析了数据库驱动注册使用DriverManager.registerDriver的方式会导致程序的耦合性提高，我们使用Class.forName()的方式来对程序解耦，他是通过反射的方式来注册驱动的。 1Class.forName(&quot;com.mysql.jdbc.Driver&quot;);//此处只是一个字符串 此时的好处是，我们的类中不再依赖具体的驱动类，此时就算删除 mysql 的驱动 jar 包，依然可以编译（运 行就不要想了，没有驱动不可能运行成功的）。 同时，也产生了一个新的问题，mysql 驱动的全限定类名字符串是在 java 类中写死的，一旦要改还是要修改源码。 解决这个问题也很简单，使用配置文件配置。 工厂模式解耦在实际开发中我们可以把三层的对象都使用配置文件配置起来，当启动服务器应用加载的时候，让一个类中的 方法通过读取配置文件，把这些对象创建出来并存起来。在接下来的使用的时候，直接拿过来用就好了。 那么，这个读取配置文件，创建和获取三层对象的类就是工厂。 Ioc控制反转Inversion Of Control通过以上的分析，我们大概对解耦有了一个基本的思路，就是我们的对象要存起来，放在一个地方，然后谁要用就去取。 那么问题来了，对象要存在哪里呢？我们学过集合框架，使用List还是用Map来存储呢？其实这是根据我们是否有查找的需求，有查找需求，肯定使用Map效率更高一些。 所以，Spring的解决思路就是在应用加载的时候，使用Map来存放MVC三层使用到的对象，这个Map就是Spring的容器。 刚刚我们说了工厂模式可以解耦，啥是工厂模式呢？ 我么以前创建对象的方式就是通过new关键字来创建的，是主动的获取。所谓工厂就是负责给我们从容器中获取指定对象的类。这时候我们获取对象的方式发生了改变。 不再是new了。交给工厂去帮我们获得。有工厂为我们查找或者创建对象。是被动的。 这种被动接收的方式获取对象的思想就是控制反转，它是 spring 框架的核心之一。 到这里了，我们需要明确，Ioc解决的问题就是降低程序的耦合。也就是削减我们代码中的依赖关系。 控制反转，就是java对象不再有我们自己来控制管理了，全部交给Spring的容器来管理！ 所以称为“控制反转”， 精髓： 反转！！！","path":"2020/06/20/spring01/","date":"06-20","excerpt":"","tags":[{"name":"spring","slug":"spring","permalink":"https://castile.github.io/tags/spring/"}]},{"title":"Java并发之Java内存模型","text":"Java内存模型在讲解synchronized和volatie之前，我们首先需要了解Java内存模型(JMM) 《Java虚拟机规范》中曾试图定义一种“Java内存模型”（Java Memory Model，JMM）来屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 主内存和工作内存Java内存模型的主要目的是定义程序中各种变量的访问规则，即关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。 每条线程还有自己的工作内存（Working Memory），线程的工作内存中保存了被该线程使用的变量的主内存副本，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的数据。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图所示。 这是因为处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。线程的工作线程一般就是用高速缓存或者寄存器来实现的。 加入高速缓存带来了一个新的问题：缓存一致性。如果多个缓存共享同一块主内存区域，那么多个缓存的数据可能会不一致，需要一些协议来解决这个问题。 内存之间的交互操作 read：把一个变量的值从主内存传输到工作内存中 load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中 use：把工作内存中一个变量的值传递给执行引擎 assign：把一个从执行引擎接收到的值赋给工作内存的变量 store：把工作内存的一个变量的值传送到主内存中 write：在 store 之后执行，把 store 得到的值放入主内存的变量中 lock：作用于主内存的变量，它把一个变量标识为一条线程独占的状态 unlock 它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 比较繁琐，目前简化了。将Java内存模型的操作简化为read、write、lock和unlock四种，但这只是语言描述上的等价化简，Java内存模型的基础设计并未改变。 内存模型的三大特性 原子性 可见性 有序性 Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这三个特征来建立的。 1.原子性（Atomicity）Java内存模型要求lock、unlock、read、load、assign、use、store、write这八种操作都具有原子性，但是对于64位的数据类型（long和double），在模型中特别定义了一条宽松的规定：允许虚拟机将没有被volatile修饰的64位数据的读写操作划分为两次32位的操作来进行，即允许虚拟机实现自行选择是否要保证64位数据类型的load、store、read和write这四个操作的原子性，这就是所谓的“long和double的非原子性协定”（Non-Atomic Treatment of doubleand long Variables）。 如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既不是原值，也不是其他线程修改值的代表了“半个变量”的数值。不过这种读取到“半个变量”的情况是非常罕见的，经过实际测试[插图]，在目前主流平台下商用的64位Java虚拟机中并不会出现非原子性访问行为，但是对于32位的Java虚拟机，譬如比较常用的32位x86平台下的HotSpot虚拟机，对long类型的数据确实存在非原子性访问的风险。 可以大致认为基本数据类型的访问、读写都是具备原子性的。原子性保证可以用原子操作如 AtomicInteger 和AtomicDoouble等…, 除了使用原子类之外，也可以使用 synchronized 互斥锁来保证操作的原子性。它对应的内存间交互操作为：lock 和 unlock，在虚拟机实现上对应的字节码指令为 monitorenter 和 monitorexit。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.atomic.AtomicInteger;/** * @author Hongliang Zhu * @create 2020-06-19 9:40 */public class Atomic &#123; public static void main(String[] args) throws InterruptedException &#123;// AtomicAdd atomicAdd = new AtomicAdd(); AddNotSafe addNotSafe = new AddNotSafe(); final int threadNums = 1000; CountDownLatch latch = new CountDownLatch(threadNums); ExecutorService service = Executors.newCachedThreadPool(); for(int i = 0; i &lt; threadNums; i++)&#123; service.execute(()-&gt;&#123;// atomicAdd.add(); addNotSafe.add(); latch.countDown(); &#125;); &#125; latch.await(); service.shutdown(); System.out.println(addNotSafe.get()); &#125;&#125;class AtomicAdd&#123; // 每次执行结果都是1000 private AtomicInteger atomicInteger = new AtomicInteger(); public void add()&#123; atomicInteger.incrementAndGet(); &#125; public int get()&#123; return atomicInteger.get(); &#125;&#125;class AddNotSafe&#123; // 每次得出的结果都不一样 976/954 ，比1000小 private int cnt = 0; public void add()&#123; this.cnt+=1; &#125; public int get()&#123; return this.cnt; &#125;&#125; 2.可见性（Visibility）可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。 Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的。在下文的volatile讲解会了解到，**volatile可以保证变量的可见性，但是volatile 并不能保证操作的原子性。** 主要有三种实现可见性的方式： volatile synchronized，对一个变量执行 unlock 操作之前，必须把变量值同步回主内存。 final，被 final 关键字修饰的字段在构造器中一旦初始化完成，并且没有发生 this 逃逸（其它线程通过 this 引用访问到初始化了一半的对象），那么其它线程就能看见 final 字段的值。注意：final可以在class里面先定义，但是必须在构造器中为其初始化！！！ 3.有序性（Ordering）有序性是指：在本线程内观察，所有操作都是有序的。在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序。在 Java 内存模型中，允许编译器和处理器对指令进行重排序，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 volatile 关键字通过添加内存屏障的方式来禁止指令重排，即重排序时不能把后面的指令放到内存屏障之前。 也可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码 先行发生原则“先行发生”（Happens-Before）的原则。这个原则非常重要，它是判断数据是否存在竞争，线程是否安全的非常有用的手段。 先行发生是Java内存模型中定义的两项操作之间的偏序关系，比如说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来，则它们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。 1. 程序次序规则程序次序规则（Program Order Rule）：在一个线程内，按照控制流顺序，书写在前面的操作先行发生于书写在后面的操作。注意，这里说的是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 2.管程锁定规则管程锁定规则（Monitor Lock Rule）：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是“同一个锁”，而“后面”是指时间上的先后。 也就是说先获得的锁需要先解锁才能被后面的线程获得锁。 3.volatile变量规则volatile变量规则（Volatile Variable Rule）：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的“后面”同样是指时间上的先后。先写进去主内存，然后才能从主内存中读取到工作内存中。 4. 线程启动规则线程启动规则（Thread Start Rule）：Thread对象的start()方法先行发生于此线程的每一个动作。 5.线程终止规则线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread::join()方法是否结束、Thread::isAlive()的返回值等手段检测线程是否已经终止执行。 6.线程中断规则线程中断规则（Thread Interruption Rule）：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread::interrupted()方法检测到是否有中断发生。 也就是说，interrupt() 方法只是标记线程的中断，也就是线程设置一个中断标记，然后他可以通过interrupted() 方法来检测是否有中断发生。所以应该是先标记中断在检测中断。 7.对象终结规则对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的finalize()方法的开始。 8.传递性传递性（Transitivity）：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 Java语言无须任何同步手段保障就能成立的先行发生规则有且只有上面这些.. 先行发生原则举例123456789private int value = 0; public int getValue() &#123; return value; &#125; public void setValue(int value) &#123; this.value = value; &#125; 假设存在线程A和B，线程A先（时间上的先后）调用了setValue(1)，然后线程B调用了同一个对象的getValue()，那么线程B收到的返回值是什么？ 我们依次分析一下先行发生原则中的各项规则。由于两个方法分别由线程A和B调用，不在一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然就不会发生lock和unlock操作，所以管程锁定规则不适用；由于value变量没有被volatile关键字修饰，所以volatile变量规则不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起，因此我们可以判定，尽管线程A在操作时间上先于线程B，但是无法确定线程B中getValue()方法的返回结果，换句话说，这里面的操作不是线程安全的。 那怎么修复这个问题呢？我们至少有两种比较简单的方案可以选择：要么把getter/setter方法都定义为synchronized方法，这样就可以套用管程锁定规则；要么把value定义为volatile变量，由于setter方法对value的修改不依赖value的原值，满足volatile关键字使用场景，这样就可以套用volatile变量规则来实现先行发生关系。 总结Java内存模型的目标是为了屏蔽操作系统和硬件之间对内存的不同访问差异，让Java程序在各种平台下都能对数据达到一致的访问效果。也就是说，Java内存模型就是想定义变量的访问规则，关注在虚拟机中把变量值存储到内存和从内存中取出变量值这样的底层细节。 我们知道， 处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。 但是引入高速缓存会带来一个新的问题：缓存一致性。因为Java内存模型中，每一个线程都有一个自己的工作内存，变量都是存储在主存中的，线程只能操作自己工作内存中的变量，不同线程之间的变量传递需要通过主存来完成。线程的工作内存是高速缓存实现的，当多个缓存通过访问主存中的同一块内存区域的话，多个缓存的数据可能会不一致，所以就需要一些规则或者说协议来约定来解决缓存不一致的问题。 关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存，如何从工作内存同步回主内存的细节实现，java内存模型定义了八种操作。 内存中的交互操作包括read、write、load、store、sign、lock、unlock。 Java内存模型是围绕着并发编程中原子性、可见性、有序性这三个特征来建立的。所谓原子性就是说 一个操作是不可中断的，要么全部执行成功要么全部执行失败，原子性可以通过jdk自带的原子类来实现；可见性就是如果有一个线程修改了一个共享变量的值，那么其他的线程也能看到修改的结果， Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的，实现可见性可以通过volatile、synchronized、final关键字来实现。有序性，即程序执行的顺序按照代码的先后顺序执行。因为编译器会对代码进行指令重排序优化 ，带来了有序性问题，重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。可以使用volatile关键字来禁止指令重排序，内部是通过内存屏障来实现。还可以通过 synchronized 来保证有序性，它保证每个时刻只有一个线程执行同步代码，相当于是让线程顺序执行同步代码。 除了可以用 volatile 和 synchronized 来保证有序性，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 有程序次序规则，管程锁定规则，volatile变量规则，线程启动规则，线程终止规则、线程中断规则，对象终结规则，传递性。 Java内存模型就先到这里，后面如果与其他感想的话会补充一下，接下来就要学习synchronized和volatile的原理，也就是Java并发机制的底层实现原理，这个比较重要。 参考 https://cyc2018.github.io/CS-Notes 周志华：《深入理解Java虚拟机》第三版","path":"2020/06/19/synchronized和volatile/","date":"06-19","excerpt":"","tags":[{"name":"juc","slug":"juc","permalink":"https://castile.github.io/tags/juc/"},{"name":"synchronized","slug":"synchronized","permalink":"https://castile.github.io/tags/synchronized/"},{"name":"volatile","slug":"volatile","permalink":"https://castile.github.io/tags/volatile/"},{"name":"并发","slug":"并发","permalink":"https://castile.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"CentOs7安装MySQL5踩坑记录","text":"安装CentOs7 主要就是配置分区 /boot:200m 、 /:10240m(10G) 、 /swap:2048m 然后配置网络 ifconfig –&gt; ssh远程连接。 安装mysql在/opt目录下： 检查是否安装过： rpm -qa|grep -i mysql yum -y remove maria* 删除 mariadb 下载服务器包：wget https://dev.mysql.com/get/Downloads/MySQL-5.5/MySQL-server-5.5.59-1.el7.x86_64.rpm 下载客户端包：wget https://dev.mysql.com/get/Downloads/MySQL-5.5/MySQL-client-5.5.59-1.el7.x86_64.rpm 安装客户端和服务端 rpm -ivh –nodeps MySQL-server-5.5.59-1.el7.x86_64.rpm rpm -ivh –nodeps MySQL-client-5.5.59-1.el7.x86_64.rpm # –nodeps就是安装时不检查依赖关系 启动服务报错 service mysql start 解决： /usr/bin/mysql_install_db –user=mysql 因为需要初始化，因为新安装的mysql服务后，一般需要执行数据库初始化操作 ，从而生成与权限相关的表，执行命令。 service mysql start 启动数据库 设置mysql服务开机自启 ： systemctl enable mysql 验证自启动是否成功 : chkconfig mysql on 查看mysql的安装位置： ps -ef|grep mysql 修改字符集 尝试插入中文字符有乱码； 查看字符集： mysql&gt; show variables like ‘character%’; 修改字符集 修改my.cnf在/usr/share/mysql/ 中找到my.cnf的配置文件，拷贝其中的my-huge.cnf 到 /etc/ 并命名为my.cnf然后修改my.cnf:[client]default-character-set=utf8[mysqld]character_set_server=utf8character_set_client=utf8collation-server=utf8_general_ci[mysql]default-character-set=utf8 但是我的并没有这个文件… 只有上述几个，经查资料发现： 分别用于不同的硬件环境下的配置文件 my-small.cnf （内存 &lt;= 64M）my-medium.cnf （内存 128M）my-large.cnf （内存 512M）my-huge.cnf （内存 1G-2G）my-innodb-heavy-4G.cnf （内存 4GB） 这里我的内存设置为2G，所以将my-huge.cnf复制到/etc/下并改名字为my.cnf 然后打开修改字符集。 然后重新启动mysql。 但是原库的设定不会发生变化，参数修改只会对新建的数据库生效 已生成的库表字符集如何变更修改数据库的字符集： `mysql&gt; alter database mydb character set &#39;utf8&#39;;` 修改数据表的字符集： `mysql&gt; alter table mytbl convert to character set &#39;utf8&#39;;` 但是原有的数据如果是用非’utf8’编码的话，数据本身不会发生改变。 开启mysql的远程登录1 . 设置权限 grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;root&#39;; #权限放大到任何一台机器都可以远程登录 flush privileges; 关闭防火墙：systemctl stop firewall 设置开机禁用防火墙：systemctl disable firewalld.service 最重要一步： 打开文件查找到 [mysqld] ，在其下方添加上一行 skip-grant-tables，然后保存。 这样才可以成功连接。 systemctl和防火墙firewalld命令 见下： 12345678910111213141516171819202122232425262728293031323334 一、防火墙的开启、关闭、禁用命令 （1）设置开机启用防火墙：systemctl enable firewalld.service （2）设置开机禁用防火墙：systemctl disable firewalld.service （3）启动防火墙：systemctl start firewalld （4）关闭防火墙：systemctl stop firewalld （5）检查防火墙状态：systemctl status firewalld 二、使用firewall-cmd配置端口 （1）查看防火墙状态：firewall-cmd --state （2）重新加载配置：firewall-cmd --reload （3）查看开放的端口：firewall-cmd --list-ports （4）开启防火墙端口：firewall-cmd --zone=public --add-port=9200/tcp --permanent 命令含义： –zone #作用域 –add-port=9200/tcp #添加端口，格式为：端口/通讯协议 –permanent #永久生效，没有此参数重启后失效 注意：添加端口后，必须用命令firewall-cmd --reload重新加载一遍才会生效 （5）关闭防火墙端口：firewall-cmd --zone=public --remove-port=9200/tcp --permanent MySQL密码设置和开机启动设置密码： /usr/bin/mysqladmin -u root password 123456 自启动 ：查看 以上是mysql的运行级别 我们运行： ntsysv 可以看到开机自启的服务，mysql服务前面有一个*号，表示开机自启 参考 https://blog.csdn.net/u012402177/article/details/82870433 https://blog.csdn.net/IndexMan/article/details/84641233 https://blog.csdn.net/qq_22227087/article/details/80946894 https://www.cnblogs.com/weibanggang/p/11230528.html https://www.cnblogs.com/nxmxl/p/11766671.html","path":"2020/06/17/centosmysql/","date":"06-17","excerpt":"","tags":[{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"}]},{"title":"GC垃圾回收机制","text":"垃圾收集主要是针对堆和方法区进行。程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后就会消失，因此不需要对这三个区域进行垃圾回收。 概述 在次数上频繁收集发生在young区，在次数上较少收集发生在old区。在元空间/永久代基本不动。 JVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。因此GC按照回收的区域又分了两种类型，一种是普通GC（minor GC），一种是全局GC（major GC or Full GC） Minor GC和Full GC的区别： 普通GC（minor GC）：只针对新生代区域的GC，指发生在新生代的垃圾收集动作，因为大多数Java对象存活率都不高，所以Minor GC非常频繁，一般回收速度也比较快。 全局GC（major GC or Full GC）：指发生在老年代的垃圾收集动作，出现了Major GC，经常会伴随至少一次的Minor GC（但并不是绝对的）。Major GC的速度一般要比Minor GC慢上10倍以上 ，因为收集的区域较大。 判断对象是否存活在垃圾回收器对堆内存回收前，需要判断对象是否存活。 引用计数算法: 给每个对象添加一个引用计数器,每当对象被引用,，对象的引用计数器就加1,当引用失效时，引用计数器就减1。 直到引用计数器为0,就代表对象不再被引用。 可达性算法: 通过GC ROOT的对象节点往下搜索，节点走过的路径被称为引用链。 如果一个对象不处于任何引用链，那么就可以判断此对象是不可达的。 引用计数法为对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 在两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。正是因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。而且每次对对象赋值时都需要维护一个引用计数器，且计数器本身也有一定的消耗。 下面的代码来自《深入理解Java虚拟机》 第三版中： 1234567891011121314151617181920212223package com.atguigu.jvm; /**@Description:-verbose:gc*/public class RefCountGC&#123; private byte[] bigSize = new byte[2 * 1024 * 1024];//这个成员属性唯一的作用就是占用一点内存 Object instance = null; public static void main(String[] args) &#123; RefCountGC objectA = new RefCountGC(); RefCountGC objectB = new RefCountGC(); objectA.instance = objectB; objectB.instance = objectA; objectA = null; objectB = null; System.gc(); &#125;&#125; 上面代码中，objectA和objectB引用的对象实例互相持有了对象的引用，因此把objectA和objectB的引用去除后，由于两个对象之间还存在相互的引用，所以就无法回收这两个RefCountGC对象。 可达性分析算法 通过GC ROOT的对象节点往下搜索，节点走过的路径被称为引用链。 如果一个对象不处于任何引用链，那么就可以判断此对象是不可达的。 以 GC Roots 为起始点进行搜索，可达的对象都是存活的，不可达的对象可被回收。 Java 虚拟机使用该算法来判断对象是否可被回收，GC Roots 一般包含以下内容： 虚拟机栈中局部变量表中引用的对象（stack） 本地方法栈中 JNI （ Java Native Interface ）中引用的对象 方法区中类静态属性引用的对象（static） 方法区中的常量引用的对象 （finnal） Java虚拟机内部的引用，如基本数据类型对应的Class对象，一些常驻的异常对象（比如NullPointExcepiton、OutOfMemoryError）等，还有系统类加载器。 所有被同步锁（synchronized关键字）持有的对象。 方法区的回收【见jvm01】因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，所以在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载。 为了避免内存溢出，在大量使用反射和动态代理的场景都需要虚拟机具备类卸载功能。 类的卸载条件很多，需要满足以下三个条件，并且满足了条件也不一定会被卸载： 该类所有的实例都已经被回收，此时堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 四大引用类型无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。 Java 提供了四种强度不同的引用类型。 强引用被强引用关联的对象不会被回收。使用 new 一个新对象的方式来创建强引用。 1Object obj = new Object(); 软引用被软引用关联的对象只有在内存不够的情况下才会被回收。使用 SoftReference 类来创建软引用。 123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联 弱引用被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。使用 WeakReference 类来创建弱引用。 123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null; 虚引用又称为幽灵引用或者幻影引用，一个对象是否有虚引用的存在，不会对其生存时间造成影响，也无法通过虚引用得到一个对象。 为一个对象设置虚引用的唯一目的是能在这个对象被回收时收到一个系统通知。 使用 PhantomReference 来创建虚引用。 123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj, null);obj = null; 垃圾收集算法常见的垃圾回收算法主要有以下4种: 复制算法（copying） 标记-清除算法 标记-整理算法 分代收集算法 复制算法新生代使用的GC是Minor GC，这一个阶段主要使用的是复制算法来进行垃圾回收。 Minor GC会把Eden中的所有活的对象都移到Survivor区域中，如果Survivor区中放不下，那么剩下的活的对象就被移到Old generation中，也即一旦收集后，Eden是就变成空的了。 当对象在 Eden ( 包括一个 Survivor 区域，这里假设是 from 区域 ) 出生后，在经过一次 Minor GC 后，如果对象还存活，并且能够被另外一块 Survivor 区域所容纳( 上面已经假设为 from 区域，这里应为 to 区域，即 to 区域有足够的内存空间来存储 Eden 和 from 区域中存活的对象 )，则使用复制算法将这些仍然还存活的对象复制到另外一块 Survivor 区域 ( 即 to 区域 ) 中，然后清理所使用过的 Eden 以及 Survivor 区域 ( 即 from 区域 )，并且将这些对象的年龄设置为1，以后对象在 Survivor 区每熬过一次 Minor GC，就将对象的年龄 + 1，当对象的年龄达到某个值时 ( 默认是 15 岁，通过-XX:MaxTenuringThreshold 来设定参数)，这些对象就会成为老年代。 -XX:MaxTenuringThreshold — 设置对象在新生代中存活的次数 HotSpot JVM把年轻代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to）。默认比例为8:1:1,一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理)，这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，当它的年龄增加到一定程度时，就会被移动到年老代中。因为年轻代中的对象基本都是朝生夕死的(90%以上)，所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块（from 、 to。 伊甸+from的copy到to中），每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。 所以复制算法总结起来就是： 将堆内存分为2块大小相等的内存空间， 每次只使用其中的一块内存，另一块则空闲。 当其中一块内存使用完后， 就将仍然存活的对象复制到另一块空闲内存空间，再清理已使用的内存。 HotSpot 虚拟机的 Eden 和 Survivor 大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 就不够用了，此时需要依赖于老年代进行空间分配担保，也就是借用老年代的空间存储放不下的对象。 缺点复制算法它的缺点也是相当明显的。 1、它浪费了一半的内存，这太要命了。 只使用了内存的一半。 2、如果对象的存活率很高，我们可以极端一点，假设是100%存活，那么我们需要将所有对象都复制一遍，并将所有引用地址重置一遍。复制这一工作所花费的时间，在对象存活率达到一定程度时，将会变的不可忽视。 所以从以上描述不难看出，复制算法要想使用，最起码对象的存活率要非常低才行，而且最重要的是，我们必须要克服50%内存的浪费。 标记-清除算法(Mark-Sweep)标记-清除算法分为2个步骤：标记和清除。 首先标记出所有可达(存活)的对象，在标记完成后， 统一回收所有未被标记(不可达)的对象。 在标记阶段，程序会检查每个对象是否为活动对象，如果是活动对象，则程序会在对象头部打上标记。 在清除阶段，会进行对象回收并取消标志位，另外，还会判断回收后的分块与前一个空闲分块是否连续，若连续，会合并这两个分块。回收对象就是把对象作为分块，连接到被称为 “空闲链表” 的单向链表，之后进行分配时只需要遍历这个空闲链表，就可以找到分块。 在分配时，程序会搜索空闲链表寻找空间大于等于新对象大小 size 的块 block。如果它找到的块等于 size，会直接返回这个分块；如果找到的块大于 size，会将块分割成大小为 size 与 (block - size) 的两部分，返回大小为 size 的分块，并把大小为 (block - size) 的块返回给空闲链表。 用通俗的话解释一下标记清除算法，就是当程序运行期间，若可以使用的内存被耗尽的时候，GC线程就会被触发并将程序暂停，随后将要回收的对象标记一遍，最终统一回收这些对象，完成标记清理工作接下来便让应用程序恢复运行。 标记：从引用根节点开始标记遍历所有的GC Roots， 先标记出要回收的对象。 清除：遍历整个堆，把标记的对象清除。 标记-清除算法一般用于老年代。 因为老年代中的对象存活率较高，几乎很少被回收， 所以标记-清除和标记-整理算法GC的时间不会太长， GC的对象相比新生代更少。 缺点 缺点：此算法需要暂停整个应用，会产生内存碎片 。 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 对象在内存中的分布可能是不连续的，分散的，标记-清除后可能造成不连续的内存碎片。 当内存碎片过多后，后续想要分配较大的对象时，无法找到足够大的内存碎片， 可能又需要触发GC。 标记-整理算法(Mark-Compact) 标记-整理算法是对标记-清除算法的一种改进。 标记-整理算法与标记-清除算法的在标记阶段是相同的， 都是首先标记出所有可达(存活)的对象。 但标记之后并不直接清理未被标记(不可达)的对象， 而是使被标记(存活)的对象向内存一端移动，然后清理掉这一端外的内存。 标记-整理算法的优点是: 几乎不会如标记-清除算法那样产生不连续的内存碎片。 但，所谓慢工出细活，标记-整理的效率是比标记-清除要低的。 标记-整理算法和标记-清除算法一样，一般用于老年代。 分代收集现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用：复制算法 老年代使用：标记 - 清除 或者 标记 - 整理 算法 年轻代(Young Gen)年轻代特点是区域相对老年代较小，对像存活率低。 这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因而很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。 老年代(Tenure Gen)老年代的特点是区域较大，对象存活率高。 这种情况，存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记清除或者是标记清除与标记整理的混合实现。 Mark阶段的开销与存活对象的数量成正比，这点上说来，对于老年代，标记清除或者标记整理有一些不符，但可以通过多核/线程利用，对并发、并行的形式提标记效率。 Sweep阶段的开销与所管理区域的大小成正相关，但Sweep“就地处决”的特点，回收的过程没有对象的移动。使其相对其它有对像移动步骤的回收算法，仍然是效率最好的。但是需要解决内存碎片问题。 Compact阶段的开销与存活对象的数据成开比，如上一条所描述，对于大量对象的移动是很大开销的，做为老年代的第一选择并不合适。 基于上面的考虑，老年代一般是由标记清除或者是标记清除与标记整理的混合实现。以hotspot中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高，而对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器做为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial Old执行Full GC以达到对老年代内存的整理。 内存分配与垃圾回收策略 对象优先在eden区域被分配 大对象将直接进入老年代 (大对象是指需要大量连续的内存空间的对象，如长字符串，大数组等。) 长期存活的对象将进入老年代 总结：一次GC的过程首先堆分为新生代，老年代，新生代又分为伊甸区和两个幸存者区（from， to）。 对象优先在eden区被分配，当eden区内存不足时， JVM发起Minor GC。Minor GC的范围包括eden和From Survivor: 首先JVM会根据可达性算法标记出所有存活的对象。 如果存活的对象中，有的对象的年龄已经达到晋升阈值 (阈值是动态计算的，可以通过-XX:MaxTenuringThreshold设置最大年龄阈值)， 那么将已经达到阈值的对象复制到老年代中。 如果To Survivor空间不足以存放剩余存活对象， 则直接将存活的对象提前复制到老年代。 如果老年代也没有足够的空间存放存活的对象， 那么将触发Full GC(GC整个堆，包括新生代和老年代)。 如果To Survivor可以存放存活的对象， 那么将对象复制到To Survivor空间，并清理eden和From Survivor。 此时From Survivor为空， 那么From Survivor就成为了下一次的To Survivor， 此时To Survivor存放着存活的对象，就成为了下一次的From Survivor。 这样From Survivor与To Survivor就是不断交替复制的使用。 老年代的空间比新生代的空间要大， 所以老年代的Major GC要比Minor GC耗时更长。 根据垃圾回收器的不同，老年代的GC算法也不同。 动态年龄阈值JVM并不要求对象年龄一定要达到 MaxTenuringThreshold 才会 晋升到老年代，晋升的年龄阈值是动态计算的。￼￼￼￼￼ 如果在Survivor中，某个相同年龄阶段的所有对象大小的总和 大于Survivor区域的一半，则大于等于这个年龄的所有对象可以直接进入老年代，无需等到MaxTenuringThreshold。 空间分配担保在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 的值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 的值不允许冒险，那么就要进行一次 Full GC。 解释一下“冒险”是冒了什么风险：前面提到过，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在Minor GC后仍然存活的情况——最极端的情况就是内存回收后新生代中所有对象都存活，需要老年代进行分配担保，把Survivor无法容纳的对象直接送入老年代，这与生活中贷款担保类似。老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，但一共有多少对象会在这次回收中活下来在实际完成内存回收之前是无法明确知道的，所以只能取之前每一次回收晋升到老年代对象容量的平均大小作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。 取历史平均值来比较其实仍然是一种赌概率的解决办法，也就是说假如某次Minor GC存活后的对象突增，远远高于历史平均值的话，依然会导致担保失败。如果出现了担保失败，那就只好老老实实地重新发起一次Full GC，这样停顿时间就很长了。虽然担保失败时绕的圈子是最大的，但通常情况下都还是会将-XX：HandlePromotionFailure开关打开，避免Full GC过于频繁。 ​ —-《深入理解java虚拟机》 Full GC 的触发条件对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件： 1. 调用 System.gc() 只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。 2. 老年代空间不足老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。 为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。 3. 空间分配担保失败 使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的 4. JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。 当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。 为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。 5. Concurrent Mode Failure 执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足），便会报 Concurrent Mode Failure 错误，并触发 Full GC。 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程：单线程指的是垃圾收集器只使用一个线程，而多线程使用多个线程； 串行与并行：串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并行指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 Serial收集器 Serial收集器为单线程环境设计,并只使用一个线程进行垃圾回收。 在回收时，会暂停用户线程,并不适用于并发环境。 Serial收集器在单线程环境中是很高效的,它没有多线程切换的消耗。 Serial收集器采用复制算法 Serial Old 串行收集器(老年代版本) 它是 Serial收集器的老年代使用的GC收集器，同样是一个单线程的垃圾收集器。 Serial Old收集器采用的是标记-整理算法。 123456789101112131415/** 开启串行收集器使用 -XX:+UseSerialGC , * 这样默认新生代使用 Serial 收集器, * 老年代使用 Serial Old 收集器. * * 设置VM参数: * * -XX:+Xlogs:gc* 打印gc信息 * -XX:+PrintCommandLineFlags 打印java版本信息 * -XX:+UseSerialGC 使用串行GC */ //如果程序正常运行,日志会显示 :// 新生代的信息为: def new generation.....// 老年代的信息为: tenured generation..... ParNew 收集器 它是 Serial 收集器的多线程版本。 它是 Server 场景下默认的新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合使用。 ParNew收集器采用复制算法 123456/** * * 设置ParNewGC回收器的参数为: * -XX:+UseConcMarkSweepGC * */ 参考 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011. Chapter 2. The Structure of the Java Virtual Machine Jvm memory Getting Started with the G1 Garbage Collector JNI Part1: Java Native Interface Introduction and “Hello World” application Memory Architecture Of JVM(Runtime Data Areas) JVM Run-Time Data Areas Android on x86: Java Native Interface and the Android Native Development Kit 深入理解 JVM(2)——GC 算法与内存分配策略 深入理解 JVM(3)——7 种垃圾收集器 JVM Internals Guide to WeakHashMap in Java Tomcat example source code file (ConcurrentCache.java) https://guang19.github.io/framework-learning/gitbook_doc/jdk-jvm-juc/GC.html#%E5%88%A4%E6%96%AD%E5%AF%B9%E8%B1%A1%E5%AD%98%E6%B4%BB%E7%9A%84%E6%96%B9%E6%B3%95","path":"2020/06/15/jvm05/","date":"06-15","excerpt":"","tags":[{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"},{"name":"gc","slug":"gc","permalink":"https://castile.github.io/tags/gc/"}]},{"title":"jvm04-Heap堆结构和JVM常量池","text":"Heap 堆 堆是JVM中内存占用最大的一块区域，它是所有线程共享的一块区域。 堆的作用是为对象分配内存并存储和回收它们。 堆是垃圾回收的主要区域，所以堆区也被成为GC堆。 一个JVM实例只存在一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件后，需要把类、方法、常变量放到堆内存中，保存所有引用类型的真实信息，以方便执行器执行，堆内存分为三部分 ： 堆区可以划分为新生代、老年代、永久代(java7)/元空间(java8)。元空间保存的是类的元数据信息，所谓元数据口哈斯描述数据的数据，这里指的是类元数据，而就是说保存的是类的描述信息，即类的结构信息。 新生代可以继续划分为伊甸园区(Eden区)，幸存者0区（Survivor 0【from】），幸存者1区(survivor 1 【to】)。 在默认情况下，新生代栈堆区的1/3, 老年代占堆区的2/3。 Eden区栈新生代的80%，Survivor区占20%， 其中from和to比例为1:1 (通过-XX:NewRatio参数可以调整新生代和老年代的空间占比) (通过-XX:SurvivorRatio参数可以调整eden和survivor的空间占比) Java7之前堆内存逻辑上分为三部分：新生+养老+永久，物理上由新生+养老区 新生区是类的诞生、成长、消亡的区域，一个类在这里产生，应用，最后被垃圾回收器收集，结束生命。新生区又分为两部分： 伊甸区（Eden space）和幸存者区（Survivor pace） ，所有的类都是在伊甸区被new出来的。幸存区有两个： 0区（Survivor 0 space）和1区（Survivor 1 space）。当伊甸园的空间用完时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收(Minor GC)，将伊甸园区中的不再被其他对象所引用的对象进行销毁。然后将伊甸园中的剩余对象移动到幸存 0区。若幸存 0区也满了，再对该区进行垃圾回收，然后移动到 1 区。那如果1 区也满了呢？再移动到养老区。若养老区也满了，那么这个时候将产生MajorGC（FullGC），进行养老区的内存清理。若养老区执行了Full GC之后发现依然无法进行对象的保存，就会产生OOM异常“OutOfMemoryError”。 如果出现java.lang.OutOfMemoryError: Java heap space异常，说明Java虚拟机的堆内存不够。原因有二： （1）Java虚拟机的堆内存设置不够，可以通过参数-Xms、-Xmx来调整。 （2）代码中创建了大量大对象，并且长时间不能被垃圾收集器收集（存在被引用）。 发生在新生代的GC叫做Young GC或Minor GC, 发生在老年代的GC叫做Old GC或Major GC 在java8之后，永久区换成了元空间。其他不变、 永久区(java7之前有) 永久存储区是一个常驻内存区域，用于存放JDK自身所携带的 Class,Interface 的元数据，也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭 JVM 才会释放此区域所占用的内存。 实际而言，方法区（Method Area）和堆一样，是各个线程共享的内存区域，它用于存储虚拟机加载的：类信息+普通常量+静态常量+编译器编译后的代码等等，虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap(非堆)，目的就是要和堆分开。 对于HotSpot虚拟机，很多开发者习惯将方法区称之为“永久代(Parmanent Gen)” ，但严格本质上说两者不同，或者说使用永久代来实现方法区而已，永久代是方法区(相当于是一个接口interface)的一个实现，jdk1.7的版本中，已经将原本放在永久代的字符串常量池移走。 JVM常量池Jvm常量池分为: Class常量池(静态常量池) 运行时常量池 字符串常量池(全局常量池) 包装类型缓存池 Class常量池(静态常量池)当Java源文件被编译后，就会生成Class字节码文件。 Class常量池就存在于Class文件中(Class文件的Constant Pool中)。 Class文件常量池主要存放两大常量:字面量和符号引用。 字面量: 字面量分为文本字符串(如: “abc”,1等)和用final修饰的成员变量(实例变量和静态变量) 符号引用: 符号引用包括三种：类的全限定名，方法名和描述符，字段名和描述符。 123456789101112131415161718192021/** * @author Hongliang Zhu * @create 2020-06-14 16:35 */public class ClassTest &#123; static int a = 10; public static void main(String[] args) &#123; String sss = &quot;Hello world&quot;; int result = add(2,3); System.out.println(sss); &#125; public static int add(int x, int y)&#123; int sum = x + y; return sum; &#125;&#125; 使用命令：javap -v ClassTest.class 反编译 运行时常量池运行是常量池是在类加载阶段，将class二进制数据加载到内存， 并将数据保存到方法区,其中class文件中的常量池将保存到 运行时常量池(数据都在方法区，常量池肯定也在方法区)。 也就是说一个Class文件常量池对应一个运行时常量池。 字符串常量池(全局常量池)字符串常量池在jdk7之前都是存于永久代(永久代)之中, jdk7以后存于 堆区之中。 包装类型缓存池包装类缓存池并不是所有的包装类都有，并且缓存池缓存的是一定范围内的数据。 拥有包装类型缓存池的类有:Integer,Byte,Character,Long,Short， 而Float，Double，Boolean都不具有缓存池。 包装类的缓存池缓存的范围基本都为: -128 - 127之间， Character的缓存范围为 0 - 127(也就是全部字符都缓存了-对应的ASCII码表）。 1234boolean values true and false //布尔类型中的两个取值 true和falseall byte values //byte类型所有数据，即-128～127short values between -128 and 127 //short类型大小范围-128~127char in the range \\u0000 to \\u007F //char类型所有数据，即所有字符 参考 https://guang19.github.io/framework-learning/gitbook_doc/jdk-jvm-juc","path":"2020/06/14/jvm04/","date":"06-14","excerpt":"","tags":[{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"}]},{"title":"jvm03-方法区和栈","text":"Method Area 方法区在jvm01中，谈到了类加载， 类加载器 负责加载class文件，class文件在文件开头有特定的文件标示，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构 。 注意上面说的方法区和数据结构。所谓方法区，里面供各线程共享的运行时内存区域。它存储了每一个类的结构信息，这个结构信息也就是class模板。例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容。上面讲的是规范，在不同虚拟机里头实现是不一样的，最典型的就是永久代(PermGen space)和元空间(Metaspace)。 这里理解一下，啥是永久代，啥又是元空间，懵逼。。。这个考科一这样理解，上面说到这个方法区是个规范，在不同虚拟机里头实现是不一样的，相当于多态的思想。 如： 12方法区 f = new 永久代() // java7方法区 f = new 元空间() // java8 上图中，运行时数据区中亮色的是有GC的，灰色的不存在GC且线程私有。实例变量存在堆内存中,和方法区无关。 总结： 方法区：1. 存储了每一个类的结构信息。 2. 方法区是规范，不同的虚拟机有不同的实现。 栈Stack 记住一句话： 栈管运行，堆管存储。 栈也叫栈内存，主管Java程序的运行，是在线程创建时创建，它的生命期是跟随线程的生命期，线程结束栈内存也就释放，对于栈来说不存在垃圾回收问题，只要线程一结束该栈就Over，生命周期和线程一致，是线程私有的。8种基本类型的变量+对象的引用变量+实例方法都是在函数的栈内存中分配。 栈存储什么栈帧中主要保存3 类数据： 本地变量（Local Variables）:输入参数和输出参数以及方法内的变量； 栈操作（Operand Stack）:记录出栈、入栈的操作； 栈帧数据（Frame Data）:包括类文件、方法等等。 1234public int getsss(int x, int y)&#123; int result = x+y; return result; &#125; x, y ,result 就是输入参数， 方法内的变量。 栈运行原理栈中的数据都是以栈帧（Stack Frame）的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法(Method)和运行期数据的数据集，当一个方法A被调用时就产生了一个栈帧 F1，并被压入到栈中， A方法又调用了 B方法，于是产生栈帧 F2 也被压入栈， B方法又调用了 C方法，于是产生栈帧 F3 也被压入栈， …… 执行完毕后，先弹出F3栈帧，再弹出F2栈帧，再弹出F1栈帧…… 遵循“先进后出”/“后进先出”原则。 每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。栈的大小和具体JVM的实现有关，通常在256K~756K之间,与等于1Mb左右。 图示在一个栈中有两个栈帧：栈帧 2是最先被调用的方法，先入栈，然后方法 2 又调用了方法1，栈帧 1处于栈顶的位置，栈帧 2 处于栈底，执行完毕后，依次弹出栈帧 1和栈帧 2，线程结束，栈释放。 每执行一个方法都会产生一个栈帧，保存到栈(后进先出)的顶部，顶部栈就是当前的方法，该方法执行完毕 后会自动将此栈帧出栈。 StackOverflowError123456789public class TT &#123; public static void main(String[] args) &#123; m(); &#125; public static void m()&#123; m(); &#125;&#125; 所以，StackOverflowerror是一个Error。 堆、栈、方法区的关系 引用在栈中，new出来的实例对象在堆中。模板在方法区。 HotSpot是使用指针的方式来访问对象： Java堆中会存放访问类元数据的地址，（元数据： 描述数据的数据，也就是类的模板，模板在方法区中，堆中会访问方法区模板的地址，根据模板来生成不同的实例对象） reference存储的就直接是对象的地址。","path":"2020/06/13/jvm03/","date":"06-13","excerpt":"","tags":[{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"}]},{"title":"jvm02-Native Interface本地接口","text":"本地接口 我们所说的栈，指的是上面的java栈，而不是本地方法栈。。。 本地接口的作用是融合不同的编程语言为 Java 所用，它的初衷是融合 C/C++程序，Java 诞生的时候是 C/C++横行的时候，要想立足，必须有调用 C/C++程序，于是就在内存中专门开辟了一块区域处理标记为native的代码，它的具体做法是 Native Method Stack中登记 native方法，在Execution Engine 执行时加载native libraies。 目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用 Socket通信，也可以使用Web Service等等，不多做介绍。 来看个例子。Thread类中的start()方法： 123456789101112131415161718192021222324252627282930public synchronized void start() &#123; /** * This method is not invoked for the main method thread or &quot;system&quot; * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state &quot;NEW&quot;. */ if (threadStatus != 0) // 这个表示线程的状态 throw new IllegalThreadStateException(); group.add(this); boolean started = false; try &#123; start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125;&#125;private native void start0(); // 本地方法 在一个Thread中，不能调用两次start方法，否则会报错：Exception in thread &quot;main&quot; java.lang.IllegalThreadStateException。 在调用start方法，实际上调用的是start0() 方法，看上面的源代码，start0（）是一个native方法，native方法表示这哥不归java语言本身管了，需要调用外部的方法，比如是C语言写的方法，native方法存放在本地方法栈里面，普通方法的调用存放在java栈里面。 它的具体做法是Native Method Stack中登记native方法，在Execution Engine 执行时加载本地方法库。 native是一个关键字，有声明，无实现。一个方法标记成native表示这个函数是去调用C语言的函数库，第三方的函数库。native方法的运行和装载是在本地方法栈中装载和运行的。 程序计数器每个线程都有一个程序计数器，是线程私有的, 就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎读取下一条指令，是一个非常小的内存空间，几乎可以忽略不计。 这块内存区域很小，它是当前线程所执行的字节码的行号指示器，字节码解释器通过改变这个计数器的值来选取下一条需要执行的字节码指令。 如果执行的是一个Native方法，那这个计数器是空的。 用以完成分支、循环、跳转、异常处理、线程恢复等基础功能。不会发生内存溢出(OutOfMemory=OOM)错误。","path":"2020/06/13/jvm02/","date":"06-13","excerpt":"","tags":[{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"}]},{"title":"jvm01-类加载机制","text":"JVM 学习今天终于决定要学学JVM了，一方面对于面试来说，这个是必考的，另一方面，深入了解jvm对于一个标准的java程序员来说，是很有必要的，知其然还要知其所以然。 JVM的位置 可以看到JVM是在操作系统之上的， 它与硬件没有直接的交互。 JVM体系结构 它分为上、中、下三层，类加载系统、运行时数据区，执行引擎。 类装载器ClassLoader 负责加载class文件，class文件在文件开头有特定的文件标示，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构。并且ClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定 。 对于上面这段话，我们详细来理解一下。首先明确以下，类加载器只负责加载class文件，也就是java程序编译之后的字节码文件。这个字节码文件在文件开头有特定的文件标识，看下图：（cafe babe）。 java的图标不就是一杯咖啡吗哈哈哈哈、、、 类的生命周期当java源代码文件被javac编译成class文件后，并不能直接运行， 而是需要经过加载，连接和初始化这几个阶段后才能使用。 在使用完类或JVM被销毁后，JVM会将类卸载掉。 类加载过程类加载过程需要经过3个阶段: 加载 连接 初始化 其中连接又可分为3个阶段: 验证 ， 准备 ， 解析。 加载在加载阶段，类加载器将类的class文件的二进制数据读取到内存， 并保存到方法区，并在堆区生成该类的Class对象。 通常有多种方式可以获取类的二进制数据: 通过javac编译器编译java源文件，读取在本地磁盘上生成的class文件。 从Jar，ZIP等归档文件中读取class文件。 通过网络读取类的字节流。 通过动态生成字节码的技术(如使用动态代理，cglib)来生成class。 连接1.验证 验证阶段是为了确保类的字节流符合虚拟机规范，并且不会对虚拟机造成恶意损害。 JVM会对字节流进行如下验证: 文件格式验证:会验证class文件是否符合虚拟机规范，如是否以0×CAFEBABE开头， 主次版本号是否在虚拟机规定范围类，常量池中的类型是否有JVM不支持的类型。 元数据验证: 会对类的元信息进行语义分析，确保符合Java语法规范。 字节码验证: 通过分析数据流和控制流，确保类的方法体的程序语义是合法的， 符合逻辑的。 符号引用验证: 确保常量池中的符号引用能在解析阶段正常解析。 2.准备: 准备阶段会为类的静态变量初始化零值，如(0,0L,null,false). 3.解析: 解析阶段会将常量池中的符号引用转为直接引用。 符号引用包括类的全限定名，方法名和描述符，字段名和描述符。直接引用是指向目标的指针，可以简单理解为目标的内存地址。 初始化 初始化阶段是类加载过程的最后一个阶段。 在这个阶段,只有主动使用类才会初始化类，总共有8种情况会涉及到主动使用类。 当jvm执行new指令时会初始化类，即当程序创建一个类的实例对象。 当jvm执行getstatic指令时会初始化类，即程序访问类的静态变量(不是静态常量，常量归属于运行时常量池)。 当jvm执行putstatic指令时会初始化类，即程序给类的静态变量赋值。 当jvm执行invokestatic指令时会初始化类，即程序调用类的静态方法。 当使用反射主动访问这个类时,也会初始化类,如Class.forname(“…”),newInstance()等等。 当初始化一个子类的时候，会先初始化这个子类的所有父类，然后才会初始化这个子类。 当一个类是启动类时，即这个类拥有main方法，那么jvm会首先初始化这个类。 MethodHandle和VarHandle可以看作是轻量级的反射调用机制，而要想使用这2个调用， 就必须先使用findStatic/findStaticVarHandle来初始化要调用的类。 使用在类被初始化完成后，就可以使用类了。 类的卸载类被卸载(Class对象被GC掉)需要满足3个条件: 该类的实例对象都已被GC，也就是说堆中不存在该类的实例对象。 该类没有在其它任何地方被使用。 加载该类的类加载器实例已被GC。 在JVM的生命周期中，被JVM自带的类加载器所加载的类是不会被卸载的。 而被我们自定义的类加载器所加载的类是可能会被卸载的。 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; Object object = new Object(); System.out.println(object.getClass().getClassLoader()); Main m = new Main(); System.out.println(m.getClass().getClassLoader()); System.out.println(m.getClass().getClassLoader().getParent()); System.out.println(m.getClass().getClassLoader().getParent().getParent()); &#125;&#125; 通过参数-XX:+TraceClassLoading 来打印类加载的信息。 类加载有如下几类： 虚拟机自带的加载器 启动类加载器（Bootstrap）C++， 用来加载jdk自带的类。 打开jdk， 里面有一个jre（java runtime environment）中 rt.jar文件，来看看里面是啥玩意： 这里面其实就是我们平时使用的JDK自带的类库，包括Object类等。所以Bootstrap类加载器就是加载这些的，正是因为jvm已经帮我们加载好了这些类，我们才可以直接使用。 扩展类加载器（Extension）Java： 首先要知道为啥有这个扩展类加载器，顾名思义就是加载扩展类的加载器，由于java是一门不断发展的语言，jdk也在快速的迭代，由java1.5， 1.6 然后1.8， 现在好像出了jdk14.。。。，还有就是java jdk中有很多以javax开头的包，在jre/lib/ext/*下的包就时使用扩展类加载器加载的。 应用程序类加载器（AppClassLoader）Java也叫系统类加载器，加载当前应用的classpath的所有类。也就是自己写的类。 12345678910111213public class Main &#123; public static void main(String[] args) &#123; Object object = new Object(); System.out.println(object.getClass().getClassLoader()); Main m = new Main(); System.out.println(m.getClass().getClassLoader()); System.out.println(m.getClass().getClassLoader().getParent()); System.out.println(m.getClass().getClassLoader().getParent().getParent()); &#125;&#125; 1234nullsun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@4554617cnull 上面输出表示，Object的加载器是null表示是启动类加载器（BootStrap）。sun.misc.Launcher是java虚拟机的一个入口应用。 用户自定义加载器Java.lang.ClassLoader的子类，用户可以定制类的加载方式。 双亲委派机制当一个类收到了类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一个层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class），子类加载器才会尝试自己去加载。 双亲委派机制是指在加载一个类的时候，JVM会判断这个类是否已经被其类加载器加载过了。 如果已经加载过了，那么直接返回这个类。 如果没有加载，就使用这个类对应的加载器的父类加载器判断， 一层一层的往上判断，最终会由BootstrapClassLoader判断。 如果BootstrapClassLoader判断都没有加载这个类, 那么就由BootstrapClassLoader尝试加载。 如果BootstrapClassLoader加载失败了， 就由BootstrapClassLoader的子类加载器们加载。 1234567891011package java.lang;/** * @author Hongliang Zhu * @create 2020-06-13 15:40 */public class String &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello&quot;); &#125;&#125; 上面的自己写的String类，会一层一层向上去找父类加载器去加载，而jdk自带的就有java.lang.String 类，所以jvm会调用启动类加载器加载java.lang.String类，而这个类中没有main函数，随意会报错。所以双亲委派机制的作用是保证安全性，保证沙箱安全。防止原生类被覆盖。 总结： 采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个 Object对象。 参考 https://guang19.github.io/framework-learning/gitbook_doc/jdk-jvm-juc","path":"2020/06/13/jvm01/","date":"06-13","excerpt":"","tags":[{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"}]},{"title":"pageHelper分页插件踩坑","text":"问题最近一个项目中使用了pageHelper分页插件。项目地址 : http://git.oschina.net/free/Mybatis_PageHelper。 在controller中使用该插件进行分页查询遇到如下两个问题： 找不到分页插件pagehelper的class: NotFoundClass exception 。。。 在controller中return分页查询的结果，浏览器响应的json对象为空。。。奇了怪了！ 解决 首先在common-service模块中的pom引入pageHelper的jar包： 123456789&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.miemiedev&lt;/groupId&gt; &lt;artifactId&gt;mybatis-paginator&lt;/artifactId&gt; &lt;/dependency&gt; 注意上面的mybatis-paginator 是pagehelper所依赖的包， 也需要一并引入。 为了程序的优雅性，并不推荐网上一些解决方案，直接再web层的pom引用分页的jar包。使用分布式模块，远程调用service，在service层引入jar包 这个错误。。。其实，就是分页的结果pojo需要写上get和set方法！！！！需要符合一个标准的java bean对象的标准。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.qingcheng.entity;import java.io.Serializable;import java.util.List;/** * * 分页结果的封装实体类 * @author Hongliang Zhu * @create 2020-06-11 16:50 */public class PageResult&lt;T&gt; implements Serializable &#123; // 泛型类 ： 可以封装任何数据的分页查询结果 private Long total; // 总记录数 private List&lt;T&gt; rows; // 数据 public PageResult(Long total, List&lt;T&gt; rows) &#123; this.total = total; this.rows = rows; &#125; public Long getTotal() &#123; return total; &#125; public void setTotal(Long total) &#123; this.total = total; &#125; public List&lt;T&gt; getRows() &#123; return rows; &#125; public void setRows(List&lt;T&gt; rows) &#123; this.rows = rows; &#125; @Override public String toString() &#123; return &quot;PageResult&#123;&quot; + &quot;total=&quot; + total + &quot;, rows=&quot; + rows + &#x27;&#125;&#x27;; &#125;&#125; 这错误太坑了。。。怪自己！ 之后成功解决，也该睡了，心累。","path":"2020/06/12/pageHelper/","date":"06-12","excerpt":"","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"}]},{"title":"网易秋招编程题-跳石板","text":"描述 小易来到了一条石板路前，每块石板上从1挨着编号为：1、2、3……. 这条石板路要根据特殊的规则才能前进：对于小易当前所在的编号为K的 石板，小易单次只能往前跳K的一个约数(不含1和K)步，即跳到K+X(X为K的一个非1和本身的约数)的位置。 小易当前处在编号为N的石板，他想跳到编号恰好为M的石板去，小易想知道最少需要跳跃几次可以到达。 例如： N = 4，M = 24： 4-&gt;6-&gt;8-&gt;12-&gt;18-&gt;24 于是小易最少需要跳跃5次，就可以从4号石板跳到24号石板 输入： 输入为一行，有两个整数N，M，以空格隔开。 (4 ≤ N ≤ 100000) (N ≤ M ≤ 100000) 输出 输出小易最少需要跳跃的步数,如果不能到达输出-1 示例： 4 24 5 思路一看到题干上说要求最小、最少。。等字眼，就要想到是动态规划类型的题目，要明确状态转移方程，还有个小难点就是一个数的约数怎么求。 设 $dp[i]$ 表示从初始石板到目标石板需要跳跃的最少次数。首先dp数组应该初始化一个很大的值，表示都不可达，除了自己到自己需要跳0次，即 $dp[N] = 0$. 求出当前石块编号的所有约数，对约数们遍历，则有一下状态转移方程(c为约数)：$$dp[i + c] = Min{ dp[i + c], dp[i]+1}. —&gt; dp[i + c] != Integer.MaxValue$$ $$dp[i + c] = dp[i]+1; —&gt;dp[i+c] = Integet.MaxValue$$ 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import java.util.ArrayList;import java.util.Arrays;import java.util.Scanner;/** * * [编程题]跳石板 网易秋招 * @author Hongliang Zhu * @create 2020-05-31 21:31 */public class skipStone &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int N = sc.nextInt(); // 起始位置 int M = sc.nextInt(); // 终止位置 int []dp = new int[M+1]; // dp[i] ： 到第i个石块最少需要跳多少次。 Arrays.fill(dp, Integer.MAX_VALUE); // 均初始化为无穷大 dp[N] = 0; // 自己到自己跳0次 for(int i = N; i &lt;= M; i++)&#123; if(dp[i] == Integer.MAX_VALUE) continue; // 不可达 // 遍历 当前i的约数 ArrayList&lt;Integer&gt; factors = getFactors(i); for(int j = 0; j &lt; factors.size(); j++)&#123; int skip = i+factors.get(j); if(skip &gt; M)&#123; continue; &#125; if(dp[skip] == Integer.MAX_VALUE)&#123; dp[skip] = dp[i]+1; &#125;else &#123; dp[skip] = Math.min(dp[skip], dp[i]+1); &#125; &#125; &#125; if(dp[M] == Integer.MAX_VALUE) System.out.println(-1); else System.out.println(dp[M]); &#125; /** * 获得当前数的约数 ， 除了1和它自己 * @param n * @return */ public static ArrayList&lt;Integer&gt; getFactors(int n)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int i = 2; i &lt;= Math.sqrt(n); i++)&#123; if(n % i == 0)&#123; list.add(i); if(n / i != i)&#123; list.add(n / i); &#125; &#125; &#125; return list; &#125;&#125;","path":"2020/05/31/skipstone/","date":"05-31","excerpt":"","tags":[{"name":"dp","slug":"dp","permalink":"https://castile.github.io/tags/dp/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"}]},{"title":"网易秋招编程题-优雅的点","text":"描述 小易有一个圆心在坐标原点的圆，小易知道圆的半径的平方。小易认为在圆上的点而且横纵坐标都是整数的点是优雅的，小易现在想寻找一个算法计算出优雅的点的个数，请你来帮帮他。 例如：半径的平方如果为25 优雅的点就有：(+/-3, +/-4), (+/-4, +/-3), (0, +/-5) (+/-5, 0)，一共12个点。 输入： 输入为一个整数，即为圆半径的平方,范围在32位int范围内。 输出： 输出为一个整数，即为优雅的点的个数 思路醉了，现场做不得劲，回过头来看发现真简单。。。可能心态不行吧。稳重点！ 分两种情况：1. 能被完整开平方的 ，这种需要加上横坐标为0的四个点。 2. 不能完整开平方的，也就是数开出来会有小数，此时可用floor函数向下取个整，这样就会比半径更小了。 在第一个象限遍历横坐标的范围，满足勾股定理，且纵坐标也是整数的就是满足条件，即“优雅的点”, 最后别忘了有四个象限，需要乘以4。 代码实现1234567891011121314151617181920212223242526272829303132333435import java.util.Scanner;/** * @author Hongliang Zhu * @create 2020-05-31 16:27 */public class point &#123; public static void main(String[] args) &#123; Scanner sc = new Scanner(System.in); int radius = sc.nextInt(); double r = Math.sqrt(radius); int range = (int)Math.floor(r); int count = 0; for(int i = 1; i &lt;= range; i++)&#123; for(int j = 1; j &lt;= range; j++)&#123; if( i*i + j*j == radius)&#123; count++; &#125; &#125; &#125; count*=4; if(range == r)&#123; count+=4; &#125; System.out.println(count);// System.out.println(Math.sqrt(25)== (int)Math.floor(Math.sqrt(25) )); &#125;&#125;","path":"2020/05/31/point/","date":"05-31","excerpt":"","tags":[{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"数学","slug":"数学","permalink":"https://castile.github.io/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"网易秋招编程题-回文序列","text":"描述 如果一个数字序列逆置之后跟原序列是一样的就称这样的数字序列为回文序列。例如： {1, 2, 1}, {15, 78, 78, 15} , {112} 是回文序列, {1, 2, 2}, {15, 78, 87, 51} ,{112, 2, 11} 不是回文序列。 现在给出一个数字序列，允许使用一种转换操作： 选择任意两个相邻的数，然后从序列移除这两个数，并用这两个数字的和插入到这两个数之前的位置(只插入一个和)。 现在对于所给序列要求出最少需要多少次操作可以将其变成回文序列。 输入： 输入为两行，第一行为序列长度n ( 1 ≤ n ≤ 50) 第二行为序列中的n个整数item[i] (1 ≤ item[i] ≤ 1000)，以空格分隔。 输出： 输出一个数，表示最少需要的转换次数 示例： 输入 4 1 1 1 3 输出 2 思路首先回文序列一定是两端相等，对于这样的问题，选用双端队列来处理，或者双向链表，便于首尾操作。首先判断首尾是否相等，如果相等的话，则让首尾元素出队，在剩下的元素中进一步判断，减小问题的规模。 那么由于题目说需要的最少操作次数，所以需要在小的一端进行相邻元素的加操作。如果首 &lt; 尾，则将首元素的以及其相邻的元素加起来，然后这两个元素出队，加和进队。如果首&gt; 尾， 则在尾部元素进行相加的操作，操作和首部类似。然后在进行下一步的判断，看看首尾元素是否相等，如若还不相等，则继续操作，如果相等，则首尾出队，直至队列中元素的个数只有一个，此时一定是回文序列。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.LinkedList;import java.util.Scanner;/** * 回文序列 * @author Hongliang Zhu * @create 2020-05-31 16:53 *//* */public class netease01 &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); // 个数 LinkedList&lt;Integer&gt; items = new LinkedList&lt;&gt;(); for(int i = 0; i &lt; n; i++)&#123; items.offer(scanner.nextInt()); &#125; int count = 0; // 计数 while (items.size() &gt; 1)&#123; int first = items.getFirst(); int end = items.getLast(); if(first == end)&#123; // 首尾出队列 items.poll(); items.removeLast(); &#125;else &#123; int add = 0; if(first &lt;= end)&#123; // 队首小 ，加上其相邻的元素 count++; add+=first; items.removeFirst(); add+=items.removeFirst(); // 插入 items.addFirst(add); &#125;else &#123; // 队尾小 count++; add+=end; items.removeLast(); add+=items.removeLast(); // 插入 items.addLast(add); &#125; &#125; &#125; System.out.println(count); &#125;&#125;","path":"2020/05/31/netease/","date":"05-31","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"},{"name":"数据结构","slug":"数据结构","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"ajax发送异步请求","text":"AJAX概念：ASynchronous JavaScript And XML ：异步的JavaScript 和 XML。 同步和异步异步和同步：客户端和服务器端相互通信的基础上。 同步请求：客户端必须等待服务器端的响应。在等待的期间客户端不能做其他操作。 异步请求：客户端不需要等待服务器端的响应。在服务器处理请求的过程中，客户端可以进行其他的操作。 Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。 通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。 传统的网页（不使用 Ajax）如果需要更新内容，必须重载整个网页页面。优点就是可以提升用户的体验。 Ajax的实现方式原生的JS实现方式1234567891011121314151617181920212223242526272829303132333435363738394041 //1.创建核心对象var xmlhttp;if (window.XMLHttpRequest)&#123;// code for IE7+, Firefox, Chrome, Opera, Safari xmlhttp=new XMLHttpRequest();&#125;else&#123;// code for IE6, IE5 xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;);&#125;//2. 建立连接/* 参数： 1. 请求方式：GET、POST * get方式，请求参数在URL后边拼接。send方法为空参 * post方式，请求参数在send方法中定义 2. 请求的URL： 3. 同步或异步请求：true（异步）或 false（同步） */xmlhttp.open(&quot;GET&quot;,&quot;ajaxServlet?username=tom&quot;,true);//3.发送请求xmlhttp.send();//4.接受并处理来自服务器的响应结果//获取方式 ：xmlhttp.responseText//什么时候获取？当服务器响应成功后再获取//当xmlhttp对象的就绪状态改变时，触发事件onreadystatechange。xmlhttp.onreadystatechange=function()&#123; //判断readyState就绪状态是否为4，判断status响应状态码是否为200 if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200) &#123; //获取服务器的响应结果 var responseText = xmlhttp.responseText; alert(responseText); &#125;&#125; JQeury实现方式$.ajax()：语法：$.ajax(&#123;键值对&#125;); 123456789101112131415//使用$.ajax()发送异步请求$.ajax(&#123; url:&quot;ajaxServlet1111&quot; , // 请求路径 type:&quot;POST&quot; , //请求方式 //data: &quot;username=jack&amp;age=23&quot;,//请求参数 data:&#123;&quot;username&quot;:&quot;jack&quot;,&quot;age&quot;:23&#125;, success:function (data) &#123; alert(data); &#125;,//响应成功后的回调函数 error:function () &#123; alert(&quot;出错啦...&quot;) &#125;,//表示如果请求响应出现错误，会执行的回调函数 dataType:&quot;text&quot;//设置接受到的响应数据的格式&#125;); $.get()：发送get请求语法：$.get(url, [data], [callback], [type])： 参数： `url`：请求路径 `data`：请求参数 `callback`：回调函数 `type`：响应结果的类型 $.post()：发送post请求语法：$.post(url, [data], [callback], [type])， 参数同get 12345678//定义方法 function func() &#123; // 使用ajax发送异步请求 $.get(&quot;ajaxServlet&quot;, &#123;&quot;username&quot;:&quot;zhuhongliang&quot;&#125;, function (data) &#123; alert(data); &#125;, &quot;text&quot;); &#125; 检查用户名是否存在1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;注册页面&lt;/title&gt; &lt;script src=&quot;js/jquery-3.3.1.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $(function () &#123; $(&quot;#username&quot;).blur(function () &#123; // 获取文本输入框的值 var username = $(this).val(); //发送ajax请求 var span = $(&quot;#s_username&quot;); $.get(&quot;findUserServlet&quot;, &#123;&#x27;username&#x27;:username&#125;, function (data) &#123; // alert(data); // 期望返回的数据格式 // 判断userExist键是否为true if(data.userExist)&#123; // 用户名存在 span.css(&quot;color&quot;,&quot;red&quot;); span.html(data.msg); &#125;else&#123; // 用户名不存在 span.html(data.msg); span.css(&quot;color&quot;,&quot;green&quot;); &#125; &#125;, &quot;json&quot;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form&gt; &lt;input type=&quot;text&quot; id=&quot;username&quot; name=&quot;username&quot; placeholder=&quot;请输入用户名&quot;&gt; &lt;span id=&quot;s_username&quot;&gt;&lt;/span&gt; &lt;br&gt; &lt;input type=&quot;password&quot; name=&quot;password&quot; placeholder=&quot;请输入密码&quot;&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;注册&quot;&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;","path":"2020/05/09/ajax发送异步请求/","date":"05-09","excerpt":"","tags":[{"name":"web","slug":"web","permalink":"https://castile.github.io/tags/web/"}]},{"title":"Spring中的事务控制","text":"引言JavaEE 体系进行分层开发，事务处理位于业务层，Spring 提供了分层设计业务层的事务处理解决方案。spring 框架为我们提供了一组事务控制的接口。这组接口是在 spring-tx-5.0.2.RELEASE.jar 中。spring 的事务控制都是基于 AOP 的，它既可以使用编程的方式实现，也可以使用配置的方式实现。重点掌握配置实现。 Spring中事务控制的 API介绍PlatformTransactionManager此接口是 spring 的事务管理器，它里面提供了我们常用的操作事务的方法： 123456789public interface PlatformTransactionManager &#123; /* 获取事务的状态信息 */ TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; /*提交事务*/ void commit(TransactionStatus status) throws TransactionException; /*回滚事务*/ void rollback(TransactionStatus status) throws TransactionException;&#125; 我们在开发中都是使用它的实现类: 真正管理事务的对象 ：org.springframework.jdbc.datasource.DataSourceTransactionManager ：使用 Spring JDBC 或 iBatis 进行持久化数据时使用 。org.springframework.orm.hibernate5.HibernateTransactionManager 使用 Hibernate 版本进行持久化数据时使用。 TransactionDefinition它是事务的定义信息对象，里面有如下方法： 读写型事务：增删改 开启事务 只读型事务：执行查询时，也会开启事务 事务的隔离级别 事务的传播行为A 方法和B方法都有事务，当A调用B时，会将A中的事务传播给B方法，B方法对于实物的处理方式就是事务的传播行为。 当事务方法被另一个事务方法调用时，必须指定事务应该如何传播。例如：方法可能继续在现有事务中运行，也可能开启一个新事务，并在自己的事务中运行。 REQUIRED:如果当前没有事务，就新建一个事务，如果已经存在一个事务中，加入到这个事务中。一般的选择（默认值） SUPPORTS:支持当前事务，如果当前没有事务，就以非事务方式执行（没有事务） MANDATORY：使用当前的事务，如果当前没有事务，就抛出异常 REQUERS_NEW: 新建事务，如果当前在事务中，把当前事务挂起。 NOT_SUPPORTED: 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 NEVER: 以非事务方式运行，如果当前存在事务，抛出异常 NESTED: 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行 REQUIRED 类似的操作。 是不是有点晕。。。我也是。 超时时间默认值是-1，没有超时限制。如果有，以秒为单位进行设置。 是否是只读事务建议查询时设置为只读。 TransactionStatus此接口提供的是事务具体的运行状态，描述了某个时间点上事务对象的状态信息，包含6个具体的操作。 123456789101112131415161718public interface TransactionStatus extends SavepointManager, Flushable &#123; /* 判断事务是否为新的事务 */ boolean isNewTransaction(); /* 获取事务是否存在存储点 */ boolean hasSavepoint(); /* 设置事务回滚 */ void setRollbackOnly(); /* 判断事务是否回滚 */ boolean isRollbackOnly(); /* 刷新事务 */ @Override void flush(); /* 判断事务是否完成 */ boolean isCompleted();&#125; 基于 XML 的声明式事务控制数据库 DAO123456789101112131415161718192021222324252627282930package com.hongliang.dao;import com.hongliang.domain.Account;/** * 账户的持久层接口 */public interface IAccountDao &#123; /** * 根据Id查询账户 * @param accountId * @return */ Account findAccountById(Integer accountId); /** * 根据名称查询账户 * @param accountName * @return */ Account findAccountByName(String accountName); /** * 更新账户 * @param account */ void updateAccount(Account account);&#125; Service1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.hongliang.service.impl;import com.hongliang.dao.IAccountDao;import com.hongliang.domain.Account;import com.hongliang.service.IAccountService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * 账户的业务层实现类 * * 事务控制应该都是在业务层 */public class AccountServiceImpl implements IAccountService &#123; private IAccountDao accountDao; public void setAccountDao(IAccountDao accountDao) &#123; this.accountDao = accountDao; &#125; @Override public Account findAccountById(Integer accountId) &#123; return accountDao.findAccountById(accountId); &#125; @Override public void transfer(String sourceName, String targetName, Float money) &#123; System.out.println(&quot;transfer....&quot;); //2.1根据名称查询转出账户 Account source = accountDao.findAccountByName(sourceName); //2.2根据名称查询转入账户 Account target = accountDao.findAccountByName(targetName); //2.3转出账户减钱 source.setMoney(source.getMoney()-money); //2.4转入账户加钱 target.setMoney(target.getMoney()+money); //2.5更新转出账户 accountDao.updateAccount(source);// int i=1/0; //2.6更新转入账户 accountDao.updateAccount(target); &#125;&#125; pom文件依赖123456789101112131415161718192021222324252627282930313233343536373839&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.19&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置bean.xml配置事务管理器123&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;ds&quot;&gt;&lt;/property&gt;&lt;/bean&gt; 配置事务的通知引用事务管理器123!-- 配置事务的通知--&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;/tx:advice&gt; 配置事务的属性123456789101112131415&lt;!--在 tx:advice 标签内部 配置事务的属性 --&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;!-- 指定方法名称：是业务核心方法 read-only：是否是只读事务。默认 false，不只读。 isolation：指定事务的隔离级别。默认值是使用数据库的默认隔离级别。 propagation：指定事务的传播行为。 timeout：指定超时时间。默认值为：-1。永不超时。 rollback-for：用于指定一个异常，当执行产生该异常时，事务回滚。产生其他异常，事务不回滚。 没有默认值，任何异常都回滚。 no-rollback-for：用于指定一个异常，当产生该异常时，事务不回滚，产生其他异常时，事务回滚。没有默认值，任何异常都回滚。 --&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; isolation=&quot;DEFAULT&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;/&gt; &lt;tx:method name=&quot;find*&quot; read-only=&quot;true&quot; propagation=&quot;SUPPORTS&quot;&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; 配置 AOP 切入点表达式1234567&lt;!-- 配置AOP--&gt;&lt;aop:config&gt;&lt;!-- 配置切入点表达式--&gt;&lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.hongliang.service.impl.*.*(..))&quot;/&gt;&lt;/aop:config&gt; 配置切入点表达式和事务通知的对应关系在 aop:config标签内部: 12&lt;!-- 建立切入点表达式和事务通知的对应关系 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pt1&quot;&gt;&lt;/aop:advisor&gt; 配置完成后的bean.xml 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;bean id=&quot;accountDao&quot; class=&quot;com.hongliang.dao.impl.AccountDaoImpl&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;ds&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;!-- 配置业务层--&gt; &lt;bean id=&quot;accountService&quot; class=&quot;com.hongliang.service.impl.AccountServiceImpl&quot;&gt; &lt;property name=&quot;accountDao&quot; ref=&quot;accountDao&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;ds&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?serverTimezone=UTC&quot;&gt;&lt;/property&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;ds&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;!-- 配置事务的通知--&gt; &lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;*&quot; isolation=&quot;DEFAULT&quot; propagation=&quot;REQUIRED&quot; read-only=&quot;false&quot;/&gt; &lt;tx:method name=&quot;find*&quot; read-only=&quot;true&quot; propagation=&quot;SUPPORTS&quot;&gt;&lt;/tx:method&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt;&lt;!-- 配置AOP--&gt; &lt;aop:config&gt;&lt;!-- 配置切入点表达式--&gt; &lt;aop:pointcut id=&quot;pt1&quot; expression=&quot;execution(* com.hongliang.service.impl.*.*(..))&quot;/&gt;&lt;!-- 建立切入点表达式和事务通知的对应关系 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut-ref=&quot;pt1&quot;&gt;&lt;/aop:advisor&gt; &lt;/aop:config&gt;&lt;/beans&gt; 测试1234567891011121314151617/** * 使用Junit单元测试：测试我们的配置 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:bean.xml&quot;)public class AccountServiceTest &#123; @Autowired private IAccountService as; @Test public void testTransfer()&#123; as.transfer(&quot;马化腾&quot;,&quot;王思聪&quot;,1000f); &#125;&#125; 经过测试，事务可以成功控制。 基于注解的配置方式环境搭建同上 创建业务层接口和实现类并使用注解让 spring 管理 创建 Dao 接口和实现类并使用注解让 spring 管理 配置步骤配置spring容器要扫描的包123&lt;!-- 配置spring容器要扫描的包--&gt;&lt;context:component-scan base-package=&quot;com.hongliang&quot;&gt;&lt;/context:component-scan&gt; 配置事务管理器并注入数据源123456789101112&lt;!-- 配置数据源 --&gt;&lt;bean id=&quot;ds&quot; class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;&gt;&lt;/property&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?serverTimezone=UTC&quot;&gt;&lt;/property&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;&gt;&lt;/property&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;!-- 配置事务管理器 --&gt; &lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;ds&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 开启spring对注解事务的支持123&lt;!-- 开启spring对注解事务的支持--&gt;&lt;tx:annotation-driven transaction-manager=&quot;transactionManager&quot; &gt;&lt;/tx:annotation-driven&gt; 在业务层使用@Transactional 注解 该注解的属性和 xml 中的属性含义一致。该注解可以出现在接口上，类上和方法上。 出现接口上，表示该接口的所有实现类都有事务支持。 出现在类上，表示类中所有方法有事务支持 出现在方法上，表示方法有事务支持。 以上三个位置的优先级：方法&gt;类&gt;接口。 不使用 xml的配置方式 （纯注解 ）配置类取代bean.xmlSpringconfiguration.java12345678910111213/** * spring的配置类： 相当于bean.xml * @author Hongliang Zhu * @create 2020-04-28 22:43 */@Configuration@ComponentScan(&quot;com.hongliang&quot;)@Import(&#123;jdbcConfig.class, TransactionConfig.class&#125;)@PropertySource(&quot;jdbc.properties&quot;)@EnableTransactionManagement //开启spring对注解事务的支持public class Springconfiguration &#123;&#125; jdbcConfig.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 数据库相关的配置类 * @author Hongliang Zhu * @create 2020-04-28 22:45 */public class jdbcConfig &#123; @Value(&quot;$&#123;jdbc.driverClass&#125;&quot;) private String driverClass; @Value(&quot;$&#123;jdbc.url&#125;&quot;) private String url; @Value(&quot;$&#123;jdbc.username&#125;&quot;) private String username; @Value(&quot;$&#123;jdbc.password&#125;&quot;) private String password; /** * 创建JdbcTemplate * @param dataSource * @return */ @Bean(name = &quot;jdbctemplate&quot;) // 放入spring容器中 public JdbcTemplate createJdbcTemplate(DataSource dataSource)&#123; return new JdbcTemplate(dataSource); &#125; /** * 创建数据源对象 * @return */ @Bean(name = &quot;dataSource&quot;) public DataSource createDataSource()&#123; DriverManagerDataSource ds = new DriverManagerDataSource(); ds.setPassword(driverClass); ds.setUrl(url); ds.setUsername(username); ds.setPassword(password); return ds; &#125;&#125; TransactionConfig.java12345678910111213141516171819/** * 和事务相关的配置类 * @author Hongliang Zhu * @create 2020-04-28 22:58 */public class TransactionConfig &#123; /** * 创建事务管理器对象 * @param dataSource * @return */ @Bean(name = &quot;transactionManager&quot;) // 放入spring容器中 public PlatformTransactionManager createTransactionManager(DataSource dataSource)&#123; return new DataSourceTransactionManager(dataSource); &#125;&#125; 测试12345678910111213141516/** * @author Hongliang Zhu * @create 2020-04-28 23:01 */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes = Springconfiguration.class) // 引入配置public class serviceText &#123; @Autowired private IAccountService service; @Test public void test()&#123; service.transfer(&quot;马化腾&quot;, &quot;王思聪&quot;, 2000f); &#125;&#125;","path":"2020/04/28/Spring中的事务控制/","date":"04-28","excerpt":"","tags":[{"name":"spring","slug":"spring","permalink":"https://castile.github.io/tags/spring/"}]},{"title":"搞定Latex","text":"安装Latex参照网上博客安装即可。 开始 使用记事本写下如下代码：test.tex 保存，cmd运行命令： 1latex test.tex 编译成pdf文件 1dvipdfmx test.dvi 也可以直接使用xelatex命令直接生成pdf文件，免去了使用中间命令。 上述的操作比较复杂，流程繁琐，可以直接写一个bat批处理文件： 效果是一样的。 TexStudio软件设置以支持中文： 新建一个文档：F5构建并查看 一个latex文档包括导言区和正文区：在导言区进行一些全局的设置 并且只能有一个正文区，通过命名来设置一些显示效果，$$符号是在行内嵌入公式，双$符号是另起一行嵌入公式。文档中如果要换行，则在之间插入一个空行即可，或者 \\ \\ . 中文设置查看是否是xelatex编译器, 编码为UTF-8。然后导入\\usepackage&#123;ctex&#125;。 LATEX 源代码中，空格键和 Tab 键输入的空白字符视为“空格”。连续的若干个空白字符视为一个空格。一行开头的空格忽略不计。 分段的方法有两种： （1）行末的回车视为一个空格，但连续两个回车，也就是空行，会将文字分段。多个空行被视为一个空行。 （2）也可以在行末使用 \\par 命令分段。 字体设置字体族设置：罗马字体，无衬线字体，打字机字体 12345678% 字体族设置（罗马字体，无衬线字体，打字机字体）\\textrm&#123;Roman Family&#125; % 罗马字体\\textsf&#123;Sans Serif Family&#125; % 无衬线字体\\texttt&#123;Typewriter Family&#125; % 打字机字体\\rmfamily Roman Family % 字体声明： 声明后面字体为罗马字体&#123;\\sffamily Sans Serif Family&#125; &#123;\\ttfamily Typewriter Family&#125; 大括号对声明分组，指定作用的范围。 完整源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263%导言区\\documentclass[12px]&#123;article&#125; %book, report , lettle\\title&#123;\\heiti 视频目标分割算法综述&#125;%\\author&#123;\\kaishu 卡西迪奥&#125;\\author&#123;小明\\thanks&#123;第一作者&#125; \\and 小红\\thanks&#123;第二作者&#125; \\and 隔壁老王\\thanks&#123;通讯作者&#125;&#125; \\usepackage&#123;ctex&#125;% 自定义命令\\newcommand&#123;\\myfont&#125;&#123;\\textbf&#123;\\textsf&#123;Fancy Text&#125;&#125;&#125;% 正文区\\begin&#123;document&#125; \\maketitle % 字体族设置（罗马字体，无衬线字体，打字机字体） \\textrm&#123;Roman Family&#125; % 罗马字体 \\textsf&#123;Sans Serif Family&#125; % 无衬线字体 \\texttt&#123;Typewriter Family&#125; % 打字机字体 \\rmfamily Roman Family % 字体声明： 声明后面字体为罗马字体 &#123;\\sffamily Sans Serif Family&#125; &#123;\\ttfamily Typewriter Family&#125; &#123;\\sffamily Video object segmentation (VOS) is a fundamental task in computer vision, with important applications including video editing, robotics, and selfdriving cars. According to whether the ground-truth mask of the target objects is given for the first frame, VOS task can be seen as semi-supervised VOS and unsupervised VOS. &#125; &#123;\\rmfamily Given the mask of the target objects for the first frame, algorithm for semi-supervised VOS focuses on using it to model the appearance of the objects of interest, such as fine-tuning the model using the first frame or matching the pixel or superpixel of following frames with the first frame. Motion cue or temporal information is considered to be complementary information to enhance performance. While the information for the object of interest is unknown, the method of unsupervised VOS leverages the motion cue and the general appearance model to get dominant feature and segment the salient object .&#125; % 字体形状设置（直立，斜体，伪斜体，小型大写） \\textup&#123;Upright Shape&#125; \\textit&#123;Italic Shape&#125; \\textsl&#123;Slanted Shape&#125; \\textsc&#123; Small Caps Shape&#125; &#123;\\upshape Upright Shape &#125; &#123;\\itshape Italic Shape &#125; &#123;\\slshape Slanted Shape&#125; &#123;\\scshape Small Caps Shape&#125; % 中文字体设置 \\noindent 我是全局字体，我使用的是宋体\\\\ &#123;\\kaishu 我是ctex已定义好的字体，我使用的楷体&#125;\\\\ &#123;\\heiti 我是ctex已定义好的字体，我使用的黑体&#125;\\\\ &#123;\\fangsong 我是ctex已定义好的字体，我使用的仿宋&#125;\\\\ % 设置字体大小 &#123;\\tiny Hello&#125; \\\\ &#123;\\scriptsize Hello&#125; \\\\ &#123;\\footnotesize Hello&#125; \\\\ &#123;\\small Hello&#125; \\\\ &#123;\\normalsize Hello&#125; \\\\ &#123;\\large Hello&#125; \\\\ &#123;\\Large Hello&#125; \\\\ &#123;\\LARGE Hello&#125; \\\\ &#123;\\huge Hello&#125; \\\\ &#123;\\Huge Hello&#125; \\\\ % 中文字体字号 \\zihao&#123;4&#125; 你好 \\myfont \\end&#123;document&#125; Latex的篇章结构 Latex 插图通过\\usepackage&#123;graphicx&#125;来引入。支持EPS，PDF，PNG，JPEG，BMP 1234567891011121314151617181920212223242526%导言区\\documentclass&#123;ctexart&#125;% 导言区：\\usepackage&#123;graphicx&#125;% 语法：\\includegraphics[keyvals]&#123;imagefile&#125;\\usepackage&#123;graphicx&#125;\\graphicspath&#123;&#123;figures/&#125;,&#123;pic/&#125;&#125; % 图片在当前目录下的figures目录% 正文区\\begin&#123;document&#125; \\zihao&#123;4&#125;\\LaTeX&#123;&#125;中的插图： \\includegraphics[scale=0.5]&#123;camel&#125; \\includegraphics[scale=0.3,height=10cm]&#123;head&#125; \\includegraphics[scale=0.4]&#123;cosnet&#125; \\includegraphics[scale=0.5, angle=45]&#123;camel&#125; \\includegraphics[scale=0.3,height=10cm,,angle=90]&#123;head&#125; \\includegraphics[scale=0.4,clip]&#123;cosnet&#125;\\end&#123;document&#125; Latex中的表格1234567891011121314151617181920212223242526\\documentclass&#123;ctexart&#125; % ctexbook, ctexrep% \\usepackage&#123;ctex&#125;%正文区\\begin&#123;document&#125; \\begin&#123;table*&#125; \\centering \\caption&#123;成绩表&#125; \\begin&#123;tabular&#125;&#123;|l||c|c||c|p&#123;3cm&#125;|&#125; % l 表示左对齐， r表示右对齐， c居中 \\hline 姓名 &amp; 语文 &amp; 数学 &amp; 英语 &amp; 备注 \\\\ \\hline \\hline 张三 &amp; 98 &amp; 100 &amp; 99 &amp; 优秀 \\\\ \\hline 李四 &amp; 94 &amp; 88 &amp; 56 &amp; 补考另行通知 \\\\ \\hline 梨花 &amp; 88 &amp; 99 &amp; 100 &amp; 优秀 \\\\ \\hline \\end&#123;tabular&#125;\\end&#123;table*&#125;\\end&#123;document&#125; Latex中的浮动体12345678910111213141516171819202122232425262728293031323334353637\\documentclass&#123;ctexart&#125;\\usepackage&#123;graphicx&#125;\\graphicspath&#123;&#123;figures/&#125;&#125;\\begin&#123;document&#125; \\LaTeX&#123;&#125;中的插图： 这个是一只骆驼，骆驼见图\\ref&#123;fig-camel&#125; \\begin&#123;figure&#125;[htbp] \\centering \\includegraphics[scale=0.3]&#123;camel&#125; \\caption&#123;\\ 这是一只骆驼&#125;\\label&#123;fig-camel&#125; \\end&#123;figure&#125; \\LaTeX&#123;&#125;中的表格： \\begin&#123;table&#125;[h] \\centering \\caption&#123;考试成绩单&#125; \\begin&#123;tabular&#125;&#123;|l||c|c||c|p&#123;3cm&#125;|&#125; \\hline 姓名 &amp; 语文 &amp; 数学 &amp; 英语 &amp; 备注 \\\\ \\hline \\hline 张三 &amp; 98 &amp; 100 &amp; 99 &amp; 优秀 \\\\ \\hline 李四 &amp; 94 &amp; 88 &amp; 56 &amp; 补考另行通知 \\\\ \\hline 梨花 &amp; 88 &amp; 99 &amp; 100 &amp; 优秀 \\\\ \\hline \\end&#123;tabular&#125; \\end&#123;table&#125; \\end&#123;document&#125; 浮动体可以实现灵活分页和排版。，避免无法分割的内容产生的页面空白。还可以使用caption给图表添加标题，以及使用label和ref实现对图表的交叉引用。 可以设置图表的允许位置，默认是tbp： h: 此处here – 代码所在的上下文位置 t: 页顶top – 代码所在页面或者之后页面的顶部 b: 页底bottom – 代码所在页面或者之后页面的底部 p: 独立一页page – 浮动页面 Latex中的数学公式特殊字符懒得写了。。。可以去各大博客看看。 矩阵12345678910111213141516171819202122232425262728293031323334353637\\documentclass&#123;ctexart&#125;\\usepackage&#123;amsmath&#125;\\begin&#123;document&#125; \\[ \\begin&#123;matrix&#125; 0 &amp; 1 \\\\ 1 &amp; 0 \\end&#123;matrix&#125; \\qquad % pmatrix环境 \\begin&#123;pmatrix&#125; 0 &amp; -i \\\\ i &amp; 0 \\end&#123;pmatrix&#125; \\qquad % bmatrix环境 \\begin&#123;bmatrix&#125; 0 &amp; -1 \\\\ 1 &amp; 0 \\end&#123;bmatrix&#125; \\qquad % Bmatrix环境 \\begin&#123;Bmatrix&#125; 0 &amp; -i \\\\ i &amp; 0 \\end&#123;Bmatrix&#125; \\qquad % vmatrix环境 \\begin&#123;vmatrix&#125; a &amp; b \\\\ c &amp; d \\end&#123;vmatrix&#125; \\qquad % Vmatrix环境 \\begin&#123;Vmatrix&#125; 0 &amp; -i \\\\ i &amp; 0 \\end&#123;Vmatrix&#125; \\qquad \\]\\end&#123;document&#125; 12345678910111213141516\\[A = \\begin&#123;bmatrix&#125;a_&#123;11&#125; &amp; \\dots &amp; a_&#123;1n&#125; \\\\&amp; \\ddots &amp; \\vdots \\\\0 &amp; &amp; a_&#123;nn&#125;\\end&#123;bmatrix&#125;_&#123;n \\times n&#125;\\]\\[A = \\begin&#123;pmatrix&#125;a_&#123;11&#125;^2 &amp; a_&#123;12&#125;^2 &amp; a_&#123;13&#125;^2 \\\\0 &amp; a_&#123;22&#125; &amp; a_&#123;23&#125; \\\\0 &amp; 0 &amp; a_&#123;33&#125;\\end&#123;pmatrix&#125;\\] 多行公式12345678910111213141516171819\\documentclass&#123;ctexart&#125;\\usepackage&#123;amsmath&#125;\\usepackage&#123;amssymb&#125;\\begin&#123;document&#125;% 多行公式 带编号 \\begin&#123;gather&#125; a + b = b + a \\\\ ab ba \\end&#123;gather&#125; % 多行公式 %不带编号 \\begin&#123;gather*&#125; a + b = b + a \\\\ ab ba \\end&#123;gather*&#125; \\end&#123;document&#125; Latex参考文献BibTex12345678910111213141516\\documentclass&#123;ctexart&#125;\\bibliographystyle&#123;plain&#125; % plain alpha abbrv% 正文区\\begin&#123;document&#125; 我引用了一篇文章\\cite&#123;20174704440428&#125;\\\\ 我引用了一篇文章\\cite&#123;20181605023233&#125;\\\\ 我引用了一篇文章\\cite&#123;20183905849930&#125;\\\\ 我引用了一篇文章\\cite&#123;20193207282709&#125;\\\\ 我引用了一篇文章\\cite&#123;20194407608844&#125; 在谷歌学术上引用\\cite&#123;logothetis1996visual&#125; \\bibliography&#123;test&#125;\\end&#123;document&#125; 可以使用zotero火狐插件导出bibTex， 知网也行。 好了，就这样。Latex学习曲线听陡峭的。。。命令很多，不用就会忘记，所以以后还是多用用的，工具还是挺强大的！","path":"2020/04/28/Latex/","date":"04-28","excerpt":"","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://castile.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"latex","slug":"latex","permalink":"https://castile.github.io/tags/latex/"}]},{"title":"Motion-Attentive Transition for Zero-Shot Video Object Segmentation","text":"Motion-Attentive Transition for Zero-Shot Video Object Segmentation [2020]论文地址：https://arxiv.org/abs/2003.04253 github: https://github.com/tfzhou/MATNet 这篇文章的结果在Davis2016数据集上达到了82.5，截止到2020年4月16日11:03取得了第一名的成绩:100: Overview论文提出了一种基于双流编码的用于Zero-Shot视频目标分割任务，称为 Motion-Attentive Transition Network (MATNet) 。它和以往的双流网络有区别，以往的双流网络将运动信息和外观信息独立的处理，视为同等重要， 学习直接将光流映射到相应的分割掩码中，并且会导致外观网络的过度拟合。而MAT-Net不但继承了传统双流网络的特性（对多模态的学习），而且还能逐步转移中间的运动注意特征，以促进外观学习。 NetWorkMAT-Net的网络结构如下图所示： 网络由三部分组成： 交叉编码网络（Interleaved encoder）, 桥接网络（a bridge network ），解码网络（decoder）。 Interleaved encoder 编码器依赖于一个双流结构来合编码对象的外观和运动信息，不像以前的工作一样对待两个流，编码器在每个网络中间层包含一个MAT block，它为信息传播提供了一个运动到外观的路径。 以ResNet-101作为backbone，则编码器的流程为：首先输入image $I_a$ 和它对应的光流图 $I_m$ ，encoder分别提取中间特征$ V_{a,i} \\in R^{W * H * C} $ 和 $ V_{m,i} \\in R^{W * H * C} $, $ i \\in {2,3,4,5} $, 表示residual stage。MAT-Block会增强这些特征：$$U_{a,i}， U_{m,i} =F{{MAT}(V{a,i}, V_{m,i})}$$$U$ 表示增强之后的特征。 Bridge Network桥接网络由SSA模块构成。使用尺度敏感注意(SSA)来自适应地选择和转换编码器的特性，而不是直接通过跳过连接来连接编码器和解码器。具体来说，SSA被添加到每一对编码器和解码器层中，它包含一个两级注意方案， 其中，局部注意采用信道和空间两种注意机制，将输入特征集中在正确的目标区域，同时抑制冗余特征中可能存在的噪声，而全局注意则针对多尺度目标对特征进行重新校准。 Decoder Network 解码器网络采用粗到精的方案进行分割，它由四个BAR（ Boundary-Aware Refinement ）模块组成。 Motion-Attentive Transition ModuleMAT-module 由一个soft attention和一个attention transition单元组成。SA 集中注意到输入图像的重要区域，AT则将注意的运动特征转移到外观流中，以促进外观学习 。 Soft Attention 这个单元在每个空间位置上对输入的特征图$V_m$(或$V_a$)进行加权 。 Attention Transition 矩阵S可以有效地捕获两个特征空间之间的两两关系。 然后对S的每一行进行归一化，得到一个基于运动特征的注意图 $S^r$ 并实现增强的外观特征$U_a$ 下面是MAT-block的计算图： Scale-Sensitive Attention Module基于 CBAM: Convolutional Block Attention Module 。 Convolutional Block Attention Module (CBAM) 表示卷积模块的注意力机制模块。是一种结合了空间（spatial）和通道（channel）的注意力机制模块。相比于senet只关注通道（channel）的注意力机制可以取得更好的效果。 SSA 基于CBAM，加上了全局的注意$F_g$， 给定一个特征图作为输入$U \\in R^{WH2C}$, SSA refine it: CBAM Boundary-Aware Refinement Module 对于BAR来说，有两个因素是非常关键的： ASPP模块，可以增大感受野的同时，获得更大的特征图。 引入了一种启发式的方法来自动挖掘 hard negative pixels 来支持$F_{bdry}$的训练 : 使用HED-model来预测边界特征图$E\\in[0,1]^{W*H}$, $E_k$ 表示第k个像素是边界的概率。 那么，如果像素k具有较高的边缘概率（eg ： &gt;0.2）并且落在扩展的ground-truth区域之外 ，则将其视为hard negative pixels。 如果像素k是硬像素，则其权值$w_k = 1+ E_k$; 否则$w_k =1$。 然后，使用$w_k$对下面的边界损失进行加权，以便在硬像素分类错误时对其进行重罚 $M^b$ 和 $G^b$ 分别是边缘预测和ground-truth ExperimentsAblation study ResultDavis16 Youtube-Object CosNet : 70.5 AGNN： 81.1 75.9 70.7 78.1 67.9 69.7 77.4 67.3 68.3 47.8 70.8 FBMS CosNet：75.6","path":"2020/04/16/MAT-Net/","date":"04-16","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"UVOS","slug":"UVOS","permalink":"https://castile.github.io/tags/UVOS/"}]},{"title":"语义分割算法之DeepLabV3+","text":"语义分割算法之DeepLabV3+论文标题： Encoder-Decoder with Atrous Separable Convolution for Semantic ImageSegmentation DeepLab series has come along for versions from DeepLabv1 (2015 ICLR), DeepLabv2 (2018 TPAMI), and DeepLabv3 (arXiv). 论文地址： https://arxiv.org/pdf/1802.02611.pdf github： https://github.com/jfzhang95/pytorch-deeplab-xception 语义分割主要面临两个问题，第一是物体的多尺度问题，第二是DCNN的多次下采样会造成特征图分辨率变小，导致预测精度降低，边界信息丢失。DeepLab V3设计的ASPP模块较好的解决了第一个问题，而这里要介绍的DeepLabv3+则主要是为了解决第2个问题的。 我们知道从DeepLabV1系列引入空洞卷积开始，我们就一直在解决第2个问题呀，为什么现在还有问题呢？见以前的博客：deeplabv1和deeplabv2和deeplabv3-空洞卷积(语义分割)。对于DeepLabV3，如果Backbone为ResNet101，Stride=16将造成后面9层的特征图变大，后面9层的计算量变为原来的4倍大。而如果采用Stride=8，则后面78层的计算量都会变得很大。这就造成了DeepLabV3如果应用在大分辨率图像时非常耗时。所以为了改善这个缺点，DeepLabV3+来了。 Overview (a): With Atrous Spatial Pyramid Pooling (ASPP), able to encode multi-scale contextual information. ASPP 模块，可以编码多尺度特征， 其中的8x是直接双线性插值操作，不用参与训练 。 (b)： With Encoder-Decoder Architecture, the location/spatial information is recovered. Encoder-Decoder Architecture has been proved to be useful in literature such as FPN, DSSD, TDM, SharpMask, RED-Net, and U-Net for different kinds of purposes. 编解码器结构， 可以恢复位置/空间信息。 事实证明，编码器/解码器体系结构在FPN，DSSD，TDM，SharpMask，RED-Net和U-Net等文献中可用于多种用途。 融合了低层和高层的信息。 (c): DeepLabv3+ makes use of (a) and (b). 本文使用的DeeplabV3+结构。采用了(a)和(b)。 Further, with the use of Modified Aligned Xception, and Atrous Separable Convolution, a faster and stronger network is developed. 此外，通过使用修正的对齐Xception和Atrous可分离卷积，可以开发出更快，更强大的网络。 最后，DeepLabv3 +的性能优于PSPNet（在2016年ILSVRC场景解析挑战赛中排名第一）和之前的DeepLabv3。 OutLine Atrous Separable Convolution Encoder-Decoder Architecture Modified Aligned Xception Ablation Study Comparison with State-of-the-art Approaches Atrous Separable ConvolutionAtrous Convolution 对于输出y上的每个位置i和一个滤波器w, atrous卷积应用于输入特征映射x，其中atrous rate对应于我们采样输入信号时的步幅。 空洞卷积详见： https://hongliangzhu.cn/2020/04/09/deeplabv3-%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/#%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF Atrous Separable Convolution （a）和（b），深度可分卷积：将标准卷积分解为深度卷积，然后再进行点向卷积（即1×1卷积），大大降低了计算复杂度。 （c）: 它在保持相似（或更好）性能的同时，大大降低了所提出模型的计算复杂度。 Combining with point-wise convolution, it is Atrous Separable Convolution. Encoder-Decoder Architecture为了解决上面提到的DeepLabV3在分辨率图像的耗时过多的问题，DeepLabV3+在DeepLabV3的基础上加入了编码器。这是Deeplabv3+的一个主要的创新点。 DeepLabv3 as Encoder编码器就是一个DeeplabV3结构。 首先选一个低层级的feature用1 * 1的卷积进行通道压缩（原本为256通道，或者512通道），目的是减少低层级的比重。论文认为编码器得到的feature具有更丰富的信息，所以编码器的feature应该有更高的比重。 这样做有利于训练。 对于图像分类的任务来说， 最终特征图的空间分辨率通常比输入图像分辨率小32倍，因此输出步幅= 32。 （output stride = 32） 对于语义分割来说，缩小32倍太小了。 通过移除最后一个（或者两个）块中的步幅并相应的应用空洞卷积，采用out stride=16（或者8）进行更加密集的特征提取。 同时，Deeplabv3增强了ASPP模块， 该模块通过以不同rate应用具有图像级别特征的atrous卷积来探测多尺度的卷积特征。 Proposed Decoder对于解码器部分，直接将编码器的输出上采样4倍，使其分辨率和低层级的feature一致。举个例子，如果采用resnet conv2 输出的feature，则这里要x4上采样。将两种feature连接后，再进行一次3x3的卷积（细化作用），然后再次上采样就得到了像素级的预测。 实验结果表明，这种结构在Stride=16时有很高的精度速度又很快。stride=8相对来说只获得了一点点精度的提升，但增加了很多的计算量。 Modified Aligned XceptionAligned Xception可参考：https://towardsdatascience.com/review-dcn-deformable-convolutional-networks-2nd-runner-up-in-2017-coco-detection-object-14e488efce44 Xception 是用于图像分类任务的 Aligned Xception 是来自可变形卷积，用于目标检测。 Modified Aligned Xception论文受到近期MSRA组在Xception上改进工作可变形卷积(Deformable-ConvNets)启发，Deformable-ConvNets对Xception做了改进，能够进一步提升模型学习能力，新的结构如下： 更深的Xception结构，不同的地方在于不修改entry flow network的结构，为了快速计算和有效的使用内存 所有的max pooling结构被stride=2的深度可分离卷积代替 每个3x3的depthwise convolution都跟BN和Relu 最后将改进后的Xception作为encodet主干网络，替换原本DeepLabv3的ResNet101。 Ablation StudyDecoder Design论文使用modified aligned Xception改进后的ResNet-101，在ImageNet-1K上做预训练，通过扩张卷积做密集的特征提取。采用DeepLabv3的训练方式(poly学习策略，crop 513x513)。注意在decoder模块同样包含BN层。 为了评估在低级特征使用1*1卷积降维到固定维度的性能，做了如下对比实验： 实验中取了conv2尺度为[3x3, 256]的输出，降维后的通道数在32和48之间最佳，最终选择了48。 编解码特征图融合后经过了3x3卷积，论文探索了这个卷积的不同结构对结果的影响 And it is most effective to use the Conv2 (before striding) feature map and two extra [3×3 conv; 256 channels] operations. 最终，选择了使用两组3x3卷积。这个表格的最后一项代表实验了如果使用Conv2和Conv3同时预测，上采样2倍后与Conv3结合，再上采样2倍的结果对比，这并没有提升显著的提升性能，考虑到计算资源的限制，论文最终采样简单的decoder方案，即我们看到的DeepLabV3+的网络结构图。 Model Variants with ResNet as Backbone Baseline (First row block): 77.21% to 79.77% mIOU With Decoder (Second row block): The performance is improved from 77.21% to 78.85% or 78.51% to 79.35%. The performance is further improved to 80.57% when using multi-scale and left-right flipped inputs. Coarser feature maps (Third row block): i.e. stride = 32, the performance is not good. Modified Aligned Xception as Backbone Baseline (First row block): 79.17% to 81.34% mIOU. With Decoder (Second row block): 79.93% to 81.63% mIOU. Using Depthwise Separable Convolution (Third row block): Multiply-Adds is significantly reduced by 33% to 41%, while similar mIOU performance is obtained. Pretraining on COCO (Fourth row block): Extra 2% improvement. Pretraining on JFT (Fifth row block): Extra 0.8% to 1% improvement. 这里可以看到使用深度分离卷积可以显著降低计算消耗。 Visualization Comparison with State-of-the-art Approaches DeepLabv3+ outperforms many SOTA approaches . 论文提出的DeepLabv3+是encoder-decoder架构，其中encoder架构采用Deeplabv3，decoder采用一个简单却有效的模块用于恢复目标边界细节。并可使用空洞卷积在指定计算资源下控制feature的分辨率。论文探索了Xception和深度分离卷积在模型上的使用，进一步提高模型的速度和性能。模型在VOC2012上获得了SOAT。Google出品，必出精品，这网络真的牛。 源码分析github：https://github.com/jfzhang95/pytorch-deeplab-xception.git 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&quot;&quot;&quot; Dilated ResNet with multi-grid + improved ASPP + decoder&quot;&quot;&quot;class DeepLab(nn.Module): def __init__(self, backbone=&#x27;resnet&#x27;, output_stride=16, num_classes=21, sync_bn=True, freeze_bn=False): super(DeepLab, self).__init__() if backbone == &#x27;drn&#x27;: output_stride = 8 if sync_bn == True: BatchNorm = SynchronizedBatchNorm2d else: BatchNorm = nn.BatchNorm2d # 基网络 self.backbone = build_backbone(backbone, output_stride, BatchNorm) # ASPP模块 self.aspp = build_aspp(backbone, output_stride, BatchNorm) # 编解码器 self.decoder = build_decoder(num_classes, backbone, BatchNorm) self.freeze_bn = freeze_bn def forward(self, input): # backbone 输出低级特征和编码特征 x, low_level_feat = self.backbone(input) x = self.aspp(x) x = self.decoder(x, low_level_feat) # 上采样 x = F.interpolate(x, size=input.size()[2:], mode=&#x27;bilinear&#x27;, align_corners=True) return x&quot;&quot;&quot; 构建backbone&quot;&quot;&quot;from modeling.backbone import resnet, xception, drn, mobilenetdef build_backbone(backbone, output_stride, BatchNorm): if backbone == &#x27;resnet&#x27;: return resnet.ResNet101(output_stride, BatchNorm) elif backbone == &#x27;xception&#x27;: return xception.AlignedXception(output_stride, BatchNorm) elif backbone == &#x27;drn&#x27;: return drn.drn_d_54(BatchNorm) elif backbone == &#x27;mobilenet&#x27;: return mobilenet.MobileNetV2(output_stride, BatchNorm) else: raise NotImplementedError ASPP： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192import mathimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom modeling.sync_batchnorm.batchnorm import SynchronizedBatchNorm2dclass _ASPPModule(nn.Module): def __init__(self, inplanes, planes, kernel_size, padding, dilation, BatchNorm): super(_ASPPModule, self).__init__() self.atrous_conv = nn.Conv2d(inplanes, planes, kernel_size=kernel_size, stride=1, padding=padding, dilation=dilation, bias=False) self.bn = BatchNorm(planes) self.relu = nn.ReLU() self._init_weight() def forward(self, x): x = self.atrous_conv(x) # 空洞卷积 x = self.bn(x) # 加入bn层 return self.relu(x) def _init_weight(self): for m in self.modules(): if isinstance(m, nn.Conv2d): torch.nn.init.kaiming_normal_(m.weight) elif isinstance(m, SynchronizedBatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_()class ASPP(nn.Module): def __init__(self, backbone, output_stride, BatchNorm): super(ASPP, self).__init__() if backbone == &#x27;drn&#x27;: inplanes = 512 elif backbone == &#x27;mobilenet&#x27;: inplanes = 320 else: inplanes = 2048 if output_stride == 16: dilations = [1, 6, 12, 18] elif output_stride == 8: dilations = [1, 12, 24, 36] else: raise NotImplementedError self.aspp1 = _ASPPModule(inplanes, 256, 1, padding=0, dilation=dilations[0], BatchNorm=BatchNorm) self.aspp2 = _ASPPModule(inplanes, 256, 3, padding=dilations[1], dilation=dilations[1], BatchNorm=BatchNorm) self.aspp3 = _ASPPModule(inplanes, 256, 3, padding=dilations[2], dilation=dilations[2], BatchNorm=BatchNorm) self.aspp4 = _ASPPModule(inplanes, 256, 3, padding=dilations[3], dilation=dilations[3], BatchNorm=BatchNorm) self.global_avg_pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)), nn.Conv2d(inplanes, 256, 1, stride=1, bias=False), BatchNorm(256), nn.ReLU()) self.conv1 = nn.Conv2d(1280, 256, 1, bias=False) self.bn1 = BatchNorm(256) self.relu = nn.ReLU() self.dropout = nn.Dropout(0.5) self._init_weight() def forward(self, x): x1 = self.aspp1(x) x2 = self.aspp2(x) x3 = self.aspp3(x) x4 = self.aspp4(x) x5 = self.global_avg_pool(x) x5 = F.interpolate(x5, size=x4.size()[2:], mode=&#x27;bilinear&#x27;, align_corners=True) x = torch.cat((x1, x2, x3, x4, x5), dim=1) x = self.conv1(x) x = self.bn1(x) x = self.relu(x) return self.dropout(x) def _init_weight(self): for m in self.modules(): if isinstance(m, nn.Conv2d): # n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels # m.weight.data.normal_(0, math.sqrt(2. / n)) torch.nn.init.kaiming_normal_(m.weight) elif isinstance(m, SynchronizedBatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_()def build_aspp(backbone, output_stride, BatchNorm): return ASPP(backbone, output_stride, BatchNorm) Decoder：编解码器 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import mathimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom modeling.sync_batchnorm.batchnorm import SynchronizedBatchNorm2dclass Decoder(nn.Module): def __init__(self, num_classes, backbone, BatchNorm): super(Decoder, self).__init__() if backbone == &#x27;resnet&#x27; or backbone == &#x27;drn&#x27;: low_level_inplanes = 256 elif backbone == &#x27;xception&#x27;: low_level_inplanes = 128 elif backbone == &#x27;mobilenet&#x27;: low_level_inplanes = 24 else: raise NotImplementedError # 低级特征融合 降维到48 1x1卷积 self.conv1 = nn.Conv2d(low_level_inplanes, 48, 1, bias=False) self.bn1 = BatchNorm(48) self.relu = nn.ReLU() self.last_conv = nn.Sequential(nn.Conv2d(304, 256, kernel_size=3, stride=1, padding=1, bias=False), BatchNorm(256), nn.ReLU(), nn.Dropout(0.5), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False), BatchNorm(256), nn.ReLU(), nn.Dropout(0.1), nn.Conv2d(256, num_classes, kernel_size=1, stride=1)) self._init_weight() def forward(self, x, low_level_feat): low_level_feat = self.conv1(low_level_feat) low_level_feat = self.bn1(low_level_feat) low_level_feat = self.relu(low_level_feat) x = F.interpolate(x, size=low_level_feat.size()[2:], mode=&#x27;bilinear&#x27;, align_corners=True) x = torch.cat((x, low_level_feat), dim=1) x = self.last_conv(x) return x def _init_weight(self): for m in self.modules(): if isinstance(m, nn.Conv2d): torch.nn.init.kaiming_normal_(m.weight) elif isinstance(m, SynchronizedBatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() elif isinstance(m, nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_()def build_decoder(num_classes, backbone, BatchNorm): return Decoder(num_classes, backbone, BatchNorm) 参考 Review: DeepLabv3+ — Atrous Separable Convolution (Semantic Segmentation) 项目实战 DeepLabV1,V2,V3 Google三大语义分割算法源码解析 语义分割算法之DeepLabV3+论文解读及代码分析","path":"2020/04/14/语义分割算法之DeepLabV3/","date":"04-14","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"}]},{"title":"deeplabv3-空洞卷积(语义分割)","text":"Overview《Rethinking Atrous Convolution for Semantic Image Segmentation》 deeplab-ppt：Rethinking-Atrous-Convolution-for-Semantic-Image-Segmentation 深层卷积神经网络(DCNNs)应用于语义分割的任务，我们考虑了面临的两个挑战： 第一个挑战：连续池化操作或卷积中的stride导致的特征分辨率降低。这使得DCNN能够学习更抽象的特征表示。然而，这种不变性可能会阻碍密集预测任务，因为不变性也导致了详细空间信息的不确定。为了克服这个问题，我们提倡使用空洞卷积。 第二个挑战：多尺度物体的存在。几种方法已经被提出来处理这个问题，在本文中我们主要考虑了这些工作中的四种类型，如图所示。 第一种：Image Pyramid，将输入图片放缩成不同比例，分别应用在DCNN上，将预测结果融合得到最终输出 第二种：Encoder-Decoder，将Encoder阶段的多尺度特征运用到Decoder阶段上来恢复空间分辨率 第三种：在原始模型的顶端叠加额外的模块，以捕捉像素间长距离信息。例如Dense CRF，或者叠加一些其他的卷积层 第四种：Spatial Pyramid Pooling空间金字塔池化，使用不同采样率和多种视野的卷积核，以捕捉多尺度对象 Deeplabv3的主要创新点就是改进了ASPP模块，一个1x1的卷积和3个3x3的空洞卷积，每个卷积核有256个且都有BN层，包含图像及特征（全局平均池化）。 提出了更通用的框架，适用于任何网络； 复制了resnet最后的block，并级联起来 在ASPP中使用BN层 没有随机向量场 在DeepLabv1和DeepLabv2发表之后，作者试图去重新构造DeepLab结构，并最终提出了一个更加强大的结构DeepLabv3。甚至去掉在DeepLabv1和DeepLabv2中使用的后处理过程(条件随机场)，DeepLabv3的表现依然超过了DeepLabv1和DeepLabv2。 因此，论文的名称叫做“针对图像语义分割的空洞卷积网络重构”。使用“重构”这个词，就是在致敬Inception-v3，Inception-v3的原文章名称就叫“ Rethinking the Inception Architecture for Computer Vision ”，inception-v3是在Inception-v1和inception-v2的基础上重新构造而得的。现在，DeepLabv2被重构成DeepLabv3。它是一份2017年ARXIV的技术报告，超过200次引用。 大纲 空洞卷积 使用多网格的深层空洞卷积 Atrous空间金字塔 在 PASCAL VOC 2012 进行验证 和PASCAL VOC 2012上最优的方法进行比较 和Cityscape上最优秀的方法进行比较 空洞卷积不同扩张率r的空洞卷积： 对于输出y上的每个位置$i$以及滤波核，空洞卷积应用在输入特征$x$上，扩张率$r$和对输入信号的采样步长相关. 这相当于在输入$x$上进行上采样，在空间维度连续两个元素之间插入r-1个0 当r=1时这就是一个标准的卷积了 通过调整r，我们可以调整滤波器的视野 他也被称之为扩张卷积(扩张网络)或空洞算法 上面：标准卷积 下面：Atrous卷积(空洞卷积)。我们可以看到不当rate=2时，信号时交替采样的。首先pad=2意味这在边界的两边会加上2个0。又因为rate=2，我们对输入的信号每2个进行抽样计算卷积。Atrous卷积允许我们去拓宽感受野，关联更多的上下文信息。因此它给我们提供了 一个高效的控制感受野的机制，能更好的在精确定位(小的感受野)和上下文语义相关性(达的感受野)之间找到平衡。 使用多网格(Multi Grid)的深层空洞卷积 (a)、非空洞卷积：标准卷积和池化使得输出维度的缩小倍数增加，如：当层次增加时输出特征维度变小。然而特征维度不断的缩小对语义分割是不利的，因为位置和空间信息在深层次中丢失的太多了。 (b)、空洞卷积：使用空洞卷积，我们可以保持步幅不变，在不增加参数数量的情况下获得更大的感受野。最终，我们可以得到更大的输出特征，这个对与语义分割是非常好的。 举个例子，当输出的缩小倍数stride=16时，多个网格为(1,2,4)，三个卷积的空洞率为rates =2X(1,2,4)=(2,4,8)。 Atrous空间金字塔池(ASPP) ASPP 已经被用在DeepLabv2了。这次，来自Inception-v2的批量归一化(BN)也会引入到ASPP中。 使用ASPP的原因是，发现随着扩张率增加，有效的滤波权重会变小（相同个数的权重被应用到较大的视野范围中）。 一个1X1的卷积和三个扩张率为(6,12,18)的3X3的卷积核，输出的缩小倍数为16。 都使用256个滤波器和批量归一化(BN)。 当输出的缩小倍数为8时，扩张率是加倍的。 所有分支连接起来先通过另一个1X1的卷积(256个滤波器和批量归一化)，最后使用1X1的卷积核卷积产生概率值。 Upsampling Logits 在DeepLabv2中，训练过程中，真实目标被下采样了8倍。 在DeepLabv3中，发现，最重要的是保证真实背景的完整性，而不是对最终值的上采样。 图像金字塔(Image pyramid)同样的模型，通常使用共享权重，使用多尺度的输入。小尺寸的输入特征响对应长距离语义，大尺寸输入的相应修正细节。通过拉普拉斯金字塔对输入图像进行变换，将不同尺度的图片输入到DCNN，并将所有比例的特征图合并。有人将多尺度输入按顺序从粗到细依次应用，也有人直接将输入调整成不同的大小，并融合所有大小的特征。这类模型的主要缺点是由于GPU内存，较大/更深的DCNN不方便应用，因此通常在推理阶段应用。 编码器-解码器(Encoder-decoder) 该模型由两部分组成： (a)编码器中，特征映射的空间维度逐渐减小，从而更容易捕获较长范围内的信息； (b)解码器中，目标细节和空间维度逐渐恢复。例如，有人反卷积来学习对低分辨率特征响应进行上采样。SegNet复用编码器中的池化索引，学习额外的卷积层来平滑特征响应；U-net将编码器中的特征层通过跳跃连接添加到相应的解码器激活层中；LRR使用了一个拉普拉斯金字塔重建网络。最近，RefineNet等证明了基于编码-解码结构的有效性。这类模型也在对象检测的领域得到了应用。 在PASCAL VOC 2012上进行实验验证Output Stride 使用带空洞卷积的ResNet-50模型，在不同的下采样倍数条件下的平均交并比(mIOU)的对比 当使用的ResNet-50，如上面表格所示，这种情况下输出下采样256倍时表现是最糟糕的。 当输出维度变大时使用空洞卷积，mIou从20.29%增加到了75.18%。这显示了，当使用更多的blocks级联时，空洞卷积是必不可少的。 ResNet-101 ResNet-50 vs ResNet-101 : ResNet-101的平均交并比始终比ResNet-50高。 显然，7层网络之后ResNet-50下平均交并比轻微下降而ResNet-101效果仍在上升。 Multi-Grid受到了采用不同大小网格层次结构的多重网格方法的启发，我们提出的模型在block4和block7中采用了不同的空洞率。 特别的，我们定义Multi_Grid =(r1, r2, r3) 为block4到block7内三个卷积层的unit rates。卷积层的最终空洞率等于unit rate和corresponding rate的乘积。例如，当output_stride = 16 ，Multi_Grid = (1, 2, 4)，三个卷积就会在block4有 rates = 2 · (1, 2, 4) = (2, 4, 8) 。 Employing multi-grid method for ResNet-101 with different number of cascaded blocks at output stride = 16. 当输出缩小倍数为16时，采用多层网格的ResNet-101在不同串联块数下的平均交并比。 一般情况下，采用多层网格方法效果要好于采用（r1,r2,r3）=(1,1,1)的单一网格方法。 仅加倍单位扩张率（例如（r1,r2,r3）=(2,2,2)）并不会增强分割效果。在多层网格下加深网络层数可以增强分割表现。 最佳模型的结构是采用7层网络，且（r1,r2,r3）=（1，2，1）。增加网络的深度配合multi-grid可以提升网络的性能。 Inference Strategy 在数据集上的测试方案：MG：multi grid。OS：output stride。MS：在测试过程中的多尺度输入。Flip：对输入图片添加左右翻转操作。 模型训练时的 output stride 是16。 测试时，可以得到更多特征细节的 output stride 8相较于 output stride 16，平均交并比提升了1.39%。 当同时使用多尺度输入如{0.5，0.75，1.0，1.25，1.5，1.75}和左右翻转输入图片操作时，效果提升到79.35%。 ASPP 当output stride为16时，不同空洞卷积池化操作及多层网格参数的平均交并比结果对比。 ParseNet下的图像池化或者图像层级特征也是考虑到全局上下文信息。 当采用ASPP=(6,12,18)时，多层网格结构（1，2，4）效果要优于（1，1，1）和（1，2，1）。 采用ASPP（6，12，18）效果优于ASPP=（6，12，18，24）。 采用池化操作，平均交并比可以提升到77.21%。 Crop Size, Upsampling Logits, Batch Norm, Batch Size, Train &amp; Test Output Stride裁切大小，上采样，批量归一化，批次大小，训练和测试的输出步长 使用更大的裁剪大小为513结果要好裁剪大小为321. 采用上采样和批量归一化，精度达到77.21%。 批次大小分别设置4,8,12,16，其中16结果最好。 训练和测试集的输出步长为（8,8）时精度为77.21%，而使用步长为（16,8）时，精度为78.51%。 采用所有技巧 MG(1, 2, 4) + ASPP(6, 12, 18) + Image Pooling：精度为77.21%. 输出步长为8时，精度为78.51%。 多尺度测试，精度为79.45%。 水平翻转，精度为79.77%。 采用COCO数据集预训练，精度为82.7%。 经过对网络的重新构建，没有使用之前在DeepLabv2中采用的条件随机场后处理，精度已经超过了采用COCO数据集预训练和条件随机场的精度, 其精度为77.69%。 Comparison with State-of-the-art ApproachesPASCAL VOC 2012 Test Set DeepLabv3：在PASCAL VOC 2012训练验证集上微调，输出步长8，在困难样本上采取bootstrapping方法。特别是包含困难类别的进行复制，到达精度85.7%。 上面示例图显示了bootstrapping方法在困难样本上的效果，提升了稀少样本如自行车等类别的精度和分割效果。 DeepLabv3分割效果优于PSPNet,而后者是ILSVRC 2016场景分割比赛中的冠军。 deepLabv3-JFT采用了在ImageNet和JFT-300M数据集上训练的ResNet101权重模型，达到精度为86.9%。 PASCAL VOC 2012量化结果（最后一行，失败的例子） 在Cityscape数据集上表现最佳的方法对比Different Settings 类似于测试时采用output stride 8，多尺度输入和水平翻转操作的PASCAL VOC 2012数据集，平均交并比逐渐提升。 Cityscape 测试集 测试集为了在对比中获得更佳的效果，DeepLabv3在粗糙训练集中进一步训练（例如，3475张精确标记的图片和额外的20000张粗略标记的图片）。 在测试过程中，要求多尺度输入和精确维度输出。其中，输入尺度范围为{0.75，1，1.25，1.5，1.75，2}，并且评估输出维度为4，这在验证集中分别贡献了0.8%和0.1%的提升。 最后，在测试集中达到了81.3%的平均交并比，这稍高于PSPNet。 在cityspace中的分割结果： DeepLabv3仅比PSPNet效果高一点，这可能也是为什么它在arXiv中仅作为技术报告。但是后来提出的DeepLabv3+远优于DeepLabv3。希望后续有机会可以学习DeepLabv3+。 结论提出的模型DeepLab V3采用atrous convolution的上采样滤波器提取稠密特征映射和去捕获大范围的上下文信息。具体来说，编码多尺度信息，提出了级联模块逐步翻倍的atrous rates，提出了ASPP模块增强图像级的特征，探讨了多采样率和有效视场下的滤波器特性。实验结果表明，该模型在Pascal voc 2012语义图像分割基准上比以前的DeppLab版本有了明显的改进，并取得了SOAT精度。 参考 https://zhuanlan.zhihu.com/p/40470298 https://towardsdatascience.com/review-deeplabv3-atrous-convolution-semantic-segmentation-6d818bfd1d74 https://www.yanxishe.com/TextTranslation/1536 https://www.yanxishe.com/columnDetail/15197","path":"2020/04/09/deeplabv3-空洞卷积-语义分割/","date":"04-09","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"}]},{"title":"deeplabv1和deeplabv2","text":"来自： review-deeplabv1-deeplabv2-atrous-convolution-semantic-segmentation Overview在本文中，回顾了DeepLabv1和DeepLabv2网络，因为他们都使用带孔卷积 Atrous Convolution和全连接的条件随机场（Conditional Random Field，CRF），除了DeepLabv2有一个额外的技术叫做空间金字塔池化Atous Spatial Pyramid Pooling（ASPP），这是DeepLabv2与DeepLabv1的主要区别。 （当然，还有其他差别，例如：DeepLabv2使用ResNet和VGGNet进行实验，但DeepLabv1仅使用VGGNet。） 上图是DeepLab模型架构。首先，输入图像通过网络中的atrous卷积和ASPP。然后，网络的输出图进行双线性插值bilinearly interpolated，并通过完全连接的CRF来微调结果并获得最终输出。 DeepLabv1和DeepLabv2已经在2015 ICLR和2018 TPAMI上发布。 本文涉及的内容： 带孔卷积 空间金字塔池化 全连接的条件随机场 实验结果 Atrous 卷积“Atrous”这个词确实来自法语“àtrous”意思：洞。因此Atrous conv.也被称为“空洞卷积”。一些论文也称之为”dilated convolution”。它通常用于小波变换，现在它被应用于卷积中以进行深度学习。 下面是atrous卷积的表达式： 1维的带孔卷积（r &gt; 1：atrous卷积，r = 1：标准卷积） 当r = 1时，它是我们通常使用的标准卷积。 当r &gt; 1时，它是一个带孔的卷积，r是在卷积过程中对输入样本进行采样的步幅。 下图说明这一点： 标准卷积（a）空洞卷积（b） atrous卷积的想法很简单。在上图的顶部是标准卷积。 在图(b)，它是一个空洞卷积。我们可以看到，当rate = 2时，输入信号被交替采样。首先，pad = 2 意味着我们在左侧和右侧填充2个零。然后，在 rate = 2的情况下，我们有每2个输入就对输入信号进行采样以进行卷积。因此，在输出端，我们将有5个输出，这使得输出的特征图增大。如果我们还记得FCN一文中，一系列的卷积和池化会使输出特征图非常小，因此最后需要32倍的上采样，这是有些放大过度的上采样。 此外，atrous卷积使我们扩大卷积核filter的视野以包含更大的感受域信息。同时，它提供了一种有效的机制来控制感受野的大小，并找到精确定位（小视野）和通过前后信息修复（大视场）细节之间的最佳平衡。 在DeepLab中，使用VGG-16或ResNet-101，最后一个池化（pool5）或卷积conv5_1的步幅分别设置为1，以避免信号被过度抽取。并且使用rate=2的空洞卷积替换所有后续卷积层。这使得输出变大很多。我们只需要进行8次上采样即可对输出要求的尺寸。并且双线性插值对于8×上采样具有相当好的性能。 带孔空间金字塔池化 (ASPP) 上图是ASPP模型 （ 带孔的空间金字塔池化 ： Atrous Spatial Pyramid Pooling ） 为了分类中间像素（橘色），利用多个不同rate并行的filter，使用了多尺度信息。 ASPP实际上是空间金字塔池的一个版本，其中的概念已经在SPPNet中描述。在ASPP中，在输入特征映射中应用不同rate的并行空洞卷积，并融合在一起。由于同一类的物体在图像中可能有不同的比例，ASPP有助于考虑不同的物体比例，这可以提高准确性。 完全连接的条件随机场(CRF)完全连接的CRF在双线性插值后应用于网络输出上 $x$是像素的标签分配。 $P(x_i)$是在像素$i$处的标签分配的概率。因此，第一项$\\theta_i$是对数概率。对于第二项，$\\theta_{ij}$，它是一个滤波器。当$x_i != x_j$ 时，μ= 1。当$x_i = x_j$时，μ= 0。在括号中，它是两个内核的加权和。第一个核取决于像素值差和像素位置差，这是一种双边的filter。双边滤波器具有保留边缘的特性。第二个内核仅取决于像素位置差异，这是一个高斯滤波器。那些σ和w，通过交叉验证找到。迭代次数为10。 上：得分图（softmax函数前的输入），下图：置信图（softmax函数的输出） 通过10倍的CRF，飞机周围不同颜色的小区域变得平滑起来。 但是，CRF是一个后阶段的处理过程，它使DeepLabv1和DeepLabv2变为不是端到端的学习框架。并且它是不在DeepLabv3和DeepLabv3 +中使用。 结果消融实验 DeepLab-LargeFOV（左：即仅单个atrous conv），DeepLab-ASPP（右，即ASPP） 在PASCAL VOC 2012验证集中使用ResNet-101的每个模型组件的结果 简单使用ResNet-101: 68.72% MSC: 多尺度输入 COCO: 由COCO数据集预训练的模型 Aug: 通过随机缩放（从0.5到1.5）输入图像进行数据增强 LargeFOV: 使用一次空洞卷积上采样的DeepLab模型 ASPP: 使用并行的空洞卷积的DeepLab模型 CRF: 全连接的条件随机场做最后处理 与最先进的方法对比 ​ PASCAL VOC 2012测试集 ​ PASCAL-Context 如上所述测试四个数据集。结果表明，与最先进的方法相比，DeepLabv2具有竞争力。 定性的结果 (Qualitative Results) 但DeepLab也有一些失败的例子，其中自行车和椅子由多个细小的部分组成，如自行车和椅腿的部分： 参考 https://www.leiphone.com/news/201903/4qqzNxc4PaQKMgij.html http://liangchiehchen.com/projects/DeepLab.html https://www.jianshu.com/p/9184455a4bd3","path":"2020/04/09/deeplabv1和deeplabv2/","date":"04-09","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"}]},{"title":"MyBatis配置sqlMapConfig.xml中settings标签错误","text":"错误：在 Mybatis 的配置文件 SqlMapConfig.xml 文件中添加延迟加载的配置。 配置标签的时候运行程序出现以下错误： org.apache.ibatis.exceptions.PersistenceException: Error building SqlSession. Cause: org.apache.ibatis.builder.BuilderException: Error creating document instance. Cause: org.xml.sax.SAXParseException; lineNumber: 54; columnNumber: 17; 元素类型为 “configuration” 的内容必须匹配 “(properties?,settings?,typeAliases?,typeHandlers?,objectFactory?,objectWrapperFactory?,reflectorFactory?,plugins?,environments?,databaseIdProvider?,mappers?)”。 解决天杀的MyBatis。。。我服了， 原来Mybatis的配置节点必须按顺序来，顺序错了就会报以上的错误。 元素类型为 “configuration” 的内容必须匹配 “ (properties?,settings?,typeAliases?,typeHandlers?,objectFactory?,objectWrapperFactory?,reflectorFactory?,plugins?,environments?,databaseIdProvider?,mappers?)&quot;。 应该按照以上顺序来配置configuration里面的设置。 坑。。。","path":"2020/03/31/MyBatis配置sqlMapConfig-xml中settings标签错误/","date":"03-31","excerpt":"","tags":[{"name":"errors","slug":"errors","permalink":"https://castile.github.io/tags/errors/"},{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"}]},{"title":"IDEA搭建MyBatis项目使用jndi异常org.apache.ibatis.builder.BuilderException:Error parsing SQL Mapper Configuration. Cause:java.io.IOException:Could not find resource com/hongliang/dao/UserDao.xml","text":"异常在idea中创建的Maven的webapp工程，使用jndi连接数据库发生了如下错误： 解决方法方法一网上有人说： IDEA的锅：IDEA的Maven是不会编译src的java目录的xml文件，所以在Mybatis的配置文件中找不到xml文件！ 把pom文件拿出来； 把下面这段代码复制到前面去 src/main/java **/*.xml 方法二 mapper resource 这种方式加载不到资源，其他的url class和package都可以，如果想解决问题的话，可以不使用resource这种方式！ 我使用的package方式可以。 方法三 推荐方法二！！！！！！ 参考 https://blog.csdn.net/u010648555/article/details/70880425?depth_1-utm_source=distribute.pc_relevant.none-task https://blog.csdn.net/qq_23184291/article/details/78089115","path":"2020/03/31/idea中MyBatis的JNDI工程错误/","date":"03-31","excerpt":"","tags":[{"name":"errors","slug":"errors","permalink":"https://castile.github.io/tags/errors/"},{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"},{"name":"maven","slug":"maven","permalink":"https://castile.github.io/tags/maven/"}]},{"title":"自定义MyBatis","text":"自定义MyBatis H5版本思维导图","path":"2020/03/27/自定义MyBatis/","date":"03-27","excerpt":"","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"}]},{"title":"第一个MyBatis项目","text":"框架它是我们软件开发中的一套解决方案，不同的框架解决的是不同的问题。 使用框架的好处：框架封装了很多的细节，使开发者可以使用极简的方式实现功能。大大提高开发效率。 三层架构表现层：是用于展示数据的 业务层：是处理业务需求 持久层：是和数据库交互的 持久层技术解决方案 JDBC技术： Connection PreparedStatement ResultSet Spring的JdbcTemplate： Spring中对jdbc的简单封装 Apache的DBUtils： 它和Spring的JdbcTemplate很像，也是对Jdbc的简单封装 以上这些都不是框架，JDBC是规范，Spring的JdbcTemplate和Apache的DBUtils都只是工具类。 MyBatismybatis是一个持久层框架，用java编写的。它封装了jdbc操作的很多细节，使开发者只需要关注sql语句本身，而无需关注注册驱动，创建连接等繁杂过程。它使用了ORM思想实现了结果集的封装。 ORMObject Relational Mappging 对象关系映射 简单的说就是把数据库表和实体类及实体类的属性对应起来，让我们可以操作实体类就实现操作数据库表。 创建Maven工程 填写配置文件pom导入jar包的坐标：mybatis / mysql / log4j / junit 等 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;zhu.hong&lt;/groupId&gt; &lt;artifactId&gt;maven_mybatis&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;LATEST&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;LATEST&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 创建DAO接口在对应的包下创建 123456789101112131415161718package zhu.hong.dao;import zhu.hong.entity.User;import java.util.List;/** * @author Hongliang Zhu * @create 2020-03-26 15:45 */public interface UserDAO &#123; /** * 查询所有操作 * @return */ List&lt;User&gt; findAll();&#125; 添加sqlMapConfig.xml文件在main下的resources下创建sqlMapConfig.xml文件, 对数据库的连接进行配置 123456789101112131415161718192021222324252627282930313233&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!-- Mybatis 主配置文件 --&gt;&lt;configuration&gt;&lt;!-- 配置环境 --&gt; &lt;environments default=&quot;mysql&quot;&gt;&lt;!-- 配置mysql环境 --&gt; &lt;environment id=&quot;mysql&quot;&gt;&lt;!-- 配置事物类型 --&gt; &lt;transactionManager type=&quot;JDBC&quot;&gt;&lt;/transactionManager&gt;&lt;!-- 配置数据源 --&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;!-- 配置连接数据库的4个基本信息 --&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///test?serverTimezone=UTC&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;!-- 指定映射配置文件的位置， 映射配置文件指的是每个dao独立的配置文件--&gt; &lt;mappers&gt; &lt;mapper resource=&quot;zhu/hong/dao/UserDAO.xml&quot;&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; 添加UserDAO.xml配置文件在resources下面创建和main下的相同的目录结构, 添加UserDAO.xml文件。在Mybatis中它把持久层的操作接口名称和映射文件也叫做：Mapper，所以：UserDao 和 UserMapper是一样的 注意里面填写的配置信息：映射配置 映射配置文件的mapper标签的namespace属性的取值必须是dao接口的全限定类。 映射配置文件的操作配置（select），id属性的取值必须是dao接口的方法名 123456789101112&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;zhu.hong.dao.UserDAO&quot;&gt;&lt;!-- 配置查询所有 --&gt; &lt;select id=&quot;findAll&quot; resultType=&quot;zhu.hong.entity.User&quot;&gt; select * from users &lt;/select&gt;&lt;/mapper&gt; resultType=”zhu.hong.entity.User”： 因为需要对结果集封装，所以要指定封装到哪里。 这样配置之后就无需再写DAO接口的实现类了。 测试注意下面的步骤： 12345678910111213141516171819202122232425262728293031323334353637383940414243package zhu.hong.test;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import zhu.hong.dao.UserDAO;import zhu.hong.entity.User;import java.io.InputStream;import java.util.List;/** * @author Hongliang Zhu * @create 2020-03-26 16:02 */public class MyBatisTest &#123; public static void main(String[] args) throws Exception &#123; //1. 读取配置文件 InputStream in = Resources.getResourceAsStream(&quot;SQLMapConfig.xml&quot;); //2. 创建SqlSessionFactory 工厂 SqlSessionFactoryBuilder builder = new SqlSessionFactoryBuilder(); SqlSessionFactory factory = builder.build(in); //3. 使用工厂生产sqlSession对象 SqlSession sqlSession = factory.openSession(); //4. 使用SQLSession创建DAO接口的代理对象 UserDAO userDAO = sqlSession.getMapper(UserDAO.class); //5. 使用代理对象执行方法 List&lt;User&gt; users = userDAO.findAll(); for (User user: users)&#123; System.out.println(user); &#125; //6. 释放资源 sqlSession.close(); in.close(); &#125;&#125; 使用 注解配置使用了注解配置后，UserDAO.xml就没啥用了，可以直接删除，不删除会报错… 在DAO接口方法中使用注解声明 123456789101112131415161718package zhu.hong.dao;import org.apache.ibatis.annotations.Select;import zhu.hong.entity.User;import java.util.List;/** * @author Hongliang Zhu * @create 2020-03-26 15:45 */public interface UserDAO &#123; /** * 查询所有操作 * @return */ @Select(&quot;select * from users&quot;) // select注解 List&lt;User&gt; findAll();&#125; 然后在sqlMapConfig.xml中修改： 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;!-- Mybatis 主配置文件 --&gt;&lt;configuration&gt;&lt;!-- 配置环境 --&gt; &lt;environments default=&quot;mysql&quot;&gt;&lt;!-- 配置mysql环境 --&gt; &lt;environment id=&quot;mysql&quot;&gt;&lt;!-- 配置事物类型 --&gt; &lt;transactionManager type=&quot;JDBC&quot;&gt;&lt;/transactionManager&gt;&lt;!-- 配置数据源 --&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;!-- 配置连接数据库的4个基本信息 --&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.cj.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///test?serverTimezone=UTC&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;123456&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;!-- 指定映射配置文件的位置， 映射配置文件指的是每个dao独立的配置文件--&gt; &lt;mappers&gt;&lt;!-- 如果是使用注解配置的话， 应该指定class文件 --&gt;&lt;!-- &lt;mapper resource=&quot;zhu/hong/dao/UserDAO.xml&quot;&gt;&lt;/mapper&gt;--&gt; &lt;mapper class=&quot;zhu.hong.dao.UserDAO&quot;&gt;&lt;/mapper&gt; &lt;/mappers&gt;&lt;/configuration&gt; 在实际开发中，都是越简便越好，所以都是采用不写dao实现类的方式。不管使用XML还是注解配置。但是Mybatis它是支持写dao实现类的。","path":"2020/03/26/第一个MyBatis项目/","date":"03-26","excerpt":"","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"},{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"}]},{"title":"过滤器和监听器","text":"Filter：过滤器 概念： 生活中的过滤器：净水器,空气净化器，土匪、 web中的过滤器：当访问服务器的资源时，过滤器可以将请求拦截下来，完成一些特殊的功能。 过滤器的作用： 一般用于完成通用的操作。如：登录验证、统一编码处理、敏感字符过滤… 快速入门： 步骤： 定义一个类，实现接口Filter 复写方法 配置拦截路径 web.xml 注解 代码： 过滤器细节： web.xml配置 123456789 &lt;filter&gt; &lt;filter-name&gt;demo1&lt;/filter-name&gt; &lt;filter-class&gt;cn.itcast.web.filter.FilterDemo1&lt;/filter-class&gt; &lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;demo1&lt;/filter-name&gt; &lt;!-- 拦截路径 --&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 过滤器执行流程 执行过滤器 执行放行后的资源 回来执行过滤器放行代码下边的代码 过滤器生命周期方法 init:在服务器启动后，会创建Filter对象，然后调用init方法。只执行一次。用于加载资源 doFilter:每一次请求被拦截资源时，会执行。执行多次 destroy:在服务器关闭后，Filter对象被销毁。如果服务器是正常关闭，则会执行destroy方法。只执行一次。用于释放资源 过滤器配置详解 拦截路径配置： 具体资源路径： /index.jsp 只有访问index.jsp资源时，过滤器才会被执行 拦截目录： /user/* 访问/user下的所有资源时，过滤器都会被执行 后缀名拦截： *.jsp 访问所有后缀名为jsp资源时，过滤器都会被执行 拦截所有资源：/* 访问所有资源时，过滤器都会被执行 拦截方式配置：资源被访问的方式 注解配置： 设置dispatcherTypes属性 REQUEST：默认值。浏览器直接请求资源 FORWARD：转发访问资源 INCLUDE：包含访问资源 ERROR：错误跳转资源 ASYNC：异步访问资源 web.xml配置 设置标签即可 过滤器链(配置多个过滤器) 执行顺序：如果有两个过滤器：过滤器1和过滤器2 1. 过滤器1 2. 过滤器2 3. 资源执行 4. 过滤器2 5. 过滤器1 过滤器先后顺序问题： 注解配置：按照类名的字符串比较规则比较，值小的先执行 如： AFilter 和 BFilter，AFilter就先执行了。 web.xml配置： 谁定义在上边，谁先执行 案例1_登录验证需求：访问资源。验证其是否登录如果登录了，则直接放行。如果没有登录，则跳转到登录页面，提示”您尚未登录，请先登录”。 案例2_敏感词汇过滤 需求： 对录入的数据进行敏感词汇过滤 敏感词汇参考《敏感词汇.txt》 如果是敏感词汇，替换为 *** 分析： 对request对象进行增强。增强获取参数相关方法 放行。传递代理对象 增强对象的功能： 设计模式：一些通用的解决固定问题的方式 装饰模式 代理模式 概念： 真实对象：被代理的对象 代理对象： 代理模式：代理对象代理真实对象，达到增强真实对象功能的目的 实现方式： 静态代理：有一个类文件描述代理模式 动态代理：在内存中形成代理类 实现步骤： 代理对象和真实对象实现相同的接口 代理对象 = Proxy.newProxyInstance(); 使用代理对象调用方法。 增强方法 增强方式： 增强参数列表 增强返回值类型 增强方法体执行逻辑 Listener：监听器 概念：web的三大组件之一。 事件监听机制 事件 ：一件事情 事件源 ：事件发生的地方 监听器 ：一个对象 注册监听：将事件、事件源、监听器绑定在一起。 当事件源上发生某个事件后，执行监听器代码 ServletContextListener:监听ServletContext对象的创建和销毁 方法： void contextDestroyed(ServletContextEvent sce) ：ServletContext对象被销毁之前会调用该方法 void contextInitialized(ServletContextEvent sce) ：ServletContext对象创建后会调用该方法 步骤： 定义一个类，实现ServletContextListener接口 复写方法 配置 web.xml 123 &lt;listener&gt;&lt;listener-class&gt;listener.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; @Weblistener 监听器接口： 一、监听对象创建/销毁的监听器接口 ​ Interface ServletRequestListener 监听request对象的创建或销毁 ​ Interface HttpSessionListener 监听session对象的创建或销毁 ​ Interface ServletContextListener 监听servletContext对象的创建或销毁 二、监听对象属性的变化 ​ Interface ServletRequestAttributeListener 监听request对象属性变化: 添加、移除、修改 ​ Interface HttpSessionAttributeListener 监听session对象属性变化: 添加、移除、修改 Interface ServletContextAttributeListener 监听servletContext对象属性变化 三、session相关监听器 Interface HttpSessionBindingListener 监听对象绑定到session上的事件 Interface HttpSessionActivationListener(了解) 监听session序列化及反序列化的事件","path":"2020/03/24/过滤器和监听器/","date":"03-24","excerpt":"","tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://castile.github.io/tags/JavaWeb/"}]},{"title":"计算机视觉中的注意力机制","text":"计算机视觉中的注意力机制 深度学习中的注意力机制借鉴了人类的注意力思维方式。因此，我们首先简单介绍人类视觉的选择性注意力。视觉注意力机制是人类视觉所特有的大脑信号处理机制。人类视觉通过快速扫描全局图像，获得需要重点关注的目标区域，也就是所说的注意力焦点，然后对这一区域投入更多的注意力资源，以获取更多所需要关注目标的细节信息，从而抑制其它无用信息。这是人类利用有限的注意力资源从大量信息中快速筛选出高价值信息的手段，是人类在长期进化中形成的一种生存机制。人类视觉注意力机制极大地提高了视觉信息处理的效率与准确性。 各种注意力模型： http://element-ui.cn/news/show-23981.aspx https://zhuanlan.zhihu.com/p/79725498 Non-local Neural Networks及自注意力机制思考 分割 ICCV2019: Segmentation论文","path":"2020/03/23/计算机视觉中的注意力机制/","date":"03-23","excerpt":"","tags":[{"name":"Attention","slug":"Attention","permalink":"https://castile.github.io/tags/Attention/"}]},{"title":"GCNet： 当NLNet遇到SENet","text":"概述GCNet: Non-local Networks Meet Squeeze-Excitation Networks and Beyond【CVPR2019】传送地址：https://arxiv.org/pdf/1904.11492.pdf GitHub：https://github.com/xvjiarui/GCNet. Non-Local Network (NLNet) 在捕获长距离依赖关系（ long-range dependency ）方面是一项开创性的工作，它通过在一个位置的计算响应是输入特性图中所有位置的特征的加权总和来获得全局上下文的信息。但是作者发现，对于一副图片，不同的query positions 通过 non-local结构获得的全局上下文信息几乎一样，这让作者对Non-local产生了质疑，Non-Local的参数量和计算量相对来说都比较大，这么费力气去计算响应图，发现每个位置的attention都几乎一致。所以作者提出了一种简化的网络，在准确率差不多的情况下，计算量却降低了，然后作者发现经过他改造后的网络结构和 Squeeze-Excitation Network (SENet) 的结构很相似。把它称作为GCNet(global conntext block)。SENet 的 three steps：1、全局上下文建模；2、channel-wise 依赖关系转换；3、特征融合。 这种GC block是轻量级的，这就可以被运用到backbone网络中，并且可以多层，从而构成一个 GCNet，它通常在各种识别任务的主要基准上都优于简化的NLNet和SENet 。 SENet、Non-local以及本文的GCNet都是想办法获取视频或者image中的long-range dependency ，它们的目的都是尽可能从全局的角度（global context）来理解视频和图像。在卷积神经网络中，单靠传统的卷积层是无法自己做到这一点的（或者说做的不够好），卷积层是在局部邻域（ local neighborhood ）内建立像素关系，其长期依赖关系主要通过深度叠加卷积层来建模 。虽然可以通过不断的加深网络，来达到网络后半部分的神经元的感受野变大，这样计算量大，优化也很困难，达到一种不那么“local”的效果。但这种粗暴的加深网络的做，有如下三个缺点： 不够精巧，参数量、计算量粗暴拼凑出来的。 网络越深，优化难度越大。 不那么”local”并不代表全局，有最大距离的限制。 比如在网络的后半部分，feature map右下角的cell，感受野可能扩大了，但可能还是始终无法获得原图片上左上角的信息(因为卷积操作最大距离的限制)。 non-local 和 SENet 不同查询位置的注意力图几乎是相同的 but surprisingly observe that the attention maps for different query positions are almost the same, indicating only query-independent dependency is learnt. 如下图所示。 二者都是通过从各个位置聚集的相同特征来强化原有特征，但在聚集策略、转换和强化功能上的选择又相互区别。 通过对这些函数的抽象，得到了一个统一简化的NL块和SE块的三步通用框架: (a)上下文建模模块，它将所有位置的特征集合在一起，形成全局上下文特征; (b)特征转换模块，以捕捉各通道之间的相互依存关系; (c)融合模块，将全局上下文特征合并到所有位置的特征中 Long-range dependency modeling 最近的远程依赖关系（Long-range dependency）建模方法可以分为两类。第一种是采用自我注意机制（self-attention）来建立两两关系的模型。第二种方法是对查询无关（ query-independent ）的全局上下文建模 。 Analysis on Non-local Networks既然attention map与具体点的位置无关，一个最直观的反应是，那就不要每一个点单独算一个attention map了。用另外一种同样能够获得全局信息，但一个feature map上的点共用的特征吧。基于此，本文作者提出了简化版的NL(snl)。从网络结构上可以看是如图2的变化： 两个标准任务的两个距离测量结果如表1所示。首先，“input”列中的余弦距离值较大，表明Non-local block的输入特征可以在不同位置上进行识别。但是“output”中的余弦距离值非常小，这表明由Non-local block建模的全局上下文特征对于不同的查询位置几乎是相同的。对于所有实例化，“att”上的两个距离度量值都非常小，这再次验证了来自可视化的观察结果。换句话说，虽然一个Non-local block打算计算特定于每个查询位置的全局上下文，但是训练后的全局上下文实际上是独立于查询位置的。因此，不需要为每个查询位置计算查询特定的全局上下文，从而允许我们简化非本地块 。 GCNet 通过计算一个全局( query-independent )的attention map并共享所有查询位置的global attention map来简化Non-local. 如下图(b),这是简化后的Non-local，一个直观的感觉是block结构确实简化了。 简化后的Non-local公式： 为了进一步降低这个简化块的计算成本，我们应用分配律将$W_v$移出 attention pooling ，即 关键部分在于**+**号后面的变化。Non-local **+号后面的内容与$x_i$有关，因此每一个点 i，需要计算一次。而SNL的表达公式+**号后面的内容已与$x_i$无关，也即计算一次，然后所有位置上共享，也映证了上文所讲的query-independent。 看上图（b），简化后的NL block可以抽象成三个过程： 首先采用1x1的卷积，$W_k$为权值矩阵以及一个softmax函数去获得attention weight，然后将注意力权重汇集到原始图中以获得全局上下文特征。 通过1x1卷积，$W_v$为权重，进行特征转换。 特征融合。 它使用加法将全局上下文特性聚合到每个位置的特征上。 到目前为止，该网络结构还只能称之为SNL。作者对SNL做了一些结构的优化，就变成了最终的GC block。主要有两点： 对于SNL模块中右下角的1x1卷积，它的参数量是CxC 。例如，输入通道是2048，输出通道是2048。则参数量就是4000000。这样会导致该模块不够轻量级，无法插入网络的任意位置。作者是通过一个bottleneck结构来替换。这样参数量可以从CxC 到 2xCxC/r（r通常设置为16）。 参数数量可以减少到原来的SNL块的1/8。 two-level bottleneck 的引入增加了网络优化的难度，因此作者引入了layer norm（作者论文中实验讲，这一加入还是蛮有效的，0.x个点吧）。 GC 公式： 具体地： 这个结构和SENet的结构很像： 这时，作者提出了一个“Global context modeling framework”来抽象这一类结构:就是上面说的三个过程:Context modeling、Transform、Fusion Specifically, our GC block consists of: (a) global attention pooling for context modeling; (b)bottleneck transform to capture channel-wise dependencies; and (c) broadcast element-wise addition for feature fusion. 作者在论文中总结了自己提出的GCNet与SENet网络之间的差异： 1、SENet在融合的时候使用的是rescale，而GCNet使用的是sum。因此&quot;SE recalibrate the importance of channels but inadequately models long-range dependency&quot;。 2、Layer-norm的使用。 3、SE中用于提取全局信息的global pooling 是GCNet global attention pooling的一种特例 4、性能上，优于SENet。 参考 https://blog.csdn.net/u011345885/article/details/96566339 non-local论文地址non-local代码地址gcnet论文地址gcnet代码地址senet论文地址senet代码地址","path":"2020/03/23/GCNet/","date":"03-23","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"Attention","slug":"Attention","permalink":"https://castile.github.io/tags/Attention/"}]},{"title":"Pytorch错误解决","text":"1.writer.add_graph(model, model_input)12from torch.utils.tensorboard import SummaryWriterwriter = SummaryWriter(&#x27;./run/exp&#x27;) 使用TensorBoard对训练可视化，在增加模型的计算图的时候，报了以下错误： 1writer.add_graph(model, [dummy_input, dummy_input,dummy_input], verbose=True) RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same 输入的数据类型与网络参数的类型不符。 查询网上都说： 但是全都是bullshit！！！！！ 正确解决方案： 12dummy_input = torch.rand(2, 3, 378,378)writer.add_graph(model, [dummy_input.cuda(), dummy_input.cuda(), dummy_input.cuda()], verbose=True) 注意：pytorch模型不会记录其输入输出的大小，更不会记录每层输出的尺寸。 所以，tensorbaord需要一个假的数据 data （dummy_input）来探测网络各层输出大小，并指示输入尺寸。","path":"2020/03/19/Pytorch错误解决/","date":"03-19","excerpt":"","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://castile.github.io/tags/Pytorch/"}]},{"title":"Cookie和Session会话技术","text":"会话技术 会话：一次会话中包含多次请求和响应。 ​ 一次会话：浏览器第一次给服务器资源发送请求，会话建立，直到有一方断开为止 功能：在一次会话的范围内的多次请求间，共享数据 方式： 客户端会话技术：Cookie 服务器端会话技术：Session Cookie概念客户端会话技术，将数据保存到客户端 快速入门 使用步骤： 创建Cookie对象，绑定数据 new Cookie(String name, String value) 发送Cookie对象 response.addCookie(Cookie cookie) 获取Cookie，拿到数据 Cookie[] request.getCookies() 实现原理 基于响应头set-cookie和请求头cookie实现 cookie的细节 一次可不可以发送多个cookie? 可以 可以创建多个Cookie对象，使用response调用多次addCookie方法发送cookie即可。 cookie在浏览器中保存多长时间？ 默认情况下，当浏览器关闭后，Cookie数据被销毁 持久化存储： setMaxAge(int seconds) 正数：将Cookie数据写到硬盘的文件中。持久化存储。并指定cookie存活时间，时间到后，cookie文件自动失效 负数：默认值 零：删除cookie信息 cookie能不能存中文？ 在tomcat 8 之前 cookie中不能直接存储中文数据。 需要将中文数据转码—一般采用URL编码(%E3) 在tomcat 8 之后，cookie支持中文数据。特殊字符还是不支持，建议使用URL编码存储，URL解码解析 cookie共享问题？ 假设在一个tomcat服务器中，部署了多个web项目，那么在这些web项目中cookie能不能共享？ 默认情况下cookie不能共享 setPath(String path):设置cookie的获取范围。默认情况下，设置当前的虚拟目录 如果要共享，则可以将path设置为”/“ 不同的tomcat服务器间cookie共享问题？* `setDomain(String path)`:如果设置一级域名相同，那么多个服务器之间`cookie`可以共享 * `setDomain(&quot;.baidu.com&quot;),`那么`tieba.baidu.com`和`news.baidu.com`中`cookie`可以共享 Cookie的特点和作用 cookie存储数据在客户端浏览器 浏览器对于单个cookie 的大小有限制(4kb) 以及 对同一个域名下的总cookie数量也有限制(20个) 作用： cookie一般用于存储少量的不太敏感的数据 在不登录的情况下，完成服务器对客户端的身份识别 案例：记住上一次访问时间 需求： 访问一个Servlet，如果是第一次访问，则提示：您好，欢迎您首次访问。 如果不是第一次访问，则提示：欢迎回来，您上次访问时间为:显示时间字符串 分析： 可以采用Cookie来完成 在服务器中的Servlet判断是否有一个名为lastTime的cookie 有：不是第一次访问 响应数据：欢迎回来，您上次访问时间为:2018年6月10日11:50:20 写回Cookie：lastTime=2018年6月10日11:50:01 没有：是第一次访问 响应数据：您好，欢迎您首次访问 写回Cookie：lastTime=2018年6月10日11:50:01 1234567891011121314// 代码实现： package cn.itcast.cookie; import javax.servlet.ServletException; import javax.servlet.annotation.WebServlet; import javax.servlet.http.Cookie; import javax.servlet.http.HttpServlet; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpServletResponse; import java.io.IOException; import java.net.URLDecoder; import java.net.URLEncoder; import java.text.SimpleDateFormat; import java.util.Date; 123456789101112131415161718192021222324252627282930313233@WebServlet(&quot;/cookieTest&quot;)public class CookieTest extends HttpServlet &#123; protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //设置响应的消息体的数据格式以及编码 response.setContentType(&quot;text/html;charset=utf-8&quot;); //1.获取所有Cookie Cookie[] cookies = request.getCookies(); boolean flag = false;//没有cookie为lastTime //2.遍历cookie数组 if(cookies != null &amp;&amp; cookies.length &gt; 0)&#123; for (Cookie cookie : cookies) &#123; //3.获取cookie的名称 String name = cookie.getName(); //4.判断名称是否是：lastTime if(&quot;lastTime&quot;.equals(name))&#123; //有该Cookie，不是第一次访问 flag = true;//有lastTime的cookie //设置Cookie的value //获取当前时间的字符串，重新设置Cookie的值，重新发送cookie Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy年MM月dd日 HH:mm:ss&quot;); String str_date = sdf.format(date); System.out.println(&quot;编码前：&quot;+str_date); //URL编码 str_date = URLEncoder.encode(str_date,&quot;utf-8&quot;); System.out.println(&quot;编码后：&quot;+str_date); cookie.setValue(str_date); //设置cookie的存活时间 cookie.setMaxAge(60 * 60 * 24 * 30);//一个月 response.addCookie(cookie); 1234567891011121314 //响应数据 //获取Cookie的value，时间 String value = cookie.getValue(); System.out.println(&quot;解码前：&quot;+value); //URL解码： value = URLDecoder.decode(value,&quot;utf-8&quot;); System.out.println(&quot;解码后：&quot;+value); response.getWriter().write(&quot;&lt;h1&gt;欢迎回来，您上次访问时间为:&quot;+value+&quot;&lt;/h1&gt;&quot;); break; &#125; &#125;&#125; 1234567891011121314151617181920if(cookies == null || cookies.length == 0 || flag == false)&#123; //没有，第一次访问 //设置Cookie的value //获取当前时间的字符串，重新设置Cookie的值，重新发送cookie Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy年MM月dd日 HH:mm:ss&quot;); String str_date = sdf.format(date); System.out.println(&quot;编码前：&quot;+str_date); //URL编码 str_date = URLEncoder.encode(str_date,&quot;utf-8&quot;); System.out.println(&quot;编码后：&quot;+str_date); Cookie cookie = new Cookie(&quot;lastTime&quot;,str_date); //设置cookie的存活时间 cookie.setMaxAge(60 * 60 * 24 * 30);//一个月 response.addCookie(cookie); response.getWriter().write(&quot;&lt;h1&gt;您好，欢迎您首次访问&lt;/h1&gt;&quot;);&#125; &#125; protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; this.doPost(request, response); &#125; &#125; Session：主菜概念服务器端会话技术，在一次会话的多次请求间共享数据，将数据保存在服务器端的对象中。HttpSession。 快速入门 获取HttpSession对象： HttpSession session = request.getSession(); 使用HttpSession对象： Object getAttribute(String name) void setAttribute(String name, Object value) void removeAttribute(String name) 原理 Session的实现是依赖于Cookie的。 细节 当客户端关闭后，服务器不关闭，两次获取session是否为同一个？ 默认情况下。不是。 如果需要相同，则可以创建Cookie,键为JSESSIONID，设置最大存活时间，让cookie持久化保存。123Cookie c = new Cookie(&quot;JSESSIONID&quot;,session.getId()); c.setMaxAge(60*60); response.addCookie(c); 客户端不关闭，服务器关闭后，两次获取的session是同一个吗？ 不是同一个，但是要确保数据不丢失。tomcat自动完成以下工作 session的钝化： 在服务器正常关闭之前，将session对象序列化到硬盘上 session的活化： 在服务器启动后，将session文件转化为内存中的session对象即可。 session什么时候被销毁？ 服务器关闭 session对象调用invalidate() 。 session默认失效时间 30分钟 选择性配置修改 30 session的特点 session用于存储一次会话的多次请求的数据，存在服务器端 session可以存储任意类型，任意大小的数据 session与Cookie的区别： session存储数据在服务器端，Cookie在客户端 session没有数据大小限制，Cookie有 session数据安全，Cookie相对于不安全 ​","path":"2020/03/19/会话管理/","date":"03-19","excerpt":"","tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://castile.github.io/tags/JavaWeb/"}]},{"title":"JDBC学习笔记","text":"JDBC核心技术来自于尚硅谷宋红康老师的笔记 第1章：JDBC概述1.1 数据的持久化 持久化(persistence)：把数据保存到可掉电式存储设备中以供之后使用。大多数情况下，特别是企业级应用，数据持久化意味着将内存中的数据保存到硬盘上加以”固化”，而持久化的实现过程大多通过各种关系数据库来完成。 持久化的主要应用是将内存中的数据存储在关系型数据库中，当然也可以存储在磁盘文件、XML数据文件中。 1.2 Java中的数据存储技术 在Java中，数据库存取技术可分为如下几类： JDBC直接访问数据库 JDO (Java Data Object )技术 第三方O/R工具，如Hibernate, Mybatis 等 JDBC是java访问数据库的基石，JDO、Hibernate、MyBatis等只是更好的封装了JDBC。 1.3 JDBC介绍 JDBC(Java Database Connectivity)是一个独立于特定数据库管理系统、通用的SQL数据库存取和操作的公共接口（一组API），定义了用来访问数据库的标准Java类库，（java.sql,javax.sql）使用这些类库可以以一种标准的方法、方便地访问数据库资源。 JDBC为访问不同的数据库提供了一种统一的途径，为开发者屏蔽了一些细节问题。 JDBC的目标是使Java程序员使用JDBC可以连接任何提供了JDBC驱动程序的数据库系统，这样就使得程序员无需对特定的数据库系统的特点有过多的了解，从而大大简化和加快了开发过程。 如果没有JDBC，那么Java程序访问数据库时是这样的： 有了JDBC，Java程序访问数据库时是这样的： 总结如下： 1.4 JDBC体系结构 JDBC接口（API）包括两个层次： 面向应用的API：Java API，抽象接口，供应用程序开发人员使用（连接数据库，执行SQL语句，获得结果）。 面向数据库的API：Java Driver API，供开发商开发数据库驱动程序用。 JDBC是sun公司提供一套用于数据库操作的接口，java程序员只需要面向这套接口编程即可。 不同的数据库厂商，需要针对这套接口，提供不同实现。不同的实现的集合，即为不同数据库的驱动。 ————面向接口编程 1.5 JDBC程序编写步骤 补充：ODBC(Open Database Connectivity，开放式数据库连接)，是微软在Windows平台下推出的。使用者在程序中只需要调用ODBC API，由 ODBC 驱动程序将调用转换成为对特定的数据库的调用请求。 第2章：获取数据库连接2.1 要素一：Driver接口实现类2.1.1 Driver接口介绍 java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现。 在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类(java.sql.DriverManager)去调用这些Driver实现。 Oracle的驱动：oracle.jdbc.driver.OracleDriver mySql的驱动： com.mysql.jdbc.Driver 将上述jar包拷贝到Java工程的一个目录中，习惯上新建一个lib文件夹。 在驱动jar上右键–&gt;Build Path–&gt;Add to Build Path 注意：如果是Dynamic Web Project（动态的web项目）话，则是把驱动jar放到WebContent（有的开发工具叫WebRoot）目录中的WEB-INF目录中的lib目录下即可 2.1.2 加载与注册JDBC驱动 加载驱动：加载 JDBC 驱动需调用 Class 类的静态方法 forName()，向其传递要加载的 JDBC 驱动的类名 Class.forName(“com.mysql.jdbc.Driver”); 注册驱动：DriverManager 类是驱动程序管理器类，负责管理驱动程序 使用DriverManager.registerDriver(com.mysql.jdbc.Driver)来注册驱动 通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类都包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例。下图是MySQL的Driver实现类的源码： 2.2 要素二：URL JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。 JDBC URL的标准由三部分组成，各部分间用冒号分隔。 jdbc:子协议:子名称 协议：JDBC URL中的协议总是jdbc 子协议：子协议用于标识一个数据库驱动程序 子名称：一种标识数据库的方法。子名称可以依不同的子协议而变化，用子名称的目的是为了定位数据库提供足够的信息。包含主机名(对应服务端的ip地址)，端口号，数据库名 举例： 几种常用数据库的 JDBC URL MySQL的连接URL编写方式： jdbc:mysql://主机名称:mysql服务端口号/数据库名称?参数=值&amp;参数=值 jdbc:mysql://localhost:3306/atguigu jdbc:mysql://localhost:3306/atguigu**?useUnicode=true&amp;characterEncoding=utf8**（如果JDBC程序与服务器端的字符集不一致，会导致乱码，那么可以通过参数指定服务器端的字符集） jdbc:mysql://localhost:3306/atguigu?user=root&amp;password=123456 Oracle 9i的连接URL编写方式： jdbc:oracle:thin:@主机名称:oracle服务端口号:数据库名称 jdbc:oracle:thin:@localhost:1521:atguigu SQLServer的连接URL编写方式： jdbc:sqlserver://主机名称:sqlserver服务端口号:DatabaseName=数据库名称 jdbc:sqlserver://localhost:1433:DatabaseName=atguigu 2.3 要素三：用户名和密码 user,password可以用“属性名=属性值”方式告诉数据库 可以调用 DriverManager 类的 getConnection() 方法建立到数据库的连接 2.4 数据库连接方式举例2.4.1 连接方式一12345678910111213141516171819202122@Test public void testConnection1() &#123; try &#123; //1.提供java.sql.Driver接口实现类的对象 Driver driver = null; driver = new com.mysql.jdbc.Driver(); //2.提供url，指明具体操作的数据 String url = &quot;jdbc:mysql://localhost:3306/test&quot;; //3.提供Properties的对象，指明用户名和密码 Properties info = new Properties(); info.setProperty(&quot;user&quot;, &quot;root&quot;); info.setProperty(&quot;password&quot;, &quot;abc123&quot;); //4.调用driver的connect()，获取连接 Connection conn = driver.connect(url, info); System.out.println(conn); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; 说明：上述代码中显式出现了第三方数据库的API 2.4.2 连接方式二123456789101112131415161718192021222324@Test public void testConnection2() &#123; try &#123; //1.实例化Driver String className = &quot;com.mysql.jdbc.Driver&quot;; Class clazz = Class.forName(className); Driver driver = (Driver) clazz.newInstance(); //2.提供url，指明具体操作的数据 String url = &quot;jdbc:mysql://localhost:3306/test&quot;; //3.提供Properties的对象，指明用户名和密码 Properties info = new Properties(); info.setProperty(&quot;user&quot;, &quot;root&quot;); info.setProperty(&quot;password&quot;, &quot;abc123&quot;); //4.调用driver的connect()，获取连接 Connection conn = driver.connect(url, info); System.out.println(conn); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 说明：相较于方式一，这里使用反射实例化Driver，不在代码中体现第三方数据库的API。体现了面向接口编程思想。 2.4.3 连接方式三12345678910111213141516171819202122@Test public void testConnection3() &#123; try &#123; //1.数据库连接的4个基本要素： String url = &quot;jdbc:mysql://localhost:3306/test&quot;; String user = &quot;root&quot;; String password = &quot;abc123&quot;; String driverName = &quot;com.mysql.jdbc.Driver&quot;; //2.实例化Driver Class clazz = Class.forName(driverName); Driver driver = (Driver) clazz.newInstance(); //3.注册驱动 DriverManager.registerDriver(driver); //4.获取连接 Connection conn = DriverManager.getConnection(url, user, password); System.out.println(conn); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 说明：使用DriverManager实现数据库的连接。体会获取连接必要的4个基本要素。 2.4.4 连接方式四12345678910111213141516171819202122232425262728293031323334353637@Test public void testConnection4() &#123; try &#123; //1.数据库连接的4个基本要素： String url = &quot;jdbc:mysql://localhost:3306/test&quot;; String user = &quot;root&quot;; String password = &quot;abc123&quot;; String driverName = &quot;com.mysql.jdbc.Driver&quot;; //2.加载驱动 （①实例化Driver ②注册驱动） Class.forName(driverName); //Driver driver = (Driver) clazz.newInstance(); //3.注册驱动 //DriverManager.registerDriver(driver); /* 可以注释掉上述代码的原因，是因为在mysql的Driver类中声明有： static &#123; try &#123; DriverManager.registerDriver(new Driver()); &#125; catch (SQLException var1) &#123; throw new RuntimeException(&quot;Can&#x27;t register driver!&quot;); &#125; &#125; */ //3.获取连接 Connection conn = DriverManager.getConnection(url, user, password); System.out.println(conn); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; 说明：不必显式的注册驱动了。因为在DriverManager的源码中已经存在静态代码块，实现了驱动的注册。 2.4.5 连接方式五(最终版)123456789101112131415161718192021@Test public void testConnection5() throws Exception &#123; //1.加载配置文件 InputStream is = ConnectionTest.class.getClassLoader().getResourceAsStream(&quot;jdbc.properties&quot;); Properties pros = new Properties(); pros.load(is); //2.读取配置信息 String user = pros.getProperty(&quot;user&quot;); String password = pros.getProperty(&quot;password&quot;); String url = pros.getProperty(&quot;url&quot;); String driverClass = pros.getProperty(&quot;driverClass&quot;); //3.加载驱动 Class.forName(driverClass); //4.获取连接 Connection conn = DriverManager.getConnection(url,user,password); System.out.println(conn); &#125; 其中，配置文件声明在工程的src目录下：【jdbc.properties】 1234user=rootpassword=abc123url=jdbc:mysql://localhost:3306/testdriverClass=com.mysql.jdbc.Driver 说明：使用配置文件的方式保存配置信息，在代码中加载配置文件 使用配置文件的好处： ①实现了代码和数据的分离，如果需要修改配置信息，直接在配置文件中修改，不需要深入代码②如果修改了配置信息，省去重新编译的过程。 第3章：使用PreparedStatement实现CRUD操作3.1 操作和访问数据库 数据库连接被用于向数据库服务器发送命令和 SQL 语句，并接受数据库服务器返回的结果。其实一个数据库连接就是一个Socket连接。 在 java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式： Statement：用于执行静态 SQL 语句并返回它所生成结果的对象。 PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句。 CallableStatement：用于执行 SQL 存储过程 3.2 使用Statement操作数据表的弊端 通过调用 Connection 对象的 createStatement() 方法创建该对象。该对象用于执行静态的 SQL 语句，并且返回执行结果。 Statement 接口中定义了下列方法用于执行 SQL 语句： 12int excuteUpdate(String sql)：执行更新操作INSERT、UPDATE、DELETEResultSet executeQuery(String sql)：执行查询操作SELECT 但是使用Statement操作数据表存在弊端： 问题一：存在拼串操作，繁琐 问题二：存在SQL注入问题 SQL 注入是利用某些系统没有对用户输入的数据进行充分的检查，而在用户输入数据中注入非法的 SQL 语句段或命令(如：SELECT user, password FROM user_table WHERE user=’a’ OR 1 = ‘ AND password = ‘ OR ‘1’ = ‘1’) ，从而利用系统的 SQL 引擎完成恶意行为的做法。 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。 代码演示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110public class StatementTest &#123; // 使用Statement的弊端：需要拼写sql语句，并且存在SQL注入的问题 @Test public void testLogin() &#123; Scanner scan = new Scanner(System.in); System.out.print(&quot;用户名：&quot;); String userName = scan.nextLine(); System.out.print(&quot;密 码：&quot;); String password = scan.nextLine(); // SELECT user,password FROM user_table WHERE USER = &#x27;1&#x27; or &#x27; AND PASSWORD = &#x27;=&#x27;1&#x27; or &#x27;1&#x27; = &#x27;1&#x27;; String sql = &quot;SELECT user,password FROM user_table WHERE USER = &#x27;&quot; + userName + &quot;&#x27; AND PASSWORD = &#x27;&quot; + password + &quot;&#x27;&quot;; User user = get(sql, User.class); if (user != null) &#123; System.out.println(&quot;登陆成功!&quot;); &#125; else &#123; System.out.println(&quot;用户名或密码错误！&quot;); &#125; &#125; // 使用Statement实现对数据表的查询操作 public &lt;T&gt; T get(String sql, Class&lt;T&gt; clazz) &#123; T t = null; Connection conn = null; Statement st = null; ResultSet rs = null; try &#123; // 1.加载配置文件 InputStream is = StatementTest.class.getClassLoader().getResourceAsStream(&quot;jdbc.properties&quot;); Properties pros = new Properties(); pros.load(is); // 2.读取配置信息 String user = pros.getProperty(&quot;user&quot;); String password = pros.getProperty(&quot;password&quot;); String url = pros.getProperty(&quot;url&quot;); String driverClass = pros.getProperty(&quot;driverClass&quot;); // 3.加载驱动 Class.forName(driverClass); // 4.获取连接 conn = DriverManager.getConnection(url, user, password); st = conn.createStatement(); rs = st.executeQuery(sql); // 获取结果集的元数据 ResultSetMetaData rsmd = rs.getMetaData(); // 获取结果集的列数 int columnCount = rsmd.getColumnCount(); if (rs.next()) &#123; t = clazz.newInstance(); for (int i = 0; i &lt; columnCount; i++) &#123; // //1. 获取列的名称 // String columnName = rsmd.getColumnName(i+1); // 1. 获取列的别名 String columnName = rsmd.getColumnLabel(i + 1); // 2. 根据列名获取对应数据表中的数据 Object columnVal = rs.getObject(columnName); // 3. 将数据表中得到的数据，封装进对象 Field field = clazz.getDeclaredField(columnName); field.setAccessible(true); field.set(t, columnVal); &#125; return t; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭资源 if (rs != null) &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (st != null) &#123; try &#123; st.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; 综上： 3.3 PreparedStatement的使用3.3.1 PreparedStatement介绍 可以通过调用 Connection 对象的 preparedStatement(String sql) 方法获取 PreparedStatement 对象 PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句 PreparedStatement 对象所代表的 SQL 语句中的参数用问号(?)来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数. setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值 3.3.2 PreparedStatement vs Statement 代码的可读性和可维护性。 PreparedStatement 能最大可能提高性能： DBServer会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。 在statement语句中,即使是相同操作但因为数据内容不一样,所以整个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存。这样每执行一次都要对传入的语句编译一次。 (语法检查，语义检查，翻译成二进制命令，缓存) PreparedStatement 可以防止 SQL 注入 3.3.3 Java与SQL对应数据类型转换表 Java类型 SQL类型 boolean BIT byte TINYINT short SMALLINT int INTEGER long BIGINT String CHAR,VARCHAR,LONGVARCHAR byte array BINARY , VAR BINARY java.sql.Date DATE java.sql.Time TIME java.sql.Timestamp TIMESTAMP 3.3.4 使用PreparedStatement实现增、删、改操作1234567891011121314151617181920212223242526//通用的增、删、改操作（体现一：增、删、改 ； 体现二：针对于不同的表）public void update(String sql,Object ... args)&#123; Connection conn = null; PreparedStatement ps = null; try &#123; //1.获取数据库的连接 conn = JDBCUtils.getConnection(); //2.获取PreparedStatement的实例 (或：预编译sql语句) ps = conn.prepareStatement(sql); //3.填充占位符 for(int i = 0;i &lt; args.length;i++)&#123; ps.setObject(i + 1, args[i]); &#125; //4.执行sql语句 ps.execute(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally&#123; //5.关闭资源 JDBCUtils.closeResource(conn, ps); &#125;&#125; 3.3.5 使用PreparedStatement实现查询操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 通用的针对于不同表的查询:返回一个对象 (version 1.0)public &lt;T&gt; T getInstance(Class&lt;T&gt; clazz, String sql, Object... args) &#123; Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try &#123; // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.预编译sql语句，得到PreparedStatement对象 ps = conn.prepareStatement(sql); // 3.填充占位符 for (int i = 0; i &lt; args.length; i++) &#123; ps.setObject(i + 1, args[i]); &#125; // 4.执行executeQuery(),得到结果集：ResultSet rs = ps.executeQuery(); // 5.得到结果集的元数据：ResultSetMetaData ResultSetMetaData rsmd = rs.getMetaData(); // 6.1通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值 int columnCount = rsmd.getColumnCount(); if (rs.next()) &#123; T t = clazz.newInstance(); for (int i = 0; i &lt; columnCount; i++) &#123;// 遍历每一个列 // 获取列值 Object columnVal = rs.getObject(i + 1); // 获取列的别名:列的别名，使用类的属性名充当 String columnLabel = rsmd.getColumnLabel(i + 1); // 6.2使用反射，给对象的相应属性赋值 Field field = clazz.getDeclaredField(columnLabel); field.setAccessible(true); field.set(t, columnVal); &#125; return t; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 7.关闭资源 JDBCUtils.closeResource(conn, ps, rs); &#125; return null;&#125; 说明：使用PreparedStatement实现的查询操作可以替换Statement实现的查询操作，解决Statement拼串和SQL注入问题。 3.4 ResultSet与ResultSetMetaData3.4.1 ResultSet 查询需要调用PreparedStatement 的 executeQuery() 方法，查询结果是一个ResultSet 对象 ResultSet 对象以逻辑表格的形式封装了执行数据库操作的结果集，ResultSet 接口由数据库厂商提供实现 ResultSet 返回的实际上就是一张数据表。有一个指针指向数据表的第一条记录的前面。 ResultSet 对象维护了一个指向当前数据行的游标，初始的时候，游标在第一行之前，可以通过 ResultSet 对象的 next() 方法移动到下一行。调用 next()方法检测下一行是否有效。若有效，该方法返回 true，且指针下移。相当于Iterator对象的 hasNext() 和 next() 方法的结合体。 当指针指向一行时, 可以通过调用 getXxx(int index) 或 getXxx(int columnName) 获取每一列的值。 例如: getInt(1), getString(“name”) 注意：Java与数据库交互涉及到的相关Java API中的索引都从1开始。 ResultSet 接口的常用方法： boolean next() getString() … 3.4.2 ResultSetMetaData 可用于获取关于 ResultSet 对象中列的类型和属性信息的对象 ResultSetMetaData meta = rs.getMetaData(); getColumnName(int column)：获取指定列的名称 getColumnLabel(int column)：获取指定列的别名 getColumnCount()：返回当前 ResultSet 对象中的列数。 getColumnTypeName(int column)：检索指定列的数据库特定的类型名称。 getColumnDisplaySize(int column)：指示指定列的最大标准宽度，以字符为单位。 isNullable(int column)：指示指定列中的值是否可以为 null。 isAutoIncrement(int column)：指示是否自动为指定列进行编号，这样这些列仍然是只读的。 问题1：得到结果集后, 如何知道该结果集中有哪些列 ？ 列名是什么？ ​ 需要使用一个描述 ResultSet 的对象， 即 ResultSetMetaData 问题2：关于ResultSetMetaData 如何获取 ResultSetMetaData： 调用 ResultSet 的 getMetaData() 方法即可 获取 ResultSet 中有多少列：调用 ResultSetMetaData 的 getColumnCount() 方法 获取 ResultSet 每一列的列的别名是什么：调用 ResultSetMetaData 的getColumnLabel() 方法 3.5 资源的释放 释放ResultSet, Statement,Connection。 数据库连接（Connection）是非常稀有的资源，用完后必须马上释放，如果Connection不能及时正确的关闭将导致系统宕机。Connection的使用原则是尽量晚创建，尽量早的释放。 可以在finally中关闭，保证及时其他代码出现异常，资源也一定能被关闭。 3.6 JDBC API小结 两种思想 面向接口编程的思想 ORM思想(object relational mapping) 一个数据表对应一个java类 表中的一条记录对应java类的一个对象 表中的一个字段对应java类的一个属性 sql是需要结合列名和表的属性名来写。注意起别名。 两种技术 JDBC结果集的元数据：ResultSetMetaData 获取列数：getColumnCount() 获取列的别名：getColumnLabel() 通过反射，创建指定类的对象，获取指定的属性并赋值 章节练习练习题1：从控制台向数据库的表customers中插入一条数据，表结构如下： 练习题2：创立数据库表 examstudent，表结构如下： 向数据表中添加如下数据： 代码实现1：插入一个新的student 信息 请输入考生的详细信息 Type:IDCard:ExamCard:StudentName:Location:Grade: 信息录入成功! 代码实现2：在 eclipse中建立 java 程序：输入身份证号或准考证号可以查询到学生的基本信息。结果如下： 代码实现3：完成学生信息的删除功能 第4章 操作BLOB类型字段4.1 MySQL BLOB类型 MySQL中，BLOB是一个二进制大型对象，是一个可以存储大量数据的容器，它能容纳不同大小的数据。 插入BLOB类型的数据必须使用PreparedStatement，因为BLOB类型的数据无法使用字符串拼接写的。 MySQL的四种BLOB类型(除了在存储的最大信息量上不同外，他们是等同的) 实际使用中根据需要存入的数据大小定义不同的BLOB类型。 需要注意的是：如果存储的文件过大，数据库的性能会下降。 如果在指定了相关的Blob类型以后，还报错：xxx too large，那么在mysql的安装目录下，找my.ini文件加上如下的配置参数： max_allowed_packet=16M。同时注意：修改了my.ini文件之后，需要重新启动mysql服务。 4.2 向数据表中插入大数据类型12345678910111213141516171819//获取连接Connection conn = JDBCUtils.getConnection(); String sql = &quot;insert into customers(name,email,birth,photo)values(?,?,?,?)&quot;;PreparedStatement ps = conn.prepareStatement(sql);// 填充占位符ps.setString(1, &quot;徐海强&quot;);ps.setString(2, &quot;xhq@126.com&quot;);ps.setDate(3, new Date(new java.util.Date().getTime()));// 操作Blob类型的变量FileInputStream fis = new FileInputStream(&quot;xhq.png&quot;);ps.setBlob(4, fis);//执行ps.execute(); fis.close();JDBCUtils.closeResource(conn, ps); 4.3 修改数据表中的Blob类型字段1234567891011121314Connection conn = JDBCUtils.getConnection();String sql = &quot;update customers set photo = ? where id = ?&quot;;PreparedStatement ps = conn.prepareStatement(sql);// 填充占位符// 操作Blob类型的变量FileInputStream fis = new FileInputStream(&quot;coffee.png&quot;);ps.setBlob(1, fis);ps.setInt(2, 25);ps.execute();fis.close();JDBCUtils.closeResource(conn, ps); 4.4 从数据表中读取大数据类型123456789101112131415161718192021222324252627282930313233String sql = &quot;SELECT id, name, email, birth, photo FROM customer WHERE id = ?&quot;;conn = getConnection();ps = conn.prepareStatement(sql);ps.setInt(1, 8);rs = ps.executeQuery();if(rs.next())&#123; Integer id = rs.getInt(1); String name = rs.getString(2); String email = rs.getString(3); Date birth = rs.getDate(4); Customer cust = new Customer(id, name, email, birth); System.out.println(cust); //读取Blob类型的字段 Blob photo = rs.getBlob(5); InputStream is = photo.getBinaryStream(); OutputStream os = new FileOutputStream(&quot;c.jpg&quot;); byte [] buffer = new byte[1024]; int len = 0; while((len = is.read(buffer)) != -1)&#123; os.write(buffer, 0, len); &#125; JDBCUtils.closeResource(conn, ps, rs); if(is != null)&#123; is.close(); &#125; if(os != null)&#123; os.close(); &#125; &#125; 第5章 批量插入5.1 批量执行SQL语句当需要成批插入或者更新记录时，可以采用Java的批量更新机制，这一机制允许多条语句一次性提交给数据库批量处理。通常情况下比单独提交处理更有效率 JDBC的批量处理语句包括下面三个方法： addBatch(String)：添加需要批量处理的SQL语句或是参数； executeBatch()：执行批量处理语句； clearBatch():清空缓存的数据 通常我们会遇到两种批量执行SQL语句的情况： 多条SQL语句的批量处理； 一个SQL语句的批量传参； 5.2 高效的批量插入举例：向数据表中插入20000条数据 数据库中提供一个goods表。创建如下： 1234CREATE TABLE goods(id INT PRIMARY KEY AUTO_INCREMENT,NAME VARCHAR(20)); 5.2.1 实现层次一：使用Statement123456Connection conn = JDBCUtils.getConnection();Statement st = conn.createStatement();for(int i = 1;i &lt;= 20000;i++)&#123; String sql = &quot;insert into goods(name) values(&#x27;name_&#x27; + &quot;+ i +&quot;)&quot;; st.executeUpdate(sql);&#125; 5.2.2 实现层次二：使用PreparedStatement12345678910111213141516long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = &quot;insert into goods(name)values(?)&quot;;PreparedStatement ps = conn.prepareStatement(sql);for(int i = 1;i &lt;= 20000;i++)&#123; ps.setString(1, &quot;name_&quot; + i); ps.executeUpdate();&#125; long end = System.currentTimeMillis();System.out.println(&quot;花费的时间为：&quot; + (end - start));//82340 JDBCUtils.closeResource(conn, ps); 5.2.3 实现层次三12345678910111213141516171819202122232425262728293031323334/* * 修改1： 使用 addBatch() / executeBatch() / clearBatch() * 修改2：mysql服务器默认是关闭批处理的，我们需要通过一个参数，让mysql开启批处理的支持。 * ?rewriteBatchedStatements=true 写在配置文件的url后面 * 修改3：使用更新的mysql 驱动：mysql-connector-java-5.1.37-bin.jar * */@Testpublic void testInsert1() throws Exception&#123; long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); String sql = &quot;insert into goods(name)values(?)&quot;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i &lt;= 1000000;i++)&#123; ps.setString(1, &quot;name_&quot; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0)&#123; //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); &#125; &#125; long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start));//20000条：625 //1000000条:14733 JDBCUtils.closeResource(conn, ps);&#125; 5.2.4 实现层次四1234567891011121314151617181920212223242526272829303132333435363738/** 层次四：在层次三的基础上操作* 使用Connection 的 setAutoCommit(false) / commit()*/@Testpublic void testInsert2() throws Exception&#123; long start = System.currentTimeMillis(); Connection conn = JDBCUtils.getConnection(); //1.设置为不自动提交数据 conn.setAutoCommit(false); String sql = &quot;insert into goods(name)values(?)&quot;; PreparedStatement ps = conn.prepareStatement(sql); for(int i = 1;i &lt;= 1000000;i++)&#123; ps.setString(1, &quot;name_&quot; + i); //1.“攒”sql ps.addBatch(); if(i % 500 == 0)&#123; //2.执行 ps.executeBatch(); //3.清空 ps.clearBatch(); &#125; &#125; //2.提交数据 conn.commit(); long end = System.currentTimeMillis(); System.out.println(&quot;花费的时间为：&quot; + (end - start));//1000000条:4978 JDBCUtils.closeResource(conn, ps);&#125; 第6章： 数据库事务6.1 数据库事务介绍 事务：一组逻辑操作单元,使数据从一种状态变换到另一种状态。 事务处理（事务操作）：保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都**被提交(commit)，那么这些修改就永久地保存下来；要么数据库管理系统将放弃所作的所有修改，整个事务回滚(rollback)**到最初状态。 为确保数据库中数据的一致性，数据的操纵应当是离散的成组的逻辑单元：当它全部完成时，数据的一致性可以保持，而当这个单元中的一部分操作失败，整个事务应全部视为错误，所有从起始点以后的操作应全部回退到开始状态。 6.2 JDBC事务处理 数据一旦提交，就不可回滚。 数据什么时候意味着提交？ 当一个连接对象被创建时，默认情况下是自动提交事务：每次执行一个 SQL 语句时，如果执行成功，就会向数据库自动提交，而不能回滚。 关闭数据库连接，数据就会自动的提交。如果多个操作，每个操作使用的是自己单独的连接，则无法保证事务。即同一个事务的多个操作必须在同一个连接下。 JDBC程序中为了让多个 SQL 语句作为一个事务执行： 调用 Connection 对象的 setAutoCommit(false); 以取消自动提交事务 在所有的 SQL 语句都成功执行后，调用 commit(); 方法提交事务 在出现异常时，调用 rollback(); 方法回滚事务 若此时 Connection 没有被关闭，还可能被重复使用，则需要恢复其自动提交状态 setAutoCommit(true)。尤其是在使用数据库连接池技术时，执行close()方法前，建议恢复自动提交状态。 【案例：用户AA向用户BB转账100】 1234567891011121314151617181920212223242526272829303132333435363738public void testJDBCTransaction() &#123; Connection conn = null; try &#123; // 1.获取数据库连接 conn = JDBCUtils.getConnection(); // 2.开启事务 conn.setAutoCommit(false); // 3.进行数据库操作 String sql1 = &quot;update user_table set balance = balance - 100 where user = ?&quot;; update(conn, sql1, &quot;AA&quot;); // 模拟网络异常 //System.out.println(10 / 0); String sql2 = &quot;update user_table set balance = balance + 100 where user = ?&quot;; update(conn, sql2, &quot;BB&quot;); // 4.若没有异常，则提交事务 conn.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); // 5.若有异常，则回滚事务 try &#123; conn.rollback(); &#125; catch (SQLException e1) &#123; e1.printStackTrace(); &#125; &#125; finally &#123; try &#123; //6.恢复每次DML操作的自动提交功能 conn.setAutoCommit(true); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; //7.关闭连接 JDBCUtils.closeResource(conn, null, null); &#125; &#125; 其中，对数据库操作的方法为： 1234567891011121314151617181920//使用事务以后的通用的增删改操作（version 2.0）public void update(Connection conn ,String sql, Object... args) &#123; PreparedStatement ps = null; try &#123; // 1.获取PreparedStatement的实例 (或：预编译sql语句) ps = conn.prepareStatement(sql); // 2.填充占位符 for (int i = 0; i &lt; args.length; i++) &#123; ps.setObject(i + 1, args[i]); &#125; // 3.执行sql语句 ps.execute(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 4.关闭资源 JDBCUtils.closeResource(null, ps); &#125;&#125; 6.3 事务的ACID属性 原子性（Atomicity） 原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 一致性（Consistency） 事务必须使数据库从一个一致性状态变换到另外一个一致性状态。 隔离性（Isolation） 事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。 持久性（Durability） 持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。 6.3.1 数据库的并发问题 对于同时运行的多个事务, 当这些事务访问数据库中相同的数据时, 如果没有采取必要的隔离机制, 就会导致各种并发问题: 脏读: 对于两个事务 T1, T2, T1 读取了已经被 T2 更新但还没有被提交的字段。之后, 若 T2 回滚, T1读取的内容就是临时且无效的。 不可重复读: 对于两个事务T1, T2, T1 读取了一个字段, 然后 T2 更新了该字段。之后, T1再次读取同一个字段, 值就不同了。 幻读: 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表, 就会多出几行。 数据库事务的隔离性: 数据库系统必须具有隔离并发运行各个事务的能力, 使它们不会相互影响, 避免各种并发问题。 一个事务与其他事务隔离的程度称为隔离级别。数据库规定了多种事务隔离级别, 不同隔离级别对应不同的干扰程度, 隔离级别越高, 数据一致性就越好, 但并发性越弱。 6.3.2 四种隔离级别 数据库提供的4种事务隔离级别： Oracle 支持的 2 种事务隔离级别：READ COMMITED, SERIALIZABLE。 Oracle 默认的事务隔离级别为: READ COMMITED 。 Mysql 支持 4 种事务隔离级别。Mysql 默认的事务隔离级别为: REPEATABLE READ。 6.3.3 在MySql中设置隔离级别 每启动一个 mysql 程序, 就会获得一个单独的数据库连接. 每个数据库连接都有一个全局变量 @@tx_isolation, 表示当前的事务隔离级别。 查看当前的隔离级别: 1SELECT @@tx_isolation; 设置当前 mySQL 连接的隔离级别: 1set transaction isolation level read committed; 设置数据库系统的全局的隔离级别: 1set global transaction isolation level read committed; 补充操作： 创建mysql数据库用户： 1create user tom identified by &#x27;abc123&#x27;; 授予权限 123456#授予通过网络方式登录的tom用户，对所有库所有表的全部权限，密码设为abc123.grant all privileges on *.* to tom@&#x27;%&#x27; identified by &#x27;abc123&#x27;; #给tom用户使用本地命令行方式，授予atguigudb这个库下的所有表的插删改查的权限。grant select,insert,delete,update on atguigudb.* to tom@localhost identified by &#x27;abc123&#x27;; 第7章：DAO及相关实现类 DAO：Data Access Object访问数据信息的类和接口，包括了对数据的CRUD（Create、Retrival、Update、Delete），而不包含任何业务相关的信息。有时也称作：BaseDAO 作用：为了实现功能的模块化，更有利于代码的维护和升级。 下面是尚硅谷JavaWeb阶段书城项目中DAO使用的体现： 层次结构： 【BaseDAO.java】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.atguigu.bookstore.dao;import java.lang.reflect.ParameterizedType;import java.lang.reflect.Type;import java.sql.Connection;import java.sql.SQLException;import java.util.List;import org.apache.commons.dbutils.QueryRunner;import org.apache.commons.dbutils.handlers.BeanHandler;import org.apache.commons.dbutils.handlers.BeanListHandler;import org.apache.commons.dbutils.handlers.ScalarHandler;/** * 定义一个用来被继承的对数据库进行基本操作的Dao * * @author HanYanBing * * @param &lt;T&gt; */public abstract class BaseDao&lt;T&gt; &#123; private QueryRunner queryRunner = new QueryRunner(); // 定义一个变量来接收泛型的类型 private Class&lt;T&gt; type; // 获取T的Class对象，获取泛型的类型，泛型是在被子类继承时才确定 public BaseDao() &#123; // 获取子类的类型 Class clazz = this.getClass(); // 获取父类的类型 // getGenericSuperclass()用来获取当前类的父类的类型 // ParameterizedType表示的是带泛型的类型 ParameterizedType parameterizedType = (ParameterizedType) clazz.getGenericSuperclass(); // 获取具体的泛型类型 getActualTypeArguments获取具体的泛型的类型 // 这个方法会返回一个Type的数组 Type[] types = parameterizedType.getActualTypeArguments(); // 获取具体的泛型的类型· this.type = (Class&lt;T&gt;) types[0]; &#125; /** * 通用的增删改操作 * * @param sql * @param params * @return */ public int update(Connection conn,String sql, Object... params) &#123; int count = 0; try &#123; count = queryRunner.update(conn, sql, params); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return count; &#125; /** * 获取一个对象 * * @param sql * @param params * @return */ public T getBean(Connection conn,String sql, Object... params) &#123; T t = null; try &#123; t = queryRunner.query(conn, sql, new BeanHandler&lt;T&gt;(type), params); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return t; &#125; /** * 获取所有对象 * * @param sql * @param params * @return */ public List&lt;T&gt; getBeanList(Connection conn,String sql, Object... params) &#123; List&lt;T&gt; list = null; try &#123; list = queryRunner.query(conn, sql, new BeanListHandler&lt;T&gt;(type), params); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return list; &#125; /** * 获取一个但一值得方法，专门用来执行像 select count(*)...这样的sql语句 * * @param sql * @param params * @return */ public Object getValue(Connection conn,String sql, Object... params) &#123; Object count = null; try &#123; // 调用queryRunner的query方法获取一个单一的值 count = queryRunner.query(conn, sql, new ScalarHandler&lt;&gt;(), params); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return count; &#125;&#125; 【BookDAO.java】123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.atguigu.bookstore.dao;import java.sql.Connection;import java.util.List;import com.atguigu.bookstore.beans.Book;import com.atguigu.bookstore.beans.Page;public interface BookDao &#123; /** * 从数据库中查询出所有的记录 * * @return */ List&lt;Book&gt; getBooks(Connection conn); /** * 向数据库中插入一条记录 * * @param book */ void saveBook(Connection conn,Book book); /** * 从数据库中根据图书的id删除一条记录 * * @param bookId */ void deleteBookById(Connection conn,String bookId); /** * 根据图书的id从数据库中查询出一条记录 * * @param bookId * @return */ Book getBookById(Connection conn,String bookId); /** * 根据图书的id从数据库中更新一条记录 * * @param book */ void updateBook(Connection conn,Book book); /** * 获取带分页的图书信息 * * @param page：是只包含了用户输入的pageNo属性的page对象 * @return 返回的Page对象是包含了所有属性的Page对象 */ Page&lt;Book&gt; getPageBooks(Connection conn,Page&lt;Book&gt; page); /** * 获取带分页和价格范围的图书信息 * * @param page：是只包含了用户输入的pageNo属性的page对象 * @return 返回的Page对象是包含了所有属性的Page对象 */ Page&lt;Book&gt; getPageBooksByPrice(Connection conn,Page&lt;Book&gt; page, double minPrice, double maxPrice);&#125; 【UserDAO.java】12345678910111213141516171819202122232425262728293031package com.atguigu.bookstore.dao;import java.sql.Connection;import com.atguigu.bookstore.beans.User;public interface UserDao &#123; /** * 根据User对象中的用户名和密码从数据库中获取一条记录 * * @param user * @return User 数据库中有记录 null 数据库中无此记录 */ User getUser(Connection conn,User user); /** * 根据User对象中的用户名从数据库中获取一条记录 * * @param user * @return true 数据库中有记录 false 数据库中无此记录 */ boolean checkUsername(Connection conn,User user); /** * 向数据库中插入User对象 * * @param user */ void saveUser(Connection conn,User user);&#125; 【BookDaoImpl.java】1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.atguigu.bookstore.dao.impl;import java.sql.Connection;import java.util.List;import com.atguigu.bookstore.beans.Book;import com.atguigu.bookstore.beans.Page;import com.atguigu.bookstore.dao.BaseDao;import com.atguigu.bookstore.dao.BookDao;public class BookDaoImpl extends BaseDao&lt;Book&gt; implements BookDao &#123; @Override public List&lt;Book&gt; getBooks(Connection conn) &#123; // 调用BaseDao中得到一个List的方法 List&lt;Book&gt; beanList = null; // 写sql语句 String sql = &quot;select id,title,author,price,sales,stock,img_path imgPath from books&quot;; beanList = getBeanList(conn,sql); return beanList; &#125; @Override public void saveBook(Connection conn,Book book) &#123; // 写sql语句 String sql = &quot;insert into books(title,author,price,sales,stock,img_path) values(?,?,?,?,?,?)&quot;; // 调用BaseDao中通用的增删改的方法 update(conn,sql, book.getTitle(), book.getAuthor(), book.getPrice(), book.getSales(), book.getStock(),book.getImgPath()); &#125; @Override public void deleteBookById(Connection conn,String bookId) &#123; // 写sql语句 String sql = &quot;DELETE FROM books WHERE id = ?&quot;; // 调用BaseDao中通用增删改的方法 update(conn,sql, bookId); &#125; @Override public Book getBookById(Connection conn,String bookId) &#123; // 调用BaseDao中获取一个对象的方法 Book book = null; // 写sql语句 String sql = &quot;select id,title,author,price,sales,stock,img_path imgPath from books where id = ?&quot;; book = getBean(conn,sql, bookId); return book; &#125; @Override public void updateBook(Connection conn,Book book) &#123; // 写sql语句 String sql = &quot;update books set title = ? , author = ? , price = ? , sales = ? , stock = ? where id = ?&quot;; // 调用BaseDao中通用的增删改的方法 update(conn,sql, book.getTitle(), book.getAuthor(), book.getPrice(), book.getSales(), book.getStock(), book.getId()); &#125; @Override public Page&lt;Book&gt; getPageBooks(Connection conn,Page&lt;Book&gt; page) &#123; // 获取数据库中图书的总记录数 String sql = &quot;select count(*) from books&quot;; // 调用BaseDao中获取一个单一值的方法 long totalRecord = (long) getValue(conn,sql); // 将总记录数设置都page对象中 page.setTotalRecord((int) totalRecord); // 获取当前页中的记录存放的List String sql2 = &quot;select id,title,author,price,sales,stock,img_path imgPath from books limit ?,?&quot;; // 调用BaseDao中获取一个集合的方法 List&lt;Book&gt; beanList = getBeanList(conn,sql2, (page.getPageNo() - 1) * Page.PAGE_SIZE, Page.PAGE_SIZE); // 将这个List设置到page对象中 page.setList(beanList); return page; &#125; @Override public Page&lt;Book&gt; getPageBooksByPrice(Connection conn,Page&lt;Book&gt; page, double minPrice, double maxPrice) &#123; // 获取数据库中图书的总记录数 String sql = &quot;select count(*) from books where price between ? and ?&quot;; // 调用BaseDao中获取一个单一值的方法 long totalRecord = (long) getValue(conn,sql,minPrice,maxPrice); // 将总记录数设置都page对象中 page.setTotalRecord((int) totalRecord); // 获取当前页中的记录存放的List String sql2 = &quot;select id,title,author,price,sales,stock,img_path imgPath from books where price between ? and ? limit ?,?&quot;; // 调用BaseDao中获取一个集合的方法 List&lt;Book&gt; beanList = getBeanList(conn,sql2, minPrice , maxPrice , (page.getPageNo() - 1) * Page.PAGE_SIZE, Page.PAGE_SIZE); // 将这个List设置到page对象中 page.setList(beanList); return page; &#125;&#125; 【UserDaoImpl.java】123456789101112131415161718192021222324252627282930313233343536373839package com.atguigu.bookstore.dao.impl;import java.sql.Connection;import com.atguigu.bookstore.beans.User;import com.atguigu.bookstore.dao.BaseDao;import com.atguigu.bookstore.dao.UserDao;public class UserDaoImpl extends BaseDao&lt;User&gt; implements UserDao &#123; @Override public User getUser(Connection conn,User user) &#123; // 调用BaseDao中获取一个对象的方法 User bean = null; // 写sql语句 String sql = &quot;select id,username,password,email from users where username = ? and password = ?&quot;; bean = getBean(conn,sql, user.getUsername(), user.getPassword()); return bean; &#125; @Override public boolean checkUsername(Connection conn,User user) &#123; // 调用BaseDao中获取一个对象的方法 User bean = null; // 写sql语句 String sql = &quot;select id,username,password,email from users where username = ?&quot;; bean = getBean(conn,sql, user.getUsername()); return bean != null; &#125; @Override public void saveUser(Connection conn,User user) &#123; //写sql语句 String sql = &quot;insert into users(username,password,email) values(?,?,?)&quot;; //调用BaseDao中通用的增删改的方法 update(conn,sql, user.getUsername(),user.getPassword(),user.getEmail()); &#125;&#125; 【Book.java】1234567891011121314151617package com.atguigu.bookstore.beans;/** * 图书类 * @author songhongkang * */public class Book &#123; private Integer id; private String title; // 书名 private String author; // 作者 private double price; // 价格 private Integer sales; // 销量 private Integer stock; // 库存 private String imgPath = &quot;static/img/default.jpg&quot;; // 封面图片的路径 //构造器，get()，set()，toString()方法略&#125; 【Page.java】12345678910111213141516package com.atguigu.bookstore.beans;import java.util.List;/** * 页码类 * @author songhongkang * */public class Page&lt;T&gt; &#123; private List&lt;T&gt; list; // 每页查到的记录存放的集合 public static final int PAGE_SIZE = 4; // 每页显示的记录数 private int pageNo; // 当前页// private int totalPageNo; // 总页数，通过计算得到 private int totalRecord; // 总记录数，通过查询数据库得到 【User.java】12345678910111213package com.atguigu.bookstore.beans;/** * 用户类 * @author songhongkang * */public class User &#123; private Integer id; private String username; private String password; private String email; 第8章：数据库连接池8.1 JDBC数据库连接池的必要性 在使用开发基于数据库的web程序时，传统的模式基本是按以下步骤： 在主程序（如servlet、beans）中建立数据库连接 进行sql操作 断开数据库连接 这种模式开发，存在的问题: 普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码(得花费0.05s～1s的时间)。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。数据库的连接资源并没有得到很好的重复利用。若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃。 对于每一次数据库连接，使用完后都得断开。否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库。（回忆：何为Java的内存泄漏？） 这种开发不能控制被创建的连接对象数，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 8.2 数据库连接池技术 为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。 数据库连接池的基本思想：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。 数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个。 数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由最小数据库连接数来设定的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的最大数据库连接数量限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。 工作原理： 数据库连接池技术的优点 1. 资源重用 由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。 2. 更快的系统反应速度 数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间 3. 新的资源分配手段 对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源 4. 统一的连接管理，避免数据库连接泄漏 在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露 8.3 多种开源的数据库连接池 JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现： DBCP 是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。速度相对c3p0较快，但因自身存在BUG，Hibernate3已不再提供支持。 C3P0 是一个开源组织提供的一个数据库连接池，速度相对较慢，稳定性还可以。hibernate官方推荐使用 Proxool 是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，稳定性较c3p0差一点 BoneCP 是一个开源组织提供的数据库连接池，速度快 Druid 是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有BoneCP快 DataSource 通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把 DataSource 称为连接池 DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。 特别注意： 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此整个应用只需要一个数据源即可。 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但conn.close()并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。 8.3.1 C3P0数据库连接池 获取连接方式一 12345678910111213//使用C3P0数据库连接池的方式，获取数据库的连接：不推荐public static Connection getConnection1() throws Exception&#123; ComboPooledDataSource cpds = new ComboPooledDataSource(); cpds.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;); cpds.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/test&quot;); cpds.setUser(&quot;root&quot;); cpds.setPassword(&quot;abc123&quot;); // cpds.setMaxPoolSize(100); Connection conn = cpds.getConnection(); return conn;&#125; 获取连接方式二 123456//使用C3P0数据库连接池的配置文件方式，获取数据库的连接：推荐private static DataSource cpds = new ComboPooledDataSource(&quot;helloc3p0&quot;);public static Connection getConnection2() throws SQLException&#123; Connection conn = cpds.getConnection(); return conn;&#125; 其中，src下的配置文件为：【c3p0-config.xml】 12345678910111213141516171819202122232425&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;c3p0-config&gt; &lt;named-config name=&quot;helloc3p0&quot;&gt; &lt;!-- 获取连接的4个基本信息 --&gt; &lt;property name=&quot;user&quot;&gt;root&lt;/property&gt; &lt;property name=&quot;password&quot;&gt;abc123&lt;/property&gt; &lt;property name=&quot;jdbcUrl&quot;&gt;jdbc:mysql:///test&lt;/property&gt; &lt;property name=&quot;driverClass&quot;&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;!-- 涉及到数据库连接池的管理的相关属性的设置 --&gt; &lt;!-- 若数据库中连接数不足时, 一次向数据库服务器申请多少个连接 --&gt; &lt;property name=&quot;acquireIncrement&quot;&gt;5&lt;/property&gt; &lt;!-- 初始化数据库连接池时连接的数量 --&gt; &lt;property name=&quot;initialPoolSize&quot;&gt;5&lt;/property&gt; &lt;!-- 数据库连接池中的最小的数据库连接数 --&gt; &lt;property name=&quot;minPoolSize&quot;&gt;5&lt;/property&gt; &lt;!-- 数据库连接池中的最大的数据库连接数 --&gt; &lt;property name=&quot;maxPoolSize&quot;&gt;10&lt;/property&gt; &lt;!-- C3P0 数据库连接池可以维护的 Statement 的个数 --&gt; &lt;property name=&quot;maxStatements&quot;&gt;20&lt;/property&gt; &lt;!-- 每个连接同时可以使用的 Statement 对象的个数 --&gt; &lt;property name=&quot;maxStatementsPerConnection&quot;&gt;5&lt;/property&gt; &lt;/named-config&gt;&lt;/c3p0-config&gt; 8.3.2 DBCP数据库连接池 DBCP 是 Apache 软件基金组织下的开源连接池实现，该连接池依赖该组织下的另一个开源系统：Common-pool。如需使用该连接池实现，应在系统中增加如下两个 jar 文件： Commons-dbcp.jar：连接池的实现 Commons-pool.jar：连接池实现的依赖库 Tomcat 的连接池正是采用该连接池来实现的。该数据库连接池既可以与应用服务器整合使用，也可由应用程序独立使用。 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此整个应用只需要一个数据源即可。 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但上面的代码并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。 配置属性说明 属性 默认值 说明 initialSize 0 连接池启动时创建的初始化连接数量 maxActive 8 连接池中可同时连接的最大的连接数 maxIdle 8 连接池中最大的空闲的连接数，超过的空闲连接将被释放，如果设置为负数表示不限制 minIdle 0 连接池中最小的空闲的连接数，低于这个数量会被创建新的连接。该参数越接近maxIdle，性能越好，因为连接的创建和销毁，都是需要消耗资源的；但是不能太大。 maxWait 无限制 最大等待时间，当没有可用连接时，连接池等待连接释放的最大时间，超过该时间限制会抛出异常，如果设置-1表示无限等待 poolPreparedStatements false 开启池的Statement是否prepared maxOpenPreparedStatements 无限制 开启池的prepared 后的同时最大连接数 minEvictableIdleTimeMillis 连接池中连接，在时间段内一直空闲， 被逐出连接池的时间 removeAbandonedTimeout 300 超过时间限制，回收没有用(废弃)的连接 removeAbandoned false 超过removeAbandonedTimeout时间后，是否进 行没用连接（废弃）的回收 获取连接方式一： 1234567891011121314public static Connection getConnection3() throws Exception &#123; BasicDataSource source = new BasicDataSource(); source.setDriverClassName(&quot;com.mysql.jdbc.Driver&quot;); source.setUrl(&quot;jdbc:mysql:///test&quot;); source.setUsername(&quot;root&quot;); source.setPassword(&quot;abc123&quot;); // source.setInitialSize(10); Connection conn = source.getConnection(); return conn;&#125; 获取连接方式二： 12345678910111213141516171819202122//使用dbcp数据库连接池的配置文件方式，获取数据库的连接：推荐private static DataSource source = null;static&#123; try &#123; Properties pros = new Properties(); InputStream is = DBCPTest.class.getClassLoader().getResourceAsStream(&quot;dbcp.properties&quot;); pros.load(is); //根据提供的BasicDataSourceFactory创建对应的DataSource对象 source = BasicDataSourceFactory.createDataSource(pros); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;public static Connection getConnection4() throws Exception &#123; Connection conn = source.getConnection(); return conn;&#125; 其中，src下的配置文件为：【dbcp.properties】 1234567driverClassName=com.mysql.jdbc.Driverurl=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true&amp;useServerPrepStmts=falseusername=rootpassword=abc123initialSize=10#... 8.3.3 Druid（德鲁伊）数据库连接池Druid是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，可以说是目前最好的连接池之一。 123456789101112131415161718package com.atguigu.druid;import java.sql.Connection;import java.util.Properties;import javax.sql.DataSource;import com.alibaba.druid.pool.DruidDataSourceFactory;public class TestDruid &#123; public static void main(String[] args) throws Exception &#123; Properties pro = new Properties(); pro.load(TestDruid.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;)); DataSource ds = DruidDataSourceFactory.createDataSource(pro); Connection conn = ds.getConnection(); System.out.println(conn); &#125;&#125; 其中，src下的配置文件为：【druid.properties】 123456789url=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=trueusername=rootpassword=123456driverClassName=com.mysql.jdbc.DriverinitialSize=10maxActive=20maxWait=1000filters=wall 详细配置参数： 配置 缺省 说明 name 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。 如果没有配置，将会生成一个名字，格式是：”DataSource-” + System.identityHashCode(this) url 连接数据库的url，不同数据库不一样。例如：mysql : jdbc:mysql://10.20.153.104:3306/druid2 oracle : jdbc:oracle:thin:@10.20.149.85:1521:ocnauto username 连接数据库的用户名 password 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter driverClassName 根据url自动识别 这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) initialSize 0 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 maxActive 8 最大连接池数量 maxIdle 8 已经不再使用，配置了也没效果 minIdle 最小连接池数量 maxWait 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 poolPreparedStatements false 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 maxOpenPreparedStatements -1 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 validationQuery 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 testOnBorrow true 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 testOnReturn false 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 testWhileIdle false 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 timeBetweenEvictionRunsMillis 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详细看testWhileIdle属性的说明 numTestsPerEvictionRun 不再使用，一个DruidDataSource只支持一个EvictionRun minEvictableIdleTimeMillis connectionInitSqls 物理连接初始化的时候执行的sql exceptionSorter 根据dbType自动识别 当数据库抛出一些不可恢复的异常时，抛弃连接 filters 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有： 监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall proxyFilters 类型是List，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 第9章：Apache-DBUtils实现CRUD操作9.1 Apache-DBUtils简介 commons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。 API介绍： org.apache.commons.dbutils.QueryRunner org.apache.commons.dbutils.ResultSetHandler 工具类：org.apache.commons.dbutils.DbUtils API包说明： 9.2 主要API的使用9.2.1 DbUtils DbUtils ：提供如关闭连接、装载JDBC驱动程序等常规工作的工具类，里面的所有方法都是静态的。主要方法如下： public static void close(…) throws java.sql.SQLException： DbUtils类提供了三个重载的关闭方法。这些方法检查所提供的参数是不是NULL，如果不是的话，它们就关闭Connection、Statement和ResultSet。 public static void closeQuietly(…): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。 public static void commitAndClose(Connection conn)throws SQLException： 用来提交连接的事务，然后关闭连接 public static void commitAndCloseQuietly(Connection conn)： 用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断 public static void rollbackAndClose(Connection conn)throws SQLException rollbackAndCloseQuietly(Connection) public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，你不需要捕捉这个异常ClassNotFoundException。 9.2.2 QueryRunner类 该类简单化了SQL查询，它与ResultSetHandler组合在一起使用可以完成大部分的数据库操作，能够大大减少编码量。 QueryRunner类提供了两个构造器： 默认的构造器 需要一个 javax.sql.DataSource 来作参数的构造器 QueryRunner类的主要方法： 更新 public int update(Connection conn, String sql, Object… params) throws SQLException:用来执行一个更新（插入、更新或删除）操作。 …… 插入 public T insert(Connection conn,String sql,ResultSetHandler rsh, Object… params) throws SQLException：只支持INSERT语句，其中 rsh - The handler used to create the result object from the ResultSet of auto-generated keys. 返回值: An object generated by the handler.即自动生成的键值 …. 批处理 public int[] batch(Connection conn,String sql,Object[][] params)throws SQLException： INSERT, UPDATE, or DELETE语句 public T insertBatch(Connection conn,String sql,ResultSetHandler rsh,Object[][] params)throws SQLException：只支持INSERT语句 ….. 查询 public Object query(Connection conn, String sql, ResultSetHandler rsh,Object… params) throws SQLException：执行一个查询操作，在这个查询中，对象数组中的每个元素值被用来作为查询语句的置换参数。该方法会自行处理 PreparedStatement 和 ResultSet 的创建和关闭。 …… 测试 12345678910111213// 测试添加@Testpublic void testInsert() throws Exception &#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = &quot;insert into customers(name,email,birth)values(?,?,?)&quot;; int count = runner.update(conn, sql, &quot;何成飞&quot;, &quot;he@qq.com&quot;, &quot;1992-09-08&quot;); System.out.println(&quot;添加了&quot; + count + &quot;条记录&quot;); JDBCUtils.closeResource(conn, null);&#125; 12345678910111213// 测试删除@Testpublic void testDelete() throws Exception &#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = &quot;delete from customers where id &lt; ?&quot;; int count = runner.update(conn, sql,3); System.out.println(&quot;删除了&quot; + count + &quot;条记录&quot;); JDBCUtils.closeResource(conn, null);&#125; 9.2.3 ResultSetHandler接口及实现类 该接口用于处理 java.sql.ResultSet，将数据按要求转换为另一种形式。 ResultSetHandler 接口提供了一个单独的方法：Object handle (java.sql.ResultSet .rs)。 接口的主要实现类： ArrayHandler：把结果集中的第一行数据转成对象数组。 ArrayListHandler：把结果集中的每一行数据都转成一个数组，再存放到List中。 BeanHandler：将结果集中的第一行数据封装到一个对应的JavaBean实例中。 BeanListHandler：将结果集中的每一行数据都封装到一个对应的JavaBean实例中，存放到List里。 ColumnListHandler：将结果集中某一列的数据存放到List中。 KeyedHandler(name)：将结果集中的每一行数据都封装到一个Map里，再把这些map再存到一个map里，其key为指定的key。 MapHandler：将结果集中的第一行数据封装到一个Map里，key是列名，value就是对应的值。 MapListHandler：将结果集中的每一行数据都封装到一个Map里，然后再存放到List ScalarHandler：查询单个值对象 测试 12345678910111213141516171819/* * 测试查询:查询一条记录 * * 使用ResultSetHandler的实现类：BeanHandler */@Testpublic void testQueryInstance() throws Exception&#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = &quot;select id,name,email,birth from customers where id = ?&quot;; // BeanHandler&lt;Customer&gt; handler = new BeanHandler&lt;&gt;(Customer.class); Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer); JDBCUtils.closeResource(conn, null);&#125; 1234567891011121314151617181920/* * 测试查询:查询多条记录构成的集合 * * 使用ResultSetHandler的实现类：BeanListHandler */@Testpublic void testQueryList() throws Exception&#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = &quot;select id,name,email,birth from customers where id &lt; ?&quot;; // BeanListHandler&lt;Customer&gt; handler = new BeanListHandler&lt;&gt;(Customer.class); List&lt;Customer&gt; list = runner.query(conn, sql, handler, 23); list.forEach(System.out::println); JDBCUtils.closeResource(conn, null);&#125; 12345678910111213141516171819202122232425262728293031323334353637/* * 自定义ResultSetHandler的实现类 */@Testpublic void testQueryInstance1() throws Exception&#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); String sql = &quot;select id,name,email,birth from customers where id = ?&quot;; ResultSetHandler&lt;Customer&gt; handler = new ResultSetHandler&lt;Customer&gt;() &#123; @Override public Customer handle(ResultSet rs) throws SQLException &#123; System.out.println(&quot;handle&quot;);// return new Customer(1,&quot;Tom&quot;,&quot;tom@126.com&quot;,new Date(123323432L)); if(rs.next())&#123; int id = rs.getInt(&quot;id&quot;); String name = rs.getString(&quot;name&quot;); String email = rs.getString(&quot;email&quot;); Date birth = rs.getDate(&quot;birth&quot;); return new Customer(id, name, email, birth); &#125; return null; &#125; &#125;; Customer customer = runner.query(conn, sql, handler, 23); System.out.println(customer); JDBCUtils.closeResource(conn, null);&#125; 12345678910111213141516171819202122232425/* * 如何查询类似于最大的，最小的，平均的，总和，个数相关的数据， * 使用ScalarHandler * */@Testpublic void testQueryValue() throws Exception&#123; QueryRunner runner = new QueryRunner(); Connection conn = JDBCUtils.getConnection3(); //测试一：// String sql = &quot;select count(*) from customers where id &lt; ?&quot;;// ScalarHandler handler = new ScalarHandler();// long count = (long) runner.query(conn, sql, handler, 20);// System.out.println(count); //测试二： String sql = &quot;select max(birth) from customers&quot;; ScalarHandler handler = new ScalarHandler(); Date birth = (Date) runner.query(conn, sql, handler); System.out.println(birth); JDBCUtils.closeResource(conn, null);&#125; JDBC总结12345678910111213141516171819202122232425262728293031323334353637总结@Testpublic void testUpdateWithTx() &#123; Connection conn = null; try &#123; //1.获取连接的操作（ //① 手写的连接：JDBCUtils.getConnection(); //② 使用数据库连接池：C3P0;DBCP;Druid //2.对数据表进行一系列CRUD操作 //① 使用PreparedStatement实现通用的增删改、查询操作（version 1.0 \\ version 2.0)//version2.0的增删改public void update(Connection conn,String sql,Object ... args)&#123;&#125;//version2.0的查询 public &lt;T&gt; T getInstance(Connection conn,Class&lt;T&gt; clazz,String sql,Object ... args)&#123;&#125; //② 使用dbutils提供的jar包中提供的QueryRunner类 //提交数据 conn.commit(); &#125; catch (Exception e) &#123; e.printStackTrace(); try &#123; //回滚数据 conn.rollback(); &#125; catch (SQLException e1) &#123; e1.printStackTrace(); &#125; &#125;finally&#123; //3.关闭连接等操作 //① JDBCUtils.closeResource(); //② 使用dbutils提供的jar包中提供的DbUtils类提供了关闭的相关操作 &#125;&#125;","path":"2020/03/15/JDBC学习笔记/","date":"03-15","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"Mysql","slug":"Mysql","permalink":"https://castile.github.io/tags/Mysql/"}]},{"title":"JDBC错误解决","text":"JDBC连接问题环境：win10、mysql-8.17、jdbc8.17 12345678String url = &quot;jdbc:mysql://localhost:3306/books&quot;; try &#123; Class.forName(&quot;com.mysql.jdbc.Driver&quot;); Connection connection = DriverManager.getConnection(url,&quot;root&quot;,&quot;123456&quot;); System.out.println(connection); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; 报出一下警告错误： ==Loading class com.mysql.jdbc.Driver&#39;. This is deprecated. The new driver class is com.mysql.cj.jdbc.Driver’. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.== 这是因为我的mysql版本为8以上，连接方式有点变化，5.0以上是Class.forName(&quot;com.mysql.jdbc.Driver&quot;);， 而现在不推荐这样了，应该改为com.mysql.cj.jdbc.Driver 然后继续运行：又来一堆错误。。。。。。。。。。。。。。。 还是因为的的mysql版本过高。。。时区有问题。改成下面方式即可解决： 1String url = &quot;jdbc:mysql://localhost:3306/books?serverTimezone=UTC&quot;;","path":"2020/03/15/JDBC错误解决/","date":"03-15","excerpt":"","tags":[{"name":"errors","slug":"errors","permalink":"https://castile.github.io/tags/errors/"},{"name":"Mysql","slug":"Mysql","permalink":"https://castile.github.io/tags/Mysql/"}]},{"title":"Davis数据集评估工具使用-MATLAB","text":"介绍因为很久不做实验很容易忘记怎么使用，所以还是做个记录吧。 在Davis官网上下载matlab版本的代码: https://github.com/davisvideochallenge/davis-matlab/tree/davis-2016 在window操作系统下会有点问题，解压时会遇到aux文件夹内容解压失败，这是因为aux是windows保留的名称，因此不能创建名称为aux的文件夹或文件。 所以解决方法是 创建文件夹aux_ : ..\\DAVIS2016\\davis-matlab-davis-2016\\measures\\aux_ 然后把aux中对应内容解压到aux_中。还要修改的相应的文件： 修改 ..\\DAVIS2016\\davis-matlab-davis-2016\\startup.m ： 开始使用安装 修改db_root_dir.m，使得地址指向DAVIS数据库在你系统中解压的位置（包含文件夹Annotations和JPEGImages）。 1234function root_dir = db_root_dir() root_dir = &#x27;F:\\data\\DAVIS-data\\DAVIS&#x27;; %% 设置数据集的路径end 运行startup.m，添加必要的路径和执行一些检查操作。 如果上一步出问题了，就执行build.m，进行重编译。 使用 创建main.m文件，调用评估代码： 123456% main.maddpath(fullfile(db_matlab_root_dir,&#x27;db_util&#x27;));addpath(fullfile(db_matlab_root_dir,&#x27;measures&#x27;)); [eval, raw_eval] = eval_result(&#x27;mvos_test_3_final&#x27;, &#123;&#x27;J&#x27;,&#x27;F&#x27;,&#x27;T&#x27;&#125;,&#x27;val&#x27;);%function [eval, raw_eval] = eval_result(result_id, measures, gt_set) 上面eval_result(‘mvos_test_3_final’, {‘J’,’F’,’T’},’val’); 中填入你要评估的方法名称，这个是你的Reslut结果文件夹的名称，也就是分割的结果。 measures/eval_result.m并非demo，而是一个function，需要自己写个demo调用它，也就是创建的main.m 看看这个eval_result.m文件： function [eval, raw_eval] = eval_result(result_id, measures, gt_set) 输入： result_id：要评估的方法的ID，比如’COSNET’、’ARP’、’AGNN’等等 measures：要评估的指标，三种{ $J 、F、T$} 。 gt_set：用哪个集合作为gt集合，有三种：&#39;all&#39;、&#39;train&#39;、&#39;val&#39; 运行main.m就可以生成三个评价指标的mat 使用experiments\\experiments_params.m可以将表格画出来。 1234567891011121314151617% List of techniques compared% techniques = &#123;&#x27;mcg&#x27;,&#x27;sf-lab&#x27;,&#x27;sf-mot&#x27;,...% &#x27;nlc&#x27;,&#x27;cvos&#x27;,&#x27;trc&#x27;,&#x27;msg&#x27;,...% &#x27;key&#x27;,&#x27;sal&#x27;,&#x27;fst&#x27;,...% &#x27;tsp&#x27;,&#x27;sea&#x27;,&#x27;hvs&#x27;,&#x27;jmp&#x27;,&#x27;fcp&#x27;,&#x27;bvs&#x27;,&#x27;ofl&#x27;,&#x27;msk&#x27;,&#x27;osvos&#x27;,&#x27;epo+&#x27;, &#x27;AGNN&#x27;&#125;;% techniques = &#123;&#x27;AGNN&#x27;, &#x27;AGNN_CRF&#x27;, &#x27;agnn_10&#x27;, &#x27;COSNET&#x27;&#125;;% Names to be shown on the tables% techniques_paper = &#123;&#x27;MCG&#x27;,&#x27;SF-LAB&#x27;,&#x27;SF-MOT&#x27;,...% &#x27;NLC&#x27;,&#x27;CVOS&#x27;,&#x27;TRC&#x27;,&#x27;MSG&#x27;,...% &#x27;KEY&#x27;,&#x27;SAL&#x27;,&#x27;FST&#x27;,...% &#x27;TSP&#x27;,&#x27;SEA&#x27;,&#x27;HVS&#x27;,&#x27;JMP&#x27;,&#x27;FCP&#x27;,&#x27;BVS&#x27;,&#x27;OFL&#x27;,&#x27;MSK&#x27;,&#x27;OSVOS&#x27;,&#x27;epo+&#x27;, &#x27;AGNN&#x27;&#125;;% techniques_paper = &#123;&#x27;AGNN&#x27;, &#x27;AGNN_CRF&#x27;, &#x27;agnn_10&#x27;, &#x27;COSNET&#x27;&#125;;% Output folder to save filespaper_data = &#x27;~/tmp&#x27;; 上面填你要比较的方法名称。 experiments\\global_table.m 生成结果 直接运行即可得到下面表格的数据。各个方法的评价指标值，比较表格。 experiments\\attribute_table.m 直接运行即可得到下面的表格数据。在不同的挑战下各算法性能比较。 结果文件夹的位置一般你要有如下的文件层级：……/DAVIS-data/DAVIS/Results/Segmentations/480p/ 480p文件夹放入你分割的结果： 参考 https://blog.csdn.net/qq_25379821/article/details/83035945","path":"2020/03/14/Davis数据集评估工具使用-MATLAB/","date":"03-14","excerpt":"","tags":[{"name":"davis","slug":"davis","permalink":"https://castile.github.io/tags/davis/"},{"name":"matlab","slug":"matlab","permalink":"https://castile.github.io/tags/matlab/"},{"name":"人工智能","slug":"人工智能","permalink":"https://castile.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}]},{"title":"Http协议","text":"Http协议HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。 三个部分： 超文本 传输 协议 协议生活中的协议，本质上与计算机中的协议是相同的，协议的特点: 「协」字，代表的意思是必须有两个以上的参与者。例如三方协议里的参与者有三个：你、公司、学校三个；租房协议里的参与者有两个：你和房东。 「仪」字，代表的意思是对参与者的一种行为约定和规范。例如三方协议里规定试用期期限、毁约金等；租房协议里规定租期期限、每月租金金额、违约如何处理等 针对 HTTP 协议，我们可以这么理解。 HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。 传输HTTP 协议是一个双向协议。 我们在上网冲浪时，浏览器是请求方 A ，百度网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把请求数据发送给网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片、视频了。 针对传输，我们可以进一步理解了 HTTP。 HTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。 超文本HTTP 传输的内容是「超文本」。 我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」。的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算做「文本」。 再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体最关键有超链接，能从一个超文本跳转到另外一个超文本。 HTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，在经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。 什么是Http协议？ HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 Http协议的状态码 1xx1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断电续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。 4xx4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。 Http协议的内容Http请求浏览器 —–&gt; 服务器： 12345678910GET /myweb/hello HTTP/1.1 -请求行Host: localhost:8080 --请求头（多个key-value对象）User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101 Firefox/35.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-cn,en-us;q=0.8,zh;q=0.5,en;q=0.3Accept-Encoding: gzip, deflateConnection: keep-alive --一个空行name=eric&amp;password=123456 --（可选）实体内容 请求行：GET /myweb/hello HTTP/1.1 包含请求方式、协议版本和请求资源 请求方式： GET http1.0：当前浏览器客户端与服务器端建立连接之后，只能发送一次请求，一次请求之后连接关闭。 http1.1：当前浏览器客户端与服务器端建立连接之后，可以在一次连接中发送多次请求。（基本都使用1.1） 请求资源： /myweb/hello URL: 统一资源定位符。http://localhost:8080/myweb/testImg.html。只能定位互联网资源。 是URI的子集。 URI：统一资源标记符：用于标记任何资源。可以是本地文件系统，局域网的资源 请求头: 123456789101112Accept: text/html,image/* -- 浏览器接受的数据类型Accept-Charset: ISO-8859-1 -- 浏览器接受的编码格式Accept-Encoding: gzip,compress --浏览器接受的数据压缩格式Accept-Language: en-us,zh- --浏览器接受的语言Host: www.it315.org:80 --（必须的）当前请求访问的目标地址（主机:端口）If-Modified-Since: Tue, 11 Jul 2000 18:23:51 GMT --浏览器最后的缓存时间Referer: http://www.it315.org/index.jsp -- 当前请求来自于哪里User-Agent: Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0) --浏览器类型Cookie:name=eric -- 浏览器保存的cookie信息Connection: close/Keep-Alive -- 浏览器跟服务器连接状态。close: 连接关闭 keep-alive：保存连接。Date: Tue, 11 Jul 2000 18:23:51 GMT -- 请求发出的时间 实体内容：只有POST提交的参数会放到实体内容中。 Http响应服务器—–&gt; 浏览器 1234567HTTP/1.1 200 OK --响应行Server: Apache-Coyote/1.1 --响应头（key-vaule）Content-Length: 24 Date: Fri, 30 Jan 2015 01:54:57 GMT --一个空行this is hello servlet!!! --实体内容 响应行：HTTP/1.1 200 OK 协议版本、状态码、状态描述 常见的响应头： 12345678910111213141516Location: http://www.zhuhdha.org/index.jsp -表示重定向的地址，该头和302的状态码一起使用。Server:apache tomcat ---表示服务器的类型Content-Encoding: gzip -- 表示服务器发送给浏览器的数据压缩类型Content-Length: 80 --表示服务器发送给浏览器的数据长度Content-Language: zh-cn --表示服务器支持的语言Content-Type: text/html; charset=GB2312 --表示服务器发送给浏览器的数据类型及内容编码Last-Modified: Tue, 11 Jul 2000 18:23:51 GMT --表示服务器资源的最后修改时间Refresh: 1;url=http://www.it315.org --表示定时刷新Content-Disposition: attachment; filename=aaa.zip --表示告诉浏览器以下载方式打开资源（下载文件时用到）Transfer-Encoding: chunkedSet-Cookie:SS=Q0=5Lb_nQ; path=/search --表示服务器发送给浏览器的cookie信息（会话管理用到）Expires: -1 --表示通知浏览器不进行缓存Cache-Control: no-cachePragma: no-cacheConnection: close/Keep-Alive --表示服务器和浏览器的连接状态。close：关闭连接 keep-alive:保存连接 GET和POSTGet 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本、页面、图片视频等。 比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。 而POST 方法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报文的 body 里。 GET 和 POST 方法都是安全和幂等的吗？ 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 那么很明显 GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。 GET方式提交： 地址栏（URI）会跟上参数数据。以？开头，多个参数之间以&amp;分割。 GET提交参数数据有限制，不超过1KB。 GET方式不适合提交敏感密码。 注意： 浏览器直接访问的请求，默认提交方式是GET方式 POST方式提交： 参数不会跟着URI后面。而是跟在请求的实体内容中。没有？开头，多个参数之间以&amp;分割。 POST提交的参数数据没有限制。 建议用POST方式提交敏感数据。 获取请求和响应的信息HttpServletRequestHttpServletRequest对象作用是用于获取请求数据。 核心的API： ​ 请求行： ​ request.getMethod(); 请求方式 ​ request.getRequetURI() / request.getRequetURL() 请求资源 ​ request.getProtocol() 请求http协议版本 ​ 请求头： ​ request.getHeader(&quot;名称&quot;) 根据请求头获取请求值 ​ request.getHeaderNames() 获取所有的请求头名称 ​ 实体内容: ​ request.getInputStream() 获取实体内容数据 当请求服务器资源的时候，tomcat服务器已经做了以下两件事情： tomcat服务器接收到浏览器发送的请求数据，然后封装到HttpServetRequest对象 tomcat服务器调用doGet方法，然后把request对象传入到servlet中。 获取请求行1234567// 方式System.out.println(&quot;请求方式：&quot;+ req.getMethod());// 请求资源System.out.println(&quot;请求资源 URL：&quot;+ req.getRequestURL());System.out.println(&quot;请求资源 URI：&quot;+ req.getRequestURI());// 协议System.out.println(&quot;协议：&quot;+ req.getProtocol()); 请求方式：GET* 请求资源 URL：http://localhost:8080/web/req 请求资源 URI：/web/req 协议：HTTP/1.1 获取请求头1234567891011 /** * 请求头 */System.out.println(&quot;Host:&quot;+ req.getHeader(&quot;Host&quot;)); // 获取所有的请求头名称列表 Enumeration&lt;String&gt; headerNames = req.getHeaderNames(); while (headerNames.hasMoreElements())&#123; String s = headerNames.nextElement(); String header = req.getHeader(s); System.out.println(s+&quot;:&quot;+header);&#125; Host:localhost:8080 host:localhost:8080connection:keep-alivecache-control:max-age=0upgrade-insecure-requests:1user-agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36sec-fetch-dest:documentaccept:text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8,application/signed-exchange;v=b3;q=0.9sec-fetch-site:nonesec-fetch-mode:navigatesec-fetch-user:?1accept-encoding:gzip, deflate, braccept-language:zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7cookie:JSESSIONID=EE84B02DC152BC48A5AB12844C5D936F; username-localhost-8888=”2|1:0|10:1583063846|23:username-localhost-8888|44:YTBhNTIyNDJiYzM0NDFjY2FmNDQyNTc2ODM0Zjk2OGU=|eb0fd9674f9abfa8a106b4d0668f717f2e2bf5ebe8efbd907aa0fef7c72e3471”; _xsrf=2|694857a0|0a1d86b5ae8842cd51764b901e8b28b5|1583063846; Idea-e408487e=5418b1fa-da5b-44f8-b6f4-41845ecef50b; Hm_lvt_1c47812cb33835eb048ad943e868a359=1583987228 获取实体内容只有POST提交的参数会放到实体内容中 12345678910111213141516@Override protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; /** * * 实体内容 * */ ServletInputStream inputStream = req.getInputStream(); byte[] buff = new byte[1024]; int len = 0; while ((len = inputStream.read(buff) ) != -1) &#123; String str = new String(buff, 0, len); System.out.println(str); &#125; &#125; 123456&lt;h3&gt;POST方式提交&lt;/h3&gt; &lt;form action=&quot;/web/requestDemo&quot; method=&quot;POST&quot;&gt; 用户名：&lt;input type=&quot;text&quot; name=&quot;name&quot;/&gt;&lt;br/&gt; 密码：&lt;input type=&quot;password&quot; name=&quot;password&quot;/&gt;&lt;br/&gt; &lt;input type=&quot;submit&quot; value=&quot;提交&quot;/&gt; &lt;/form&gt; 传递的请求参数如何获取GET方式： 参数放在URI后面 POST方式： 参数放在实体内容中 获取GET方式参数：request.getQueryString(); 获取POST方式参数：request.getInputStream(); 问题：但是以上两种不通用，而且获取到的参数还需要进一步地解析。所以可以使用统一方便的获取参数的方式： 核心的API： request.getParameter(&quot;参数名&quot;); 根据参数名获取参数值（注意，只能获取一个值的参数） request.getParameterValue(&quot;参数名“);根据参数名获取参数值（可以获取多个值的参数） request.getParameterNames(); 获取所有参数名称列表 123456789101112131415String value = req.getQueryString(); System.out.println(va nlue); String name = req.getParameter(&quot;name&quot;); System.out.println(&quot;name:&quot;+name); String pass = req.getParameter(&quot;password&quot;); System.out.println(&quot;password：&quot;+pass); Enumeration&lt;String&gt; parameterNames = req.getParameterNames(); while (parameterNames.hasMoreElements())&#123; String s = parameterNames.nextElement(); String parameter = req.getParameter(s); System.out.println(s+&quot;：&quot;+parameter); &#125; 请求方式的编码问题【中文乱码】修改POST方式参数编码：request.setCharacterEncoding(&quot;utf-8&quot;); 修改GET方式参数编码： ​ 手动解码：String name = new String(name.getBytes(&quot;iso-8859-1&quot;),&quot;utf-8&quot;); request.setCharacterEncoding(&quot;utf-8&quot;); 只对POST方式有效，GET方式无效。 在idea中，使用GET方式提交数据，使用req.getQueryString() 得到的结果为中文乱码。手动解码也无效。。。。可以使用java.net.URLDecoder.decode(value, “UTF-8”); 的方式编码。可以消除中文乱码。 name=数字图像处理&amp;password=ll HttpServletResponse同样，tomcat已经做了两件事 tomcat服务器接收到浏览器发送的请求数据，然后封装到HttpServetRequest对象 tomcat服务器调用doGet方法，然后把request和response对象传入到servlet中。 我们可以使用HttpServletResponse设置响应信息。 响应行： response.setStatus() 设置状态码 响应头： response.setHeader(“name”,”value”) 设置响应头 ​ response.setHeader(“name”,”value”) 设置响应头 实体内容： response.getWriter().writer(); 发送字符实体内容 ​ response.getOutputStream().writer() 发送字节实体内容 举例：请求重定向【location】1234protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; resp.setStatus(302); resp.setHeader(&quot;location&quot;,&quot;/web/testMethod.html&quot;); &#125; 重定向 = location+302代码， 与resp.sendRedirect(“/web/testMethod.html”); 一样的效果。 举例： 定时刷新【refresh】12345678/** * 定时刷新 */ resp.setHeader(&quot;refresh&quot;,&quot;1&quot;);// 每隔1秒刷新一次 // 5秒后跳转到指定页面 resp.setHeader(&quot;refresh&quot;,&quot;5;url=/web/testMethod.html&quot;); 举例： content-Type作用123456789101112131415161718 /** * 图片下载 * */ File file = new File(&quot;F:/get.jpg&quot;); System.out.println(file);// resp.setHeader(&quot;Content-Type&quot;,&quot;image/jpg&quot;); // 设置传输内容的类型 resp.setContentType(&quot;image/jpg&quot;); resp.setHeader(&quot;Content-Disposition&quot;,&quot; attachment; filename=&quot;+file.getName()); // 以下载的方式打开 FileInputStream in = new FileInputStream(file); byte[] buff = new byte[1024]; int len = 0; while ((len = in.read(buff)) != -1)&#123; resp.getOutputStream().write(buff,0, len); &#125; 参考 面试官，别问我 HTTP 了！看这 30 张图就行！","path":"2020/03/13/Http协议/","date":"03-13","excerpt":"","tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://castile.github.io/tags/JavaWeb/"},{"name":"Http","slug":"Http","permalink":"https://castile.github.io/tags/Http/"}]},{"title":"Servlet详解","text":"Servlet 概述狭义的 Servlet 是指 Java 语言实现的一个接口，广义的 Servlet 是指 任何实现了这个 Servlet 接口的类，一般情况下，人们将 Servlet 理解为后者。 Servlet 运行于支持 Java 的应用服务器中。从原理上讲，Servlet 可以响应任何类型的请求，但绝大多数情况下 Servlet 只用来扩展基于 HTTP 协议的 Web 服 务器。 Servlet的特点是：运行在支持java的应用服务器上， 并且Servlet的实现遵循了服务器能够识别的规则，也就是服务器会自动 的根据请求调用对应的servlet进行请求处理。 在idea中创建一个Web应用 new–&gt;project–&gt;web Application 填上项目名称 可以看到idea的文件目录， 注意和Myeclipse区分 创建classes和lib文件 classes 存放编译好的class文件，lib存放所需要的jar包。所以要进一步配置编译目录和lib目录。 配置tomcat服务器 创建一个Servlet步骤 编写java类，继承HttpServlet类 重写doGet和doPost方法 Servlet程序交给tomcat服务器运行！！ ​ 3.1 servlet程序的class码拷贝到WEB-INF/classes目录 ​ 3.2 在web.xml文件中进行配置 123456789101112131415161718&lt;!-- 配置一个servlet --&gt; &lt;!-- servlet的配置 --&gt; &lt;servlet&gt; &lt;!-- servlet的内部名称，自定义。尽量有意义 --&gt; &lt;servlet-name&gt;FirstServlet&lt;/servlet-name&gt; &lt;!-- servlet的类全名： 包名+简单类名 --&gt; &lt;servlet-class&gt;com.first.servlet.FirstServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;!-- servlet的映射配置 --&gt; &lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;FirstServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/first&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 运行一个servlet首次访问 URL： http://localhost:8080/web/first tomcat服务器启动时，首先加载webapps中的每个web应用的web.xml配置文件。 http:// : http协议 localhost: 到本地的hosts文件中查找是否存在该域名对应的IP地址127.0.0.1 8080： 找到tomcat服务器 /web： 在tomcat的webapps目录下找 web的目录 /first :资源名称。 1）在web的web.xml中查找是否有匹配的url-pattern的内容（/first） 2）如果找到匹配的url-pattern,则使用当前servlet-name的名称到web.xml文件中查询是否相同名称的servlet配置 3）如果找到，则取出对应的servlet配置信息中的servlet-class内容： ​ 字符串： com.first.servlet.FirstServlet 通过反射： 1. 构造`FirstServlet`的对象 2. 然后调用`FirstServlet`里面的方法 Servlet的映射路径1234567&lt;servlet-mapping&gt; &lt;!-- servlet的内部名称，一定要和上面的内部名称保持一致！！ --&gt; &lt;servlet-name&gt;FirstServlet&lt;/servlet-name&gt; &lt;!-- servlet的映射路径（访问servlet的名称） --&gt; &lt;url-pattern&gt;/first&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 精确匹配 url-pattern 浏览器输入 /first http://localhost:8080/web/first /hello/first http://localhost:8080/web/hello/first 模糊匹配*代表通配符 url-pattern 浏览器输入 /* http://localhost:8080/web/**任意路径** /hello/* http://localhost:8080/web/hello/**任意路径** *.do http://localhost:8080/web/**任意路径.do** *.action http://localhost:8080/web/**任意路径.action** *.html http://localhost:8080/web/**任意路径.html** 【伪静态】 注意： url-pattern要么以 / 开头，要么以*开头。 例如， hello是非法路径。 不能同时使用两种模糊匹配，例如 /hello/*.do是非法路径 当有输入的URL有多个servlet同时被匹配的情况下： 精确匹配优先。（长的最像优先被匹配） 以后缀名结尾的模糊url-pattern优先级最低！！！ Servlet 的缺省路径servlet的缺省路径（/）是在tomcat服务器内置的一个路径。该路径对应的是一个DefaultServlet（缺省Servlet）。这个缺省的Servlet的作用是用于解析web应用的静态资源文件。 比如： URL输入http://localhost:8080/web/index.html 如何读取文件？ ​ 1）到当前web应用下的web.xml文件查找是否有匹配的url-pattern。 ​ 2）如果没有匹配的url-pattern，则交给tomcat的内置的DefaultServlet处理 ​ 3）DefaultServlet程序到web应用的根目录下查找是存在一个名称为index.html的静态文件。 ​ 4）如果找到该文件，则读取该文件内容，返回给浏览器。 ​ 5）如果找不到该文件，则返回404错误页面。 所以，先找动态的资源，再找静态的资源。 Servlet的生命周期【重要！！！】servlet类对象什么时候创建，什么时候调用什么方法，什么时候销毁。 Servlet程序的生命周期由tomcat服务器控制的！！！！ Servlet的生命周期： 1、从第一次调用到服务器关闭。 2、如果Servlet在web.xml中配置了load-on-startup，生命周期为 从服务器启动到服务器 关闭 【Servlet 的自动加载】 Servlet的生命周期方法 构造方法： 创建servlet对象的时候调用。默认情况下，第一次访问servlet的时候创建servlet对象 只调用1次。证明servlet对象在tomcat是单实例的。 init方法： 创建完servlet对象的时候调用。只调用1次。 service方法： 每次发出请求时调用。调用n次。 destroy方法： 销毁servlet对象的时候调用。停止服务器或者重新部署web应用时销毁servlet对象。只调用1次。 servlet的生命周期过程 Servlet对象的生命周期是交给Tomcat服务器来管理的。在tomcat服务器内部代码执行过程： 服务器启动的时候， 加载web.xml文件，通过xml文件的解析，在下得到servlet-class的内容，字符串：com.first.servlet.FirstServlet。 通过反射机制俩构造FirstServlet对象： 得到字节码对象 Class clazz = Class.forName(“com.first.servlet.FirstServlet”)； 调用无参数的构造方法来构造对象 Object obj = clazz.clazz.getDeclaredConstructor().newInstance(); 【servlet的构造方法被调用】 创建ServletConfig对象，再通过反射调用init方法 得到方法对象 Method init = clazz.getDeclaredMethod(“init”, ServletConfig.class); 调用方法 init.invoke(obj, servletConfig); 【servlet 的 init方法被调用】 4.创建request对象和response对象， 通过反射调用service方法 得到方法对象 Method service = clazz.getDeclaredMethod(“service”, HttpServletRequest.class, HttpServletResponse.class); 调用方法 service.invoke(obj, request, response); 【servlet 的 service方法被调用】 5.当tomcat服务器停止或者web应用重新部署，通过反射调用destroy方法 得到方法对象 1Method destroy = clazz.getDeclaredMethod(&quot;destroy&quot;); 调用 destroy.invoke(); 【servlet 的 destroy方法被调用】 下面是一个时序图，完整地描述了Servlet的生命周期 Servlet的自动加载​ 默认情况下，第一次访问servlet的时候创建servlet对象。如果servlet的构造方法或init方法中执行了比较多的逻辑代码，那么导致用户第一次访问sevrlet的时候比较慢。 ​ 可以改变Servlet创建的时机：提前到加载web应用的时候 ​ 在Servlet的配置信息中，加上即可。 1234567&lt;servlet&gt; &lt;servlet-name&gt;ServletLife&lt;/servlet-name&gt; &lt;servlet-class&gt;com.first.servlet.ServletLife&lt;/servlet-class&gt; &lt;!-- 让servlet对象自动加载 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; 注意： 整数值越大，创建优先级越低！！ &lt;/servlet&gt; 启动tomcat的时候，可以看到以下输出信息： 有参的init方法和无参的init方法1234567891011121314import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;/** * 有参数的init和无参的init方法 * */public class InitDemo extends HttpServlet &#123; @Override public void init() throws ServletException &#123; System.out.println(&quot;无参数的init方法&quot;); &#125;&#125; 有参数的init方法：是servlet的生命周期方法，一定会被tomcat服务器调用 无参数的init方法：该方法是servlet的编写初始化代码的方法。是Sun公司设计出来专门给开发者进行覆盖，然后在里面编写servlet的初始逻辑代码的方法。 注意：如果要编写初始代码，不需要覆盖有参数的init方法 可以看servlet的源码： 12345678public void init(ServletConfig config) throws ServletException &#123; this.config = config; this.init();&#125;public void init() throws ServletException &#123;&#125; Servlet的多线程并发问题Servlet对象在tomcat服务器是单实例多线程的 。 因为servlet是多线程的，所以当多个servlet的线程同时访问了servlet的共享数据，如成员变量，可能会引发线程安全问题。 解决办法： 1）把使用到共享数据的代码块进行同步（使用synchronized关键字进行同步） 2）建议在servlet类中尽量不要使用成员变量。如果确实要使用成员，必须同步。而且尽量缩小同步代码块的范围。（哪里使用到了成员变量，就同步哪里！！），以避免因为同步而导致并发效率降低。 ServletConfig对象Servlet的配置对象，是一个接口 123456789package javax.servlet;import java.util.Enumeration;public interface ServletConfig &#123; public String getServletName(); public ServletContext getServletContext(); public String getInitParameter(String name); public Enumeration&lt;String&gt; getInitParameterNames();&#125; 1234567public abstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializable &#123; private static final long serialVersionUID = 1L; private transient ServletConfig config; &#125; 作用ServletConfig对象: 主要是用于加载servlet的初始化参数。在一个web应用可以存在多个ServletConfig对象（一个Servlet对应一个ServletConfig对象）。 对象的创建与获取创建时机： 在创建完servlet对象之后，在调用init方法之前创建。 获取对象： 直接从有参数的init方法中得到。 Servlet的初始化参数配置在web.xml的中配置： 12345678910111213 &lt;servlet&gt; &lt;servlet-name&gt;config&lt;/servlet-name&gt; &lt;servlet-class&gt;com.first.servlet.config.ConfigDemo&lt;/servlet-class&gt;&lt;!-- 配置初始化参数 ,这些参数会封装ServletConfig对象中在init方法初始化 --&gt; &lt;init-param&gt; &lt;param-name&gt;path&lt;/param-name&gt; &lt;param-value&gt;f:/a.txt&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;config&lt;/servlet-name&gt; &lt;url-pattern&gt;/cfg&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 注意： servlet的参数只能由当前的这个sevlet获取！！！！ ServletConfig的API： java.lang.String getInitParameter(java.lang.String name) 根据参数名获取参数值 java.util.Enumeration getInitParameterNames() 获取所有参数 ServletContext getServletContext() 得到servlet上下文对象 java.lang.String getServletName() 得到servlet的名称 其实在HttpServlet所继承的GenericServlet类中，直接提供了上述的API，可以直接通过this关键字调用上面的方法，而不需要先获取ServletConfig对象。 123456789101112131415161718192021222324252627/** * @author Hongliang Zhu * @create 2020-03-14 9:33 */public class ConfigDemo extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; // 读取Servlet的初始化的参数// String path = config.getInitParameter(&quot;path&quot;); String path1 = this.getServletConfig().getInitParameter(&quot;path&quot;); // 也可以 String path = this.getInitParameter(&quot;path&quot;); //获取初始化参数 File file = new File(path); BufferedReader br = new BufferedReader(new FileReader(file)); String str= &quot;&quot;; while ((str = br.readLine()) != null)&#123; String gbk = new String(str.getBytes(&quot;GBK&quot;), &quot;UTF-8&quot;); System.out.println(gbk); &#125; String servletName = this.getServletName(); //当前servlet的名字，在web.xml 中的&lt;servlet-name&gt;&lt;/servlet-name&gt;中的名字 System.out.println(servletName); &#125;&#125; ServletContext对象123456789101112131415161718public interface ServletContext &#123; public static final String TEMPDIR = &quot;javax.servlet.context.tempdir&quot;; /** * @since Servlet 3.0 */ public static final String ORDERED_LIBS = &quot;javax.servlet.context.orderedLibs&quot;; /** * Return the main path associated with this context. * * @return The main context path * * @since Servlet 2.5 */ public String getContextPath();&#125; 作用ServletContext对象 ,叫做Servlet的上下文对象。表示一个当前的web应用环境。一个web应用中只有一个ServletContext对象。 注意与ServletConfig对象区分，一个Servlet对应一个ServletConfig对象，一个web应用里面可以有多个Servlet，但是一个web应用程序只能有一个ServletContext对象。可以将web.xml文件的整个信息封装到ServletContext对象。 对象创建和得到创建时机：加载web应用时创建ServletContext对象。 得到对象： 从ServletConfig对象的getServletContext方法得到 那么问题来了，为啥要从ServletConfig对象中得到ServletContext对象呢？因为ServletContext对象是在tomcat服务器启动的时候就已经创建好了，而ServletConfig对象实在Servlet构建之后，调用init方法之前创建的。所以ServletContext是优先于ServletConfig对象创建的。 如果我们自己设计获取ServletContext对象，可能会这样设计： 123456// 创建ServletConfig对象public void init( ServletConfig config, ServletContext context )&#123; //多了一个参数 得到ServletConfig对象; 得到ServletContext对象;&#125; 上面的设计会多了一个参数，因为ServletContext是整个web程序的全局的对象，而每个Servlet各自有自己的ServletConfig对象，如果每个Servlet都要这样这样传递ServletContext对象的话，未免过于麻烦，所以，我觉得sun公司设计的时候应该是如下设计的： 首先创建ServletContext对象 : ServletContext = context = new ServletContext(); 这是在服务器启动的时候就创建了。 创建ServletConfig对象： 12345678910111213141516171819ServletConfig config = new ServletConfig();config.setServletContext(context); // 设置ServletContextinterface ServletConfig&#123; ServletContext context; public ServletContext getServletContxt()&#123; return contxt; &#125;&#125;public void init( ServletConfig config )&#123; 得到ServletConfig对象 从ServletConfig对象中得到ServletContext对象 SerlvetContext context = config.getServletContext(); &#125; ServletContext对象的核心API(作用) 方法 作用 String getContextPath() 得到当前web应用的路径 String getInitParameter(String name) 得到web应用的初始化参数 Enumeration getInitParameterNames() void setAttribute(String name, Object object) 域对象有关的方法 Object getAttribute(String name) removeAttribute(String name) RequestDispatcher getRequestDispatcher(String path) 转发（类似于重定向） String getRealPath(String path) 得到web应用的资源文件 InputStream getResourceAsStream(String path) 得到当前web应用的路径String getContextPath()： 通常在请求重定向的时候用 12345678// 得到ServletContext对象 ServletContext servletContext = this.getServletContext(); // 得到web路径 String contextPath = servletContext.getContextPath(); System.out.println(contextPath); resp.sendRedirect(contextPath+&quot;/testMethod.html&quot;); // 自动找到当前运行的web目录 得到web应用的初始化参数在web.xml文件中配置web应用参数，是在所有外面配置： 12345678910111213141516171819202122232425262728&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;web-app xmlns=&quot;http://xmlns.jcp.org/xml/ns/javaee&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd&quot; version=&quot;4.0&quot;&gt;&lt;!-- 配置web应用参数 --&gt; &lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;Tom&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;school&lt;/param-name&gt; &lt;param-value&gt;BJTU&lt;/param-value&gt; &lt;/context-param&gt; &lt;servlet&gt; &lt;servlet-name&gt;context&lt;/servlet-name&gt; &lt;servlet-class&gt;com.first.servlet.context.contextDemo&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;context&lt;/servlet-name&gt; &lt;url-pattern&gt;/text&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 12345678 // 得到web应用参数Enumeration&lt;String&gt; initParameterNames = servletContext.getInitParameterNames();while (initParameterNames.hasMoreElements())&#123; String s = initParameterNames.nextElement(); String initParameter = servletContext.getInitParameter(s); System.out.println(s+&quot;:&quot;+initParameter);&#125; 域对象有关的方法域对象：作用是用于保存数据，获取数据。可以在不同的动态资源之间共享数据。 两个Servlet之间共享数据可以通过传递参数的方式： response.sendRedirect（“/servlet2?name=tom”） 然后在servlet2中调用request.getParameter(“name”)；获取数据 但是这种方式只能传递字符串，如果要传递一个对象呢？这就不行了，所以，域对象的作用就凸显了，域对象可以共享任何类型的数据。ServletContext就是一个域对象。 保存数据：void setAttribute(java.lang.String name, java.lang.Object object) 获取数据： java.lang.Object getAttribute(java.lang.String name) 删除数据： void removeAttribute(java.lang.String name) ServletContext域对象：作用范围在整个web应用中有效！ 转发RequestDispatcher getRequestDispatcher(java.lang.String path) 123 // 转发RequestDispatcher rd = this.getServletContext().getRequestDispatcher(&quot;/testMethod.html&quot;);rd.forward(req,resp); 1）转发 ​ a）地址栏不会改变 ​ b）转发只能转发到当前web应用内的资源 ​ c）可以在转发过程中，可以把数据保存到request域对象中 2）重定向 ​ a）地址栏会改变，变成重定向到地址。 ​ b）重定向可以跳转到当前web应用，或其他web应用，甚至是外部域名网站。 ​ c）不能在重定向的过程中把数据保存到request中。 结论： 如果要使用request域对象进行数据共享，只能用转发技术！","path":"2020/03/13/Servlet详解/","date":"03-13","excerpt":"","tags":[{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://castile.github.io/tags/JavaWeb/"},{"name":"Servlet","slug":"Servlet","permalink":"https://castile.github.io/tags/Servlet/"}]},{"title":"快速排序应用-荷兰国旗问题","text":"描述快速排序 快速排序的思想是，通过一趟排序将待排记录分割成独立的两部分，其中一部分记录的关键字均比另一部分记录的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序的目的。 快速排序之所以快，是因为它使用了分治法。它虽然也是通过不断的比较和移动来实现排序的，只不过它的实现，增大了比较的距离和移动的距离。而冒泡排序只是相邻的比较和交换。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package Sort.QuickSort;/** * 快速排序优化，随机快速排序 * @author Hongliang Zhu * @create 2020-03-10 22:13 */public class quickS1 &#123; public static void quickSort(int[] arrs)&#123; if(arrs == null || arrs.length &lt; 2) return; quick(arrs, 0, arrs.length-1); &#125; /** * * @param arr 数组 * @param left 左边界 0 * @param right 右边界 下标 */ public static void quick(int[] arr, int left, int right)&#123; if(left &lt; right)&#123; // 随机选择一个数域最后一个数进行交换 swap(arr, left+(int)(Math.random()*(right-left+1)), right); // Math.random() 返回[0, 1) 的随机数 int[] pivot = partition(arr, left, right); quick(arr, left, pivot[0] - 1); quick(arr, pivot[0]+1, right); &#125; &#125; // 以数组最后一个元素为轴枢，将整个数组划分为 小于、等于、大于 三个部分 public static int[] partition(int[] arr, int left, int right)&#123; int less = left - 1; int greater = right; while (left &lt; greater)&#123; if (arr[left] &lt; arr[right])&#123; less++; swap(arr, less, left);// left++; &#125;else if( arr[left] &gt; arr[right])&#123; // 交换more前一个元素 greater--; swap(arr, left, greater); &#125;else &#123; left++; &#125; &#125; swap(arr, left, right); return new int[]&#123;less + 1, greater&#125;; &#125; public static void swap(int[] arr, int i, int j)&#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t; &#125; public static void main(String[] args) &#123; int[] arr = &#123;43, -31, 10, -38, -42, -2, 22, 29, 30, 15, -60, -50, -13, 26, 3, 22, 27, 24, 18, 18, 42, -40, 22, 8, 33, -52, -70, -55, 31, 42, 82, 19, -8, 8, 41, -35, 59, 65, -23, 3, -34, 65&#125;; quickSort(arr); for (int i: arr)&#123; System.out.print(i+&quot; &quot;); &#125; System.out.println(); &#125;&#125; 经典快排和数据的状态有关：当然上述代码是经过优化了 当数据是极端情况，比如： 9，8，7，6，5，4，3，2，1。 选择最后一个元素为轴枢，会发现，每一个元素都比轴枢大，进行一次快速排序之后，最后会将轴枢放在第一位，复杂度都是：$O(N^2)$ . 上面代码减少了不必要的交换，即将轴枢保存了下来， 不用每次都交换，在最终确定位置的时候再交换。 进一步优化： 我们都知道，递归对性能是有一定影响的，quickSort函数尾部有两次递归操作。如果待排序的序列极为极端不平衡，递归的深度几乎接近于n的高度（没有了二分法的优势）。这样的时间复杂度也是达到了最坏的程度$ O (N^2) $ ，而不是平衡时的$O(nlogn)$。 时间慢也就算了，但是栈的大小也是有限的，每次递归操作都消耗一定的栈空间，函数的参数越多，每次递归调用参数耗费的空间也是越多。 如果能减少递归，性能也因此大大提高: 12345678910 public void quickSort(int[] arrs, int low, int high) &#123; if (arrs == null || arrs.length == 0) return; while(low &lt; high)&#123; // 改成迭代式 ， 减少递归 int Pivot = Patition(arrs, low, high); quickSort(arrs, low, Pivot-1);// quickSort(arrs, Pivot + 1, high); low = Pivot+1; &#125; &#125; 这是一个很好的方法。我们把if改成while，然后一次递归之后，左边的部门已经排好序了，low已经没有用处了，所以把pivot+1赋值给low作为下一个参数， 对右半部分排序，减少了一半的递归程度。 因此采用迭代而不是递归的方法可以缩减堆栈深度，从而提高了整体性能。 荷兰国旗问题一其实荷兰国旗问题就是一个数组划分的问题 给定一个数组arr，和一个数num，请把小于等于num的数放在数组的左边，大于num的数放在数组的右边。 要求额外空间复杂度O(1)，时间复杂度O(N)。 分析很明显这就是快速排序的一次划分的过程，只不过轴枢是给定的一个数。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445package Sort.QuickSort;/** * 荷兰国旗问题一： * 给定一个数组arr，和一个数num，请把小于等于num的数放在数组的左边， * 大于num的数放在数组的右边。 要求额外空间复杂度O(1)，时间复杂度O(N)； * * @author Hongliang Zhu * @create 2020-03-10 23:22 */public class SpiltArray &#123; public static void splitArray_(int[] arr, int num) &#123; if (arr == null || arr.length &lt; 2) return; sort(arr, 0, arr.length - 1, num); &#125; public static void sort(int[] arr, int left, int right, int num) &#123; int less = left - 1; while (left &lt;= right) &#123; if (arr[left] &lt;= num) &#123; swap(arr, ++less, left++); &#125; else &#123; left++; &#125; &#125; &#125; public static void swap(int[] arr, int i, int j) &#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t; &#125; public static void main(String[] args) &#123;// int[] arr = &#123;1, 2, 8, -2, 4, 3, 4, 2, 8, 12, 3, 9, 8, 10, 9, 5, -1, 4, 9, 2&#125;; int[] arr = &#123;1, 2, 8, 4, 3, 12, 10, 9, 2, 3&#125;; splitArray_(arr, 6); for (int i : arr) &#123; System.out.print(i + &quot; &quot;); &#125; System.out.println(); &#125;&#125; 荷兰国旗问题二 给定一个数组arr，和一个数num，请把小于num的数放在数组的左边，等于num的数放在数组的中间，大于num的数放在数组的右边。 要求额外空间复杂度O(1)，时间复杂度O(N) 。 这题与上面的题目区别是，这个题目是要将数组划分成三个部分，大于部分，等于部分，小于部分。 参照快速排序代码，很容易解出来。直接看代码就懂了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package Sort.QuickSort;/** * 荷兰国旗问题二： * 给定一个数组arr，和一个数num，请把小于num的数放在数组的左边， * 等于num的数放在数组的中间，大于num的数放在数组的右边。 * 要求额外空间复杂度O(1)，时间复杂度O(N) * * @author Hongliang Zhu * @create 2020-03-10 22:13 */public class SplitArray2 &#123; public static int[] SplitArray2(int[] arrs, int num) &#123; if (arrs == null || arrs.length &lt; 2) return null; int[] p = sort(arrs, 0, arrs.length - 1, num); return p; &#125; // 以数组最后一个元素为轴枢，将整个数组划分为 小于、等于、大于 三个部分 public static int[] sort(int[] arr, int left, int right, int num) &#123; int less = left - 1; int greater = right + 1; while (left &lt; greater) &#123; if (arr[left] &lt; num) &#123; swap(arr, ++less, left++); &#125; else if (arr[left] &gt; arr[right]) &#123; swap(arr, --greater, left); &#125; else &#123; left++; &#125; &#125; swap(arr, left, right); return new int[]&#123;less + 1, greater&#125;; &#125; public static void swap(int[] arr, int i, int j) &#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t; &#125; public static void main(String[] args) &#123;// int[] arr = &#123;43, -31, 10, -38, -42, -2, 22, 29, 30, 15, -60, -50, -13, 26, 3, 22, 27, 24, 18, 18, 42, -40, 22, 8, 33, -52, -70, -55, 31, 42, 82, 19, -8, 8, 41, -35, 59, 65, -23, 3, -34, 65&#125;; int[] arr = &#123;1, 2, 6, 4, 8, 6, 10, 12, 6, 9, 2, 3&#125;; int[] p = SplitArray2(arr, 6); for (int i : arr) &#123; System.out.print(i + &quot; &quot;); &#125; System.out.println(); System.out.println(&quot;==============&quot;); System.out.println(&quot;小于的区域：&quot;); for (int i = 0; i &lt; p[0]; i++) &#123; System.out.print(arr[i] + &quot; &quot;); &#125; System.out.println(); System.out.println(&quot;==============&quot;); System.out.println(&quot;等于的区域：&quot;); for (int i = p[0]; i &lt;= p[1]; i++) &#123; System.out.print(arr[i] + &quot; &quot;); &#125; System.out.println(); System.out.println(&quot;==============&quot;); System.out.println(&quot;大于的区域：&quot;); for (int i = p[1]+1; i &lt; arr.length; i++) &#123; System.out.print(arr[i] + &quot; &quot;); &#125; System.out.println(); &#125;&#125; 1 2 3 4 2 6 6 6 9 10 8 12 小于的区域： 1 2 3 4 2 等于的区域： 6 6 6 大于的区域： 9 10 8 12","path":"2020/03/10/快速排序应用-荷兰国旗问题/","date":"03-10","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"快速排序","slug":"快速排序","permalink":"https://castile.github.io/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"排序","slug":"排序","permalink":"https://castile.github.io/tags/%E6%8E%92%E5%BA%8F/"}]},{"title":"Java8中的Lambda表达式","text":"Java8新特性Java 8 于2014年3月14号发布，可以看成是自Java 5 以来最具革命性的版本。Java 8为Java语言、编译器、类库、开发工具与JVM带来了大量新特性。 速度更快 代码更少(增加了新的语法：Lambda 表达式 强大的 Stream API 便于并行 最大化减少空指针异常：Optional Lambda表达式Lambda 是一个匿名函数，我们可以把 Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使Java的语言表达能力得到了提升。 Lambda 表达式在Java 8 语言中引入了一个新的语法元素和操作符。这个操作符为 -&gt; ， 该操作符被称为 Lambda 操作符或箭头操作符。它将 Lambda 分为两个部分： 左侧：指定了 Lambda 表达式需要的参数列表。 右侧：指定了 Lambda 体，即 Lambda 表达式要执行的功能。 12345@Test public void test()&#123; Comparator&lt;Integer&gt; con = (o1, o2)-&gt; o1.compareTo(o2); System.out.println(con.compare(11, 56)); &#125; 1234567891011121314151617public void happy(double money, Consumer&lt;Double&gt; con)&#123; con.accept(money); &#125; @Test public void test1()&#123; // 原始写法 happy(19000, new Consumer&lt;Double&gt;() &#123; @Override public void accept(Double money) &#123; System.out.println(&quot;花了&quot;+ money); &#125; &#125;); // lambda表达式 happy(9000, money-&gt;System.out.println(&quot;花了&quot;+money));&#125; Lambda表达式语法格式语法格式一： 无参数， 无返回值 1Runnable r = ()-&gt; System.out.println(&quot;helllo&quot;); 语法格式二： 需要一个参数，但是没有返回值。如果只有一个参数，参数的小括号可以省略。 1Consumer&lt;String&gt; con = str -&gt; System.out.println(str);con.accept(&quot;hello&quot;); 语法格式三： Lambda 需要两个或以上的参数，多条执行语句，并且有返回值 。 1234Comparator&lt;Integer&gt; com = (x, y)-&gt;&#123; System.out.println(&quot;实现函数式接口方法...&quot;); return Integer.compare(x, y); &#125;;","path":"2020/03/05/Java8中的Lambda表达式/","date":"03-05","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"Java动态编译与脚本引擎","text":"动态编译JAVA 6.0引入了动态编译机制。 动态编译的应用场景可以做一个浏览器端编写java代码，上传服务器编译和运行的在线评测 系统。 服务器动态加载某些类文件进行编译。 动态编译的两种做法 通过Runtime调用javac，启动新的进程去操作。 通过JavaCompiler动态编译。 JavaCompiler： JavaCompiler.run(…): int run(InputStream in, OutputStream out, OutputStream err, String… arguments); 第一个参数：为java编译器提供参数 输入： null 表示System.in 第二个参数：得到 Java 编译器的输出信息 : null 表示System.out 第三个参数：接收编译器的 错误信息: null 表示System.err 第四个参数：可变参数（是一个String数组）能传入一个或多个 Java 源文件 返回值：0表示编译成功，非0表示编译失败 12345678910111213141516171819202122232425262728293031323334import javax.tools.JavaCompiler;import javax.tools.ToolProvider;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;/** * 动态编译 * @author Hongliang Zhu * @create 2020-03-03 14:58 */public class TestDynamic &#123; public static void main(String[] args) throws IOException &#123; // 编译 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); int run = compiler.run(null, null, null, &quot;F:\\\\java\\\\base\\\\DynamicCompille\\\\src\\\\hello.java&quot;); System.out.println(run == 0?&quot;编译成功&quot;:&quot;编译失败&quot;); //执行class 运行程序 Runtime runtime = Runtime.getRuntime(); Process process = runtime.exec(&quot;java -cp F:\\\\java\\\\base\\\\DynamicCompille\\\\src hello&quot;); InputStream inputStream = process.getInputStream(); BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String info = &quot;&quot;; while ((info = reader.readLine()) != null)&#123; System.out.println(info); &#125; &#125;&#125; 编译成功 hello!!! 通过反射运行编译好的类1234567891011121314151617@Test public void TestReflect()&#123; try &#123; URL[] uRls = new URL[]&#123;new URL(&quot;file:/&quot;+&quot;F:/java/base/DynamicCompille/src/&quot;)&#125;; URLClassLoader loader = new URLClassLoader(uRls); Class clazz = loader.loadClass(&quot;hello&quot;); // 调用加载类的main方法 Method m = clazz.getMethod(&quot;main&quot;, String[].class); m.invoke(null, (Object)new String[]&#123;&#125;); // 由于可变参数是JDK5.0之后才有的，上面代码会编译成： m.invoke(null, &quot;aa0, &quot;bb&quot;);, 我们知道 // main方法中的参数是一个String[],这样就会发生参数个数不匹配的问题，所以要加上Object强制装换。 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; hello!!! 同样可以执行。 脚本引擎JAVA脚本引擎是从JDK6.0之后添加的新功能。 脚本引擎介绍：使得 Java 应用程序可以通过一套固定的接口与各种脚本引擎交互，从而达到在 Java 平台上调用各种脚本语言的目的。 Java 脚本 API 是连通 Java 平台和脚本语言的桥梁。可以把一些复杂异变的业务逻辑交给脚本语言处理，这又大大提高了 开发效率。 脚本引擎执行JavaScript代码获取脚本程序输入，通过脚本引擎运行脚本并返回运行结果，这是最核心的接口。 Rhino 是一种使用 Java 语言编写的 JavaScript 的开源实现，原先由Mozilla开发 ，现在被集成进入JDK 6.0。 通过脚本引擎的运行上下文在脚本和 Java 平台间交换数据，通过 Java 应用程序调用脚本函数。 1234567891011121314// 获得脚本引擎对象ScriptEngineManager scriptEngineManager = new ScriptEngineManager();ScriptEngine engine = scriptEngineManager.getEngineByName(&quot;javascript&quot;);//定义变量，存储到引擎上下文中engine.put(&quot;msg&quot;, &quot;you see you , one day day de&quot;);// 下面是JavaScript脚本String str = &quot;var user = &#123; name: &#x27;jack&#x27;, age:18, schools:[&#x27;北京交通大学&#x27;,&#x27;计算机与信息技术学院&#x27;]&#125;;&quot;;str+=&quot;print(user.name);&quot;;// 执行脚本engine.eval(str);System.out.println(engine.get(&quot;msg&quot;));engine.eval(&quot;msg = &#x27;day by day&#x27;;&quot;); //更改System.out.println(engine.get(&quot;msg&quot;)); jack you see you , one day day de day by day 脚本引擎执行JavaScript函数123456789// 定义函数engine.eval( &quot;function add(a, b)&#123; var sum = a+b; return sum;&#125;&quot;);//执行js函数// 取得调用接口Invocable jsInvoke = (Invocable)engine;Object add = jsInvoke.invokeFunction(&quot;add&quot;, new Object[]&#123;13, 44&#125;);System.out.println(add); // 打印返回结果 57.0 交换数据1234567// 导入其他java包，使用其他包中的Java类String jsCode = &quot; var list = java.util.Arrays.asList([\\&quot;北京交通大学\\&quot;,\\&quot;计算机与信息技术学院\\&quot;]);&quot;;engine.eval(jsCode);List&lt;String&gt; list = (List) engine.get(&quot;list&quot;);for (String t: list)&#123; System.out.println(t); // 北京交通大学 计算机与信息技术学院&#125; 脚本引擎执行js文件a.js: 12345678910// 定义test方法function test()&#123; var a = 3; var b =4; print(&quot;invoke js file:&quot; + (a+b));&#125;// 执行testtest() 12345// 执行一个js文件InputStream resource = testengine.class.getClassLoader().getResourceAsStream(&quot;a.js&quot;);BufferedReader br = new BufferedReader(new InputStreamReader(resource));engine.eval(br); // invoke js file:7br.close(); invoke js file: 7","path":"2020/03/03/Java动态编译/","date":"03-03","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"归并排序应用之逆序对的个数","text":"描述在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。 12输入: [7,5,6,4]输出: 5 代码归并排序的应用，在merge操作的时候就可以计算出逆序对 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public int reversePairs(int[] nums) &#123; return merge(nums, 0, nums.length - 1); &#125; public int merge(int[] nums, int low, int high)&#123; if(low &gt;= high) return 0; int mid = low + ((high - low) &gt;&gt; 1); // 要加括号 return merge(nums, low, mid) + merge(nums, mid+1, high) + mergr_op(nums, low, mid, high); &#125; public int mergr_op(int[] nums, int low, int mid, int high)&#123; int k = 0; int[] help = new int[high - low +1]; int p1 = low; int p2 = mid+1; int res = 0; // 逆序对的个数 while(p1 &lt;= mid &amp;&amp; p2 &lt;= high)&#123; if(nums[p1] &lt;= nums[p2])&#123; help[k++] = nums[p1++]; &#125;else if(nums[p1] &gt; nums[p2])&#123; res += (mid - p1 + 1); help[k++] = nums[p2++]; &#125; &#125; while(p1 &lt;= mid)&#123; help[k++] = nums[p1++]; &#125; while(p2 &lt;= high)&#123; help[k++] = nums[p2++]; &#125; //copy for(int i = 0; i &lt; high - low +1; i++)&#123; nums[low + i] = help[i]; &#125; return res; &#125;&#125; 结果：","path":"2020/03/03/归并排序应用之逆序对的个数/","date":"03-03","excerpt":"","tags":[{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"},{"name":"归并排序","slug":"归并排序","permalink":"https://castile.github.io/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"}]},{"title":"Java之反射机制Reflection","text":"动态语言程序运行时，可以改变程序结构或变量类型。典型的语言：Python、ruby、js等。 C, C++, JAVA不是动态语言，JAVA可以称之为“准动态语言”。但是JAVA有一定的动态性，我们可以利用反射机制、 字节码操作获得类似动态语言的特性。JAVA的动态性让编程的时候更加灵活！ Java反射机制Reflection（反射）是被视为动态语言的关键，反射机制允许程序在执行期借助于Reflection API取得任何类的内部信息，并能直接操作任意对象的内部属性及方法。 程序在运行状态中，可以动态加载一个只有名称的类，对于任意一个 已加载的类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性。 加载完类之后，在堆内存中，就产生了一个 Class 类型的对象（一个类只有一个 Class 对象），这个对象就包含了完整的类的结构信息。 我们可以通过这个对象看到类的结构。这个对象就像一面镜子，透过这个镜子看到类的结构，所以，我们形象的称之为：反射。 Java反射机制提供的功能 在运行时判断任意一个对象所属的类 在运行时构造任意一个类的对象 在运行时判断任意一个类所具有的成员变量和方法 在运行时调用任意一个对象的成员变量和方法 生成动态代理 反射初体验一个Peason类，里面包含了： 无参数构造方法 有参数构造方法（包括private和public的） public的属性name、private的属性age get和set方法 自定义方法（包括private和public的） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * @author Hongliang Zhu * @create 2020-03-02 11:27 */public class Peason &#123; public String name; // 私有 private int age; public Peason() &#123; &#125; public Peason(String name, int age) &#123; this.name = name; this.age = age; &#125; private Peason(String name) &#123; // 私有 this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return &quot;Peason&#123;&quot; + &quot;name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &quot;, age=&quot; + age + &#x27;&#125;&#x27;; &#125; private String show(String nation)&#123; // 私有 System.out.println(&quot;国籍为：&quot; + nation); return nation; &#125; public void show()&#123; System.out.println(&quot;我是一个人&quot;); &#125;&#125; 反射示例，通过反射创建对象，调用对象的属性和方法以及修改私有的属性和调用使用的方法： 1234567891011121314151617181920212223242526272829303132333435363738@Test public void test() throws Exception &#123; Class clazz = Peason.class; // 通过反射，创建对象 Constructor constructor = clazz.getConstructor(String.class, int.class); Object tom = constructor.newInstance(&quot;tom&quot;, 15); System.out.println(tom.toString()); // Peason&#123;name=&#x27;tom&#x27;, age=15&#125; System.out.println((tom instanceof Peason)); // 通过反射， 调用对象指定的属性和方法 Field age = clazz.getDeclaredField(&quot;name&quot;); age.set(tom, &quot;zhu&quot;); System.out.println(tom.toString()); Field[] declaredFields = clazz.getDeclaredFields(); System.out.println(Arrays.toString(declaredFields)); // 方法 Method show = clazz.getDeclaredMethod(&quot;show&quot;); show.invoke(tom); System.out.println(&quot;**********************************************&quot;); //调用私有方法和属性 Constructor cons1 = clazz.getDeclaredConstructor(String.class); cons1.setAccessible(true); Object jack = cons1.newInstance(&quot;jack&quot;); System.out.println(jack.toString()); Field name = clazz.getDeclaredField(&quot;name&quot;); name.setAccessible(true); name.set(jack, &quot;lihang&quot;); System.out.println(jack.toString()); // 调用私有的方法 Method showNation = clazz.getDeclaredMethod(&quot;show&quot;, String.class); showNation.setAccessible(true); Object china = showNation.invoke(jack, &quot;China&quot;);// 国籍为：China System.out.println(china instanceof String); System.out.println(china); &#125; 既然使用反射也可以创建对象，那么在开发中是使用new还是使用反射来创建对象呢？ 答案是通过new关键字来创建对象。如果在编译之前不知道需要创建哪个对象，则需要通过反射来创建对象，体现了反射的动态性。 封装性的目的就是为了不让外面的对象来调用私有的方法，然而反射却可以调用私有的属性和方法，那么反射机制与面向对象的封装性是不是矛盾的呢？其实不矛盾，因为封装的目的中带有提示的成分，建议程序员不要去调用私有的方法，因为以及提供了public的方法，没有必要去调用的私有的方法，这是封装的一种提示。而反射是可不可以的问题。 Class对象java.lang.Class类十分特殊，用来表示java中的类型。 class / interface / enum / annotation / [] / primitive type / void 1234567891011Class c1 = Object.class;System.out.println(c1); // class java.lang.ObjectClass c2 = int[][].class;System.out.println(c2); // class [[IClass c3 = int[].class;System.out.println(c3); // class [Iint[] a = new int[10];int[] b = new int[100];Class c4 = a.getClass();Class c5 = b.getClass();System.out.println(c4 == c5); // true 只要是同一维度，就是相同的Class对象 对象照镜子后可以得到的信息：某个类的属性、方法和构造器、某个类到底实现了哪些接口。对于每个类而言，JRE 都为其保留一个不变的 Class 类型的对象。一个 Class 对象包含了特定某个类的有关信息。Class类是Reflection的根源。针对任何您想动态加载、运行的类，唯有先获得相应的Class 对象。 Class本身也是一个类 Class对象只能由系统建立对象 一个类在JVM 中只会有一个Class实例 （重要： 不管你用哪种方式获取的Class实例，都是同一个） 一个Class对象对应的是一个加载到JVM中的一个.class文件 每个类的实例都会记得自己是由哪个Class实例所生成 通过Class可以完整地得到一个类中的完整结构 类加载的过程程序进过javac.exe 命令以后，会生成过程一个或者多个字节码文件(.class结尾)，接着我们使用java.exe 命令对某个字节码文件进行解释执行。相当于字节码文件加载到内存中。此过程就称为类的加载，我们就称为运行时类，此运行时类就作为一个Class的一个实例。 加载到内存中的运行时类，会缓存一段时间。在此时间之内，我们可以通过不同的方式来获取次运行时类。 Class对象的获取第一种方法若已知具体的类，通过类的class属性获取，该方法最为安全可靠，程序性能最高。 12Class&lt;PersonC&gt; clazz = PersonC.class;System.out.println(clazz); // class PersonC 第二种方式已知某个类的实例，调用该实例的getClass()方法获取Class对象 123PersonC p = new PersonC();Class clazz1 = p.getClass();System.out.println(clazz1); // class PersonC 第三种方式已知一个类的全类名，且该类在类路径下，可通过Class类的静态方法forName()获取，可能抛出ClassNotFoundException。 1234public void test1() throws ClassNotFoundException &#123; Class clazz2 = Class.forName(&quot;PersonC&quot;); System.out.println(clazz2); &#125; 123System.out.println(clazz == clazz1); //trueSystem.out.println(clazz == clazz2);//trueSystem.out.println(clazz1 == clazz2);//true 第四种方式：类加载器123ClassLoader loader = this.getClass().getClassLoader();Class clazz4 = loader.loadClass(&quot;PersonC&quot;);System.out.println(clazz4); // class PersonC 类加载机制当程序主动使用某个类时，如果该类还未被加载到内存中，则系统会通过如下三个步骤来对该类进行初始化。 加载将 class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后生成一个代表这个类的 java.lang.Class对象，作为方法区中类数据的访问入口（即引用地址）。所有需要访问和使用类数据只能通过这个Class对象。这个加载的过程需要类加载器参与。 链接将Java类的二进制代码合并到 JVM 的运行状态之中的过程。 验证：确保加载的类信息符合JVM规范，例如：以cafe开头，没有安全方面的问题 准备：正式为类变量（ static）分配内存并设置类变量默认初始值的阶段，这些内存都将在方法区中进行分配。比如 static int n; 在这个环节n会被赋值为 0 。 解析：虛拟机常量池内的符号引用（常量名）替换为直接引用（地址）的过程。 初始化执行类构造器&lt;cini&gt;()方法的过程。类构造器&lt; clinit&gt;()方法是由编译期自动收集类中所有类变量的赋值动作和静态代码块中的语句合并产生的。（类构造器是构造类信息的，不是构造该类对象的构造器）。static int n = 2; //初始化阶段赋值 当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 虛拟机会保证一个类的&lt; clinit&gt;()方法在多线程环境中被正确加锁和同步。 举例说明类加载123456789class A&#123; static &#123; // 静态代码块 m = 300; &#125; static int m = 100; // 静态变量&#125; public void testLoadingClass()&#123; System.out.println(A.m); // &#125; 根据类加载机制，首先第一步类加载，将A加载到内存当中，已经有一个class实例了； 第二步是类的链接，进行类变量的默认初始值， 将m 赋值为0， 即链接结束后 m = 0; 第三步是初始化， 由于静态代码块在静态变量定义之前，所以，m 先赋值为300， 然后赋值为100。 m的值由&lt; clinit&gt;()方法执行决定的。 这个A的类构造器&lt; clinit&gt;()方法由类变量的赋值和静态的代码块中的语句按照顺序合并产生，类似于： 1234&lt; clinit&gt;()&#123; m = 300; m = 100;&#125; 故，最终输出的值为100。 类的主动引用此过程一定会发生类的初始化 new一个类的对象 调用类的静态成员(除了final常量)和静态方法 使用java.lang.reflect包的方法对类进行反射调用 当虚拟机启动，java Hello，则一定会初始化Hello类。说白了就是先启动main方法所在的类 当初始化一个类，如果其父类没有被初始化，则先会初始化他的父类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * l类加载全过程 * @author Hongliang Zhu * @create 2020-03-06 10:57 */public class classLoader &#123; static &#123; System.out.println(&quot;classLoader 类的静态代码块&quot;); &#125; public static void main(String[] args) throws ClassNotFoundException &#123; System.out.println(&quot;classLoader 中 main方法...&quot;); /* 类的主动引用 */ // 调用类的静态成员（除finall）// System.out.println(A.k); System.out.println(A.b); //finall 常量不会初始化类A ： 属于被动引用 // new 对象 A a = new A(); // 反射// Class a = Class.forName(&quot;A&quot;); &#125;&#125;class A extends Father&#123; public static int k = 100; public static final int b = 100; static &#123; System.out.println(&quot;静态初始化类A&quot;); k = 600; &#125; public A()&#123; System.out.println(&quot;类A的构造函数&quot;); &#125;&#125;class Father&#123; static &#123; System.out.println(&quot;父类Father的静态代码块&quot;); &#125; public Father()&#123; System.out.println(&quot;父类Father的构造函数&quot;); &#125;&#125; 上述代码执行情况： classLoader 类的静态代码块 classLoader 中 main方法… 100 父类Father的静态代码块 静态初始化类A 父类Father的构造函数 类A的构造函数 类的被动引用不会发生类的初始化 当访问一个静态域时，只有真正声明这个域的类才会被初始化 通过子类引用父类的静态变量，不会导致子类初始化 通过数组定义类引用，不会触发此类的初始化 引用常量不会触发此类的初始化（常量在编译阶段就存入调用类的常量池中了）final 123456789101112131415161718192021class Father&#123; static int father = 666; static &#123; System.out.println(&quot;父类Father的静态代码块&quot;); &#125; public Father()&#123; System.out.println(&quot;父类Father的构造函数&quot;); &#125;&#125;public static void main(String[] args) throws ClassNotFoundException &#123; System.out.println(&quot;classLoader 中 main方法...&quot;); /** * * 被动引用 */ // System.out.println(A.b); //finall 常量不会初始化类A A[] arr = new A[10]; System.out.println(A.father); &#125; classLoader 类的静态代码块 classLoader 中 main方法… 父类Father的静态代码块 666 类加载器ClassLoader 类加载器作用： 类加载的作用：将class文件字节码内容加载到内存中，并将这些静态数据转换成方法区的运行时数据结构，然后在堆中生成一个代表这个类的 java.lang.class对象，作为方法区中类数据的访问入口。 类缓存：标准的 JavaSE 类加载器可以按要求查找类，但一旦某个类被加载到类加载器中，它将维持加载（缓存）一段时间。不过JVM垃圾回收机制可以回收这些Class对象。 类加载器是用来把类(class)装载进内存的。JVM 规范定义了两种类型的类加载器：启动类加载器(bootstrap)和用户自定义加载器(user-defined class loader)。 JVM在运行时会产生3个类加载器组成的初始化加载器层次结构 ，如下图所示： 引导类加载器：用C++编写的，是JVM自带的类装载器，负责Java平台核心库，用来装载核心类库。该加载器无法直接获取。 扩展类加载器：负责jre/lib/ext目录下的jar包或 –D java.ext.dirs 指定目录下的jar包装入工作库。 系统类加载器：负责java –classpath 或 –D java.class.path所指的目录下的类与jar包装入工作 ，是最常用的加载器。 1234567891011121314151617181920212223242526272829import org.junit.Test;/** * @author Hongliang Zhu * @create 2020-03-02 17:08 */public class TestClassLoader &#123; @Test public void test()&#123; ClassLoader classLoader = TestClassLoader.class.getClassLoader(); // sun.misc.Launcher$AppClassLoader@18b4aac2 System.out.println(classLoader); // sun.misc.Launcher$AppClassLoader@18b4aac2 系统类加载器 ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader(); System.out.println(systemClassLoader); ClassLoader parent = classLoader.getParent(); System.out.println(parent); // sun.misc.Launcher$ExtClassLoader@a09ee92 ClassLoader parent1 = parent.getParent(); System.out.println(parent1); // null ClassLoader classloader = Class.forNme(&quot;java.lang.Object&quot;).getClassLoader(); System.out.println(classloader); //null 说明是由引导类加载器加载的 &#125;&#125; 对于自定义类， 使用的是系统类加载器进行加载。调用系统类加载器的getParent()方法，获取扩展类系统加载器，调用扩展类系统加载器getParent() 无法获取引导类加载器，引导类加载器主要负责加载java的核心类库，无法加载自定义类。 类加载器的代理模式代理模式 – 交给其他加载器来加载指定的类。 双亲委托机制 ： 就是某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父类加载器，依次追溯，直到最高的爷爷辈的，如果父类加载器 可以完成类加载任务，就成功返回；只有父类加载器无法完成此加载 任务时，才自己去加载。 双亲委托机制是为了保证 Java 核心库的类型安全 这种机制就保证不会出现用户自己能定义java.lang.Object/String类的情况。 类加载器除了用于加载类，也是安全的最基本的屏障。 双亲委托机制是代理模式的一种。并不是所有的类加载器都采用双亲委托机制。tomcat服务器类加载器也使用代理模式，所不同的是它是首先尝试去加载某个类，如果找不到再代理给父类加载器。 这与一般类加载器的顺序是相反的。 ClassLoader的作用举例：读取配置文件12345678910public static void main(String[] args) throws IOException &#123; Properties properties = new Properties(); FileInputStream fis = new FileInputStream(&quot;./reflect/jdbc.properties&quot;); properties.load(fis); String user = properties.getProperty(&quot;user&quot;); String password = properties.getProperty(&quot;password&quot;); System.out.println(&quot;user = &quot;+user + &quot;, passeord = &quot;+ password); &#125; 自定义类加载器流程继承 java.lang.ClassLoader 1、首先检查请求的类型是否已经被这个类装载器装载到命名空间中了，如果已经装载，直接返回；否则转入步骤2。 2、委派类加载请求给父类加载器（更准确的说应该是双亲类加载器，真个虚拟机中各种类加载器最终会呈现树状结构），如果父类加载器能够完成，则返回父类加载器加载的Class实例；否则转入步骤3。 3、调用本类加载器的findClass（…）方法，试图获取对应的字节码，如果获取的到，则调用defineClass（…）导入类型到方法区；如 果获取不到对应的字节码或者其他原因失败，返回异常给loadClass（…）， loadClass（…）转抛异常，终止加载过程（注意：这里的 异常种类不止一种）。 文件系统类加载器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import java.io.*;/** * 自定义文件系统加载器 * @author Hongliang Zhu * @create 2020-03-06 14:29 */public class fileSystemClassLoader extends ClassLoader&#123; private String rootDir; public fileSystemClassLoader(String rootDir) &#123; this.rootDir = rootDir; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; loadedClass = findLoadedClass(name); // 如果有已经加载的类，则返回 if( loadedClass != null)&#123; return loadedClass; &#125;else &#123; ClassLoader parent = this.getParent(); try &#123; loadedClass = parent.loadClass(name); // 委托给父类去加载 &#125;catch (Exception e)&#123;// e.printStackTrace(); &#125; if(loadedClass != null)&#123; return loadedClass; &#125;else&#123;// 父类无法加载 // 本类加载， 读取文件，转换成字节数组 byte[] classData = getClassData(name); if(classData == null)&#123; throw new ClassNotFoundException(); &#125;else&#123; loadedClass = defineClass(name, classData, 0, classData.length); &#125; &#125; &#125; return loadedClass; &#125; //com.test.java 将直接骂文件转换成字节数组 private byte[] getClassData(String name) &#123; String path = rootDir + &quot;/&quot;+ name.replace(&quot;.&quot;, &quot;/&quot;)+&quot;.class&quot;; byte[] data = new byte[1024]; ByteArrayOutputStream baos = new ByteArrayOutputStream(); FileInputStream is = null; try &#123; is = new FileInputStream(path); int len = 0; while ((len = is.read(data)) != -1)&#123; baos.write(data, 0, len); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; if(is != null)&#123; try &#123; is.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if(baos != null)&#123; try &#123; baos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; return null; &#125;&#125; 123456789101112131415161718192021222324/** * @author Hongliang Zhu * @create 2020-03-06 15:26 */public class TestFileSystemClassLoader &#123; public static void main(String[] args) throws ClassNotFoundException &#123; fileSystemClassLoader loader = new fileSystemClassLoader(&quot;F:/java&quot;); Class&lt;?&gt; aClass = loader.loadClass(&quot;com.test.java.hello&quot;); Class&lt;?&gt; aClass1 = loader.loadClass(&quot;com.test.java.hello&quot;); fileSystemClassLoader loader1 = new fileSystemClassLoader(&quot;F:/java&quot;); Class&lt;?&gt; cc = loader1.loadClass(&quot;com.test.java.hello&quot;); Class&lt;?&gt; c1 = loader.loadClass(&quot;java.lang.String&quot;); System.out.println(aClass.hashCode()); System.out.println(aClass1.hashCode()); System.out.println(cc.hashCode()); // 不同的类加载器 System.out.println(cc.getClassLoader()); // fileSystemClassLoader@677327b6 System.out.println(c1.getClassLoader()); &#125;&#125; 2133927002 2133927002 1836019240 fileSystemClassLoader@677327b6 null 注意：被两个类加载器加载的同一个类，JVM不认为是相同的类。 通过反射创建运行时对象12345Class clazz = PersonC.class; // 通过反射，创建对象 Constructor constructor = clazz.getConstructor(String.class, int.class); Object tom = constructor.newInstance(&quot;tom&quot;, 15); System.out.println(tom.toString()); // PersonC&#123;name=&#x27;tom&#x27;, age=15&#125; 获取类的属性和内部结构首先创建一个结构丰富的类，包含继承、实现接口，有参构造和无参构造、以及权限不同的属性和方法、带返回值的和不带返回值的，还有注解信息。 123456789101112131415161718192021222324252627282930313233343536373839404142package com;import annotation.MyAnnotation;/** * 一个结构非常丰富的类 * @author Hongliang Zhu * @create 2020-03-02 21:33 */@Myannotation(value = &quot;hi&quot;) // 注解public class Person extends Creature&lt;String&gt; implements Comparable&lt;String&gt;, Myinterface &#123; private String name; // 私有权限 int age; // 默认权限 public int id; // 公共权限 public Person() &#123; &#125; private Person(String name)&#123; this.name = name; &#125; Person(String name, int age)&#123; this.name = name; this.age = age; &#125; private String show(String nation)&#123; System.out.println(&quot;我的国籍为：&quot;+ nation); return nation; &#125; public String display(String insterests)&#123; return insterests; &#125; @Override public void info() &#123; System.out.println(&quot;这是一个人...&quot;); &#125; @Override public int compareTo(String o) &#123; return 0; &#125;&#125; 父类： 12345678910111213141516171819package com;import java.io.Serializable;/** * @author Hongliang Zhu * @create 2020-03-02 21:29 */public class Creature&lt;T&gt; implements Serializable &#123; private char gender; public double weight; public void eat()&#123; System.out.println(&quot;生物在吃东西...&quot;); &#125; public void breath()&#123; System.out.println(&quot;生物在呼吸...&quot;); &#125;&#125; 接口： 123public interface Myinterface &#123; void info();&#125; 注解： 12345@Target(&#123;TYPE, ElementType.CONSTRUCTOR, ElementType.LOCAL_VARIABLE, ElementType.METHOD, ElementType.FIELD, ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface Myannotation &#123; String value() default &quot;Hello&quot;;&#125; 获取属性结构Field【了解】getFields()123456Class clazz = Person.class;// 获取属性Field[] fields = clazz.getFields();for(Field f: fields)&#123; System.out.println(f);&#125; public int com.Person.id public double com.Creature.weight getFields(): 获取当前运行时类及其父类中所有声明为public访问权限的属性。 getDeclaredFields()1234Field[] declaredFields = clazz.getDeclaredFields();for (Field f: declaredFields)&#123; System.out.println(f);&#125; private java.lang.String com.Person.name int com.Person.age public int com.Person.id getDeclaredFields(): 获取当前运行时类当中声明的所有属性。 获取属性的权限、数据类型和变量名1234567891011121314151617181920public void test2()&#123; Class clazz = Person.class; Field[] declaredFields = clazz.getDeclaredFields(); System.out.println(&quot;1.权限修饰符:&quot;); for (Field f: declaredFields)&#123; int modifiers = f.getModifiers(); System.out.println(Modifier.toString(modifiers)); &#125; System.out.println(&quot;2. 数据类型&quot;); for (Field f: declaredFields)&#123; Class type = f.getType(); System.out.println(type.getName()); &#125; System.out.println(&quot;3. 变量名&quot;); for (Field f: declaredFields)&#123; String name = f.getName(); System.out.println(name); &#125; &#125; 1.权限修饰符: private ​ public 2.数据类型 java.lang.String int int 3.变量名 name age id getModifiers()： 获取属性的权限修饰符。 getType()： 获取属性的数据类型。 getName()： 获取属性的名称。 获取运行类的方法结构getMethods()1234Method[] methods = clazz.getMethods();for(Method m: methods)&#123; System.out.println(m);&#125; public int com.Person.compareTo(java.lang.String)public int com.Person.compareTo(java.lang.Object)public void com.Person.info()public java.lang.String com.Person.display(java.lang.String)public void com.Creature.breath()public void com.Creature.eat()public final void java.lang.Object.wait() throws java.lang.InterruptedExceptionpublic final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionpublic final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionpublic boolean java.lang.Object.equals(java.lang.Object)public java.lang.String java.lang.Object.toString()public native int java.lang.Object.hashCode()public final native java.lang.Class java.lang.Object.getClass()public final native void java.lang.Object.notify()public final native void java.lang.Object.notifyAll() getMethods(): 获取当前运行时类及其父类中所有声明为public访问权限的方法。 getDeclaredMethods()同属性结构：getDeclaredMethods() ：获取当前运行时类当中声明的所有属性。（不包含父类中的） public int com.Person.compareTo(java.lang.String)public int com.Person.compareTo(java.lang.Object)public void com.Person.info()private java.lang.String com.Person.show(java.lang.String)public java.lang.String com.Person.display(java.lang.String) 方法也能获取一些自身的结构： 权限修饰符、返回值类型、方法名、形参列表、异常信息、返回值。里面都有对应的方法，可以去查询API。 public Class&lt;?&gt; getReturnType()取得全部的返回值 public Class&lt;?&gt;[] getParameterTypes()取得全部的参数 public int getModifiers()取得修饰符 public Class&lt;?&gt;[] getExceptionTypes()取得异常信息 获取构造器public Constructor&lt;T&gt;[] getConstructors()： 返回此 Class 对象所表示的类的所有public构造方法。 public Constructor&lt;T&gt;[] getDeclaredConstructors()： 返回此 Class 对象表示的类声明的所有构造方法 。 ​ Constructor类中 ： 取得修饰符: public int getModifiers(); 取得方法名称: public String getName(); 取得参数的类型：public Class&lt;?&gt;[] getParameterTypes(); 获取运行时类的父类public Class&lt;? Super T&gt; getSuperclass()： 返回表示此 Class 所表示的实体（类、接口、基本类型）的父类的 Class。 123456Class clazz = Person.class;Class superclass = clazz.getSuperclass();System.out.println(superclass); // class com.CreatureType genericSuperclass = clazz.getGenericSuperclass(); // 带泛型的父类System.out.println(genericSuperclass); // com.Creature&lt;java.lang.String&gt; 获取运行时带泛型类的父类的泛型1234567Class clazz = Person.class;Type genericSuperclass = clazz.getGenericSuperclass();ParameterizedType parameterizedType = (ParameterizedType) genericSuperclass;// 获取泛型类型Type[] actualTypeArguments = parameterizedType.getActualTypeArguments();System.out.println(actualTypeArguments[0].getTypeName()); // java.lang.String 在JDBC中需要使用到。DAO操作。 获取父类泛型类型：Type getGenericSuperclass() 泛型类型：ParameterizedType 获取实际的泛型类型参数数组：getActualTypeArguments() 获取运行时类实现的接口public Class&lt;?&gt;[] getInterfaces() ； 1234Class[] interfaces = clazz.getInterfaces(); for(Class i: interfaces)&#123; System.out.println(i); &#125; interface java.lang.Comparable interface com.Myinterface 1234Class[] interfaces1 = clazz.getSuperclass().getInterfaces(); for(Class i: interfaces1)&#123; System.out.println(i); &#125; interface java.io.Serializable 获取运行时类所在的包Package getPackage() 12Package aPackage = clazz.getPackage();System.out.println(aPackage); // package com 获取注解详见《Java注解Annotation》文章反射注解部分。 使用反射生成并操作对象使用反射获取指定的属性在反射机制中，可以直接通过Field类操作类中的属性，通过Field类提供的set()和get()方法就可以完成设置和取得属性内容的操作 。 public Field getField(String name) 返回此Class对象表示的类或接口的指定的public的Field。 public Field getDeclaredField(String name)返回此Class对象表示的类或接口的指定的Field。（所有声明的，也包括私有属性） 在Field中： public Object get(Object obj) 取得指定对象obj上此Field的属性内容 public void set(Object obj,Object value) 设置指定对象obj上此Field的属性内容 注：在类中属性都设置为**非public**的前提下，在使用set()和get()方法时，首先要使用Field类中的setAccessible(true)方法将需要操作的属性设置为可以被外部访问。 public void setAccessible(true)访问私有属性时，让这个属性可见。 1234567891011121314151617181920public void test4() throws Exception&#123; Class clazz = Person.class; // 创建实例对象 Person p = (Person) clazz.getConstructor().newInstance(); // 获取指定的属性 Field f = clazz.getField(&quot;id&quot;); // 获取指定的属性值 String name = f.getName(); System.out.println(name); //设置当前的属性值 f.set(p, 100); System.out.println(p.toString()); // 获取指定的s属性;私有 Field name1 = clazz.getDeclaredField(&quot;name&quot;); name1.setAccessible(true);//设定可访问 name1.set(p, &quot;zhuhongliang&quot;); System.out.println(p.toString()); &#125; 使用反射获取指定的方法通过反射，调用类中的方法，通过Method类完成。步骤： 1.通过Class类的getMethod(String name, Class … parameterTypes)方法取得一个Method对象，并设置此方法操作时所需要的参数类型。 2.之后使用Object invoke(Object obj, Object[] args)进行调用，并向方法中传递要设置的obj对象的参数信息。 Object invoke(Object obj, Object[] args): 1.Object 对应原方法的返回值，若原方法无返回值，此时返回null 2.若原方法若为静态方法，此时形参Object obj可为null 或者 对于的calss对象。 3.若原方法形参列表为空，则Object[] args为null 4.若原方法声明为private,则需要在调用此invoke()方法前，显式调用方法对象的setAccessible(true)方法，将可访问private的方法。 123456// 在Person类增加入菜静态方法：// 静态方法 private static String showdesc(String name)&#123; System.out.println(&quot;英俊潇洒 &quot;); return name; &#125; 12345678910111213141516 @Test public void test5() throws Exception &#123; Class clazz = Person.class; // 创建实例对象 Person p = (Person) clazz.getConstructor().newInstance(); Method show = clazz.getDeclaredMethod(&quot;show&quot;, String.class); show.setAccessible(true); show.invoke(p, &quot;加拿大&quot;); System.out.println(&quot;-------------调用静态方法--------&quot;); Method showdesc = clazz.getDeclaredMethod(&quot;showdesc&quot;, String.class); showdesc.setAccessible(true); Object invoke = showdesc.invoke(null,&quot;应似飞鸿踏雪泥&quot;); // 具有返回值 System.out.println(invoke);&#125; 我的国籍为：加拿大 ————-调用静态方法——– 英俊潇洒 应似飞鸿踏雪泥 调用指定的构造器1234567public void test6() throws Exception &#123; Class clazz = Person.class; Constructor cons = clazz.getDeclaredConstructor(String.class); cons.setAccessible(true); Person zhu = (Person) cons.newInstance(&quot;zhu&quot;); System.out.println(zhu.toString());&#125; setAccessible启用和禁用访问安全检查的开关，值为 true 则指示反射的对象在使用时应该取消 Java 语言访问检查。值为 false 则指示反射的对象应该实施 Java 语言访问检查。并不是为true 就能访问为false就不能访问。 禁止安全检查，可以提高反射的运行速度。 123456789101112131415161718192021222324252627282930313233343536373839404142import com.Person;import java.lang.reflect.Method;/** * 反射性能 * @author Hongliang Zhu * @create 2020-03-03 14:26 */public class TestAccessiable &#123; public static void main(String[] args) throws Exception &#123; Class clazz = Person.class; Person p = (Person) clazz.getDeclaredConstructor().newInstance(); Method test = clazz.getDeclaredMethod(&quot;test&quot;); Person p1 = new Person(); long start = System.currentTimeMillis(); for(int i =0 ; i &lt; 1000000000L; i++)&#123; p1.test(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot;普通方法调用10亿次，耗时：&quot;+ (end - start)); start = System.currentTimeMillis(); for(int i =0 ; i &lt; 1000000000L; i++)&#123; test.invoke(p); &#125; end = System.currentTimeMillis(); System.out.println(&quot;反射方法动态调用调用10亿次，耗时：&quot;+ (end - start)); test.setAccessible(true); start = System.currentTimeMillis(); for(int i =0 ; i &lt; 1000000000L; i++)&#123; test.invoke(p); &#125; end = System.currentTimeMillis(); System.out.println(&quot;反射方法动态调用调用10亿次，跳过安全检查，耗时：&quot;+ (end - start)); &#125;&#125; 普通方法调用10亿次，耗时：396 反射方法动态调用调用10亿次，耗时：1886 反射方法动态调用调用10亿次，跳过安全检查，耗时：1545 反射的应用–动态代理代理设计模式： 使用一个代理将对象包装起来, 然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理，代理对象决定是否以及何时将方法调用转到原始对象上。 静态代理特征是代理类和目标对象的类都是在编译期间确定下来，不利于程序的扩展。同时，每一个代理类只能为一个接口服务，这样一来程序开发中必然产生过多的代理。最好可以通过一个代理类完成全部的代理功能。 动态代理是指客户通过代理类来调用其它对象的方法，并且是在程序运行时根据需要动态创建目标类的代理对象。 静态代理123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.zhu.proxy;import java.security.PublicKey;/** * 静态代理 * @author Hongliang Zhu * @create 2020-03-03 13:03 */interface ClothFactory&#123; void produceCloth();&#125;//代理类class ProxyClothFactory implements ClothFactory&#123; private ClothFactory factory; // 构造方法 public ProxyClothFactory(ClothFactory factory)&#123; this.factory = factory; &#125; @Override public void produceCloth() &#123; System.out.println(&quot;代理类做一些准备工作...&quot;); factory.produceCloth(); System.out.println(&quot;代理类做一些收尾工作...&quot;); &#125;&#125;// 被代理类class Nike implements ClothFactory&#123; @Override public void produceCloth() &#123; System.out.println(&quot;Nike公司生产运动服...&quot;); &#125;&#125;public class StaticProxyTest &#123; public static void main(String[] args) &#123; // 创建被代理类对象 Nike nike = new Nike(); // 创建代理类对象 ProxyClothFactory proxyClothFactory = new ProxyClothFactory(nike); proxyClothFactory.produceCloth(); &#125;&#125; 代理类做一些准备工作… Nike公司生产运动服… 代理类做一些收尾工作… 动态代理Proxy : 专门完成代理的操作类，是所有动态代理类的父类。通过此类为一个或多个接口动态地生成实现类。 提供用于创建动态代理类和动态代理对象的静态方法: static Object newProxyInstance( ClassLoader loader, Class[] interfaces, InvocationHandler h)直接创建一个动态代理对象。 static Class getProxyClass( ClassLoader loader, Class… interfaces) 创建一个动态代理类所对应的Class对象。 创建一个代理对象，将被代理对象的类加载器，Class对象，实现的接口一句执行函数的句柄作为参数传入到代理类对象中。通过调用代理类对象的同名方法就会通过invoke()动态调用代理类中的同名方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.zhu.proxy;import java.awt.*;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * 动态代理 * @author Hongliang Zhu * @create 2020-03-03 13:14 */interface Human&#123; String getBelief(); // 信仰 void eat(String food);&#125;// 被代理类class SuperMan implements Human&#123; @Override public String getBelief() &#123; return &quot;I believe I can fly!&quot;; &#125; @Override public void eat(String food) &#123; System.out.println(&quot;我喜欢吃&quot;+ food); &#125;&#125;/** * 动态代理： * 1. 如何根据加载到内存中的被代理类， 动态的创建一个代理类及其对象？ * 2. 当通过代理类的对象调用方法时， 如何动态地去调用被代理类中的同名方法？ */class ProxyFactory&#123; // 调用此方法， 返回一个代理类的对象 Object obj是一个被代理类 public static Object getProxyInstance(Object obj)&#123; MyInvocationHandler handler = new MyInvocationHandler(); handler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), handler); &#125;&#125;class MyInvocationHandler implements InvocationHandler&#123; private Object obj; // 需要使用被代理类的对象进行赋值 public void bind(Object obj)&#123; this.obj = obj; &#125; //当我们通过代理类的对象调用方法a中， 就会自动调用如下的方法：invoke // 将被代理类要执行的方法a的功能就声明在invoke()中 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; // method: 即为代理类对象调用的方法，此方法也就作为了被代理类的方法 Object returnValue = method.invoke(obj, args); return returnValue; &#125;&#125;public class ProxyTest &#123; public static void main(String[] args) &#123; // 创建一个代理类对象 Human proxyInstance = (Human) ProxyFactory.getProxyInstance(new SuperMan()); String belief = proxyInstance.getBelief(); System.out.println(belief); proxyInstance.eat(&quot;胖哥俩&quot;); System.out.println(&quot;----------------------------------&quot;); ClothFactory proxyInstance1 = (ClothFactory) ProxyFactory.getProxyInstance(new Nike()); proxyInstance1.produceCloth(); &#125;&#125; I believe I can fly! 我喜欢吃胖哥俩 Nike公司生产运动服… 总结 动态代理步骤 创建一个实现接口InvocationHandler的类，它必须实现invoke方法，以完成代理的具体操作。 1234567891011public Object invoke(Object theProxy, Method method, Object[] params) throws Throwable&#123; try &#123; Object retval = method.invoke(targetObj, params); // Print out the result System.out.println(retval); return retval; &#125; catch (Exception exc)&#123;&#125; &#125; Object theProxy： 被代理的对象 Method method： 要调用的方法 Object[] params： 方法调用时所需要的参数 创建被代理的类以及接口 通过Proxy的静态方法创建一个代理对象。 通过代理对象调用被代理对象的方法。","path":"2020/03/02/Java之反射机制Reflect/","date":"03-02","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"反射","slug":"反射","permalink":"https://castile.github.io/tags/%E5%8F%8D%E5%B0%84/"}]},{"title":"Non-local Neural Networks","text":"论文： https://arxiv.org/abs/1711.07971v3 作者： Xiaolong Wang, Ross Girshick, Abhinav Gupta, Kaiming He Non-local Neural Networks概述文章从BM3D去噪算法中的non-local means 和self-attention出发，在neural network中考虑不同空间和时间位置上的特征之间的关系。non-local在一个位置的计算响应是输入特性图中所有位置的特征的加权总和。一组位置可以在空间、时间或时空上，适用于图像、序列和视频问题。 在深度神经网络中捕获long-range dependencies是非常重要的。对于序列数据，比如音频，语言文本，通常是使用循环网络来对long-range dependencies建模。对于图像数据，是通过不断堆叠卷积层以获得大的感受野来对long-range dependencies进行建模。 卷积运算和循环网络运算论是在空间上还是在时间上都是只处理一个局部邻域，因此，long-range dependencies只能在重复应用这些操作时捕获，这些操作通过数据逐步传播信号。但是这种重复操作有很多缺点或者限制。 首先，计算效率很低，第二，很依赖于训练技巧，很难优化，随着网络的深读增加，很导致梯度消失和梯度爆炸等问题。 最后，这些挑战使得多跳依赖关系建模（multihop dependency modeling）变得困难，例如，当需要在遥远的位置之间来回传递消息时。 使用Non-local有很多优势： 与卷积操作和RNN相比， Non-local操作通过计算任意两个位置之间的交互来直接捕获long-range dependencies，而不管它们的位置距离的有多远。 Non-local很有效，即使只有很少的层（比如5层）也能取得最佳效果在一些实验中。 Non-local操作的输入大小可变，并且可以轻松地与其他操作(例如，卷积)相结合。 Non-local MeanNL-means去噪与常用的双线性滤波、中值滤波等利用图像局部信息来滤波不同的是，它利用了整幅图像来进行去噪，以图像块为单位在图像中寻找相似区域，再对这些区域求平均，能够比较好地去掉图像中存在的高斯噪声。 Graphical models Long-range dependencies 可以通过图模型来进行建模，比如CRF。在深度神经网络的环境下，CRF可以被用来对语义分割预测结果的后处理操作。 CRF的迭代平均场推理可以转化为递归网络并进行训练 。 Self-attention论文的工作和机器翻译中的自注意力机制有关。自注意模块在一个 embedding space通过关注所有位置并取它们的加权平均值来计算序列(例如，一个句子)中某个位置的响应。 Non-local Neural Networks 上面的公式中，输入是x，输出是y，i 和 j 分别代表输入的某个空间位置， $x_i$ 是一个向量，维数跟x的channel数一样，$f$ 是一个计算任意两点相似关系的函数，$g $ 是一个映射函数，将一个点映射成一个向量，可以看成是计算一个点的特征。$C(x)$ 是一个normalize系数。也就是说，为了计算输出层的一个点，需要将输入的每个点都考虑一遍，而且考虑的方式很像attention：输出的某个点在原图上的attention，而mask则是由相似性给出。看下图： Non-local操作可以看成attention 与卷积操作比较，卷积运算将一个局部邻域的加权输入相加，比如在一维卷积中，kernel size为3 的卷积核： $i -1 \\le j \\le i + 1$。 与循环网络比较，一个在时间 $i $ 递归操作的局部一般是基于当前状态和上一次的时间的状态。 Non-local与全连接网络也不一样， 在上述公式是根据不同位置之间的关系计算响应， 而fc是使用学习到的权重来计算的。换句话说， $x_i$ 和 $x_j$ 之间的关系也不是在fc中输入数据的函数。而且， Non-local支持可变尺寸，并且输出的尺寸和输入的一样。 以图像为例，为了简化问题，作者简单地设置$g$函数为一个1*1的卷积： $g(x_j) = W_gx_j$ 。 相似性度量函数 $f$ 的选择有多种: Gaussian$$f(x_i, x_j) = e^{\\mathbf{x_i}^\\mathsf{T} \\mathbf{x_j}}$$ $$C(\\mathbf{x}) = \\sum_{\\forall j} f(\\mathbf{x_i, \\mathbf{x_j}})$$ $\\mathbf{x_i}^\\mathsf{T} \\mathbf{x_j}$ 是点积相似性，也可以用欧氏距离。但是点积在依稀额深度学习框架中实现起来更方便一些。 Embedded Gaussian是上一中的一个扩展，通过在一个嵌入空间中计算$$f(x_i, x_j) = e^{\\theta(\\mathbf{x_i})\\top \\phi(\\mathbf{x_j})}$$ $$\\theta(\\mathbf{x_i}) = W_{\\theta}\\mathbf{x_i} \\space\\space, \\space \\phi(\\mathbf{x_j}) = W_{\\phi}{\\mathbf{x_j}}$$ $$设： C(\\mathbf{x}) = \\sum_{\\forall j} f(\\mathbf{x_i, \\mathbf{x_j}})$$ 最近提出的用于机器翻译的自我注意模块《Attention is all you need》是Embedded Gaussian 版本中Non-local操作的一个特例。从中可以看出，对于 $i$ , $\\frac{1}{ C(\\mathbf{x})}f(\\mathbf{x_i, \\mathbf{x_j}})$ 相当于对 $j$ 维进行softmax操作。所以：$$\\mathbf{y} = softmax(\\mathbf{x^{\\top}}W_{\\theta}^\\top W_{\\phi}\\mathbf{x})g(\\mathbf{x})$$这就是self-attentiond 的形式。 Dot product$$f(x_i, x_j) =\\theta(\\mathbf{x_i})\\top \\phi(\\mathbf{x_j})$$ $$normalization factor： C\\mathbf(x) = N$$ Concatenation Relation Networks中的成对函数将连接用于视觉推理:$$f(\\mathbf{x_i}, \\mathbf{x_j}) = ReLu(\\mathbf{w_f^T[\\theta(x_i), \\phi(x_j)]}).$$ 这相当于embedded的两个点拼接作为带ReLU激活函数全连接层的输入。它在visual reasoning中用的比较多。 后两种选择的归一化系数 $C(x)$选择为$\\mathbf{x}$的点数，只是为了简化计算，同时，还能保证对任意尺寸的输入，不会产生数值上的尺度伸缩。 Embedding的实现方式，以图像为例，在文章中都采用1*1的卷积，也就是$\\theta $和$\\phi$都是卷积操作。 Non-local Block 为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学习 x的residual 。$$\\mathbf{z_i} = W_z\\mathbf{y_i + x_i}$$$+\\mathbf{x_i}$ 表示残差连接。 $W_z$ 实际上是一个卷积操作，它的输出channel数跟x一致。这样以来，non-local操作就可以作为一个组件，组装到任意卷积神经网络中。 实现 看下图：计算相似性 总结1、单一的non-local block加在较浅层次效果显著。高层次丢失的信息太多了，找不到细小的远距离的联系，太模糊了。 2、多个non-local block加入，也就是加深non-local特性，有一定效果提升但不会很明显。 既然容易起作用的是在低层加，那么使劲加深意义不大，加多了这种东西就要考虑梯度消失和引入噪声。毕竟你把背景全都扔进来算。 3、时空同时non-local比单一时间维度或单一空间维度效果都要好。 4、non-local比3D-CNN要好。 参考 https://zhuanlan.zhihu.com/p/33345791","path":"2020/03/01/Non-local/","date":"03-01","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"}]},{"title":"归并排序应用之-计算数组的小和","text":"问题描述 小和问题： 在一个数组中，每一个数左边比当前数小的数累加起来，叫做这个数组的小和。求一个数组的小和。 数组小和的定义如下： 例如，数组s = [1, 3, 5, 2, 4, 6] 在s[0]的左边小于或等于s[0]的数的和为0； 在s[1]的左边小于或等于s[1]的数的和为1； 在s[2]的左边小于或等于s[2]的数的和为1+3=4； 在s[3]的左边小于或等于s[3]的数的和为1； 在s[4]的左边小于或等于s[4]的数的和为1+3+2=6； 在s[5]的左边小于或等于s[5]的数的和为1+3+5+2+4=15。 所以s的小和为0+1+4+1+6+15=27 给定一个数组s，实现函数返回s的小和 要求时间复杂度为O(logN)， 空间复杂度为O(N). 牛客网： 计算数组的小和. 输入描述: 第一行有一个整数N。表示数组长度接下来一行N个整数表示数组内的数 输出描述: 一个整数，表示答案。 示例1： 输入： 6 1 3 5 2 4 6 输出： 27 备注$1 \\le N \\le 10^5$ $-100 \\le arr_i \\le 100$ 分析可以使用暴力方法，双重for循环，遍历数组中每一个元素，计算它左边比他小的数，累加起来即得答案。 但是题目要求时间复杂度为 $O(log N)$ , 此题可用归并排序思想来解答， 在merge的过程中计算小和。 a. 将当前序列分为两个子序列，分别求其小和 b. 对a划分得到的两个子序列进行merge操作，得到合并过程产生的小和，再加上a得到的两个子序列的小和之和 c. 递归地执行a和b。 求一个数组的小和，可以转化为求每个元素在小和累加过程出现的次数，然后将当前元素与出现次数相乘，累加得到小和。假设当前元素为a，a右边比a大的元素个数则为a在小和累加过程出现的次数 。 代码 注意两个细节， 这个题目的小和，当左边的数字和当前的数相等时，也算一个小和。所有循环里面的判断if 应该是 &lt;= 。然后就是help数组的大小应为high-low+1， 注意拷贝回原数组的细节： github： https://github.com/Castile/algorithm/blob/master/leetcode/src/Sort/smallSum.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273import java.util.Scanner;/** * * @author Hongliang Zhu * @create 2020-02-29 22:53 */public class Main &#123; // 暴力方法 O(N^2) public static long smallSum(int[] arr)&#123; long sum = 0; for(int i = 0; i &lt; arr.length; i++)&#123; for(int j = 0; j &lt; i; j++)&#123; if(arr[j] &lt; arr[i])&#123; sum+=arr[j]; &#125; &#125; &#125; return sum; &#125; public static long samllSum_merge(int[] arr, int low, int high)&#123; if(low == high) return 0; // 计算mid的位置 int mid = low + (( high - low ) &gt;&gt; 1); // 这样可以避免溢出，而且使用了位运算，效率更高 return samllSum_merge(arr, low, mid) + samllSum_merge(arr, mid+1, high) + merge(arr, low, mid, high); &#125; // 归并两个有序的数组 public static long merge(int[]arr, int low, int mid, int high)&#123; int[] help = new int[high - low + 1]; // 注意此处数组的大小 long result = 0; int p = low; int q = mid + 1; int k = 0; while (p &lt;= mid &amp;&amp; q &lt;= high)&#123; if(arr[p] &lt;= arr[q])&#123; // 左边比又变小，产生小和 result += arr[p] * ( high - q + 1); help[k++] = arr[p++]; &#125;else if(arr[p] &gt; arr[q])&#123; help[k++] = arr[q++]; &#125; &#125; while(p &lt;= mid)&#123; help[k] = arr[p++]; k++; &#125; while(q &lt;= high)&#123; help[k] = arr[q++]; k++; &#125; // copy for(int i = 0; i &lt; high - low + 1; i++)&#123; arr[low + i] = help[i]; &#125; return result; &#125; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); int n = scanner.nextInt(); int[] arr = new int[n]; for(int i = 0; i &lt;n; i++)&#123; arr[i] = scanner.nextInt(); &#125; long sum = samllSum_merge(arr,0, arr.length -1); System.out.println(sum); &#125;&#125;","path":"2020/02/29/小和问题/","date":"02-29","excerpt":"","tags":[{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"},{"name":"归并排序","slug":"归并排序","permalink":"https://castile.github.io/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"}]},{"title":"Java注解(Annotation)","text":"注解Annotation从 JDK 5.0 开始, Java 增加了对元数据(MetaData) 的支持, 也就是 Annotation(注解)。 Annotation 其实就是代码里的特殊标记, 这些标记可以在编译, 类加载, 运行时被读取, 并执行相应的处理。通过使用 Annotation, 程序员可以在不改变原有逻辑的情况下, 在源文件中嵌入一些补充信息。 Annotation 可以像修饰符一样被使用, 可用于修饰包, 类, 构造器, 方法, 成员变量, 参数，局部变量的声明 , 这些信息被保存在 Annotation 的 “name=value” 对中。我们可以通过反射机制编程实现对这些元数据的访问。 Annotation 能被用来为程序元素(类, 方法, 成员变量等) 设置元数据。 在Java SE中，注解的使用目的比较简单，例如标记过时的方法，忽略警告等。 在Java EE / Android中注解占据了更重要的角色，例如用来配置应用程序的任何切面，代替JavaEE旧版中所遗留的繁冗代码和XML配置。 未来的开发模式都是基于注解的，JPA是基于注解的，Spring2.5以上都是基于注解的，Hibernate3.x以后也都是基于注解的，Struts2也有一部分是基于注解的了。 注解是一种趋势， 一定程度上可以说： ​ 框架 = 注解 + 反射 + 设计模式。 Annotation 架构 (1). 1 个 Annotation 和 1 个 RetentionPolicy 关联。 可以理解为：每1个Annotation对象，都会有唯一的RetentionPolicy属性。 (2). 1 个 Annotation 和 1~n 个 ElementType 关联。 可以理解为：对于每 1 个 Annotation 对象，可以有若干个 ElementType 属性。 (3). Annotation 有许多实现类，包括：Deprecated, Documented, Inherited, Override 等等。 Annotation 的每一个实现类，都 “和 1 个 RetentionPolicy 关联” 并且 “ 和 1~n 个 ElementType 关联”。 Annotation 组成部分 JavaAnnotation 的组成中有 3 个非常重要的主干类。它们分别是： Annotation.java：1234567891011package java.lang.annotation;public interface Annotation &#123; boolean equals(Object obj); int hashCode(); String toString(); Class&lt;? extends Annotation&gt; annotationType();&#125; Annotation 就是个接口。 每 1 个 Annotation“ 都与 “1 个 RetentionPolicy“ 关联，并且与 “1～n 个 ElementType“ 关联。可以通俗的理解为：每 1 个 Annotation 对象，都会有唯一的 RetentionPolicy 属性；至于 ElementType 属性，则有 1~n 个。 ElementType.java：12345678910111213141516171819package java.lang.annotation;public enum ElementType &#123; TYPE, /* 类、接口（包括注释类型）或枚举声明 */ FIELD, /* 字段声明（包括枚举常量） */ METHOD, /* 方法声明 */ PARAMETER, /* 参数声明 */ CONSTRUCTOR, /* 构造方法声明 */ LOCAL_VARIABLE, /* 局部变量声明 */ ANNOTATION_TYPE, /* 注释类型声明 */ PACKAGE /* 包声明 */&#125; ElementType 是 Enum 枚举类型，它用来指定 Annotation 的类型。 每 1 个 Annotation“ 都与 “1～n 个 ElementType“ 关联。当 Annotation 与某个 ElementType 关联时，就意味着：Annotation有了某种用途。例如，若一个 Annotation 对象是 METHOD 类型，则该 Annotation 只能用来修饰方法。 RetentionPolicy.java：12345678package java.lang.annotation;public enum RetentionPolicy &#123; SOURCE, /* Annotation信息仅存在于编译器处理期间，编译器处理完之后就没有该Annotation信息了 */ CLASS, /* 编译器将Annotation存储于类对应的.class文件中。默认行为 */ RUNTIME /* 编译器将Annotation存储于class文件中，并且可由JVM读入 */&#125; RetentionPolicy 是 Enum 枚举类型，它用来指定 Annotation 的策略。通俗点说，就是不同 RetentionPolicy 类型的 Annotation 的作用域不同。 每 1 个 Annotation 都与 1 个 RetentionPolicy关联 ： a) 若 Annotation 的类型为 SOURCE，则意味着：Annotation 仅存在于编译器处理期间，编译器处理完之后，该 Annotation 就没用了。 例如，” @Override” 标志就是一个 Annotation。当它修饰一个方法的时候，就意味着该方法覆盖父类的方法；并且在编译期间会进行语法检查！编译器处理完后，”@Override” 就没有任何作用了。 b） 若 Annotation 的类型为 CLASS，则意味着：编译器将 Annotation 存储于类对应的 .class 文件中，它是 Annotation 的默认行为。 c) 若 Annotation 的类型为 RUNTIME，则意味着：编译器将 Annotation 存储于 class 文件中，并且可由JVM读入。 也就是说可以通过反射机制来读取。 JDk中的内置注解Java 定义了一套注解，共有 7 个，3 个在 java.lang 中，剩下 4 个在 java.lang.annotation 中。 使用 Annotation 时要在其前面增加 @ 符号, 并把该 Annotation 当成一个修饰符使用。用于修饰它支持的程序元素。 @Override定义在java.lang.Override中，此注解只适用修饰方法，表示一个方法声明重写父类中的另一个方法声明。 如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误。 @Deprecated定义在java.lang.Deprecated中， 用于表示某个程序元素(类, 方法等)已过时。此注解可用于修辞方法、属性、类 ，表示不鼓励程序员使用这样的元素，通常是因为它很危险或存在更好的选择。 1234@Documented@Retention(RetentionPolicy.RUNTIME) public @interface Deprecated &#123;&#125; @ SuppressWarnings定义在java.lang.SuppressWarnings中，用来抑制编译时的警告信息。 12345@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123; String[] value();&#125; (1) @interface – 它的用来修饰 SuppressWarnings，意味着 SuppressWarnings 实现了java.lang.annotation.Annotation 接口；即 SuppressWarnings 就是一个注解 。 (2) @Retention(RetentionPolicy.SOURCE) – 它的作用是指定 SuppressWarnings 的策略是 RetentionPolicy.SOURCE。这就意味着，SuppressWarnings 信息仅存在于编译器处理期间，编译器处理完之后 SuppressWarnings 就没有作用了。 (3) @Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;) – 它的作用是指定 SuppressWarnings 的类型同时包括TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE。 (04) String[] value(); 意味着，SuppressWarnings 能指定参数 。 与前两个注释有所不同，你需要添加一个参数才能正确使用，这些参数值都是已经定义好了的，我们选择性的使用就好了，参数如下： 1234567deprecation -- 使用了不赞成使用的类或方法时的警告unchecked -- 执行了未检查的转换时的警告，例如当使用集合时没有用泛型 (Generics) 来指定集合保存的类型。fallthrough -- 当 Switch 程序块直接通往下一种情况而没有 Break 时的警告。path -- 在类路径、源文件路径等中有不存在的路径时的警告。serial -- 当在可序列化的类上缺少 serialVersionUID 定义时的警告。finally -- 任何 finally 子句不能正常完成时的警告。all -- 关于以上所有情况的警告。 (5) SuppressWarnings 的作用是，让编译器对”它所标注的内容”的某些警告保持静默。例如，”@SuppressWarnings(value=&#123;&quot;deprecation&quot;, &quot;unchecked&quot;&#125;)“ 表示对”它所标注的内容”中的 “SuppressWarnings 不再建议使用警告”和”未检查的转换时的警告”保持沉默。 自定义注解Annotation 通用定义12345@Documented@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation1 &#123;&#125; 定义新的 Annotation 类型使用 @interface 关键字。 自定义注解自动继承了java.lang.annotation.Annotation 接口。 Annotation的成员变量在 Annotation 定义中以无参数方法的形式来声明。其方法名和返回值定义了该成员的名字和类型。称之为配置参数。例如： String[] values(); 如果只有一个参数成员，一般参数名为value 可以在定义 Annotation 的成员变量时为其指定初始值, 指定成员变量的初始值可使用default关键字。 123public @interface MyAnnotation&#123; String name() default &quot;jack&quot;;&#125; 没有成员定义的 Annotation 称为标记, 比如 @Override; 包含成员变量的 Annotation 称为元数据 Annotation, 再使用该注解的时候要使用成员变量，指定值。 注： 自定义注解必须定义注解信息处理流程才有意义。 (注解信息处理流程，是注解和注释的重大区别 。如果没有注解信息处理流程，则注解毫无意义）。使用反射实现。 元注解元注解的作用就是负责注解其他注解， 对现有的注解进行解释说明的注解。（注解注解的注解。…晕） JDK5.0提供了专门在注解上的注解类型，分别是： @Retention @Target @Documented @Inherited 元数据： String name = &quot;zhu&quot;; 其中 String name 就是一个元数据， 用来修饰主要数据（”zhu”）的数据。 @Retention只能用于修饰一个 Annotation 定义, 用于指定该 Annotation 可以保留多长时间（生命周期）。 @Rentention 包含一个 RetentionPolicy 类型的成员变量, 使用 @Rentention 时必须为该 value 成员变量指定值。 RetentionPolicy.SOURCE ： 编译器直接丢弃这种策略的注释， 编译成class文件中不会保留该注解信息。 RetentionPolicy.CLASS: 编译器将把注释记录在 class 文件中。当运行 Java 程序时， JVM 不会保留注解。 这是默认值。 RetentionPolicy.RUNTIME： 编译器将把注释记录在class文件中。当运行Java程序时, JVM会保留注解。程序可以通过反射获取该注解。 可以参考上文[@Retention](#Annotation 组成部分). @Target前面我们说过，ElementType 是 Annotation 的类型属性。而 @Target 的作用，就是来指定 Annotation 的类型属性。查看[ElementType ](# ElementType.java:)。 用于修饰 Annotation 定义, 用于指定被修饰的 Annotation 能用于修饰哪些程序元素。@Target 也包含一个名为 value 的成员变量。 定义 Annotation 时，@Target 可有可无。若有 @Target，则该 Annotation 只能用于它所指定的地方；若没有 @Target，则该 Annotation 可以用于任何地方。 如： 1234567@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123; String[] value();&#125; @Inherited被它修饰的 Annotation 将具有继承性.如果某个类使用了被 @Inherited 修饰的 Annotation, 则其子类将自动具有该注解。 实际开发中应用的较少。 @Documented用于指定被该元 Annotation 修饰的 Annotation 类将被 javadoc 工具提取成文档。 定义为Documented的注解必须设置Retention值为RUNTIME。 JDK8中注解的新特性可重复注解在JDK8之前，如果需要使用重复注解： 1234567891011121314151617package annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * @author Hongliang Zhu * @create 2020-02-29 12:45 */@Target(&#123;ElementType.CONSTRUCTOR, ElementType.LOCAL_VARIABLE, ElementType.METHOD, ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation&#123; String name() default &quot;jack&quot;;&#125; 需要定义一个注解，里面加入要重复注解类型的数组： 123456789package annotation;/** * @author Hongliang Zhu * @create 2020-02-29 16:19 */public @interface MyAnnotaionss &#123; MyAnnotation[] value(); // 数组&#125; 使用： 12345@MyAnnotaionss( &#123; @MyAnnotation(name = &quot;tom&quot;), @MyAnnotation(name = &quot;zhu&quot;) &#125;) public void print()&#123; System.out.println(&quot;注解测试&quot;); &#125; 在JDk8之后：使用@Repeatable 可以实现可重复注解。 ①. 在MyAnnotation上声明@Repeatable， 成员值为@Repeatable.class`。 ②. MyAnnotation 的 Target 与 Retention 等元注解和 MyAnnotations的要相同。 ③. 使用可重复注解： 123456789101112@Repeatable(MyAnnotaionss.class)@Target(&#123;ElementType.CONSTRUCTOR, ElementType.LOCAL_VARIABLE, ElementType.METHOD, ElementType.FIELD&#125;)@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation&#123; String value() default &quot;jack&quot;;&#125;@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.CONSTRUCTOR, ElementType.LOCAL_VARIABLE, ElementType.METHOD, ElementType.FIELD&#125;)public @interface MyAnnotaionss &#123; MyAnnotation[] value();&#125; 12345@MyAnnotation(value = &quot;zhu&quot;)@MyAnnotation(value = &quot;jerry&quot;) // 可重复注解public void print()&#123; System.out.println(&quot;注解测试&quot;);&#125; 类型注解来看看jdk8中的ElementType的定义。 123456789101112131415161718192021222324252627282930313233343536373839public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Formal parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE&#125; 在Java8之前， 注解只能是在声明的地方所使用的， Jva8之后， 注解可以应用到任何地方。 TYPE_PARAMETER ： 表示该注解能写在类型变量的声明语句中（如： 泛型声明）。 TYPE_USE ： 表示该注解能卸载使用类型的任何语句中。 定义一个注解： 123456@Repeatable(MyAnnotaionss.class)@Target(&#123;ElementType.CONSTRUCTOR, ElementType.LOCAL_VARIABLE, ElementType.METHOD, ElementType.FIELD, ElementType.TYPE_PARAMETER, ElementType.TYPE_USE&#125;) // 添加ElementType.TYPE_PARAMETER / ElementType.TYPE_USE@Retention(RetentionPolicy.RUNTIME)public @interface MyAnnotation&#123; String value() default &quot;jack&quot;;&#125; 123456class Generic&lt;@MyAnnotation T&gt;&#123; public void show()&#123; ArrayList&lt;@MyAnnotation String&gt; list = new ArrayList&lt;&gt;(); int num = (@MyAnnotation int) 10L; // 这样在任何类型上都可以使用注解。后面可以通过反射机制来获取信息。 &#125;&#125; 注解的作用 编译检查： @SuppressWarnings, @Deprecated 和 @Override 都具有编译检查作用。 若某个方法被 @Override 的标注，则意味着该方法会覆盖父类中的同名方法。如果有方法被 @Override 标示，但父类中却没有”被 @Override 标注”的同名方法，则编译器会报错。 可以在反射中使用Annotation： 在反射的 Class, Method, Field 等函数中，有许多于 Annotation 相关的接口。这也意味着，我们可以在反射中解析并使用 Annotation。 根据 Annotation 生成帮助文档： 通过给 Annotation 注解加上 @Documented 标签，能使该 Annotation 标签出现在 javadoc 中。 能够帮忙查看代码： 通过 @Override, @Deprecated 等，我们能很方便的了解程序的大致结构。另外，我们也可以通过自定义 Annotation 来实现一些功能。 实例： 通过反射模拟注解信息处理流程模拟ORM： Object Relation Mapping 数据库中表对应着Java中的一个类， 字段对应属性，本例通过读取类上的注解来生成一个sql语句来创建一个数据库中表。 定义类上的注解123456789101112131415161718package annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * * 用于注解类的注解 * @author Hongliang Zhu * @create 2020-03-01 14:27 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface stTable &#123; String value();&#125; 定义字段Field的注解12345678910111213141516171819package annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * 注解字段 * @author Hongliang Zhu * @create 2020-03-01 14:28 */@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface stField &#123; String colunName(); // 列名 String type(); //类型 int length(); // 长度&#125; Person类上使用注解1234567891011121314151617181920212223242526272829303132package annotation;/** * Person类，对应数据库中的一个表 * @author Hongliang Zhu * @create 2020-03-01 14:25 */@stTable(&quot;st_table&quot;)public class Person &#123; @stField(colunName = &quot;st_name&quot;, type = &quot;varchar&quot;, length = 10) private String name; @stField(colunName = &quot;id&quot;, type = &quot;int&quot;, length = 16) private int id; public void setName(String name) &#123; this.name = name; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public int getId() &#123; return id; &#125;&#125; 第三方程序通过反射机制读取注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package annotation;import java.lang.annotation.Annotation;import java.lang.reflect.Field;/** * 通过反射机制获取一个类的注解信息。来进行sql语句的拼接，生成一个数据库中的一个表 * @author Hongliang Zhu * @create 2020-03-01 14:30 */public class getTable &#123; public static void main(String[] args) &#123; try &#123; Class clazz = Class.forName(&quot;annotation.Person&quot;); // 获取类的注解信息 Annotation[] annotations = clazz.getAnnotations(); for(Annotation a : annotations)&#123; System.out.println(a); // @annotation.stTable(value=st_table) &#125; // 通过指定注解来获得注解信息 stTable a = (stTable) clazz.getAnnotation(stTable.class); System.out.println(a); // @annotation.stTable(value=st_table) System.out.println(a.value()); // st_table //获取属性字段的注解信息 //现获取属性 name Field name = clazz.getDeclaredField(&quot;name&quot;); stField sname = name.getAnnotation(stField.class); System.out.println(sname); // @annotation.stField(colunName=st_name, type=varchar, length=10) System.out.println(sname.colunName() + &quot;---&quot; + sname.type() + &quot;---&quot; + sname.length()); // st_name---varchar---10 // 获取属性id Field id = clazz.getDeclaredField(&quot;id&quot;); stField sid = id.getAnnotation(stField.class); // @annotation.stField(colunName=id, type=int, length=16) System.out.println(sid); System.out.println(sid.colunName() + &quot;---&quot; + sid.type() + &quot;---&quot; + sid.length()); // id---int---16 //可以拼接ddl语句，使用jdbc执行。 String sql = &quot;CREATE TABLE IF NOT EXISTS\\t&quot; +a.value()+&quot;(\\n&quot; + sid.colunName()+&quot;\\t&quot;+sid.type()+&quot;(&quot;+sid.length()+&quot;)\\tNOT NULL\\n&quot; + sname.colunName()+&quot;\\t&quot;+sname.type()+&quot;(&quot;+sname.length()+&quot;)\\n&quot;+ &quot;);&quot;; System.out.println(sql); /* CREATE TABLE IF NOT EXISTS st_table( id int(16) NOT NULL st_name varchar(10) ); */ &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 总结@interface 用来声明 Annotation。 @Documented 用来表示该 Annotation 是否会出现在 javadoc 。 @Target 用来指定 Annotation 的类型。 @Retention 用来指定 Annotation 的策略。","path":"2020/02/29/Java注解-Annotation/","date":"02-29","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"Java中的枚举类","text":"概述JDK1.5之前需要自定义枚举类 JDK 1.5 新增的 enum 关键字用于定义枚举类 当需要定义一组常量时，强烈建议使用枚举类。故里面的属性应该为final修饰。 理解：类的对象只有有限个，确定的。称之为枚举类。 若枚举只有一个成员, 则可以作为一种单例模式的实现方式。 自定义枚举类 枚举类对象的属性不应允许被改动，所以应该使用 private final 修饰。 枚举类的使用 private final 修饰的属性应该在构造器中为其赋值。 若枚举类显式的定义了带参数的构造器, 则在列出枚举值时也必须对应的传入参数。 只能获取对象的属性，不能修改，即只能提供get方法，不能提供set方法。 12345678910111213141516171819202122232425262728293031323334// 自定义枚举类对象class Seasons&#123; private final String seasonName; private final String SeasonDesc; // 私有化构造函数 private Seasons(String seasonName, String seasonDesc)&#123; this.seasonName = seasonName; this.SeasonDesc = seasonDesc; &#125; // 提供当前枚举类的多个对象 public static final public static final Seasons SPRING = new Seasons(&quot;春天&quot;, &quot;春风又绿江南岸&quot;); public static final Seasons SUMMER = new Seasons(&quot;夏天&quot;, &quot;映日荷花别样红&quot;); public static final Seasons AUTUMN = new Seasons(&quot;秋天&quot;, &quot;秋水共长天一色&quot;); public static final Seasons WINTER = new Seasons(&quot;冬天&quot;, &quot;窗含西岭千秋雪&quot;); // 获取枚举类的对象的属性 public String getSeasonName() &#123; return seasonName; &#125; public String getSeasonDesc() &#123; return SeasonDesc; &#125; @Override public String toString() &#123; return &quot;Seasons&#123;&quot; + &quot;seasonName=&#x27;&quot; + seasonName + &#x27;\\&#x27;&#x27; + &quot;, SeasonDesc=&#x27;&quot; + SeasonDesc + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 使用enum定义枚举类必须在枚举类的第一行声明枚举类对象。多个对象之间用逗号隔开，最后一个对象用；结束。 枚举类和普通类的区别： 使用 enum 定义的枚举类默认继承了 java.lang.Enum 类。 枚举类的构造器只能使用 private 访问控制符。 枚举类的所有实例必须在枚举类中显式列出 (,分隔 ; 结尾). 列出的实例系统会自动添加 public static final修饰。 1234567891011121314151617181920212223242526272829enum Season &#123; // 必须在枚举类的第一行声明枚举类对象。 SPRING(&quot;春天&quot;, &quot;春风又绿江南岸&quot;), SUMMER(&quot;夏天&quot;, &quot;映日荷花别样红&quot;), AUTUMN(&quot;秋天&quot;, &quot;秋水共长天一色&quot;), WINTER(&quot;冬天&quot;, &quot;窗含西岭千秋雪&quot;); private final String seasonName; private final String SeasonDesc; // 私有化构造函数 private Season(String seasonName, String seasonDesc) &#123; this.seasonName = seasonName; this.SeasonDesc = seasonDesc; &#125; // 获取枚举类的对象的属性 public String getSeasonName() &#123; return seasonName; &#125; public String getSeasonDesc() &#123; return SeasonDesc; &#125;&#125; 枚举类的常用方法枚举类的主要方法： values()方法：返回枚举类型的对象数组。该方法可以很方便地遍历所有的枚举值。 valueOf(String str)：可以把一个字符串转为对应的枚举类对象。要求字符串必须是枚举类对象的“名字”。如不是，会有运行时异常。 线程的状态就是一个枚举类。 1234Thread.State[] values = Thread.State.values();for (Thread.State v: values)&#123;System.out.println(v);&#125; NEWRUNNABLEBLOCKEDWAITINGTIMED_WAITINGTERMINATED 实现接口的枚举类和普通 Java 类一样，枚举类可以实现一个或多个接口 若需要每个枚举值在调用实现的接口方法呈现出不同的行为方式，则可以让每个枚举值分别来实现该方法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 定义接口interface info&#123; void show();&#125;enum Season implements info&#123; // 必须在枚举类的第一行声明枚举类对象。 SPRING(&quot;春天&quot;, &quot;春风又绿江南岸&quot;)&#123; @Override public void show() &#123; System.out.println(&quot;我是春天&quot;); &#125; &#125;, SUMMER(&quot;夏天&quot;, &quot;映日荷花别样红&quot;)&#123; @Override public void show() &#123; System.out.println(&quot;我是夏天&quot;); &#125; &#125;, AUTUMN(&quot;秋天&quot;, &quot;秋水共长天一色&quot;)&#123; @Override public void show() &#123; System.out.println(&quot;我是秋天&quot;); &#125; &#125;, WINTER(&quot;冬天&quot;, &quot;窗含西岭千秋雪&quot;)&#123; @Override public void show() &#123; System.out.println(&quot;我是冬天&quot;); &#125; &#125;; private final String seasonName; private final String SeasonDesc; // 私有化构造函数 private Season(String seasonName, String seasonDesc) &#123; this.seasonName = seasonName; this.SeasonDesc = seasonDesc; &#125; // 获取枚举类的对象的属性 public String getSeasonName() &#123; return seasonName; &#125; public String getSeasonDesc() &#123; return SeasonDesc; &#125;&#125; 12345678public static void main(String[] args) &#123; Season[] s = Season.values(); for (Season a: s)&#123; System.out.println(a); a.show(); &#125; &#125; SPRING我是春天SUMMER我是夏天AUTUMN我是秋天WINTER我是冬天","path":"2020/02/29/Java中的枚举类/","date":"02-29","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"打印出B中不在A中的数","text":"描述 一个有序数组A，另一个无序数组B，请打印B中的所有不在A中的数，A数 组长度为N，B数组长度为M。 分析方法一： 暴力求解。 对于数组B中的每一个数，都在A中通过遍历的方式找一下； 相当于：B 中每一个数都要在 A 中遍历一遍，则需要操作 N 遍，而 B 中 M 个数都需要按照上面操作一遍，共操作 M * N 遍，因此时间复杂为：O(M*N)。 方法二：二分法。因为A数组有序， 在A中查找的时候使用二分查找算法，故总体时间复杂度为$O(M* log_2^N)$. 方法三： ​ 先把数组B排序，然后用类似外排的方式打印所有不在A中出现的数； 因为可以是会用快速排序对数组 B 进行排序 。所以整体时间复杂度为$O(M*log_2^M)$ 。 ​ 具体地， 数组 A 开头放置下标 a，数组 B 开头放置下标 b，比较两个下标指向的值若 b 指向的值 &lt; a 指向的值，则 b++同时打印 b 指向的数，否则a++ , 若等于则a++, b++不打印； 因此整体外排时间复杂度最差O(M+N)。则整个算法时间复杂度为 $O(M*log_2^M) + O(M+N)$ 。 分析： 当 A 数组较短的时候，方法二较好，当 B 数组较短的时候，方法三较好，因为方法三需要对 B 进行排序； 代码实现方法一123456789101112131415// 方法一： 暴力 O(M*N) public List&lt;Integer&gt; getNotInArrays(int[] A, int[] B)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); for(int a: A)&#123; list.add(a); &#125; //循环遍历B数组 for(int i = 0; i &lt; B.length; i++)&#123; if(!list.contains(B[i]))&#123; res.add(B[i]); &#125; &#125; return res; &#125; 方法二1234567891011121314151617181920212223242526// 方法二： 二分查找 O(M*longN) public List&lt;Integer&gt; getNotInArrays_V2(int[] A, int[] B)&#123; List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); boolean contains = false; for(int i: B)&#123; int low = 0; int high = A.length - 1; while(low &lt;= high)&#123; int mid = (low+high) &gt;&gt; 1; if(A[mid] == i ) &#123; contains = true; break; //找到了 &#125; else if(A[mid] &gt; i)&#123; // 在A的左边， 更改low和high high = mid - 1; &#125;else if(A[mid] &lt; i)&#123; // 在A的右边， 更改low和high low = mid + 1; &#125; &#125; if(!contains)&#123; // 不存在 res.add(i); &#125; contains = false; // 复位 &#125; return res; &#125; 方法三123456789101112131415161718192021222324// 方法三： 对B先排序，然后使用外部排序来 求解 public List&lt;Integer&gt; getNotInArrays_V3(int[] A, int[] B) &#123; // 对B先 排序 Arrays.sort(B); List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); int a = 0; int b = 0; while ((a &lt; A.length) &amp;&amp; (b &lt; B.length)) &#123; if (A[a] == B[b]) &#123; a++; b++; &#125; else if (A[a] &lt; B[b]) &#123; a++; &#125; else if (A[a] &gt; B[b]) &#123; res.add(B[b]); b++; &#125; &#125; while (b &lt; B.length)&#123; res.add(B[b++]); &#125; return res; &#125; 完整代码： https://github.com/Castile/algorithm/blob/master/leetcode/src/Sort/GetNotInArrays.java","path":"2020/02/28/打印出B中不在A中的数/","date":"02-28","excerpt":"","tags":[{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"二分","slug":"二分","permalink":"https://castile.github.io/tags/%E4%BA%8C%E5%88%86/"}]},{"title":"JDK8中日期的API的使用","text":"jdk8之前java.util.Date 日期类​ —- java.sql.Date 数据库里面使用的数据类型 12public class Date extends java.util.Date &#123;&#125; System类提供的public static long currentTimeMillis()用来返回当前时间与1970年1月1日0时0分0秒之间以毫秒为单位的时间差。 此方法适于计算时间差 getTime() :返回自 1970 年 1 月 1 日 00:00:00 GMT 以来此 Date 对象表示的毫秒数。 toString() :把此 Date 对象转换为以下形式的 String： dow mon dd hh:mm:ss zzz yyyy 其中： dow 是一周中的某一天 (Sun, Mon, Tue, Wed, Thu, Fri, Sat)，zzz是时间标准。 java.text.SimpleDateFormat类Date类的API不易于国际化，大部分被废弃了，java.text.SimpleDateFormat类是一个不与语言环境有关的方式来格式化和解析日期的具体类。 它允许进行格式化（日期—&gt;文本）、解析（文本—-&gt;日期） 格式化： SimpleDateFormat() ：默认的模式和语言环境创建对象 public SimpleDateFormat(String pattern)：该构造方法可以用参数pattern指定的格式创建一个对象，该对象调用： public String format(Date date)：方法格式化时间对象date 解析： public Date parse(String source)：从给定字符串的开始解析文本，以生成一个日期。 三天打渔两天晒网123456789101112131415161718192021@Test public void test3() throws ParseException &#123; // 三天打渔两天晒网： 问 在xxxx-xx-xx这一天是打渔还是在晒网。 // 从1996-10-02开始三天打渔两天晒网 SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); String begin = &quot;1996-10-02&quot;; String now = &quot;2020-02-28&quot;; Date start = sdf.parse(begin); long totalMills = sdf.parse(now).getTime() - start.getTime(); long totalDays = totalMills / (24 * 60 * 60 * 1000) + 1; //防止小数点 System.out.println(&quot;总天数：&quot; + totalDays); // System.out.println(totalDays / 366.0); int res = (int)totalDays % 5; System.out.println(&quot;结果: &quot;+ res); if(res &gt;= 1 &amp;&amp; res &lt;= 3)&#123; System.out.println(&quot;在打渔。。。。。。。。。&quot;); &#125;else&#123; System.out.println(&quot;在晒网....................&quot;); &#125; &#125; java.util.Calendar(日历)类1234567891011121314151617181920@Test public void test4()&#123; Calendar calendar = Calendar.getInstance(); int days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days); // 27 days = calendar.get(Calendar.DAY_OF_YEAR); System.out.println(days); // 58 calendar.add(Calendar.DAY_OF_MONTH , -3); days = calendar.get(Calendar.DAY_OF_MONTH); // 24 System.out.println(days); Date date = calendar.getTime(); System.out.println(date); // Mon Feb 24 16:29:10 CST 2020 Date date1 = new Date(); calendar.setTime(date1); days = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(days); // 27 &#125; JDK8中的日期API概述JDK1.0中包含了一个java.util.Date类， 但是它的大多数方法已经在JDK1.1中引入Calendar类之后被弃用了。然而Calendar类也并不比Date好多少。它们面临的问题是： 可变性： 像日期和时间这样的类应该是不可变的，但是Calendar类有set方法可以改变原来的时间。 偏移性： Date的年份是从1900年开始的，而月份都是从0开始的。 格式化： 格式化只对Date有用， Calendar则不行。 此外， 它们也不是线程安全的，； 不能处理闰秒等。 闰秒：也称作“跳秒”， 是指为保持协调世界时接近于世界时时刻，由国际计量局统一规定在年底或年中（也可能在季末）对协调世界时增加或减少1秒的调整。由于地球自转的不均匀性和长期变慢性（主要由潮汐摩擦引起的），会使世界时（民用时）和原子时之间相差超过到±0.9秒时，就把协调世界时向前拨1秒（负闰秒，最后一分钟为59秒）或向后拨1秒（正闰秒，最后一分钟为61秒）； 闰秒一般加在公历年末或公历六月末。 目前，全球已经进行了27次闰秒，均为正闰秒。 最近一次闰秒在北京时间2017年1月1日7时59分59秒（时钟显示07:59:60）出现。这也是本世纪的第五次闰秒。 总结： 对日期和时间操作一直是Java程序员最痛苦的地方之一。 Java 8 吸收了 Joda-Time 的精华，以一个新的开始为 Java 创建优秀的 API。新的 java.time 中包含了所有关于时钟（Clock），本地日期（LocalDate）、本地时间（LocalTime）、本地日期时间（LocalDateTime）、时区（ZonedDateTime）和持续时间（Duration）的类。历史悠久的 Date 类新增了 toInstant() 方法，用于把 Date 转换成新的表示形式。这些新增的本地化时间日期 API 大大简化了了日期时间和本地化的管理。 使用 LocalDate、LocalTime、LocalDateTimeLocalDate、LocalTime、LocalDateTime 类的实例是不可变的对象，分别表示使用 ISO-8601日历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息。也不包含与时区相关的信息。 ​ ISO-8601日历系统是国际标准化组织制定的现代公民的日期和时间的表示法 方法 方法 描述 now() 静态方法，根据当前时间创建对象 of() 静态方法，根据指定日期/时间创建对象 plusDays, plusWeeks, plusMonths, plusYears 向当前 LocalDate 对象添加几天、几周、几个月、几年 minusDays, minusWeeks, minusMonths, minusYears 从当前 LocalDate 对象减去几天、几周、几个月、几年 plus, minus 添加或减少一个 Duration 或 Period withDayOfMonth, withDayOfYear, withMonth, withYear 将月份天数、年份天数、月份、年份修改为指定的值并返回新的 LocalDate 对象 getDayOfMonth 获得月份天数(1-31) getDayOfYear 获得年份天数(1-366) getDayOfWeek 获得星期几(返回一个 DayOfWeek 枚举值) getMonth 获得月份, 返回一个 Month 枚举值 getMonthValue 获得月份(1-12) getYear 获得年份 until 获得两个日期之间的 Period 对象，或者指定 ChronoUnits 的数字 isBefore, isAfter 比较两个 LocalDate isLeapYear 判断是否是闰年 获取当前时间的日期、时间、 日期+时间12345678910111213// now（）： 获取当前时间的日期、时间、 日期+时间LocalDate localDate = LocalDate.now();LocalTime localTime = LocalTime.now();LocalDateTime localDateTime = LocalDateTime.now();System.out.println(localDate); // 2020-02-28System.out.println(localTime); // 11:16:05.208365800System.out.println(localDateTime); // 2020-02-28T11:16:05.208365800// of(): 设置指定的年、月、日、时分秒LocalDateTime time1 = LocalDateTime.of(2020, 10, 6, 15, 23, 9);System.out.println(time1); // 2020-10-06T15:23:09 获取具体的属性值123456789 //getXXX(): 获取具体的属性值System.out.println(localDateTime.getDayOfWeek()); // FRIDAYSystem.out.println(localDateTime.getDayOfMonth()); // 28System.out.println(localDateTime.getDayOfYear()); // 59System.out.println(localDateTime.getMonth()); // FEBRUARYSystem.out.println(localDateTime.getMonthValue()); // 2System.out.println(localDateTime.getHour()); //11System.out.println(localDateTime.getMinute()); // 23System.out.println(localDateTime.getSecond()); // 26 修改-不可变体现了不可变性， 会返回新的LocalDate对象，不会修改原来的值 123456789 //修改 体现了不可变性， 会返回新的LocalDate对象，不会修改原来的值LocalDate localDate1 = localDate.withDayOfMonth(22);System.out.println(localDate1); // 2020-02-22System.out.println(localDate); // 2020-02-28// 加操作，同样是不可改变的，返回一个新的对象 不可变性LocalDateTime localDateTime1 = localDateTime.plusMonths(3);// 现有的基础上三个月System.out.println(localDateTime1); // 2020-05-28T12:50:47.920841500System.out.println(localDateTime); // 2020-02-28T12:50:47.920841500 Instant时间戳用于“时间戳”的运算。它是以Unix元年(传统的设定为UTC时区1970年1月1日午夜时分)开始所经历的描述进行运算。 类似于java.util.Date类 123456789101112131415@Testpublic void test2()&#123; Instant now = Instant.now(); System.out.println(now); // 2020-02-28T04:56:34.925610700Z 这个是本初子午线的时间，不 是东八区的时间 //处理时区问题 添加时间偏移量 OffsetDateTime offsetDateTime = now.atOffset(ZoneOffset.ofHours(8)); System.out.println(offsetDateTime); // 2020-02-28T13:01:14.149267200+08:00 // 获取对应时间点的毫秒数 类似于--- &gt; Date.getTime() long mills = now.toEpochMilli(); System.out.println(mills); // 1582866180907 //ofEpochMilli 通过给定的毫秒数，获取Instant实例 类似于--- &gt; Date(long mills) Instant instant = Instant.ofEpochMilli(156698646645646140L); System.out.println(instant); // 1582866180907&#125; 解析与格式化java.time.format.DateTimeFormatter 类：该类提供了三种格式化方法： 预定义的标准格式 语言环境相关的格式 自定义的格式 类似于SimpleDateFormat。 123456789101112131415161718192021222324252627public void test3() &#123; /* * 预定义的模式 * */ DateTimeFormatter format = DateTimeFormatter.ISO_LOCAL_DATE_TIME; //格式化 LocalDateTime localDateTime = LocalDateTime.now(); String str1 = format.format(localDateTime); System.out.println(str1); // 2020-02-28T13:12:45.4405114 System.out.println(localDateTime); //2020-02-28T13:12:45.440511400 //解析：字符串--&gt; 日期 TemporalAccessor parse = format.parse(str1); System.out.println(parse); /** * 本地化相关格式 ofLocalDateTime() * fFormatStyle.LONG / MEDIUM / SHORT : 适用于LocalDateTime */ DateTimeFormatter formatter = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.SHORT); LocalDateTime localDateTime1 = LocalDateTime.now(); String format1 = formatter.format(localDateTime1); System.out.println(format1); // 2020/2/28 下午1:22 &#125; 上面两种方式用得不多，在开发中通常使用的是自定义模式 1234567891011/**** 重点： 自定义模式*/DateTimeFormatter formatter1 = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd hh:mm:ss&quot;);//格式化String str4 = formatter1.format(LocalDateTime.now());System.out.println(str4); // 2020-02-28 01:30:33// 解析TemporalAccessor parse1 = formatter1.parse(&quot;2020-02-28 01:30:33&quot;);// &#123;NanoOfSecond=0, MilliOfSecond=0, MinuteOfHour=30, SecondOfMinute=33, HourOfAmPm=1, MicroOfSecond=0&#125;,ISO resolved to 2020-02-28System.out.println(parse1); 与传统日期处理的转换 类 To 遗留类 From 遗留类 java.time.Instant java.util.Date Date.from(instant) date.toInstant() java.time.Instant java.sql.Timestamp Timestamp.from(instant) timestamp.toInstant() java.time.ZonedDateTime** ** java.util.GregorianCalendar GregorianCalendar.from(zonedDateTime) cal.toZonedDateTime() java.time.LocalDate** ** java.sql.Time Date.valueOf(localDate) date.toLocalDate() java.time.LocalTime java.sql.Time Date.valueOf(localDate) date.toLocalTime() java.time.LocalDateTime java.sql.Timestamp Timestamp.valueOf(localDateTime) timestamp.toLocalDateTime() **java.time.ZoneId ** java.util.TimeZone Timezone.getTimeZone(id) timeZone.toZoneId() **java.time.format.DateTimeFormatter ** java.text.DateFormat formatter.toFormat() 无 其他参考API","path":"2020/02/27/JDK8中日期的API的使用/","date":"02-27","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"Java中字符串原理分析","text":"String类String 被声明为 final，因此它不可被继承。(Integer 等包装类也不能被继承） 在 Java 8 中，String 内部使用 char 数组存储数据。 12345public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[];&#125; 在 Java 9 之后，String 类的实现改用 byte 数组存储字符串，同时使用 coder 来标识使用了哪种编码 。 12345678public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final byte[] value; /** The identifier of the encoding used to encode the bytes in &#123;@code value&#125;. */ private final byte coder;&#125; value 数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。 不可变的好处1. 可以缓存hash值因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 2. String Pool 的需要如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 3. 安全性String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 的那一方以为现在连接的是其它主机，而实际情况却不一定是。 4. 线程安全String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 Program Creek : Why String is immutable in Java? String, StringBuffer and StringBuilder1. 可变性 String 不可变 如果您尝试更改其值，则会创建另一个对象 。地址改变 StringBuffer 和 StringBuilder 可变 2. 线程安全 String 不可变，因此是线程安全的 StringBuilder 不是线程安全的 1.5之后 StringBuffer 是线程安全的，内部使用 synchronized 进行同步 StackOverflow : String, StringBuffer, and StringBuilder StringBuffer和StringBuilder的区别在于，StringBuffer是线程安全的。因此，当应用程序需要在单个线程中运行时，最好使用StringBuilder。StringBuilder比StringBuffer更高效。 3. 使用场景 如果你的字符串不会改变，那就使用string类，因为string对象是不可变的。 如果您的字符串可以更改（例如：字符串构造中的大量逻辑和操作）并且只能从单个线程访问，则使用StringBuilder就足够了。 如果您的字符串可以更改，并且可以从多个线程访问，请使用StringBuffer，因为StringBuffer是同步的，所以具有线程安全性。 4. java.lang.StringBuffer代表可变的字符序列，可以对字符串内容进行增删。 很多方法与String相同，但StringBuffer是可变长度的 . StringBuffer是一个容器。 StringBuffer类有三个构造器: 1.StringBuffer() 初始容量为16的字符串缓冲区 2.StringBuffer(int size)构造指定容量的字符串缓冲区 3.StringBuffer(String str)将内容初始化为指定字符串内容 StringBuffer类的常用方法: StringBuffer append(String s), StringBuffer append(int n) , StringBuffer append(Object o) , StringBuffer append(char n), StringBuffer append(long n), StringBuffer append(boolean n), StringBuffer insert(int index, String str) public StringBuffer reverse() StringBuffer delete(int startIndex, int endIndex) public char charAt(int n ) public void setCharAt(int n ,char ch) StringBuffer replace( int startIndex ,int endIndex, String str) public int indexOf(String str) public String substring(int start,int end) public int length() String Pool字符串常量池（String Pool）保存着所有字符串字面量（literal strings），这些字面量在编译时期就确定。不仅如此，还可以使用 String 的 intern() 方法在运行过程将字符串添加到 String Pool 中。 当一个字符串调用 intern() 方法时，如果 String Pool 中已经存在一个字符串和该字符串值相等（使用 equals() 方法进行确定），那么就会返回 String Pool 中字符串的引用；否则，就会在 String Pool 中添加一个新的字符串，并返回这个新字符串的引用。 下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同字符串，而 s3 和 s4 是通过 s1.intern() 方法取得同一个字符串引用。intern() 首先把 s1 引用的字符串放到 String Pool 中，然后返回这个字符串引用。因此 s3 和 s4 引用的是同一个字符串。 123456String s1 = new String(&quot;aaa&quot;);String s2 = new String(&quot;aaa&quot;);System.out.println(s1 == s2); // falseString s3 = s1.intern();String s4 = s1.intern();System.out.println(s3 == s4); // true 如果是采用 “bbb” 这种字面量的形式创建字符串，会自动地将字符串放入 String Pool 中。 123String s5 = &quot;bbb&quot;;String s6 = &quot;bbb&quot;;System.out.println(s5 == s6); // true 在 Java 7 之前，String Pool 被放在运行时常量池中，它属于永久代。而在 Java 7，String Pool 被移到堆中。这是因为永久代的空间有限，在大量使用字符串的场景下会导致 OutOfMemoryError 错误。 StackOverflow : What is String interning? 深入解析 String#intern 直接使用双引号声明出来的String对象会直接存储在常量池中。 如果不是用双引号声明的String对象，可以使用String提供的intern方法。intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中。 new String(“abc”)使用这种方式一共会创建两个字符串对象（前提是 String Pool 中还没有 &quot;abc&quot; 字符串对象）。 &quot;abc&quot; 属于字符串字面量，因此编译时期会在 String Pool 中创建一个字符串对象，指向这个 “abc” 字符串字面量； 而使用 new 的方式会在堆中创建一个字符串对象。 创建一个测试类，其 main 方法中使用这种方式来创建字符串对象。 12345public class NewStringTest &#123; public static void main(String[] args) &#123; String s = new String(&quot;abc&quot;); &#125;&#125; 使用 javap -verbose 进行反编译，得到以下内容： 123456789101112131415161718192021// ...Constant pool:// ... #2 = Class #18 // java/lang/String #3 = String #19 // abc// ... #18 = Utf8 java/lang/String #19 = Utf8 abc// ... public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=3, locals=2, args_size=1 0: new #2 // class java/lang/String 3: dup 4: ldc #3 // String abc 6: invokespecial #4 // Method java/lang/String.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V 9: astore_1// ... 在 Constant Pool 中，#19 存储这字符串字面量 “abc”，#3 是 String Pool 的字符串对象，它指向 #19 这个字符串字面量。在 main 方法中，0: 行使用 new #2 在堆中创建一个字符串对象，并且使用 ldc #3 将 String Pool 中的字符串对象作为 String 构造函数的参数。 以下是 String 构造函数的源码，可以看到，在将一个字符串对象作为另一个字符串对象的构造函数参数时，并不会完全复制 value 数组内容，而是都会指向同一个 value 数组。 1234public String(String original) &#123; this.value = original.value; this.hash = original.hash;&#125; 面试题12345678910111213141516171819202122232425262728package string;/** * @author Hongliang Zhu * @create 2020-02-23 13:12 */public class TestString &#123; public static void main(String[] args) &#123; String s1 = &quot;abc&quot;; // 字面量 String s2 = &quot;def&quot;; String s3 = &quot;abc&quot; + &quot;def&quot;; // 字面量 String s4 = s1 + &quot;def&quot;; String s5 = &quot;abc&quot; + s2; String s6 = s1 + s2; String s7 = &quot;abcdef&quot;; System.out.println(s3 == s7); // true System.out.println(s3 == s4); // fasle System.out.println(s3 == s5); // fasle System.out.println(s3 == s6); // false System.out.println(s5 == s6); // false String s8 = s5.intern(); System.out.println(s3 == s8); //true System.out.println(s3 == s5); // fasle &#125;&#125; 结论： 1.常量与常量的拼接结果在常量池中， 且常量池中不会存在相同的常量 2.只要其中有一个是变量， 结果就在堆中， 会重新new一个对象在堆中。 比如上面的s4,s5,s6 3.如果拼接的结果调用intern方法，返回值就在常量池中。 下列程序运行的结果： 1234567891011121314151617181920212223package string;/** * @author Hongliang Zhu * @create 2020-02-23 21:03 */public class test1 &#123; String str = new String(&quot;good&quot;); char[] ch = &#123; &#x27;t&#x27;, &#x27;e&#x27;, &#x27;s&#x27;, &#x27;t&#x27; &#125;; public void change(String str, char ch[]) &#123; str = &quot;test ok&quot;; ch[0] = &#x27;g&#x27;; &#125; public static void main(String[] args) &#123; test1 ex = new test1(); ex.change(ex.str, ex.ch); // good System.out.print(ex.str + &quot; and &quot;); // good and System.out.println(ex.ch); // gest &#125;&#125;// good and gest 12345678910String s1 = &quot;123&quot;;String s2 = &quot;123&quot;; // 字面量，在常量池中String s3 = new String(&quot;123&quot;);String s4 = new String(&quot;123&quot;); // 在堆中创建System.out.println(s1.equals(s2)); // trueSystem.out.println(s1 == s2); // trueSystem.out.println(s3.equals(s4)); // trueSystem.out.println(s3 == s4); // falseSystem.out.println(s1.equals(s3)); // trueSystem.out.println(s1 == s3); // false 下面的输出是什么： 1234567891011String str = null;StringBuffer sb = new StringBuffer();sb.append(str);System.out.println(sb.length());// 4System.out.println(sb);// “null” 实际上是存储的一个&quot;null&quot;字符串StringBuffer sb1 = new StringBuffer(str); // 抛出空指针异常System.out.println(sb1);// 解释： 123456789101112131415161718192021private AbstractStringBuilder appendNull() &#123; ensureCapacityInternal(count + 4); // 如果添加的是null，那么会加上4个字节 int count = this.count; byte[] val = this.value; if (isLatin1()) &#123; val[count++] = &#x27;n&#x27;; val[count++] = &#x27;u&#x27;; val[count++] = &#x27;l&#x27;; val[count++] = &#x27;l&#x27;; &#125; else &#123; count = StringUTF16.putCharsAt(val, count, &#x27;n&#x27;, &#x27;u&#x27;, &#x27;l&#x27;, &#x27;l&#x27;); &#125; this.count = count; return this; &#125;//构造函数的形式去构造字符串public StringBuffer(String str) &#123; super(str.length() + 16); // str.length() 如果str数null，根本没有这个方法，所以会报空指针异常 append(str); &#125; String字符串对象操作 public int length() 返回字符串的长度 public char charAt(int index) 指定下标的字符 public boolean equals(Object anObject) public int compareTo(String anotherString) 比较 public int indexOf(String s) 指定字符或者字符串的下标 第一次出现 public int indexOf(String s ,int startpoint) public int lastIndexOf(String s) public int lastIndexOf(String s ,int startpoint) public boolean startsWith(String prefix) 是否以指定字符串开始的 public boolean endsWith(String suffix) 是否以指定字符串结束的 public boolean regionMatches(int firstStart,String other,int otherStart ,int length) String字符串对象修改public String substring(int startpoint) public String substring(int start,int end) //子字符串 包头不包尾 （左闭右开） pubic String replace(char oldChar,char newChar) public String replaceAll(String old,String new) public String trim() 去掉字符串首部和尾部的空格 public String concat(String str) 等价于 “ + ” public boolean contains(CharSequence s) 是否 包含指定的字符串 public String[] split(String regex) 根据给定正则表达式的匹配拆分此字符串。 源码分析构造字符串对于String来说：内部创建一个字符数组（JDK8），JDK9之后是一个字节数组 12 String str1 = new String(); // new char[]&#123;&#125;;String str2 = new Strign(&quot;abc&quot;); // new cahr[] &#123;&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;&#125; 对于StringBuffer来说： 123StringBuffer sb1 = new StringBuffer(); //char[] value = new char[16], 相当于在底层创建了一个长度为16 的数组。StringBuffer sb2 = new StringBuffer(&quot;123&quot;); // 1234567891011121314// jdk1.8源码：/** * Constructs a string buffer with no characters in it and an initial capacity of 16 characters. */ @HotSpotIntrinsicCandidate public StringBuffer() &#123; super(16); &#125; public StringBuffer(String str) &#123; super(str.length() + 16); append(str); &#125; 1sb1.append(&#x27;a&#x27;); // value[0] = &#x27;a&#x27;; StringBuffer 中的 append + 扩容1234567891011121314151617181920212223242526272829303132333435 public AbstractStringBuilder append(String str) &#123; if (str == null) &#123; return appendNull(); &#125; int len = str.length(); ensureCapacityInternal(count + len); // 扩容 putStringAt(count, str); count += len; return this; // 方法链原理 &#125;// jdk8 private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code if (minimumCapacity - value.length &gt; 0) &#123; //将原来的数组拷贝到一个新数组中，并且扩容 value = Arrays.copyOf(value, newCapacity(minimumCapacity)); &#125; &#125;// jdk8 private int newCapacity(int minCapacity) &#123; // overflow-conscious code int newCapacity = (value.length &lt;&lt; 1) + 2; //扩容为原来的两倍 + 2。 //如果新的容量比最小容量都小，那么这个新的容量就为最小容量 if (newCapacity - minCapacity &lt; 0) &#123; newCapacity = minCapacity; &#125; // 如果新的容量大于最大的容量 return (newCapacity &lt;= 0 || MAX_ARRAY_SIZE - newCapacity &lt; 0) ? hugeCapacity(minCapacity) : newCapacity; &#125; jdk12： 123456789101112131415161718192021222324 // jdk12 private void ensureCapacityInternal(int minimumCapacity) &#123; // overflow-conscious code int oldCapacity = value.length &gt;&gt; coder; if (minimumCapacity - oldCapacity &gt; 0) &#123; value = Arrays.copyOf(value, newCapacity(minimumCapacity) &lt;&lt; coder); &#125; &#125;// jdk12 private int newCapacity(int minCapacity) &#123; // overflow-conscious code int oldCapacity = value.length &gt;&gt; coder; int newCapacity = (oldCapacity &lt;&lt; 1) + 2; if (newCapacity - minCapacity &lt; 0) &#123; newCapacity = minCapacity; &#125; int SAFE_BOUND = MAX_ARRAY_SIZE &gt;&gt; coder; return (newCapacity &lt;= 0 || SAFE_BOUND - newCapacity &lt; 0) ? hugeCapacity(minCapacity) : newCapacity; &#125; 如果添加的数据在底层数组盛不下了，那就需要扩容数组。默认情况下，扩容为原来的2倍+2， 同时将原有的数组中的元素复制到新数组当中。 建议： 在实际开发中应该避免频繁的扩容，推荐使用构造函数： 12345678public StringBuffer(int capacity) &#123; super(capacity); &#125; // 或者public StringBuilder(int capacity) &#123; super(capacity); &#125; 指定容量。 同理，StringBuilder底层的append和扩容也是和StringBuffer一样的。 StringBuffer和StringBuilder的额外方法以StringBuffer为例： StringBuffer append() ; StringBuffer delete(int start, int end) ; // 删除指定位置的内容 StringBuffer insert(int offset,, xxx) ; // 在指定位置插入字符串 String replace(int start, int end, String str); StringBuffer reverse(); 反转字符串 效率测试1234567891011121314151617181920212223@Test public void efficientTest()&#123; String text = &quot;&quot;; long startTime = 0L; long endTime = 0L; StringBuffer buffer = new StringBuffer(&quot;&quot;); StringBuilder builder = new StringBuilder(&quot;&quot;); startTime = System.currentTimeMillis(); for(int i = 0;i&lt;20000;i++)&#123; buffer.append(String.valueOf(i));&#125; endTime = System.currentTimeMillis(); System.out.println(&quot;StringBuffer的执行时间：&quot;+(endTime-startTime)); startTime = System.currentTimeMillis(); for(int i = 0;i&lt;20000;i++)&#123; builder.append(String.valueOf(i));&#125; endTime = System.currentTimeMillis(); System.out.println(&quot;StringBuilder的执行时间：&quot;+(endTime-startTime)); startTime = System.currentTimeMillis(); for(int i = 0;i&lt;20000;i++)&#123; text = text + i;&#125; endTime = System.currentTimeMillis(); System.out.println(&quot;String的执行时间：&quot;+(endTime-startTime)); &#125; 在JDK8中测试：（ms） StringBuffer的执行时间：11StringBuilder的执行时间：4String的执行时间：1075 在JDk12: StringBuffer的执行时间：6StringBuilder的执行时间：2String的执行时间：545 参考 https://cyc2018.github.io/CS-Notes/ https://tech.meituan.com/2014/03/06/in-depth-understanding-string-intern.html","path":"2020/02/23/Java字符串一锅端了/","date":"02-23","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"Anchor Diffusion for Unsupervised Video Object Segmentation","text":"Anchor Diffusion for Unsupervised Video Object Segmentation基于“锚扩散”的无监督视频目标分割github： https://github.com/yz93/anchor-diff-VOS概述​ 论文指出了目前的视频目标分割方法存在的缺点。提出更简单的方法，基它基于学习属于帧的像素之间的相似性，这些帧在时间上可以任意地相隔很远。这种方法能够处理long-term的依赖关系。 ​ 这篇论文受Non-local operators的启发提出了一个简单而有效的模型无监督视频目标分割模型，可以捕获长期依赖。通过将“锚帧”的嵌入像素与当前的帧建立联系，可以学习到任意长距离的成对依赖关系。在Davis2016数据集上取得了第一名的成绩。 ​ 追踪基于时间变化的的目标，现在流行的方法是通过在视频序列中的光流或者使用RNN对运动信息进行建模。这些方法持续将前面的特征传到当前帧，让当前帧的预测依赖于整个历史的帧。但是RNNs常常依赖于训练技术，如通过时间的截断反向传播来降低参数更新的成本，这限制了它们的长期建模能力。虽然LSTM的门控机制缓解了梯度消失的问题。但在训练中，梯度爆炸的现象往往需要对梯度的范数进行裁剪或重新调整。 ​ 光流向量只能预测视频中每一帧的单步运动线索，这样会累积误差。而且计算成本很高。使用这些方法会产生不准确的结果，特别是当前景物体几乎是静态的时候。 ​ 基于双流的模型有三个缺点： ​ 第一：流估计网络通常是在合成数据集上训练的，因此在现实世界中部署时可能会导致较差的性能。​ 第二：虽然建模长期的时间依赖关系对于适应重大的在线变化是至关重要的，但是向量场只能建模短期的一 步依赖关系。​ 第三： 当前景和背景以同步方式移动时，向量场无法区分它们，即前景与背景相同的运动。 方法 我们的方法从属于锚帧的单个像素嵌入到当前帧(左侧)的所有像素嵌入之间学习一对多相似性的例子(右侧)。稠密相似点的轮廓与锚框中相应像素嵌入的颜色相匹配。注意的相似之处与前景的像素嵌入汽车(红色)产生一个整洁的热图,识别对象,而两组相似的像素嵌入“错误选择”车(绿色)和道路(紫色)更高的通信背景。这些学习到的相似性是一种简单而有效的分割前景对象的方法。彩色效果最佳。 最终的热图是所有输出热图的平均值。0.5的阈值产生最终的二进制标签。 网络结构 输入： 图片对，锚帧和目标帧 $I_t$，锚帧 $ I_0 $ 是视频序列的第一个帧，随机采样视频中的一帧作为第二张图片 特征编码：DeepLabv3将锚帧和当前要分割的帧编码成相关的嵌入向量$$X_0 ∈ R^{hw × c}$$ $$X_t ∈ R^{hw ×c }$$ ​ 将每个位置的c维特征向量称为像素嵌入。 三个分支：锚扩散分支、帧内分支、跳层连接分支 a skip connection with an identity mapping the intraframe branch the anchor-diffusion branch 在帧内分支的情况下，每个输出像素嵌入可以被认为是所有输入像素嵌入的全局集合，通过两两外观相似度加权。已有研究表明，这种非局部操作可以利用长程空间信息，有利于语义分割 第一阶段的输出会喂入三个平行的分支 ， $X_t$ 会送到所有的分支中， $X_0$ 只会送入到Anchor-Diffusion中。 最后三个分支的特征沿着通道维度Concatenate 。 Anchor diffusion为了增强前景信号，了解目标帧中的哪个像素嵌入对应于整个视频中引入的背景是很重要的。 $$ Z = \\sqrt{c} $$ ​ 过渡矩阵 P 建立了 $X_0 $ 和 $X_t$ 像 素对之间的密集对应关系。转换矩阵P学习了一个相似度度量，可以很好地识别两帧内的共同object，因此，在式中，P可以增强锚帧中具有较强对应关系的像素点的信号，减弱不具有较强对应关系的像素点的信号。由于前景目标对象几乎总是出现在两帧中，而背景变化相对较快，我们的扩散过程通常是增强前景，压制背景。 ​ Softmax函数将里面的式子的每一行进行归一化，可以保持像素嵌入的尺度不变性。如果不进行归一化，上式子可能会完全改变像素嵌入的比例。 ​ 像素嵌入随时间的时间一致性，测量为锚帧中的前景像素嵌入与逐渐变远的帧中的前景像素嵌入之间的余弦距离，得到以下结果： 这表明，AD-Net能够在较长时间内保存视频中第一帧的前景信息。 后处理Instance Pruning​ 因为AD-net主要区分前景和背景，将前景分割，但是对于有一些视频序列有很多类似前景的像素，使用Instance Pruning 可以细化分割效果。 ​ 首先，（这个实例裁剪算法）SmallStatic返回一组包围框和对应的实例掩码，它们表示小的和几乎静态的实例。输入，并为每一帧生成一个修剪掩码，该掩码合并所有比当前帧中的最大实例小得多的小型和静态实例。最后，每个输入掩码与相应的修剪掩码相乘然后，将这些实例和原始掩码作为 输出最终的预测。 结果","path":"2020/02/21/AnchorDiffusion/","date":"02-21","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"UVOS","slug":"UVOS","permalink":"https://castile.github.io/tags/UVOS/"}]},{"title":"Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks-ICCV2019","text":"Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks（ICCV2019） Wenguan Wang1∗, Xiankai Lu1∗, Jianbing Shen1y, David Crandall2, Ling Shao1 Inception Institute of Artificial Intelligence, UAE Indiana University, USA 通过图注意力神经网络的Zero-Shot视频目标分割代码： https://github.com/Castile/AGNNForVOS一、 概述​ 提出了一种基于图注意力神经网络的用于Zero-Shot的视频目标分割算法。 AGNN将此任务重新定义为在图上进行迭代信息融合的过程 。 具体来说，AGNN构建一个全连通图，有效地将帧表示为节点，任意帧对之间的关系表示为边。 潜在的两两关系由一个可微分的注意机制来描述。通过参数化消息传递，AGNN能够有效地捕获和挖掘视频帧之间更丰富、更高阶的关系，从而更全面地理解视频内容，更准确地估计前景。大量的实验验证了AGNN能够学习视频帧或相关图像之间潜在的语义或者外观关系，并找出共同的目标。【基于全局的视角】 二、 目前的方法​ 基于深度学习的方法需要大量的训练数据，利用双流网络来结合局部信息和外观信息，使用光流来对连续两帧进行运动的建模，使用RNN对时序建模。但是它们普遍存在两个局限性。首先，它们主要关注连续帧之间的局部成对或顺序关系，而忽略了帧之间普遍存在的高阶关系(因为来自同一视频的帧通常是相关的)。其次，由于他们没有充分利用丰富的关系，他们不能完全捕捉视频内容，因此对前景的估计效果很差。从另一个角度来看，由于视频对象通常存在底层对象遮挡、尺度变化大、外观变化大，仅考虑视频中连续关系或局部成对关系时，很难正确推断前景。 Zero-Shot参考：《 Rvos: End to-end recurrent network for video object segmentation 》 采用双流网络结合局部运动和外观信息，采用RNN逐帧建模 ： Segflow: Joint learning for video object segmentation and optical flow. In ICCV, 2017 Fusionseg: Learning to combine motion and appearance for fully automatic segmention of generic objects in videos. In CVPR,2017. Learning video object segmentation with visual memory. In ICCV, 2017. Unsupervised video object segmentation with motion-based bilateral networks. In ECCV, 2018. Pyramid dilated deeper convlstm for video salient object detection. In ECCV, 2018 1. Zero-Shot solution Learning to segment moving objects in videos. In CVPR, 2015 ： 设计了一种基于多层感知的运动目标检测系统 Fusionseg: Learning to combine motion and appearance for fully automatic segmention of generic objects in videos. In CVPR,2017. ： Learning video object segmentation with visual memory. In ICCV, 2017. Segflow: Joint learning for video object segmentation and optical flow. In ICCV, 2017 Instance embedding transfer to unsupervised video object segmentation. In CVPR, 2018. ： 整合深度学习的实例嵌入和运动显著性来提高性能。 Unsupervised video object segmentation with motion-based bilateral networks. In ECCV, 2018. Flow guided recurrent neural encoder for video salient object detection. In CVPR, 2018. See more, know more: Unsupervised video object segmentation with co-attention Siamese networks. In CVPR, 2019. The graph neural network model. IEEE TNNLS, 20(1):61–80, 2009 Neural message passing for quantum chemistry. In ICML, 2017 2. 基于FCN的： Triply supervised decoder networks for joint detection and segmentation. In CVPR, 2019 Fully convolutional networks for semantic segmentation. In CVPR, 2015. Ranet: Ranking attention network for fast video object segmentation. In ICCV, 2019. 3. 双流网络来融合外观信息和运动信息 Flow guided recurrent neural encoder for video salient object detection. In CVPR, 2018. Fusionseg: Learning to combine motion and appearance for fully automatic segmention of generic objects in videos. In CVPR, 2017. Segflow: Joint learning for video object segmentation and optical flow. In ICCV, 2017 三、 提出的方法-ZVOS ​ 提出了一种注意力图神经网络(AGNN)来解决Zero-Shot视频目标分割(ZVOS)问题，将ZVOS重新定义为一种端到端的、基于消息传递的图信息融合过程(如上图b所示)。具体地，构造了一个全连通图，其中视频帧被表示为节点，两帧之间的两两关系被描述为对应节点之间的边。两帧之间的关联被一个注意力机制有效地捕获，这避免了耗时的光流估计。 四、 图神经网络GNN​ GNN最初是在《 A new model for learning in graph domains. In IJCNN, 2005.》中提出的，并在《 The graph neural network model. IEEE TNNLS, 20(1):61–80, 2009. 》中进一步发展，以处理结构化数据之间的底层关系。 ​ 在《The graph neural network model》中，使用RNN对每个节点的状态进行建模，通过传递相邻节点的参数化消息来挖掘节点之间的底层关联。近年来，GNNs已成功应用于分子生物学、计算机视觉、机器学习、自然语言处理等诸多领域。GNNs的另一个流行趋势是将卷积体系结构泛化到任意图形结构数据上，即图卷积神经网络(graph convolution neural network, GCNN) ​ 提出的AGNN属于前一类;它是一个基于GNN的消息传递，其中所有的节点、边和消息传递函数都由神经网络参数化。它与图上的挖掘关系的一般思想相同，但是有显著的差异。 ​ 首先，我们的AGNN在空间信息的保留方面是独特的，这与传统的全连通是不同的，而且GNNs对于逐像素预测任务至关重要。其次，为了有效地捕获两个图像帧之间的关系，我们引入了一个可微注意力机制，该机制处理相关信息并产生进一步的鉴别边缘特征。 1. GNN 的 Survey papers Graph Neural Networks: A Review of Methods and Applications. arxiv 2018. paper Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun. A Comprehensive Survey on Graph Neural Networks. arxiv 2019. paper Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu. Deep Learning on Graphs: A Survey. arxiv 2018. paper Ziwei Zhang, Peng Cui, Wenwu Zhu. Relational Inductive Biases, Deep Learning, and Graph Networks. arxiv 2018. paper Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others. Geometric Deep Learning: Going beyond Euclidean data. IEEE SPM 2017. paper Bronstein, Michael M and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre. Computational Capabilities of Graph Neural Networks. IEEE TNN 2009. paper Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele. Neural Message Passing for Quantum Chemistry. ICML 2017. paper Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E. Non-local Neural Networks. CVPR 2018. paper Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming. The Graph Neural Network Model. IEEE TNN 2009. paper Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele. 2. GNN 的表示参考： 图神经网络模型 The Graph Neural Network Model https://zhuanlan.zhihu.com/p/76290138 五、 AGNN1. AGNN AGNN ： 提供统一的、端到端可训练的、基于图模型的ZVOS解决方案; 通过在图上迭代传播和融合消息，有效挖掘视频内部丰富多样的高阶关系; 利用可微注意机制捕获帧对之间的相关信息。 2. 符号表示训练和测视频序列： ${I = {I_i ∈ R^{wh3} }_{i = 1}^N}$ 大小是 473 x 473 ZVOS的目的是：产生相关帧的二值分割掩码: ${S= { S_i ∈ {0, 1}^{W*H}}_{i = 1}^N }$ AGNN将$I $ 表示成有向图 $G = (V, E)$: 节点node $v_i ∈ V$， 代表第 $i$ 帧 $I_i$ . 边 edge $e_{ij} = (v_i, v_j) ∈ E$ , 代表 $I_i 到 I_j 的关系$。 ​ AGNN的核心思想是在G上执行K个消息传播迭代，以有效地挖掘 $ I $ 各个节点（帧）间丰富的高阶关系。这有助于更好地从全局视图捕获视频内容，并获得更准确的前景估计。内注意通过关注同一节点嵌入内的所有位置来计算某个位置的响应。 ​ 然后从最后的节点状态 $ {h_i^K}_{i = 1}^N$ 使用读出函数得到 分割的预测 $ \\hat{S}$ FCN-Based Node Embedding我们利用DeepLabV3—一个经典的基于FCN的语义分割架构，提取有效的帧特征，作为节点表示。 对于一个节点$v_i$ , 初始的 embedding $h_i^0$ 计算：$$h_i^0 = V_i = F_{DeepLab}(I_i) ∈ R^{W * H * C}$$ $h_i^0$是一个三维的Tensor， 保存了一些空间信息和语义信息。 Intra-Attention Based Loop-Edge EmbeddingLoop Edge : $e_{i,i} ∈ E $ ， Loop Edge Embeddings : $e_{i,i}^k$ 用于捕捉帧内的节点表示（$ h_i^k$）之间的关系。 把 $e_{i,i}^k$ 当做一种 intra-attention mechanism ：比如（ Non-local neural networks 、Attention is all有need）。 有助于建模的长期，多层次的依赖图像区域 ，即可以捕获图像的长期依赖，属于self-attention（ Self-attention generative adversarial networks. In ICML, 2019. ）。 Intra-Attention 通过关注同一节点Embeddings内的所有位置来计算某个位置的响应 。 *代表卷积操作 W 代表可以训练的卷积核 α 是可学习的尺度参数 上面公式使得 $h_i^k$ 中每个位置的输出元素在对上下文信息进行编码的同时，也对其原始信息进行编码，从而提高了表达能力。 Inter-Attention Based Line-Edge Embeddingline edge : $e_{ij} ∈ E$ 连接两个不同的节点。 line-edge Embedding： $e_{i,j}^k$ 用于挖掘两个节点之间的关系。 inter-attention mechanism ： 《Hierarchical question-image co-attention for visual question answering. In NIPS, 2016. 》 使用inter-attention mechanism来捕获两个节点之间的双向关系： $ e_{i,j}^k$ = $e_{j,i}^k$ 。 对于节点$v_i$来说， $ e_{i,j}^k$ 表示 输出边的特征， $e_{j,i}^k$表示输入边的特征。 $W_c ∈ ^{C * C}$是一个可学习的权重矩阵。 $h_i^k ∈ R^{(WH) * C}$和 $h_j^k ∈ R^{(WH) * C}$ 被展平成矩阵的形式。 $ e_{i,j}^k$的每个元素 反映了 $h_i^k$的每一行与$h_j^k$的每一列之间的相似度。 所以，$ e_{i,j}^k$ 就可以看做节点$v_i$的Embedding 对节点 $v_j$的重要性， 反之亦然。 Gated Message Aggregation在AGNN中，对于在loop-edge中传递的message，将环边嵌入向量 $e_{i,j}^{k-1}$ 本身视为一个message，因为它已经包含了上下文和原始节点信息 。 $m_{j,i}^k$ : 表示 $v_j$ 传递到 $v_i$ 的message， 从而有： softmax(·) normalizes each row of the input . 因此： $m_{j,i}^k$ 的每一行是 $h_i^{k-1}$ 的每一行(位置)的加权组合，其中权值来自 $e_{i, j}^{k-1}$ 的对应列。 通过这种方式，消息函数M(·)分配其边缘加权特征(即，消息)到邻居节点 。( Graph attention networks. In ICLR, 2018. ) 然后$m_{j,i}^k$ 被重新reshape成 一个三维张量 W * H * C。 此外，由于某些节点由于摄像机移位或视野外而产生噪声，因此它们的message可能是无用的甚至有害的。我们应用一个可学习的 门G(·) 来评估一个消息 $m_{j,i}^k$ 的置信度 。 $F_{GAP}(.)$ 表示使用全局平均池化来对通道之间作出响应。 $\\sigma$ 表示 sigmoid函数。$W_g$ 和 $b_g$ 表示卷积核参数和偏置。 这里，门机制用于过滤噪声帧中不相关的信息。 ConvGRU based Node-State Update[更新节点状态]在第k次迭代，在收集到所有相邻节点和它自身的信息（$m_i$）后 ，通过将先前的状态$h_i^{k-1}$和 它接收到的消息$m_i^k$ 要一起考虑，$v_i$变成一个新的状态$h_i^k$, 为了保留$h_i^{k-1}$和$m_i^k$ 的时间信息，使用ConVGRU来更新节点的状态： Readout Function [读出函数-预测]在进行了K次迭代的消息传递之后，获得了每个节点$v_i$的最终状态 $ h_i^K $ , 在读出的阶段通过 读出函数R() 获得了分割的预测图 $\\hat{S} ∈ [0, 1]^{W * H}$ 。将最终状态节点$ h_i^K $ 与 原始节点 $V_i$ concatenate 之后使用读出函数的到预测结果： 再次，为了保存空间信息，将读出函数实现为一个小型的FCN网络，该网络由三个卷积层和一个sigmoid函数将预测归一化为[0， 1]。 ​ 在intra-attention和update function 中，卷积运算是通过1×1个卷积层来实现的。读出函数由两个3×3个卷积层组成，每个卷积层有一个1×1个卷积层。作为基于GNN模型的消息传递，这些函数在所有节点之间共享权重。此外，以上所有函数都经过精心设计，避免了干扰空间信息，这对于ZVOS是必不可少的，因为它是一个像素级的预测任务 。 六、 网络的具体信息整个模型是端到端的。 特征提取： DeepLadV3的前5个卷积块 对每个节点 得到初始的状态 $V_i$ = $h_i^0$ ∈ $R^{60 * 60 * 256}$ 然后经过K次迭之后得到分割预测图$\\hat{S} ∈ [0 ,1] ^{60 × 60}$。 训练：损失函数 binary cross entropy loss : 值得一提的是，由于AGNN在同一时间处理多个视频帧，因此在组合候选帧数量众多的情况下，它带来了一种非常有效的训练数据扩充策略。在我们的实验中，在训练过程中，由于计算的限制，我们从训练视频集中随机选择2个视频，每个视频采样3帧(N0 = 3)。另外，我们将迭代总数设为K = 3。 七、 结果","path":"2020/02/19/Zero-Shot Video Object Segmentation via Attentive Graph Neural Networks/","date":"02-19","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"VOS","slug":"VOS","permalink":"https://castile.github.io/tags/VOS/"}]},{"title":"Java之IO流","text":"一、 概览 Java 的 I/O 大概可以分成以下几类： 磁盘操作：File 字节操作：InputStream 和 OutputStream 字符操作：Reader 和 Writer 对象操作：Serializable 网络操作：Socket 新的输入/输出：NIO 流分类按照方向：一切以程序为中心 输入流： 数据源到程序（InputStream、Reader 读进来） 输出流： 程序到目的地（OutputStream、 Writer 写出去） 按照功能划分： 节点流： 可以直接从数据源或者目的地读写数据===&gt; 直接操作数据源 处理流(包装流)： 不是直接连接到数据源火目的地，是其他流进行封装。目的主要是简化操作和提高性能。 装饰者设计模式。 关系：节点流是在IO的第一线，所有操作必须同节点流。处理流是对节点流的性能进行提升。 通常很少使用单个流对象，而是将一系列的流以包装的形式链接起来处理数据。 包装可以在不改变被包装流的前提下，获得更强的流处理功能 。 按照数据分类： 字节流： 按照字节读取数据（InputStream 、 OutputStream) 字符流： 按照字符读取数据（Reader、 Writer） 编码的不同，从而有了对字符进行高效操作的字符流对象。 原理： 底层还是基于字节流，自动搜索了指定的码表（UTF-8、GBK、Unicode等） 典型的字符输入流/输出流的链接如下： 二、 磁盘操作FileFile 类可以用于表示文件和目录的信息，但是它不表示文件的内容。 File代表的是一个抽象的表示形式，用于连接java程序与磁盘的桥梁，java只能跟OS交流。 File类的构造方法 File(File parent, String child) 从父抽象路径名和子路径名字符串创建新的 File实例。 File(String pathname) 通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例。 File(String parent, String child) 从父路径名字符串和子路径名字符串创建新的 File实例。 File(URI uri) 通过将给定的 file: URI转换为抽象路径名来创建新的 File实例。 12345678910111213141516171819202122232425262728import java.io.File;/** * @author Hongliang Zhu * @create 2020-02-17 11:51 */public class Demo1 &#123; public static void main(String[] args) &#123; String path = &quot;F:/java/base/io/io.png&quot;; File file = new File(path); System.out.println(file.length()); File file1 = new File(&quot;F:/java/base/io&quot;, &quot;io.png&quot;); System.out.println(file1.length()); File file2 = new File(new File(&quot;F:/java/base&quot;), &quot;/io/io.png&quot;); System.out.println(file1.length()); System.out.println(file.getAbsoluteFile()); // 绝对路径 // 相对路径 System.out.println(System.getProperty(&quot;user.dir&quot;)); // F:\\java\\base // 构建不存在的文件 File src = new File(&quot;kkk/ooo.png&quot;); System.out.println(src); // kkk\\ooo.png &#125;&#125; 416160416160416160F:\\java\\base\\io\\io.pngF:\\java\\basekkk\\ooo.png 从 Java7 开始，可以使用 Paths 和 Files 代替 File。 12Path p = Paths.get(&quot;F:/java/base&quot;,&quot;io/io.png&quot;);System.out.println(p); // F:\\java\\base\\io\\io.png 查看文件的基本信息12345678910111213141516import java.io.File;/** * @author Hongliang Zhu * @create 2020-02-17 12:13 */public class FileDemo01 &#123; public static void main(String[] args) &#123; String path = &quot;F:/java/base/io/io.png&quot;; File file = new File(path); System.out.println(&quot;名称：&quot; + file.getName()); System.out.println(&quot;路径: &quot;+ file.getPath()); System.out.println(&quot;绝对路径: &quot;+ file.getAbsolutePath()); System.out.println(&quot;父路径：&quot; + file.getParent()); System.out.println(file.getParentFile().getName()); // 父对象 &#125;&#125; 名称：io.png路径: F:\\java\\base\\io\\io.png绝对路径: F:\\java\\base\\io\\io.png父路径：F:\\java\\base\\ioio 查看文件的状态123456789101112131415161718192021222324252627282930313233import java.awt.*;import java.io.File;/** * 文件的状态 * @author Hongliang Zhu * @create 2020-02-17 12:19 */public class FileDemo02 &#123; public static void main(String[] args) &#123; File src = new File(&quot;io/io.png&quot;); System.out.println(src.length()); // 字节数 文件的长度 System.out.println(src.getPath()); System.out.println(src.getAbsoluteFile()); System.out.println(&quot;是否存在： &quot;+ src.exists()); System.out.println(&quot;是否是文件： &quot;+ src.isFile()); System.out.println(&quot;是否是文件夹： &quot;+ src.isDirectory()); // 文件状态 src = new File(&quot;kkk.jpg&quot;); if(!src.exists())&#123; System.out.println(&quot;文件不存在&quot;); &#125;else &#123; if(src.isFile())&#123; System.out.println(&quot;文件操作&quot;); &#125;else&#123; System.out.println(&quot;文件夹操作&quot;); &#125; &#125; &#125;&#125; 416160io\\io.pngF:\\java\\base\\io\\io.png是否存在： true是否是文件： true是否是文件夹： false文件不存在 操作文件夹 boolean mkdir() 创建由此抽象路径名命名的目录。 boolean mkdirs() 创建由此抽象路径名命名的目录，包括任何必需但不存在的父目录。 123456789101112131415161718import java.io.File;/** * 文件夹 * @author Hongliang Zhu * @create 2020-02-17 12:32 */public class DirDemo1 &#123; public static void main(String[] args) &#123; // 创建目录 mkdir() : 确保上级目录存在，不然创建失败 File file = new File(&quot;./io/dir/test&quot;); boolean flag = file.mkdir(); System.out.println(flag); flag = file.mkdirs(); // 推荐 System.out.println(flag); &#125;&#125; falsetrue list文件： 123456789101112131415161718192021222324252627282930313233import java.io.File;/** * 文件夹 * @author Hongliang Zhu * @create 2020-02-17 12:32 */public class DirDemo1 &#123; public static void main(String[] args) &#123; File dir = new File(&quot;./io&quot;); // 下级名称 String[] subNames = dir.list(); // 下面一层的文件名 for(String name: subNames)&#123; System.out.println(name); &#125; System.out.println(&quot;-----------------------------------&quot;); // 下级对象 File[] subFiles = dir.listFiles(); for(File s: subFiles)&#123; System.out.println(s.getName()); &#125; System.out.println(&quot;-----------------------------------&quot;); // 所有盘符： File[] roots = dir.listRoots(); for(File f : roots)&#123; System.out.println(f.getAbsolutePath()); &#125; &#125;&#125; dirio.imlio.png src dirio.imlio.png src C:D:F:H:\\ 递归列出一个目录下的所有文件 123456789101112public static void listAllFiles(File dir) &#123; if (dir == null || !dir.exists()) &#123; return; &#125; if (dir.isFile()) &#123; System.out.println(dir.getName()); return; &#125; for (File file : dir.listFiles()) &#123; listAllFiles(file); &#125;&#125; 计算文件夹的大小： 12345678910111213141516171819202122232425262728293031323334import java.io.File;/** * * 计算一个文件夹的大小 * @author Hongliang Zhu * @create 2020-02-17 13:05 */public class countFiles &#123; private static long length = 0; public static void main(String[] args) &#123; File file = new File(&quot;./io&quot;); count(file); System.out.println(length); &#125; public static void count(File src)&#123; if(src == null || !src.exists())&#123; //文件不存在 return; &#125; if(src.isFile())&#123; // 是一个文件，计算大小 length += src.length(); &#125;else&#123; // 不是文件 for(File f : src.listFiles())&#123; count(f); &#125; &#125; &#125;&#125; 421864 进阶一下：使用面向对象的思维对文件夹进行统计大小。 12345678910111213141516171819202122232425262728293031323334353637383940import java.io.File;/** * 使用面向对象的思维对文件夹进行统计大小。 封装 * @author Hongliang Zhu * @create 2020-02-17 13:13 */public class DirCount &#123; private long length; // 文件的长度 // 源文件 private File src; private String path; // 文件路径 public DirCount(String path) &#123; this.path = path; src = new File(path); this.count(src); &#125; public long getLength() &#123; return length; &#125; private void count(File src)&#123; if(src == null || !src.exists())&#123; //文件不存在 return; &#125; if(src.isFile())&#123; // 是一个文件，计算大小 length += src.length(); &#125;else&#123; // 不是文件 for(File f : src.listFiles())&#123; count(f); &#125; &#125; &#125; public static void main(String[] args) &#123; DirCount dir = new DirCount(&quot;./io&quot;); System.out.println(dir.getLength()); &#125;&#125; 422905 三、 字符编码 计算机只能识别二进制数据，早期由来是电信号。为了方便应用计算机，让它可以识别各个国家的文字。就将各个国家的文字用数字来表示，并一一对应，形成一张表。这就是编码表。 编码就是把字符转换为字节，而解码是把字节重新组合成字符。 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节； UTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节； UTF-16be 编码中，中文字符和英文字符都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。 Java 的内存编码使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。 123456789101112131415161718192021222324252627282930313233343536373839import java.io.UnsupportedEncodingException;/** * 编码： 字符串 ---&gt; 字节 * @author Hongliang Zhu * @create 2020-02-17 15:09 */public class ContentEncode &#123; public static void main(String[] args) throws UnsupportedEncodingException &#123; String msg = &quot;性命生命使命&quot;; // 这里使用的是UTF-8编码，中文占3个字节 // 编码： 字节数组 byte[] datas = msg.getBytes(); // 使用工程默认的字符集 System.out.println(datas.length); // 18// 编码其他字符集 try &#123; datas = msg.getBytes(&quot;UTF-16LE&quot;); // 每个用2个字节 &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; System.out.println(datas.length); // 解码 msg = new String(datas, 0, datas.length, &quot;UTF-16LE&quot;); System.out.println(msg); /// 乱码问题 // 1. 字节数不够 msg = new String(datas,0, datas.length - 1, &quot;UTF-16LE&quot;); System.out.println(msg); // 2. 字符集不统一 msg = new String(datas,0, datas.length , &quot;gbk&quot;); System.out.println(msg); &#125;&#125; 1812性命生命使命性命生命使�‘`}T\u001fu}TO}T String的编码方式String 可以看成一个字符序列，可以指定一个编码方式将它编码为字节序列，也可以指定一个编码方式将一个字节序列解码为 String。 12345String str1 = &quot;中文&quot;;byte[] bytes = str1.getBytes(&quot;UTF-8&quot;);String str2 = new String(bytes, &quot;UTF-8&quot;);System.out.println(str2); 在调用无参数 getBytes() 方法时，默认的编码方式不是 UTF-16be。双字节编码的好处是可以使用一个 char 存储中文和英文，而将 String 转为 bytes[] 字节数组就不再需要这个好处，因此也就不再需要双字节编码。getBytes() 的默认编码方式与平台有关，一般为 UTF-8。 1byte[] bytes = str1.getBytes(); 四、 四大抽象类 抽象基类 字节流 字符流 常用方法 输入流 InputStream 字节输入流 Reader 字符输入流 int read()、void close() 输出流 OutputStream 字节输出流 Writer 字符输出流 void write(int)、void flush()、 void close（） Java的IO流共涉及40多个类，实际上非常规则，都是从如下4个抽象基类派生的。 由这四个类派生出来的子类名称都是以其父类名作为子类名后缀。 标准步骤想象成搬家的程序： ①. 创建源 ②. 选择流 ③. 操作(读、写) ④. 释放资源 123456789101112131415161718192021222324252627282930313233343536373839import java.io.*;/** *标准步骤： * ①. 创建源 * ②. 选择流 * ③. 操作(读、写) * ④. 释放资源 * @author Hongliang Zhu * @create 2020-02-17 16:01 */public class IOTest01 &#123; public static void main(String[] args)&#123; //①. 创建源 File file = new File(&quot;F:\\\\java\\\\base\\\\io\\\\a.txt&quot;); //②. 选择流 InputStream in = null; // 作用域提前 try &#123; in = new FileInputStream(file); //③. 操作(读、写) int temp; while ((temp = in.read()) != -1)&#123; System.out.println((char)temp); &#125; // 文件末尾返回-1 // ④. 释放资源 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != in) // 避免空指针异常，需要加上判断 in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Hello World! 文件字节输入流FileInputStream选择流就相当于选择搬家公司，read()方法就是一个字节一个字节地读取，就相当于一件物品的去搬， 而read(bytr[] a) 相当于用卡车来搬！更加快速。 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.io.*;/** *标准步骤： * ①. 创建源 * ②. 选择流 * ③. 操作(读、写) * ④. 释放资源 * @author Hongliang Zhu * @create 2020-02-17 16:01 */public class IOTest01 &#123; public static void main(String[] args)&#123; //①. 创建源 File file = new File(&quot;F:\\\\java\\\\base\\\\io\\\\a.txt&quot;); //②. 选择流 InputStream in = null; // 作用域提前 try &#123; in = new FileInputStream(file); //③. 操作(读、写) byte[] flush = new byte[1024]; // 缓冲容器 int len = -1; // 接受长度 while ((len = in.read(flush)) != -1)&#123; //字节数组 --&gt; 字符串 （解码） String str = new String(car, 0, len); System.out.println(str); &#125; // 文件末尾返回-1 // ④. 释放资源 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != in) // 避免空指针异常，需要加上判断 in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; Hello World! zhu hong liang 文件字节流输出流FileOutputStream123456789101112131415161718192021222324252627282930313233import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;/** * * 文件字节输出流 * @author Hongliang Zhu * @create 2020-02-17 16:36 */public class IOTes02 &#123; public static void main(String[] args) &#123; // create resource File file = new File(&quot;./io/dext.txt&quot;); //choose Stream FileOutputStream os = null; try &#123; os = new FileOutputStream(file, true); // 追加标志 String msg = &quot;Hello , welcome to BeiJing !&quot;; // buffer array byte[] buff = msg.getBytes(); // write os.write(buff,0, buff.length); // flush os.flush(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 实现文件拷贝 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.*;/** * * 实现文件拷贝 * @author Hongliang Zhu * @create 2020-02-17 16:51 */public class CopyFile &#123; public static void main(String[] args) &#123; File src = new File(&quot;./io/io.png&quot;); FileInputStream in = null; FileOutputStream os = null; try &#123; in = new FileInputStream(src); os = new FileOutputStream(&quot;./io/io_cpoy.png&quot;); // 写出的文件 byte[] buff = new byte[1024 * 20]; int cnt; while ((cnt = in.read(buff, 0, buff.length)) != -1) &#123; os.write(buff, 0, cnt); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; // 关闭资源 先打开的后关闭 try&#123; if(os != null)&#123; os.close(); &#125; if(in != null)&#123; in.close(); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 思考：进阶–&gt; 实现文件夹的拷贝Reader 与 Writer不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符。但是在程序中操作的通常是字符形式的数据，因此需要提供对字符进行操作的方法。 InputStreamReader 实现从字节流解码成字符流； OutputStreamWriter 实现字符流编码成为字节流。 实现逐行输出文本文件的内容： 123456789101112131415public static void readFileContent(String filePath) throws IOException &#123; FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) &#123; System.out.println(line); &#125; // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close();&#125; ByteArrayInputStream &amp; ByteArrayOuputStream上面的FileInputStream中源都是一个文件，文件是存储在磁盘中的，Java程序无法直接访问到，需要通过OS来连接，这里的字节数组流ByteArrayInputStream 的源是内存中的一个字节数组，JVM是可以直接访问的，与操作系统无关了，并且字节数组流不需要close资源，因为JVM有GC来管理，会由JVM来释放，不需要自己手动关闭。 字符串、一切数据，所有的都可以转换成字节数组，方便网络的传输，在底层使用的较多。 ByteArrayInputStream中的构造函数: 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.*;/** * 字节数组输入流 * @author Hongliang Zhu * @create 2020年2月17日19:12:50 */public class IOTest03 &#123; public static void main(String[] args)&#123; //①. 创建源 byte[] src = &quot;talk is cheap show me the code&quot;.getBytes(); //②. 选择流 InputStream in = null; // 作用域提前 try &#123; in = new ByteArrayInputStream(src); //③. 操作(读、写) byte[] flush = new byte[5]; // 缓冲容器 每三个字符读一次 int len = -1; // 接受长度 while ((len = in.read(flush)) != -1)&#123; //字节数组 --&gt; 字符串 （解码） String str = new String(flush, 0, len); System.out.println(str); &#125; // 文件末尾返回-1 // ④. 释放资源 &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != in) // 可以不用关闭 in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; ByteArrayOutputStream该类实现了将数据写入字节数组的输出流。当数据写入缓冲区时，缓冲区会自动增长。数据可以使用toByteArray()和toString() 。不需要在构造方法中传入目的数组。 关闭ByteArrayOutputStream没有任何效果。 该流中的方法可以在流关闭后调用，而不生成IOException 。 123456789101112131415161718192021222324252627282930313233import java.io.*;/** * * 字节数组输出流`ByteArrayOutputStream` * @author Hongliang Zhu * @create 2020-02-17 16:36 */public class IOTes04 &#123; public static void main(String[] args) &#123; // create resource byte[] dest = null; //choose Stream 要使用新增方法，不能使用多态 ByteArrayOutputStream os = null; try &#123; os = new ByteArrayOutputStream(); // 不需要传入目的地 String msg = &quot;Hello , welcome to BeiJing !&quot;; // buffer array byte[] buff = msg.getBytes(); // write os.write(buff,0, buff.length); // flush os.flush(); dest = os.toByteArray(); // 获取数据 System.out.println(dest.length+&quot;===&gt;&quot;+new String(dest,0, os.size())); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 综合-对接流例：将一张图片读取到一个字节数组中，先使用文件输入流，通过程序做一个中转，程序再写出到字节数组中。然后字节数组通过字节数组输入流到程序中，再使用文件输出流将字节数组写回到文件中（图片）。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import java.io.*;/** * * 字节数组输出流`ByteArrayOutputStream` * @author Hongliang Zhu * @create 2020-02-17 16:36 */public class picTest &#123; public static void main(String[] args) &#123; // 图片转换成字节数组 byte[] datas = FileToByteArray(&quot;./io/io.png&quot;); System.out.println(datas.length); ByteArrayToFile(datas, &quot;./io/ppp_img.png&quot;); &#125; /** * 图片到字节数组中 * 1. 图片到程序： FileInputStream * 2. 程序到数组： ByteArrayOutputStream */ public static byte[] FileToByteArray(String filepath)&#123; //①. 创建源 目的地 File file = new File(filepath); byte[] dext = null; //②. 选择流 InputStream in = null; // 作用域提前 ByteArrayOutputStream bos = new ByteArrayOutputStream(); try &#123; in = new FileInputStream(file); //③. 操作 byte[] flush = new byte[1024]; // 缓冲容器 int len = -1; // 接受长度 while ((len = in.read(flush)) != -1)&#123; bos.write(flush, 0, len); //写出到字节数组 &#125; bos.flush(); return bos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; try &#123; if(null != in) // 避免空指针异常，需要加上判断 in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; /** *字节数组写出到图片 * 1. 字节数组读取到程序中 : ByteArrayOutputStream * 2. 程序写出到文件: FileOutputStream * */ public static void ByteArrayToFile(byte[] datas, String filePath)&#123; //①. 创建源 File dest = new File(filePath); //②. 选择流(增加方法) 不能使用多态 InputStream in = null; // 作用域提前 OutputStream os = null; try &#123; in = new ByteArrayInputStream(datas); os = new FileOutputStream(dest); //③. 操作(读、写) byte[] flush = new byte[1024 * 10]; // 缓冲容器 int len = -1; // 接受长度 while ((len = in.read(flush)) != -1) &#123; //字节数组 --&gt; 文件 os.write(flush, 0, len); &#125; os.flush(); //刷新 &#125;catch (IOException e)&#123; e.printStackTrace(); &#125;finally &#123; if(null != os)&#123; try &#123; os.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 封装成工具类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.io.*;/** * 封装拷贝 * @author Hongliang Zhu * @create 2020-02-17 21:40 */public class FileUtils &#123; public static void main(String[] args) &#123; // 文件 到文件 try &#123; InputStream is = new FileInputStream(&quot;./io/a.txt&quot;); OutputStream os = new FileOutputStream(&quot;./io/a_copy.txt&quot;); copy(is, os); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; // 文件到字节数组 byte[] datas = null; try &#123; InputStream is = new FileInputStream(&quot;./io/io.png&quot;); ByteArrayOutputStream os = new ByteArrayOutputStream(); copy(is, os); datas = os.toByteArray(); System.out.println(datas.length); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; // 字节数组到文件 try &#123; InputStream is = new ByteArrayInputStream(datas); OutputStream os = new FileOutputStream(&quot;./io/io_copyppppp.png&quot;); copy(is, os); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125; /** * * 对接输入输出流 * @param in 输入流 * @param os 输出流 */ public static void copy(InputStream in, OutputStream os)&#123; try &#123; byte[] buff = new byte[10]; int cnt; while ((cnt = in.read(buff, 0, buff.length)) != -1) &#123; os.write(buff, 0, cnt); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; close(); &#125; &#125; /** * 释放资源 * @param ios */ public static void close(Closeable... ios)&#123; for(Closeable io: ios)&#123; try&#123; if(io != null)&#123; io.close(); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 装饰者设计模式Java I/O 使用了装饰者模式来实现。以 InputStream 为例， InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 12FileInputStream fileInputStream = new FileInputStream(filePath);BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); DataInputStream 装饰者提供了对更多数据类型进行输入的操作，比如 int、double 等基本类型。 装饰者模式有四个对象： 1、抽象组件： 需要装饰的抽象对象（接口或者抽象父类） 2、 具体组件： 需要装饰的对象（如上例的Person类） 3、 抽象装饰类： 包含了对抽象组件的引用以及装饰者共有的方法（写到构造器里面） 4、 具体装饰类： 被装饰的对象 装饰者与被装饰者拥有共同的超类，继承的目的是继承类型，而不是行为 模拟对人的声音放大123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * * 装饰者模式： 实现放大器对声音的放大功能 * @author Hongliang Zhu * @create 2020-02-17 22:31 */public class DecorateTest01 &#123; public static void main(String[] args) &#123; Person p = new Person(10); p.say(); // 装饰 Amplifier am = new Amplifier(p); am.say(); &#125;&#125;interface Say&#123; void say();&#125;class Person implements Say&#123; //属性 private int vioce = 10; // 10 db public Person(int vioce) &#123; this.vioce = vioce; &#125; public int getVioce() &#123; return vioce; &#125; @Override public void say() &#123; System.out.println(&quot;人的声音为：&quot;+ this.getVioce()); &#125;&#125;class Amplifier implements Say&#123; private Person p; Amplifier(Person p)&#123; this.p = p; &#125; @Override public void say() &#123; System.out.println(&quot;人的声音为：&quot;+ p.getVioce() * 100); System.out.println(&quot;噪音.........&quot;); &#125;&#125; 人的声音为：10人的声音为：1000噪音……… 模拟咖啡123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * * 装饰者模式： 模拟咖啡你 * 1、抽象组件： 需要装饰的抽象对象（接口或者抽象父类） * 2、 具体组件： 需要装饰的对象（如上例的Person类） * 3、 抽象装饰类： 包含了对抽象组件的引用以及装饰者共有的方法（写到构造器里面） * 4、 具体装饰类： 被装饰的对象 * @author Hongliang Zhu * @create 2020-02-17 22:31 */public class DecorateTest02 &#123; public static void main(String[] args) &#123; Drink coffe = new Coffe(); System.out.println(coffe.info() +&quot; ===&gt;&quot;+ coffe.cost()); Drink suger = new Sugar(coffe); // 装饰 加糖 System.out.println(suger.info() +&quot; ===&gt;&quot;+ suger.cost()); Drink milk = new Milk(coffe); //装饰 ， 加牛奶 System.out.println(milk.info() +&quot; ===&gt;&quot;+ milk.cost()); // 还可以混合： 既加糖也加牛奶 suger = new Sugar(milk); System.out.println(suger.info() +&quot; ===&gt;&quot;+ suger.cost()); &#125;&#125;// 饮料接口 -===&gt; 抽象组件interface Drink&#123; double cost(); // 费用 String info(); // 说明&#125;// 具体组件class Coffe implements Drink&#123; String name = &quot;原味咖啡&quot;; public String getName() &#123; return name; &#125; @Override public double cost() &#123; return 10; &#125; @Override public String info() &#123; return this.name; &#125;&#125;//抽象装饰类class Decorator implements Drink&#123; //包含了对抽象组件的引用（写到构造器里面） Drink drink; Decorator(Drink drink)&#123; this.drink = drink; &#125; // 以及装饰者共有的方法 @Override public double cost() &#123; return this.drink.cost(); &#125; @Override public String info() &#123; return this.drink.info(); &#125;&#125;//具体装饰类： 被装饰的对象class Milk extends Decorator&#123; Milk(Drink drink) &#123; super(drink); &#125; @Override public double cost() &#123; return this.drink.cost() * 4; &#125; @Override public String info() &#123; return this.drink.info() + &quot;加了牛奶&quot; ; &#125;&#125;//具体装饰类： 被装饰的对象class Sugar extends Decorator&#123; Sugar(Drink drink) &#123; super(drink); &#125; @Override public double cost() &#123; return this.drink.cost() * 2; &#125; @Override public String info() &#123; return this.drink.info() + &quot;加了蔗糖&quot; ; &#125;&#125; 原味咖啡 = &gt;10.0原味咖啡加了蔗糖 =&gt;20.0原味咖啡加了牛奶 =&gt;40.0原味咖啡加了牛奶加了蔗糖 ===&gt;80.0 五、 IO-缓冲流缓冲字节流BufferedInputStream 、BufferedOutputStream 缓冲流可以提高性能，一开始的是字节流的read()方法，可以比喻成蚂蚁搬家，一个字节一个字节地读取，使用read(byte[] buff), 自己维护了一个字节数组，相当于叫了一个搬家公司用卡车搬；而这里的缓冲流是在内部维护了一个缓冲区，默认 8k，将字节流打包，放入缓冲流中，相当于使用了一个更大的卡车。可以提高性能，避免频繁去读写。 这里的缓冲流成为处理流，任何一个处理流，不管怎么嵌套，最底层都是一个节点流，没有节点流就没有处理流。 随着流越来越多，释放资源可以直接释放处理流，处理流内部会自动释放节点流。如果需要手动释放，释放的原则是：从里到外，一依次释放。 123456789101112131415161718public class CopyFile &#123; public static void main(String[] args) &#123; File src = new File(&quot;./io/io.png&quot;); // try... with...resource try(InputStream in = new BufferedInputStream(new FileInputStream(src)); OutputStream os = new BufferedOutputStream(new FileOutputStream(&quot;./io/io_copy.png&quot;))) &#123; byte[] buff = new byte[10]; int cnt; while ((cnt = in.read(buff, 0, buff.length)) != -1) &#123; os.write(buff, 0, cnt); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 字符缓冲流BufferedReader、BufferedWriter这两个流有许多新增方法，注意不要使用多态。 BufferedReader中的String readLine() 读一行文字。 BufferedWriter中的void newLine() 写一行行分隔符。 使用缓冲流实现纯文本的拷贝： 12345678910111213141516171819202122232425import java.io.*;/** * * 利用BufferedReader和BufferWriter实现纯文本拷贝 * @author Hongliang Zhu * @create 2020-02-18 13:28 */public class CopyTxt &#123; public static void main(String[] args) &#123; File src = new File(&quot;./io/dext.txt&quot;); File dest = new File(&quot;./io/copy_dext.txt&quot;); try (BufferedReader br = new BufferedReader(new FileReader(src)); BufferedWriter bw = new BufferedWriter(new FileWriter(dest)))&#123; String line = null; // 逐行读取 while ((line = br.readLine()) != null)&#123; bw.write(line); bw.newLine(); bw.flush(); &#125; &#125;catch (IOException e)&#123; e.printStackTrace(); &#125; &#125;&#125; 转换流-InputStreamReader、OutputStreamWriter1.将字节流转换成字符流。字节流可以处理一切内容，文本、图片、音频、视频。所以在很多框架和系统中底层返回的是一个字节流。但是里面是纯文本的时候，就需要进行转换。 如System.in 和 System.out都是属于字节流。 2.在底层中，如果是一个纯文本的话，涉及到一个字符集，将字节转换成字符叫做解码，如果工程中的字符集或者系统的字符集与源的字符集不一致的话，就会出现乱码问题。这时候我们需要自己指定字符集。 InputStreamReader解码 String getEncoding() : 返回此流使用的字符编码的名称。 OutputStreamWriter编码OutputStreamWriter是字符流到字节流的桥梁：使用指定的字符编码charset将指定的字符编码成字节 。 它使用的字符集可以由名称指定，也可以被明确指定，或者可以接受平台的默认字符集。 123456789101112131415161718192021222324252627282930import java.io.*;/** * * 转换流：InputStreamReader OutputStreamWrit * 功能： * 1. 以字符流的形式操作字节流 （纯文本） 本例 * 2. 指定字符集 * * @author Hongliang Zhu * @create 2020-02-18 14:20 */public class ConvertTest &#123; // 操作System.in System.out public static void main(String[] args) &#123; // 将字节流转换成字符流 ,字符流一般用缓冲流包起来 try(BufferedReader reader = new BufferedReader(new InputStreamReader(System.in)) ; // System.in 属于字节流 BufferedWriter writer = new BufferedWriter(new OutputStreamWriter(System.out)))&#123; // 循环读取键盘输入， 输出 exit退出 String msg = &quot;&quot;; while (!(msg = reader.readLine()).equals(&quot;exit&quot;))&#123; writer.write(msg); writer.newLine(); writer.flush(); //强制刷新，因为缓冲流内部数组比较大，字符会驻留在管道中 &#125; &#125;catch (IOException e)&#123; System.out.println(&quot;操作异常&quot;); &#125; &#125;&#125; 六、 其他流（数据流、对象流、打印流）1. 数据流方便我们处理基本数据类型和字符串，不但保留了数据，还保存了数据类型。 DataInputStream构造方法： DataInputStream(InputStream in） 方法： DataOutputStream用法与DataInputStream相似 12345678910111213141516171819202122232425262728293031323334353637import java.io.*;/** * s数据流 * 1. 写出后读取 * 2. 读取顺序与写出顺序要一致 * @author Hongliang Zhu * @create 2020-02-18 14:58 */public class DataTest &#123; public static void main(String[] args) throws IOException &#123; // 写出 ByteArrayOutputStream baos = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(baos)); // 加上缓冲流，提升性能 // 操作数据类型 dos.writeUTF(&quot;良辰美景奈何天&quot;); // 24个字节 dos.writeInt(19); dos.writeChar(&#x27;a&#x27;); dos.writeBoolean(false); dos.flush(); // 读取 byte[] datas = baos.toByteArray(); System.out.println(datas.length); // 30 // 加上缓冲流，提升性能 DataInputStream dis = new DataInputStream(new BufferedInputStream(new ByteArrayInputStream(datas))); // 读取顺序与写出顺序一致 String msg = dis.readUTF(); System.out.println(&quot;字符串的大小： &quot;+msg.getBytes().length); // 这里变为21 int a = dis.readInt(); // 4个字节 char c = dis.readChar(); // 2个字节 boolean flag = dis.readBoolean(); // 1个字节 System.out.println(msg); System.out.println(flag); &#125;&#125; 30字符串的大小： 21良辰美景奈何天false 2. 打印流123456789101112131415161718192021222324252627import java.io.*;/** * 打印流 PrintStream * @author Hongliang Zhu * @create 2020-02-18 19:42 */public class PrintTest &#123; public static void main(String[] args) throws FileNotFoundException &#123; PrintStream ps = System.out; ps.println(&quot;Hello&quot;); ps.println(true); ps.flush(); ps = new PrintStream(new BufferedOutputStream(new FileOutputStream(&quot;./io/print.txt&quot;,true)), true); ps.println(&quot;这是打印流&quot;); ps.println(true); // 重定向输出端 System.setOut(ps); System.out.println(&quot;我已经变了，不是输出到控制台了！&quot;); // 重回控制台 System.setOut(new PrintStream(new BufferedOutputStream(new FileOutputStream(FileDescriptor.out)), true)); System.out.println(&quot;我回来啦！！！！&quot;); ps.close(); &#125;&#125; Hellotrue我回来啦！！！！ 还有PrintWriter。 七、 对象操作1. 序列化对象流 ObjectInputStream &amp; ObjectOutputStream 不是所有的对象都是可以序列化。序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化：ObjectOutputStream.writeObject() 反序列化：ObjectInputStream.readObject() 不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.io.*;/** * 对象流 * 1. 写出后读取 * 2. 读取的顺序与写出保持一致 * 3. 不是所有的对象都可以序列化 Serializable * @author Hongliang Zhu * @create 2020-02-18 18:47 */public class ObjectTest &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; // 写出 ByteArrayOutputStream baos = new ByteArrayOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(new BufferedOutputStream(baos)); // 加上缓冲流，提升性能 // 操作数据类型 oos.writeUTF(&quot;良辰美景奈何天&quot;); // 24个字节 oos.writeInt(18); oos.writeChar(&#x27;a&#x27;); oos.writeBoolean(true); // 对象 oos.writeObject(&quot;花谢花飞花满天&quot;); Employee e = new Employee(&quot;马云&quot;, 5000.0); oos.writeObject(e); // 序列化 oos.flush(); // 读取 byte[] datas = baos.toByteArray(); System.out.println(datas.length); // 30 // 加上缓冲流，提升性能 ObjectInputStream dis = new ObjectInputStream(new BufferedInputStream(new ByteArrayInputStream(datas))); // 读取顺序与写出顺序一致 String msg = dis.readUTF(); System.out.println(&quot;字符串的大小： &quot;+msg.getBytes().length); // 这里变为21 int a = dis.readInt(); // 4个字节 char c = dis.readChar(); // 2个字节 boolean flag = dis.readBoolean(); // 1个字节 System.out.println(msg); System.out.println(flag); Object str = dis.readObject(); Object employee = dis.readObject(); //反序列化 if( str instanceof String)&#123; String ss = (String)str; System.out.println(ss); &#125; if(employee instanceof Employee)&#123; Employee eee = (Employee)employee; System.out.println(eee.toString()); &#125; &#125;&#125;class Employee implements java.io.Serializable&#123; private String name; private double money; public void setName(String name) &#123; this.name = name; &#125; public void setMoney(double money) &#123; this.money = money; &#125; public String getName() &#123; return name; &#125; public double getMoney() &#123; return money; &#125; public Employee(String name, double money) &#123; this.name = name; this.money = money; &#125; @Override public String toString() &#123; return this.name +&quot;===&gt;&quot;+ this.money; &#125;&#125; 2. Serializable序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。 3. transienttransient 关键字可以使一些属性不会被序列化。 ArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。 1private transient Object[] elementData; 八、 commons-io组件下载 http://commons.apache.org/proper/commons-io/download_io.cgi 环境搭建环境准备：1.在idea中导入以下两个jar包 2.打开idea的project struct： 3,进入Dependencies 操作文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546import org.apache.commons.io.FileUtils;import org.apache.commons.io.filefilter.DirectoryFileFilter;import org.apache.commons.io.filefilter.EmptyFileFilter;import org.apache.commons.io.filefilter.FileFilterUtils;import org.apache.commons.io.filefilter.SuffixFileFilter;import java.io.File;import java.util.Collection;/** * @author Hongliang Zhu * @create 2020-02-18 21:47 */public class CIO_test &#123; public static void main(String[] args) &#123; // 文件大小 long len = FileUtils.sizeOf(new File(&quot;./io/io.png&quot;)); System.out.println(len); //目录大小 len = FileUtils.sizeOfDirectory(new File(&quot;./io&quot;)); System.out.println(len); // 列出当前目录下的文件 Collection&lt;File&gt; files = FileUtils.listFiles(new File(&quot;./io&quot;), EmptyFileFilter.NOT_EMPTY, null); for (File file: files)&#123; System.out.println(file.getName()); &#125; System.out.println(&quot;----------------------------------&quot;); // 列出当前目录下的件文 files = FileUtils.listFiles(new File(&quot;./io&quot;), EmptyFileFilter.NOT_EMPTY, DirectoryFileFilter.INSTANCE); for (File file: files)&#123; System.out.println(file.getAbsolutePath()); &#125; System.out.println(&quot;----------------------------------&quot;); files = FileUtils.listFiles(new File(&quot;./io&quot;), FileFilterUtils.or(new SuffixFileFilter(&quot;java&quot;), new SuffixFileFilter(&quot;txt&quot;)), DirectoryFileFilter.INSTANCE); // 文件过滤 for (File file: files)&#123; System.out.println(file.getAbsolutePath()); &#125; &#125;&#125; 4161601696597a.txta_copy.txtcopy_dext.txtdext.txtio.imlio.pngio_copy.pngio_copyppppp.pngppp_img.png print.txt F:\\java\\base.\\io\\a.txtF:\\java\\base.\\io\\a_copy.txtF:\\java\\base.\\io\\copy_dext.txtF:\\java\\base.\\io\\dext.txtF:\\java\\base.\\io\\io.imlF:\\java\\base.\\io\\io.pngF:\\java\\base.\\io\\io_copy.pngF:\\java\\base.\\io\\io_copyppppp.pngF:\\java\\base.\\io\\ppp_img.pngF:\\java\\base.\\io\\print.txtF:\\java\\base.\\io\\src\\CIOTest.javaF:\\java\\base.\\io\\src\\CIO_test.javaF:\\java\\base.\\io\\src\\ContentEncode.javaF:\\java\\base.\\io\\src\\ConvertTest.javaF:\\java\\base.\\io\\src\\CopyFile.javaF:\\java\\base.\\io\\src\\CopyTxt.javaF:\\java\\base.\\io\\src\\countFiles.javaF:\\java\\base.\\io\\src\\DataTest.javaF:\\java\\base.\\io\\src\\DecorateTest01.javaF:\\java\\base.\\io\\src\\DecorateTest02.javaF:\\java\\base.\\io\\src\\Demo1.javaF:\\java\\base.\\io\\src\\DirCount.javaF:\\java\\base.\\io\\src\\DirDemo1.javaF:\\java\\base.\\io\\src\\FileDemo01.javaF:\\java\\base.\\io\\src\\FileDemo02.javaF:\\java\\base.\\io\\src\\FileUtils.javaF:\\java\\base.\\io\\src\\IOTes02.javaF:\\java\\base.\\io\\src\\IOTes04.javaF:\\java\\base.\\io\\src\\IOTest01.javaF:\\java\\base.\\io\\src\\IOTest03.javaF:\\java\\base.\\io\\src\\listAllFiles.javaF:\\java\\base.\\io\\src\\ObjectTest.javaF:\\java\\base.\\io\\src\\Path.javaF:\\java\\base.\\io\\src\\picTest.java F:\\java\\base.\\io\\src\\PrintTest.java F:\\java\\base.\\io\\a.txtF:\\java\\base.\\io\\a_copy.txtF:\\java\\base.\\io\\copy_dext.txtF:\\java\\base.\\io\\dext.txtF:\\java\\base.\\io\\print.txtF:\\java\\base.\\io\\src\\CIOTest.javaF:\\java\\base.\\io\\src\\CIO_test.javaF:\\java\\base.\\io\\src\\ContentEncode.javaF:\\java\\base.\\io\\src\\ConvertTest.javaF:\\java\\base.\\io\\src\\CopyFile.javaF:\\java\\base.\\io\\src\\CopyTxt.javaF:\\java\\base.\\io\\src\\countFiles.javaF:\\java\\base.\\io\\src\\DataTest.javaF:\\java\\base.\\io\\src\\DecorateTest01.javaF:\\java\\base.\\io\\src\\DecorateTest02.javaF:\\java\\base.\\io\\src\\Demo1.javaF:\\java\\base.\\io\\src\\DirCount.javaF:\\java\\base.\\io\\src\\DirDemo1.javaF:\\java\\base.\\io\\src\\FileDemo01.javaF:\\java\\base.\\io\\src\\FileDemo02.javaF:\\java\\base.\\io\\src\\FileUtils.javaF:\\java\\base.\\io\\src\\IOTes02.javaF:\\java\\base.\\io\\src\\IOTes04.javaF:\\java\\base.\\io\\src\\IOTest01.javaF:\\java\\base.\\io\\src\\IOTest03.javaF:\\java\\base.\\io\\src\\listAllFiles.javaF:\\java\\base.\\io\\src\\ObjectTest.javaF:\\java\\base.\\io\\src\\Path.javaF:\\java\\base.\\io\\src\\picTest.javaF:\\java\\base.\\io\\src\\PrintTest.java 读取内容1234567891011121314151617181920212223242526272829303132import org.apache.commons.io.FileUtils;import org.apache.commons.io.LineIterator;import java.io.File;import java.io.IOException;import java.util.List;/** * commons-io * 读取内容 * @author Hongliang Zhu * @create 2020-02-18 21:47 */public class CIOTest &#123; public static void main(String[] args) throws IOException &#123; // 读取文件 String msg = FileUtils.readFileToString(new File(&quot;./io/dext.txt&quot;), &quot;UTF-8&quot;); System.out.println(msg); byte[] datas = FileUtils.readFileToByteArray(new File(&quot;./io/dext.txt&quot;)); System.out.println(datas.length); // 逐行读取 List&lt;String&gt; msgs = FileUtils.readLines(new File(&quot;./io/dext.txt&quot;),&quot;UTF-8&quot;); for(String m: msgs)&#123; System.out.println(m); &#125; LineIterator it = FileUtils.lineIterator(new File(&quot;./io/dext.txt&quot;)); while (it.hasNext())&#123; System.out.println(it.nextLine()); &#125; &#125;&#125; 写出内容123456789101112131415161718192021222324252627import org.apache.commons.io.FileUtils;import java.io.File;import java.io.IOException;import java.util.ArrayList;import java.util.List;/** * 写出内容 * @author Hongliang Zhu * @create 2020-02-19 11:27 */public class CIOtestWrite &#123; public static void main(String[] args) throws IOException &#123; // 写出文件 FileUtils.write(new File(&quot;./io/happy.txt&quot;), &quot;今天天气真好！\\r\\n&quot;, &quot;UTF-8&quot;); FileUtils.writeStringToFile(new File(&quot;./io/happy.txt&quot;), &quot;河山大好，出去走走吧！&quot;, &quot;UTF-8&quot;,true); FileUtils.writeByteArrayToFile(new File(&quot;./io/happy.txt&quot;), &quot;河山大好，出去走走吧！&quot;.getBytes(&quot;UTF-8&quot;),true); // 写出列表 List &lt;String&gt; datas = new ArrayList&lt;&gt;(); datas.add(&quot;马云&quot;); datas.add(&quot;马化腾&quot;); datas.add(&quot;李嘉诚&quot;); FileUtils.writeLines(new File(&quot;./io/happy.txt&quot;), datas, &quot;...&quot;, true); &#125;&#125; 1今天天气真好！河山大好，出去走走吧！河山大好，出去走走吧！马云...马化腾...李嘉诚... 复制文件1234567891011121314151617181920212223import org.apache.commons.io.FileUtils;import java.io.File;import java.io.IOException;import java.net.URL;/** * 拷贝文件 * @author Hongliang Zhu * @create 2020-02-19 11:37 */public class CIOCopy &#123; public static void main(String[] args) throws IOException &#123; // 复制文件 FileUtils.copyFile(new File(&quot;./io/io.png&quot;), new File(&quot;./io/cio.png&quot;)); // 拷贝文件到目录 FileUtils.copyFileToDirectory(new File(&quot;./io/io.png&quot;), new File(&quot;./io/test&quot;)); // copy URL String url = &quot;https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1582094003889&amp;di=8d3bc6164079cb45c6ba073ff143b591&amp;imgtype=0&amp;src=http%3A%2F%2Fwww.bbra.cn%2FUploadFiles%2Fimgs%2F2015%2F11%2F02%2Fmm3%2F005.jpg&quot;; FileUtils.copyURLToFile(new URL(url), new File(&quot;./io/girl.jpg&quot;)); // 可以下载一张图片 &#125;&#125; 九、 NIO新的输入/输出 (NIO) 库是在 JDK 1.4 中引入的，弥补了原来的 I/O 的不足，提供了高速的、面向块的 I/O。 1. 流与块​ I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据。 ​ 面向流的 I/O 一次处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I/O 通常相当慢。 ​ 面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性。 ​ I/O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 2. 通道与缓冲区通道通道 Channel 是对原 I/O 包中的流的模拟，可以通过它读取和写入数据。 通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。 通道包括以下类型： FileChannel：从文件中读写数据； DatagramChannel：通过 UDP 读写网络中数据； SocketChannel：通过 TCP 读写网络中数据； ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 缓冲区发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 缓冲区包括以下类型： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 2. 缓冲区状态变量 capacity：最大容量； position：当前已经读写的字节数； limit：还可以读写的字节数。 状态变量的改变过程举例： ① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。 ② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 为 5，limit 保持不变。 ③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。 ④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。 ⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置 3. 文件NIO实例12345678910111213141516171819202122232425262728293031323334353637public static void fastCopy(String src, String dist) throws IOException &#123; /* 获得源文件的输入字节流 */ FileInputStream fin = new FileInputStream(src); /* 获取输入字节流的文件通道 */ FileChannel fcin = fin.getChannel(); /* 获取目标文件的输出字节流 */ FileOutputStream fout = new FileOutputStream(dist); /* 获取输出字节流的文件通道 */ FileChannel fcout = fout.getChannel(); /* 为缓冲区分配 1024 个字节 */ ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) &#123; /* 从输入通道中读取数据到缓冲区中 */ int r = fcin.read(buffer); /* read() 返回 -1 表示 EOF */ if (r == -1) &#123; break; &#125; /* 切换读写 */ buffer.flip(); /* 把缓冲区的内容写入输出文件中 */ fcout.write(buffer); /* 清空缓冲区 */ buffer.clear(); &#125;&#125; 4. 选择器​ NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。 ​ NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 ​ 通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 ​ 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件，对于 IO 密集型的应用具有很好地性能。 ​ 应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。 创建选择器1Selector selector = Selector.open(); 将通道注册到选择器上123ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT); ​ 通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它事件，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰。 ​ 在将通道注册到选择器上时，还需要指定要注册的具体事件，主要有以下几类： SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 它们在 SelectionKey 的定义如下： 1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4; 可以看出每个事件可以被当成一个位域，从而组成事件集整数。例如： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 监听事情1int num = selector.select(); 使用 select() 来监听到达的事件，它会一直阻塞直到有至少一个事件到达。 获取到达的事件1234567891011Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove();&#125; 事件循环​ 因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。 1234567891011121314while (true) &#123; int num = selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove(); &#125;&#125; 5. 套接字NIO实例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public class NIOServer &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888); serverSocket.bind(address); while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); &#125; keyIterator.remove(); &#125; &#125; &#125; private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuilder data = new StringBuilder(); while (true) &#123; buffer.clear(); int n = sChannel.read(buffer); if (n == -1) &#123; break; &#125; buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i &lt; limit; i++) &#123; dst[i] = (char) buffer.get(i); &#125; data.append(dst); buffer.clear(); &#125; return data.toString(); &#125;&#125; 12345678910public class NIOClient &#123; public static void main(String[] args) throws IOException &#123; Socket socket = new Socket(&quot;127.0.0.1&quot;, 8888); OutputStream out = socket.getOutputStream(); String s = &quot;hello world&quot;; out.write(s.getBytes()); out.close(); &#125;&#125; 6. 内存映射文件​ 内存映射文件 I/O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I/O 快得多。 ​ 向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 ​ 下面代码行将文件的前 1024 个字节映射到内存中，map() 方法返回一个 MappedByteBuffer，它是 ByteBuffer 的子类。因此，可以像使用其他任何 ByteBuffer 一样使用新映射的缓冲区，操作系统会在需要时负责执行映射。 1MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024); 7. 对比NIO 与普通 I/O 的区别主要有以下两点： NIO 是非阻塞的； NIO 面向块，I/O 面向流。 参考 https://cyc2018.github.io/CS-Notes https://www.runoob.com/design-pattern/design-pattern-tutorial.html","path":"2020/02/17/Java之IO流/","date":"02-17","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"IO","slug":"IO","permalink":"https://castile.github.io/tags/IO/"}]},{"title":"Java之并发专题","text":"一、 进程与线程1.程序、进程、线程 程序： 程序是一段静态的代码，它是应用程序执行的蓝本 进程：进程是指一种正在运行的程序，有自己的地址空间 ​ 特点 ：动态性、并发性、独立性 线程： 进程内部的一个执行单元，它是程序中一个单一的顺序控制流程。 **如果在一个进程中同时运行了多个线程，用来完成不同的工作，则称之为多线程 **。 线程又被称为轻量级进程(lightweight process) 并发和并行的区别 ： 并行： 多个CPU同时执行多个任务 并发： 一个CPU（采用时间片）同时执行多个任务 2.进程和线程的区别 二、 使用线程有三种使用线程的方法： 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 ​ 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以理解为任务是通过线程驱动从而执行的。 实现Runnable接口1234567891011121314151617181920212223242526272829303132333435/** * @author Hongliang Zhu * @create 2020-02-13 17:02 */public class Demo2 implements Runnable &#123; @Override public void run() &#123; for(int i = 0; i &lt; 20; i++)&#123; System.out.println(&quot;学习&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; /* 使用 Runnable 实例再创建一个 Thread 实例，然后调用 Thread 实例的 start() 方法来启动线程。 */ Demo2 d2 = new Demo2(); Thread th = new Thread(d2); th.start(); // 启动线程 for(int i = 0; i &lt; 20; i++)&#123; System.out.println(&quot;听歌&quot;); Thread.sleep(1000); &#125; &#125;&#125; 继承Thread类同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 12345public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125; 1234public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 实现 Callable 接口 与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 12345public class MyCallable implements Callable&lt;Integer&gt; &#123; // 这里要通过泛型指定返回值Integer public Integer call() &#123; // 注意返回值 return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 与实现Runnable相比， Callable功能更强大些 可以有返回值，支持泛型的返回值 可以抛出异常 需要借助FutureTask，比如获取返回结果 线程池背景： 经常创建和销毁，使用量特别大的资源，比如并发情况下的线程，对性能影响很大。 思路： 提前创建好多个线程， 放入线程池当中，使用时直接获取， 用完后放回池中。可以避免频繁创建销毁、实现重复利用。类似生活中的公共交通工具。 优势： 提高反应速度（减少了创建新线程的时间） 降低资源的消耗（重复利用线程池中的线程，必须要每次都创建） 便于线程的管理。 corePoolSize : 核心池的大小 maximumPoolSize: 最大线程数 keepAliveTime: 线程没有任务时最多保持多长时间后会终止。 … 123456789// Java线程池的完整构造函数public ThreadPoolExecutor( int corePoolSize, // 线程池长期维持的线程数，即使线程处于Idle状态，也不会回收。 int maximumPoolSize, // 线程数的上限 long keepAliveTime, TimeUnit unit, // 超过corePoolSize的线程的idle时长， // 超过这个时间，多余的线程会被回收。 BlockingQueue&lt;Runnable&gt; workQueue, // 任务的排队队列 ThreadFactory threadFactory, // 新线程的产生方式 RejectedExecutionHandler handler) // 拒绝策略 12345ExecutorService service = Executors.newFixedThreadPool(10);System.out.println(service.getClass()); // class java.util.concurrent.ThreadPoolExecutorThreadPoolExecutor service1 = (ThreadPoolExecutor) Executors.newFixedThreadPool(10);service1.setCorePoolSize(15);// service1.setKeepAliveTime(); 详见[基础线程机制](#三、 基础线程机制) 参考： https://www.cnblogs.com/CarpenterLee/p/9558026.html 实现接口 VS 继承 Thread实现接口会更好一些，因为： Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 实现Runnable接口方式的多线程 优势：可以继承其它类，多线程可共享同一个Runnable对象 劣势：编程方式稍微复杂，如果需要访问当前线程，需要调用Thread.currentThread()方 法 Thread类常用方法 方法 功能 static Thread currentThread() 得到当前线程 getName( ) 返回线程的名称 setName (String name) 将线程的名称设置为由name指定的名称 int getPriority() 获得线程的优先级数值 void setPriority() 设置线程的优先级数值 void start( ) 调用run( )方法启动线程，开始线程的执行 void run( ) 存放线程体代码 isAlive() 判断线程是否还“活”着，即线程是未终止 一些多线程的例子1. 模拟龟兔赛跑12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 模拟龟兔赛跑 * @author Hongliang Zhu * @create 2020-02-13 17:18 */public class Racer implements Runnable&#123; public static String Winner; @Override public void run() &#123; for(int step = 1; step &lt;= 100; step++)&#123; // 模拟兔子每10步休息一次 if(Thread.currentThread().getName().equals(&quot;兔子&quot;) &amp;&amp; step % 10 == 0)&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; if(Thread.currentThread().getName().equals(&quot;乌龟&quot;))&#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName()+&quot;----&gt;&quot;+ step); if(isGameOver(step))&#123; break; &#125; &#125; &#125; // 判断比赛是否结束 private boolean isGameOver(int step)&#123; if(Winner != null)&#123;// System.out.println(&quot;Winner is &quot;+ Winner); return true; &#125;else if(step == 100)&#123; Winner = Thread.currentThread().getName(); System.out.println(&quot;Winner is &quot;+ Winner); return true; &#125;else &#123; return false; &#125; &#125; public static void main(String[] args) &#123; Racer racer = new Racer(); System.out.println(Thread.currentThread().getName()); // 主线程 // 创建两个线程 new Thread(racer, &quot;兔子&quot;).start(); new Thread(racer, &quot;乌龟&quot;).start(); &#125;&#125; 使用Callable接口来创建线程的方式，模拟龟兔赛跑例子 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import java.util.concurrent.*;/** * 创建线程的第三种方式 * @author Hongliang Zhu * @create 2020-02-13 17:37 */public class Racer_Call implements Callable&lt;Integer&gt; &#123; String Winner; // 胜利者 @Override public Integer call() throws Exception &#123; for(int step = 1; step &lt;= 100; step++)&#123; if(Thread.currentThread().getName().equals(&quot;pool-1-thread-1&quot;) &amp;&amp; step % 10 == 0)&#123; Thread.sleep(200); &#125; System.out.println(Thread.currentThread().getName() +&quot;====&gt;&quot;+step); if(isGameOver(step))&#123; return step; &#125; &#125; return null; &#125; private boolean isGameOver(int step)&#123; if(Winner != null)&#123;// System.out.println(&quot;Winner is &quot;+ Winner); return true; &#125;else if(step == 100)&#123; Winner = Thread.currentThread().getName(); System.out.println(&quot;Winner is &quot;+ Winner); return true; &#125;else &#123; return false; &#125; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; Racer_Call rc = new Racer_Call(); //创建执行服务 ExecutorService ex = Executors.newFixedThreadPool(2); // 线程池中两个线程 // 提交执行 Future&lt;Integer&gt; ribbits = ex.submit(rc); Future&lt;Integer&gt; turtle = ex.submit(rc); // 返回结果 int riSteps = ribbits.get(); int tu = turtle.get(); System.out.println(&quot;兔子的步数：&quot; + riSteps); System.out.println(&quot;乌龟的步数：&quot; + tu); ex.shutdownNow();// 关闭服务 &#125;&#125; 2. Web1230612345678910111213141516171819202122232425262728293031323334/** * @author Hongliang Zhu * @create 2020-02-13 17:11 */public class Web12306 implements Runnable&#123; static int tickets = 10; // 共享资源 @Override public void run() &#123; while(true)&#123; if(tickets &lt;= 0)&#123; break; &#125; System.out.println(Thread.currentThread().getName()+ &quot; ----&gt;&quot; + tickets--); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public static void main(String[] args) &#123; Web12306 w1 = new Web12306(); Web12306 w2 = new Web12306(); Web12306 w3 = new Web12306(); new Thread(w1, &quot;张三&quot;).start(); new Thread(w2, &quot;李四&quot;).start(); new Thread(w3, &quot;王五&quot;).start(); &#125;&#125; 三、 基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor： CachedThreadPool：一个任务创建一个线程； FixedThreadPool：所有任务只能使用固定大小的线程； SingleThreadExecutor：相当于大小为 1 的 FixedThreadPool。 12345678910111213141516171819202122232425import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @author Hongliang Zhu * @create 2020-02-16 17:03 */public class ExecutorTest &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); // 个任务创建一个线程； for(int i = 0; i &lt; 5; i++)&#123; executorService.execute(new MyRunnable()); &#125; executorService.shutdown(); // 关闭服务 &#125;&#125;class MyRunnable implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+ &quot;: executor test 。。。&quot;); &#125;&#125; pool-1-thread-1: executor test 。。。pool-1-thread-5: executor test 。。。pool-1-thread-4: executor test 。。。pool-1-thread-3: executor test 。。。pool-1-thread-2: executor test 。。。 Daemon 守护进程​ 守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。main() 属于非守护线程。非守护进程也说普通进程或者用户进程。 ​ 在线程启动之前使用 setDaemon() 方法可以将一个线程设置为守护线程。 1234public static void main(String[] args) &#123; Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);&#125; Java中的线程分为两类：一种是守护线程，一种是用户线程。 它们在几乎每个方面都是相同的，唯一的区别是判断JVM何时离开。 守护线程是用来服务用户线程的，通过在start()方法前调用thread.setDaemon(true)可以把一个用户线程变成一个守护线程。 Java垃圾回收就是一个典型的守护线程。 若JVM中都是守护线程，当前JVM将退出。 Threa.Sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; yield() 礼让线程对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 yield让当前正在执行线程暂停，不是阻塞线程，而是将线程转入就绪状态 如果调用了yield方法之后，没有其他等待执行的线程，这个时候当前线程就会马上恢复执行！ 1234567891011121314151617181920212223242526272829package ThreadStatus;/** * yield 礼让线程 --&gt; 高风亮节，主动让出CPU，重新回到就绪状态 直接 * @author Hongliang Zhu * @create 2020-02-13 20:31 */public class yieldDemo1&#123; public static void main(String[] args) &#123; // lambda表达式 一个线程 new Thread(()-&gt;&#123; for (int i = 0; i &lt; 100; i++)&#123; System.out.println(&quot;lambda&quot;+ i); &#125; &#125;).start(); for(int i = 0 ; i &lt; 100; i++)&#123; if(i % 10 == 0)&#123; Thread.yield(); // main 线程礼让 &#125; System.out.println(&quot;main:&quot; + i); &#125; &#125;&#125; 四、 中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException​ 通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 ​ 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 12345678910111213141516171819202122232425262728/** * @author Hongliang Zhu * @create 2020-02-16 17:18 */public class InterruptExample &#123; public static void main(String[] args) &#123; MyThread1 myThread1 = new MyThread1(); myThread1.start(); myThread1.interrupt(); // 线程中断 System.out.println(Thread.currentThread().getName()+&quot;lalla&quot;); &#125; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println(&quot;Thread run&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; interrupted()​ 如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 ​ 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 1234567891011121314151617181920212223/** * @author Hongliang Zhu * @create 2020-02-16 17:25 */public class interruptedTest &#123; public static void main(String[] args) &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt(); &#125; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // interrupted()方法会设置线程的中断标记 返回true // .. &#125; System.out.println(&quot;Thread end&quot;); &#125; &#125;&#125; Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 12345678910111213public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(2000); System.out.println(&quot;Thread run&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); executorService.shutdownNow(); System.out.println(&quot;Main run&quot;);&#125; Main run java.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at MyRunnable.run(ExecutorTest.java:25) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 五、 互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock(可重入锁)。 死锁 ： 当两个线程相互等待对方释放“锁”时就会发生死锁 出现死锁后，不会出现异常，不会出现提示，只是所有的线程都处于阻塞状态，无法继续 多线程编程时应该注意避免死锁的发生 线程同步问题的应用场景： 多个用户同时操作一个银行账户。每次取款100元，取款前先检查余额是否足够。如果不够， 放弃取款。 当多个线程访问同一个数据时，容易出现线程安全问题。需要让线程同步，保证数据安全 当两个或两个以上线程访问同一资源时，需要某种方式来确保资源在某一时刻只被一个线程 使用 看一个线程不安全的例子： 去银行取钱 会出现负数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package syn;/** * 线程不安全： 取钱 出现负数 * @author Hongliang Zhu * @create 2020-02-14 11:22 */public class UnSafeTest02 &#123; public static void main(String[] args) &#123; Account account = new Account(100, &quot;结婚礼金&quot;); DrawMoney d1 = new DrawMoney(account, 70, &quot;我&quot;); DrawMoney d2 = new DrawMoney(account, 80, &quot;老婆&quot;); d1.start(); d2.start(); &#125;&#125;class Account&#123; int money; // 金额 String name; // 名称 public Account(int money, String name) &#123; this.money = money; this.name = name; &#125;&#125;class DrawMoney extends Thread&#123; private Account account; // 操作的账户 String name; // 谁取钱 int drawingmoney; //取多少钱 int packet; // 已经取得的钱数 public DrawMoney(Account account,int m, String name) &#123; super(name); this.account = account; this.drawingmoney = m; &#125; @Override public void run() &#123; if(account.money - drawingmoney &lt; 0)&#123; return; &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; account.money -= drawingmoney; packet += drawingmoney; System.out.println(getName()+&quot;口袋里有&quot;+packet+&quot;, 账户余额为：&quot;+account.money); &#125;&#125; 我口袋里有70, 账户余额为：-50老婆口袋里有80, 账户余额为：-50 同理， 在Web12306例子中，会出现重复票的问题，以及当只剩下一张票的时候，即临界资源时，会出现负数。 线程同步的实现方案 ： 同步方法 同步代码块 synchronized 同步一个代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 1234567891011121314151617public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125;public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 12345678public static void main(String[] args) &#123; // 两个不同的对象 SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125; 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 同步一个方法 123public synchronized void func () &#123; // ...&#125; 同步一个类 123456public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; ​ 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 12345678910111213141516171819202122232425262728293031323334package syn;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @author Hongliang Zhu * @create 2020-02-16 19:37 */public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; System.out.println(); &#125; &#125; public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); //SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e1.func2()); executorService.shutdown(); &#125;&#125; 0 1 2 3 4 5 6 7 8 90 1 2 3 4 5 6 7 8 9 同步一个静态方法 123456789101112131415161718192021222324252627282930313233343536373839package syn;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * @author Hongliang Zhu * @create 2020-02-16 19:37 */public class SynchronizedExample &#123; public static synchronized void func2() &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample();// SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e1.func2()); executorService.shutdown(); &#125;&#125; 作用于整个类 0 1 2 3 4 5 6 7 8 90 1 2 3 4 5 6 7 8 9 ReentrantLock 可重入锁ReentrantLock 是 java.util.concurrent（J.U.C）包中的锁。 ​ 锁作为并发共享数据保证一致性的工具，大多数内置锁都是可重入的，也就是说如果某个线程试图获取一个已经由他自己持有的锁，那么，这个请求会立刻成功，并且将这个锁的计数器值加1。而当线程退出同步代码块时，计数器将会递减。当计数值等于零的时候，锁就会释放。如果没有可重入锁的支持，在第二次企图获得锁时将会进入死锁状态，可重入锁随处可见。 ​ synchronized的就是一个可重入锁： 1234567891011121314151617181920212223242526272829package other;/** * 可重入锁：锁可以延续使用 * @author Hongliang Zhu * @create 2020-02-16 20:15 */public class LockTest &#123; public void test()&#123; // 第一次获得锁 synchronized (this)&#123; while (true)&#123; // 第二次获得同样的锁 synchronized (this)&#123; System.out.println(&quot;可重入锁！！！&quot;); &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; new LockTest().test(); &#125;&#125; 可重入锁 ！！！ . … 下面举个例子：使用不可重入锁会导致死锁的情况，下面的代码会造成死循环 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package other;import java.security.PublicKey;/** * * 不可重入锁： 锁不可以延续使用 * @author Hongliang Zhu * @create 2020-02-16 20:21 */public class LockTest2 &#123; Lock lock = new Lock(); public void a()&#123; lock.lock(); // 获得锁 doSomething(); lock.unlock(); // 锁释放 &#125; // 不可重入 public void doSomething()&#123; lock.lock(); System.out.println(&quot;hello world&quot;); lock.unlock(); &#125; public static void main(String[] args) &#123; LockTest2 test = new LockTest2(); test.a(); test.doSomething(); &#125;&#125;class Lock&#123; //是否占用 private boolean isLocked = false; // 使用锁 public synchronized void lock()&#123; while (isLocked)&#123; // 锁被占用了之后，一直要等待锁释放之后 try &#123; wait(); // 等待线程释放锁 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; // 使用锁，占有锁 isLocked = true; &#125; // 释放锁 public synchronized void unlock()&#123; isLocked = false; // 释放 notify(); // 唤醒其他线程使用锁 &#125;&#125; 改写成可重入锁： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package other;/** * * 自己实现可重入锁： 锁可以延续使用 * @author Hongliang Zhu * @create 2020-02-16 20:21 */public class LockTest2 &#123; Lock lock = new Lock(); public void a() throws InterruptedException &#123; lock.lock(); // 获得锁 System.out.println(lock.getHoldCount()); doSomething(); lock.unlock(); // 锁释放 System.out.println(lock.getHoldCount()); &#125; // 不可重入 public void doSomething() throws InterruptedException &#123; lock.lock(); System.out.println(lock.getHoldCount()); System.out.println(&quot;hello world&quot;); lock.unlock(); System.out.println(lock.getHoldCount()); &#125; public static void main(String[] args) throws InterruptedException &#123; LockTest2 test = new LockTest2(); test.a();// test.doSomething(); Thread.sleep(1000); System.out.println(&quot;最终后的锁计数器的值为&quot;); System.out.println(test.lock.getHoldCount()); &#125;&#125;class Lock&#123; //是否占用 private boolean isLocked = false; // 如果是自己的持有锁，则可以立刻获得锁 private Thread lockedBy = null; // 存储线程 public int getHoldCount() &#123; return holdCount; &#125; // 锁的计数器 private int holdCount = 0; // 使用锁 public synchronized void lock() throws InterruptedException &#123; Thread t = Thread.currentThread(); // 当前线程 // 如果被锁了，并且持有锁的线程不等于当前线程 while (isLocked &amp;&amp; lockedBy != t)&#123; wait(); &#125; // 可以使用锁了 isLocked = true; lockedBy = t; holdCount++; // 计数器加1； &#125; // 释放锁 public synchronized void unlock()&#123; if(Thread.currentThread() == lockedBy)&#123; //当前线程等于lockedBy的时候才会释放 holdCount--; // 计数器减一 if(holdCount == 0)&#123; isLocked = false; // 释放 lockedBy = null; notify(); // 唤醒其他线程使用锁 &#125; &#125; &#125;&#125; 12hello world10最终后的锁计数器的值为0 直接用java.util.concurrent（J.U.C）包里面的类 1ReentrantLock lock = new ReentrantLock(); 将上面的代码中的 Lock lock = new Lock();改成上述代码就行了，方法都是一样的。可以运行 123456789101112131415public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125; 123456public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125; 注意：如果同步代码有异常，要将unlock()写入finally语句块 Lock和synchronized的区别 1.Lock是显式锁（手动开启和关闭锁，别忘记关闭锁），synchronized是隐式锁 2.Lock只有代码块锁，synchronized有代码块锁和方法锁 3.使用Lock锁，JVM将花费较少的时间来调度线程，性能更好。并且具有更好的扩展性（提供更多的子类） 优先使用顺序： Lock—-同步代码块（已经进入了方法体，分配了相应资源）—-同步方法（在方法体之外） 比较1. 锁的实现synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3. 等待可中断当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 4. 公平锁公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5. 锁绑定多个条件一个 ReentrantLock 可以同时绑定多个 Condition 对象 。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 同步小实例1. 快乐电影院123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package syn;/** * 快乐影院： 实现多线程买电影票 * @author Hongliang Zhu * @create 2020-02-14 17:20 */public class HappyCinema &#123; public static void main(String[] args) &#123; Cinema cinema = new Cinema(&quot;旺达&quot;, 2); new Thread(new Custom(cinema, 2), &quot;张三&quot;).start(); new Thread(new Custom(cinema, 1), &quot;李四&quot;).start(); &#125;&#125;class Custom implements Runnable&#123; Cinema cinema; // 去哪个影院看电影 int seats; // 要买多少张票 public Custom(Cinema cinema, int seats) &#123; this.cinema = cinema; this.seats = seats; &#125; @Override public void run() &#123; synchronized (cinema)&#123; if(cinema.bookTickets(seats))&#123; System.out.println(&quot;购票成功，&quot;+ Thread.currentThread().getName()+&quot;的位置为：==&gt;&quot;+seats ); &#125;else&#123; System.out.println(&quot;票不够， 购票失败&quot;); &#125; &#125; &#125;&#125;class Cinema&#123; String name; int totalSeats; // 有多少座位 public Cinema(String name, int totalSeats) &#123; this.name = name; this.totalSeats = totalSeats; &#125; public boolean bookTickets(int nums)&#123; System.out.println(&quot;当前电影院有&quot;+totalSeats+&quot;张票.&quot;); if(nums &gt; totalSeats)&#123; return false; &#125;else&#123; totalSeats-=nums; return true; &#125; &#125;&#125; 当前电影院有2张票.购票成功，张三的位置为：==&gt;2当前电影院有0张票.票不够， 购票失败 2.高级功能：快乐电影院-支持在线选座1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package syn;import java.util.ArrayList;import java.util.List;/** * 快乐影院： 实现多线程买电影票 支持选座 * @author Hongliang Zhu * @create 2020-02-14 17:20 */public class HappyMovie &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; NumsSeats = new ArrayList&lt;&gt;(); NumsSeats.add(1); NumsSeats.add(2); NumsSeats.add(3); NumsSeats.add(4); NumsSeats.add(5); NumsSeats.add(6); List&lt;Integer&gt; seat1 = new ArrayList&lt;&gt;(); seat1.add(1); seat1.add(4); seat1.add(6); List&lt;Integer&gt; seat2 = new ArrayList&lt;&gt;(); seat2.add(3); seat2.add(6); ZZCinema cinema = new ZZCinema(&quot;旺达&quot;, NumsSeats); new Thread(new HappyCustom(cinema, seat1), &quot;张三&quot;).start(); new Thread(new HappyCustom(cinema, seat2), &quot;李四&quot;).start(); &#125;&#125;class HappyCustom implements Runnable&#123; ZZCinema cinema; // 去哪个影院看电影 List&lt;Integer&gt; seats; // 要买多少张票 public HappyCustom(ZZCinema cinema, List&lt;Integer&gt; seats) &#123; this.cinema = cinema; this.seats = seats; &#125; @Override public void run() &#123; synchronized (cinema)&#123; if(cinema.bookTickets(seats))&#123; System.out.println(&quot;购票成功，&quot;+ Thread.currentThread().getName()+&quot;的位置为：==&gt;&quot;+seats ); &#125;else&#123; System.out.println(&quot;票不够，&quot;+Thread.currentThread().getName()+&quot; 购票失败&quot;); &#125; &#125; &#125;&#125;class ZZCinema&#123; String name; List&lt;Integer&gt; totalSeats; // 有多少座位 public ZZCinema(String name, List&lt;Integer&gt; totalSeats) &#123; this.name = name; this.totalSeats = totalSeats; &#125; public boolean bookTickets(List&lt;Integer&gt; seats)&#123; System.out.println(&quot;欢迎光临&quot;+ this.name +&quot;当前电影院有&quot;+totalSeats+&quot;.&quot;); if(seats.size() &gt; totalSeats.size())&#123; return false; &#125; List&lt;Integer&gt; copy = new ArrayList&lt;&gt;(); copy.addAll(totalSeats); copy.removeAll(seats); if(totalSeats.size() - copy.size() != seats.size())&#123; return false; // 出票失败 &#125; // 成功 totalSeats = copy; return true; &#125;&#125; 欢迎光临旺达当前电影院有[1, 2, 3, 4, 5, 6].购票成功，张三的位置为：==&gt;[1, 4, 6]欢迎光临旺达当前电影院有[2, 3, 5].票不够，李四 购票失败 3. 快乐12306注意和快乐电影院的实现方法，有所不同。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384package syn;import java.util.ArrayList;import java.util.List;/** * * 快乐火车票 * * @author Hongliang Zhu * @create 2020-02-14 18:53 */public class Happy12306 &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; NumsSeats = new ArrayList&lt;&gt;(); NumsSeats.add(1); NumsSeats.add(2); NumsSeats.add(3); NumsSeats.add(4); NumsSeats.add(5); NumsSeats.add(6); List&lt;Integer&gt; seat1 = new ArrayList&lt;&gt;(); seat1.add(1); seat1.add(4); seat1.add(6); List&lt;Integer&gt; seat2 = new ArrayList&lt;&gt;(); seat2.add(3); seat2.add(5); Web12306 w = new Web12306(NumsSeats, &quot;12306赣州站&quot;); new Passenger(w,seat1, &quot;张三&quot;).start(); new Passenger(w, seat2, &quot;李四&quot;).start(); &#125;&#125;class Passenger extends Thread&#123; List&lt;Integer&gt; seats; // 要买多少张票 String name; // 名字 public Passenger(Runnable target, List&lt;Integer&gt; seats, String name) &#123; // 传入target super(target, name); this.seats = seats; &#125;&#125;class Web12306 implements Runnable&#123; List&lt;Integer&gt; tickets; String name; public Web12306(List&lt;Integer&gt; tickets, String name) &#123; this.tickets = tickets; this.name = name; &#125; @Override public void run() &#123; Passenger p = (Passenger)Thread.currentThread(); // 当前乘客 if(bookTickets(p.seats))&#123; System.out.println(&quot;购票成功，&quot;+ Thread.currentThread().getName()+&quot;的位置为：==&gt;&quot;+p.seats ); &#125;else&#123; System.out.println(&quot;票不够，&quot;+Thread.currentThread().getName()+&quot; 购票失败&quot;); &#125; &#125; public synchronized boolean bookTickets(List&lt;Integer&gt; seats)&#123; // 同步方法 System.out.println(&quot;欢迎光临&quot;+ this.name +&quot;当前有&quot;+tickets+&quot;.&quot;); if(seats.size() &gt; tickets.size())&#123; return false; &#125; List&lt;Integer&gt; copy = new ArrayList&lt;&gt;(); copy.addAll(tickets); copy.removeAll(seats); if(tickets.size() - copy.size() != seats.size())&#123; return false; // 出票失败 &#125; // 成功 tickets = copy; return true; &#125;&#125; 欢迎光临12306赣州站当前有[1, 2, 3, 4, 5, 6].购票成功，张三的位置为：== &gt;[1, 4, 6]欢迎光临12306赣州站当前有[2, 3, 5].购票成功，李四的位置为：== &gt;[3, 5] 总结释放锁的操作： 当前线程的同步方法、同步代码块执行结束 当前线程在同步代码块、同步方法中遇到break、return终止了该代码块、该方法的继续执行。 当前线程在同步代码块、同步方法中出现了未处理的Error或Exception，导致异常结束 当前线程在同步代码块、同步方法中执行了锁对象的**wait()**方法，当前线程暂停，并释放锁。 不会释放锁的操作： 线程执行同步代码块或同步方法时，程序调用Thread.sleep()、Thread.yield()方法暂停当前线程的执行 线程执行同步代码块时，其他线程调用了该线程的suspend()方法将该线程挂起，该线程不会释放锁（同步监视器）。 ​ ==&gt; 应尽量避免使用suspend()和resume()来控制线程(这两个方法以及过时了! ) 七、 线程状态一个线程只能处于一种状态，并且这里的线程状态特指 Java 虚拟机的线程状态，不能反映线程在特定操作系统下的状态 。 新建（NEW）创建后尚未启动。 可运行（RUNABLE）正在 Java 虚拟机中运行。但是在操作系统层面，它可能处于运行状态，也可能等待资源调度（例如处理器资源），资源调度完成就进入运行状态。所以该状态的可运行是指可以被运行，具体有没有运行要看底层操作系统的资源调度。 阻塞（BLOCKED）请求获取 monitor lock （监视器）从而进入 synchronized 函数或者代码块，但是其它线程已经占用了该 monitor lock，所以处于阻塞状态。要结束该状态进入从而 RUNABLE 需要其他线程释放 monitor lock。 无限期等待（WAITING）等待其它线程显式地唤醒。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取 monitor lock。而等待是主动的，通过调用 Object.wait() 等方法进入。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() / Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 LockSupport.unpark(Thread) 限期等待（TIME_WAITING)无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 / Object.notify() / Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 / 被调用的线程执行完毕 LockSupport.parkNanos() 方法 LockSupport.unpark(Thread) LockSupport.parkUntil() 方法 LockSupport.unpark(Thread) 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 死亡（TERMINATED）可以是线程结束任务之后自己结束，或者产生了异常而结束。 Java SE 9 Enum Thread.State 八、线程的生命周期 九、线程之间的协作/通信当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 Join-插队在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 123456789101112131415161718192021222324252627282930313233package ThreadStatus;/** * join: 合并线程， 插队线程，注意谁被阻塞了 * @author Hongliang Zhu * @create 2020-02-13 20:55 */public class BlockedJoin implements Runnable&#123; @Override public void run() &#123; for(int i = 0; i&lt; 100; i++)&#123; System.out.println(&quot;线程&quot;+i); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; BlockedJoin t = new BlockedJoin(); Thread th = new Thread(t); th.start(); for(int i = 0; i &lt; 60; i++)&#123; if( i == 40)&#123; th.join(); // 必须当th线程执行完之后，main线程才会执行 main被阻塞！ &#125; System.out.println(&quot;main:&quot;+i); &#125; &#125;&#125; wait() 与 notify() 和 notifyAll()它们都属于 Object 的一部分，而不属于 Thread。 Java.lang.Object提供的这三个方法只有在synchronized方法或synchronized代码块中才能使用，否则会报java.lang.IllegalMonitorStateException异常。 1. wait() 方法​ wait()令当前线程挂起并放弃CPU、同步资源，使别的线程可访问并修改共享资源，而当前线程排队等候再次对资源的访问。调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 ​ 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 12345678910111213141516public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println(&quot;before&quot;); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;after&quot;); &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 2. notify()方法​ 唤醒正在排队等待同步资源的线程中优先级最高者结束等待。 3. notifyAll() 方法​ 唤醒正在排队等待资源的所有线程结束等待 。 await() signal() signalAll()​ java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。 ​ 相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 ​ 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package cooperation;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @author Hongliang Zhu * @create 2020-02-16 21:55 */public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println(&quot;before&quot;); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println(&quot;after&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before()); &#125;&#125; 12beforeafter 线程通信：生产者消费者模式​ 生产者(Productor)将产品交给店员(Clerk)，而消费者(Customer)从店员处取走产品，店员一次只能持有固定数量的产品(比如:20），如果生产者试图生产更多的产品，店员会叫生产者停一下，如果店中有空位放产品了再通知生产者继续生产；如果店中没有产品了，店员会告诉消费者等一下，如果店中有产品了再通知消费者来取走产品。 这里可能出现两个问题： 生产者比消费者快时，消费者会漏掉一些数据没有取到。 消费者比生产者快时，消费者会取相同的数据。 以一个例子来理解：生产馒头 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123package cooperation;/** * * 生产者和消费者问题： 管程法 * * @author Hongliang Zhu * @create 2020-02-15 12:21 */public class CoTest &#123; public static void main(String[] args) &#123; Buffer b = new Buffer(); // 缓存区 Product p = new Product(b); Consumer c = new Consumer(b); p.start(); c.start(); &#125;&#125;// 生产者class Product extends Thread&#123; Buffer buffer; int i = 1; public Product(Buffer buffer) &#123; this.buffer = buffer; &#125; @Override public void run() &#123; for(int i = 0; i &lt; 30 ; i++)&#123; buffer.push(new ManTou(i)); System.out.println(&quot;生产者生产了&quot;+i+&quot;号馒头， 当前共有馒头&quot;+ buffer.getNum() +&quot; 个&quot;); try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;// 缓存区class Buffer&#123; private static int max_szie = 10; // 大小 public static int getNum() &#123; return num; &#125; private static int num; private ManTou[] man = new ManTou[max_szie]; // 生产 public synchronized void push( ManTou manTou)&#123; if(num &gt;= max_szie)&#123; // 不用生产了 try &#123; this.wait(); // 缓存区满了， 生产者等待消费者消费，当消费者唤醒生产者时继续生产 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else &#123; man[num] = manTou; num++; this.notifyAll(); // 唤醒消费者来消费了 &#125; &#125; // 取走馒头 public synchronized ManTou pop()&#123; if(num &lt;= 0)&#123; // 没有馒头 try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; num--; this.notifyAll(); // 唤醒生产者该生产了 return man[num]; &#125;&#125;// 消费者class Consumer extends Thread&#123; Buffer buffer; public Consumer(Buffer buffer) &#123; this.buffer = buffer; &#125; public void run()&#123; while (true)&#123; if(buffer.getNum() == 0) break; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; ManTou m = buffer.pop(); System.out.println(&quot;消费者消费了一个&quot;+m.getId()+&quot;馒头， 当前共有馒头&quot;+ buffer.getNum() +&quot; 个&quot;); &#125; &#125;&#125;// 馒头class ManTou&#123; public int getId() &#123; return id; &#125; private int id; // 馒头的编号 public ManTou(int id) &#123; this.id = id; &#125;&#125; 生产者生产了0号馒头， 当前共有馒头1 个生产者生产了1号馒头， 当前共有馒头2 个生产者生产了2号馒头， 当前共有馒头3 个消费者消费了一个2馒头， 当前共有馒头2 个生产者生产了3号馒头， 当前共有馒头3 个生产者生产了4号馒头， 当前共有馒头4 个消费者消费了一个4馒头， 当前共有馒头3 个生产者生产了5号馒头， 当前共有馒头4 个生产者生产了6号馒头， 当前共有馒头5 个生产者生产了7号馒头， 当前共有馒头6 个消费者消费了一个7馒头， 当前共有馒头5 个生产者生产了8号馒头， 当前共有馒头6 个生产者生产了9号馒头， 当前共有馒头7 个消费者消费了一个9馒头， 当前共有馒头6 个生产者生产了10号馒头， 当前共有馒头7 个生产者生产了11号馒头， 当前共有馒头8 个生产者生产了12号馒头， 当前共有馒头9 个 … 参考 https://cyc2018.github.io/CS-Notes BruceEckel. Java 编程思想: 第 4 版 [M]. 机械工业出版社, 2007. 周志明. 深入理解 Java 虚拟机 [M]. 机械工业出版社, 2011.","path":"2020/02/16/Java之并发专题/","date":"02-16","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"线程","slug":"线程","permalink":"https://castile.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"leetcode-779-第k个语法符号","text":"描述 leetcode： 779 第K个语法符号 在第一行我们写上一个 0。接下来的每一行，将前一行中的0替换为01，1替换为10。 给定行数 N 和序数 K，返回第 N 行中第 K个字符。（K从1开始） 例子: 输入: N = 1, K = 1输出: 0 输入: N = 2, K = 1输出: 0 输入: N = 2, K = 2输出: 1 输入: N = 4, K = 5输出: 1 解释:第一行: 0第二行: 01第三行: 0110第四行: 01101001 链接：https://leetcode-cn.com/problems/k-th-symbol-in-grammar 分析既然每一行都是根据上一行来生成的，把这样的上下两行写成比特形式找一下规律。 如果当前行为 &quot;0110&quot;，由此生成的下一行为 &quot;01101001&quot;。 据此可以总结出规律，第 K 个数字是上一行第 (K+1) / 2 个数字生成的。如果上一行的数字为 0，被生成的数字为 1 - (K%2)，如果上一行的数字为 1，被生成的数字为 K%2。 如果k是偶数，表明是右子树，奇数为左子树。 还有其他方法，见官方题解： https://leetcode-cn.com/problems/k-th-symbol-in-grammar/solution/di-kge-yu-fa-fu-hao-by-leetcode/ 代码github： https://github.com/Castile/algorithm/blob/master/leetcode/src/RecurrenceAndDynamicProgramming/leetcode799_kthGrammar.java 123456789101112131415161718192021222324252627package RecurrenceAndDynamicProgramming;/** * @author Hongliang Zhu * @create 2020-02-16 14:22 *//*在第一行我们写上一个 0。接下来的每一行，将前一行中的0替换为01，1替换为10。给定行数 N 和序数 K，返回第 N 行中第 K个字符。（K从1开始） */public class leetcode799_kthGrammar &#123; public int kthGrammar(int N, int K) &#123; if(N==1) return 0; int ans = kthGrammar(N-1, (K+1)&gt;&gt;1); if(ans==1) &#123; return K%2==0?0:1; &#125; else &#123; return K%2==0?1:0; &#125; &#125;&#125;","path":"2020/02/16/leetcode-779-第k个语法符号/","date":"02-16","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-21-合并两个有序的链表","text":"​ 描述 Leetcode-21： 合并两个有序的链表 将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4链接：https://leetcode-cn.com/problems/merge-two-sorted-lists 分析 迭代：这题目是简单题，其实就是归并排序中的归并操作。不再赘述。 递归： ​ 终止条件：两条链表分别名为 l1 和 l2，当 l1 为空或 l2 为空时结束 ​ 返回值：每一层调用都返回排序好的链表头​ 本级递归内容：如果 l1 的 val 值更小，则将 l1.next 与排序好的链表头相接，l2 同理 时间复杂度： O(n+m) 空间复杂度：O(n+m) 代码github： https://github.com/Castile/algorithm/blob/master/leetcode/src/LinkedList/Leetcode21_MergeLinkedList.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647class Solution &#123; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; ListNode dummy= new ListNode(-1); ListNode list = dummy; ListNode p1 = l1; ListNode p2 = l2; while(p1 != null &amp;&amp; p2 != null)&#123; if(p1.val &gt; p2.val)&#123; list.next = p2; p2 = p2.next; &#125;else &#123; list.next = p1; p1 = p1.next; &#125; list = list.next; &#125; //处理p1 if(p1 != null)&#123; list.next = p1; &#125; if(p2 != null)&#123; list.next = p2; &#125; return dummy.next; &#125; // 递归 public ListNode mergeTwoLists_Cur(ListNode l1, ListNode l2) &#123; if(l1 == null) return l2; if(l2 == null) return l1; if(l1.val &gt; l2.val)&#123; l2.next = mergeTwoLists_Cur(l1, l2.next); return l2; &#125;else&#123; l1.next = mergeTwoLists_Cur(l1.next, l2); return l1; &#125; &#125;&#125;","path":"2020/02/16/leetcode-21-合并两个有序的链表/","date":"02-16","excerpt":"","tags":[{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"链表","slug":"链表","permalink":"https://castile.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"开源数据集","text":"开源数据集[toc] Images Analysis 数据集 介绍 备注 网址 Flickr30k 图片描述 31,783 images，每张图片5个语句标注 链接 Microsoft COCO 图片描述 330,000 images,每张图片至少5个语句标注 链接 ESP Game 多标签定义图像 20,770 images，268 tags，诸如bed, light man,music 链接 IAPRTC-12 多标签定义图像 19,452 images,291 tags 链接 NUS-WIDE 多标签定义图像 269,648 images,several tags (2-5 on average) per image 链接 CUHK-PEDES 以文搜图 34,054 images，每张图片2条描述 链接 VRD 视觉关系检测 5,000 images, 100目录，37,993对关系 链接 sVG 视觉关系检测 108,000 images, 998,000对关系 链接 Visual Genome Dataset 图像属性检测 108,077 images, 5.4 M 区域块，2.8 M 属性，2.3 M 关系 链接 VQA 问答系统 1,105,904问题，11,059,040 回答 链接 Visual7W 问答系统 327,939 问答对 链接 TID2013 图像质量评价 25张参考图像，24个失真类型 链接 CSIQ 图像质量评价 30张参考图像，6个失真类型 链接 LIVE 图像质量评价 29张参考图像，5个失真类型 链接 WATERLOO 图像质量评价 4744张参考图像，20个失真类型 链接 photo.net 图像美观评价 20,278张图像，打分[0,10] 链接 DPChallenge.com 图像美观评价 16,509张图像，打分[0,10] 链接 CUHK 图像美观评价 28,410张图像，只分高质量和低质量 链接 AVA 图像美观评价 255,500张图像，打分[0,10] 链接 top Image Motion &amp; Tracking 数据集 介绍 备注 网址 CUHK03 Person re-identification(人重识别) image num:13164 person num:1360 camera num:10( 5 pairs) 链接 CUHK02 Person re-identification(人重识别) image num:7264 person num:1816 camera num:10( 5 pairs) 链接 CUHK01 Person re-identification(人重识别) image num:3884 person num:971 camera num: 2 链接 VIPeR Person re-identification(人重识别) image num:1264 person num:632 camera num:2 链接 ETH1,2,3 Person re-identification(人重识别) image num:8580 person num:83,35,28 camera num:1 链接 PRID2011 Person re-identification(人重识别) image num:24541 person num:934 camera num:2 链接 MARS Person re-identification(人重识别) image num:11910031 person num:1261 camera num:6 链接 Market1501 Person re-identification(人重识别) image num:32217 person num:1501 camera num:6 链接 Epic Fail (EF) dataset Risk Assessment(风险评估) video num:3000 链接 Street Accident (SA) dataset Risk Assessment(风险评估) video num:1733 链接 OTB-50 visual tracking(跟踪) video num:50 链接 OTB-100 visual tracking(跟踪) video num:100 链接 VOT2015 visual tracking(跟踪) video num:60 链接 ALOV300 visual tracking(跟踪) video num:314 链接 MOT visual tracking(跟踪) video num:train:11 test:11 链接 THUMOS Temporal action localization(动作定位) video num:3K activities class:20 instances:3K 链接 ActivityNet Temporal action localization(动作定位) video num:20k activities class:200 instances:7.6K 链接 Mexaction2 Temporal action localization(动作定位) activities class:2 instances:1975 链接 FlyingChairs dataset optical flow(光流) image pairs：22k 链接 FlyingThings3D optical flow(光流) image pairs：22k 链接 KITTI benchmark suite optical flow(光流) image pairs：1600 链接 MPI Sintel optical flow(光流) image pairs：1064 链接 Video Analysis &amp; Scene Understanding 数据集 介绍 备注 网址 UCF101 动作行为识别 13320 video,101类动作，主要是五大类：1)人-物交互；2)肢体运动；3)人-人交互；4)弹奏乐器；5)运动 链接 HMDB51 动作行为识别 7000 videos,51类，包括人脸表情动作，身体动作，人与人交互等 链接 Moments-in-Time 动作行为识别 1,000,000 videos,339类 链接 ActivityNet 1.3 动作行为识别 20,000 videos,200类 链接 Kinetics 动作行为识别 300,000 videos，400类 链接 AVA 动作行为识别 57,600 videos，80类 链接 Collective Activity Dataset 群体活动行为识别 44 videos,穿叉、行走、等待、交谈和排队 五类 链接 Choi’s New Dataset 群体活动行为识别 32 videos，聚会，谈话，分开，一起走，追逐和排队 六类 None ActivityNet 1.3 检测动作事件的起始时间和终止时间 20,000 videos,200类动作的起始时间和终止时间 链接 THUMOS 检测动作事件的起始时间和终止时间 15,000 videos，101类动作的起始时间和终止时间 链接 MED 事件检测 32,744 videos,20个事件 链接 EventNet 事件检测 90,000 videos，500个事件 链接 Columbia Consumer Video 事件检测 9,317 videos，20个事件 链接 ADE20K 事件检测 20,210 videos，900个事件 链接 DAVIS 视频主物体分割 50 videos，分割标注 链接 FBMS 视频主物体分割 59 videos，分割标注 链接 IJB-C 视频人脸识别 11,000 videos， 链接 YouTube Faces 视频人脸识别 3,425 videos，1595 人 链接 MS-Celeb-1M 视频人脸识别 1,000,000 images，21,000人 链接 MSVD 视频描述 1,970 videos 链接 MSR-VTT-10K 视频描述 10，000 videos 链接 MSR-VTT-10K 视频描述 无 链接 top 3D Computer Vision 数据集 介绍 备注 网址 photoface database 基于光度立体视觉的二维和三维人脸识别数据库 总共7356张图像，包含1839个session和261个subjects None NYU Depth V2 dataset 关于RGBD 图像场景理解的数据库 提供1449张深度图片和他们的密集2d点类标注 链接 SUN RGBD dataset 是上面的NYU Depth V2 dataset的超集，多了3D bounding boxes和room layouts的标注。 有10,000张RGB-D图片，有58,657个3D包围框和146,617 个2d包围框。 链接 PASCAL3D+ 新的三维物体检测和姿态估计数据集，从PASCAL VOC 演化而来，包含图像，注解，和3D CAD模型 总共12个类，平均每个类别有3000多个实例 链接 IKEA 包含典型室内场景的三维模型的数据库，例如桌子椅子等 包含大约759张图片和219个3D模型 链接 New Tsukuba Dataset 包含了很多立体物体对的数据库，用于立体物体匹配 总共1800个立体物体对，以及每立体对的立体视差图、遮挡图和不连续图 链接 Oxford RobotCar Dataset 关于户外自动驾驶的数据集。 包含在驾驶汽车过程从6个摄像头收集的2000w张图片，和当时的激光雷达，GPS和地面实况标注。 链接 Middlebury V3 包含高分辨率物体立体视差标注的数据库 包含33个类，没有明说每类有多少数据 链接 ShapeNet 包含3D模型，和3d模型的类别标注的数据集，覆盖了常用的3D数据集PASCAL 3D+。 它涵盖55个常见的对象类别，有大约51,300个3D模型 链接 MICC dataset 包含了3D人脸扫描和在不同分辨率，条件和缩放级别下的几个视频序列的数据库。 有53个人的立体人脸数据 链接 CMU MoCap Dataset 包含了3D人体关键点标注和骨架移动标注的数据集。 有6个类别和23个子类别，总共2605个数据。 链接 DTU dataset 关于3D场景的数据集。 有124个场景，每场景有49/64个位置的RGB图像和结构光标注。 链接 top Analyzing Humans in Images 数据集 介绍 备注 网址 MSR-Action3D 包含深度的动作识别数据集， 有20个动作，总共557个序列。 链接 Florence-3D 包含深度的动作识别数据集， 有9个动作，总共215个动作序列。 链接 Berkeley MHAD 包含深度的动作识别数据集， 有11个动作，产生660个动作序列。 链接 Online Action Detection 包含深度的动作识别数据集， 数据集包含59个长序列，包含10种不同的日常生活行为。 链接 ChaLearn LAP IsoGD Dataset RGB-D图像的手势识别的数据集。 包括47933个RGB-D手势视频，有249个手势标签。Training有35878视频，Validation有5784个，test有6271个 链接 MAFA dataset 关于面部遮挡问题的数据集 有30, 811张人脸和35806张有遮挡的脸组成。 链接 MSRC-12 Kinect Gesture Dataset 手势识别数据集 有4900张图片，包含12个不同手势， 链接 2013 Chalearn Gesture Challenge dataset 手势识别数据集 有11000张图片，包含20个不同手势， 链接 WIDER FACE 人脸检测数据集 有 32,203 张图片，标注了393703个人脸。 链接 FDDB 人脸检测数据集 2845张图片，标注了5171张人脸。 链接 300-VW dataset 面部表情数据集 包含114个视频和总计218,595帧。 链接 HMDB51 人类行为识别的数据集 包含51个动作，总共有6766个视频剪辑 链接 MPII Cooking Activities Dataset 人类行为识别的数据集 包含65个动作，有5609个视频 链接 UCF101 人类行为识别的数据集 包含101个动作，有13320个视频 链接 IJB-A dataset 包含视频和图片人脸识别的数据集 包含5712个图像和2085个视频 链接 YouTube celebrities 视频人脸识别的数据集 包含47位名人的1910个视频 链接 COX 视频人脸识别的数据集 包含1000个主题的4000个视频 链接 Human3.6M 人体姿态估计的数据集 360万张3D照片，11名受试者在4个视点下执行15个了不同的动作 链接 iLIDS 行人重识别的数据集 476 张图像，包含119个人 链接 VIPeR 行人重识别的数据集 632个行人图片对（由两个相机拍摄） 链接 CUHK01 行人重识别的数据集 包含971行人, 3884张图片 链接 CUHK03 行人重识别的数据集 包含1360行人, 13164张图片 链接 RWTH-PHOENIX-Weather multi-signer 2014 手语识别的数据集 包含了5672个德语手语的句子，有65,227个手语姿势和799,006帧 链接 AFLW 人类面部关键点的数据集 总共约有25k张脸，每幅图像标注了大约21个位置。 链接 CMU mocap database 动作识别的数据集 2235个数据，包含144个不同的动作。 链接 Georgia Tech (GT) database 人脸识别数据库 50个人每人15张人脸。 链接 ORL 人脸识别数据库 40个人每个人10张图。 链接 top Application 数据集 介绍 备注 网址 DogCentric Activity Dataset 第一视角的狗和人之间的相互行为的数据集（视频） 总共有10类，具体数据量没有明说，y是动作类别 链接 JPL First-Person Interaction Dataset 第一视角观察动作的数据集 57个视频，8个大类，y是动作类别 链接 NUS-WIDE 关于图像文本匹配的数据集 269,648个图像和对应的标签 链接 LabelMe Dataset 关于图像文本匹配的数据集 3825个图像和对应标签 链接 Pascal Dataset 关于图像文本匹配的数据集 5011张训练图像和4952张测试图像 ) ICDAR 2015 关于文本检测的数据集 1500张训练，1000张测试，y为四边形的四个顶点。 链接 COCO-Text 关于文本检测的数据集 63686张图片，其中43686张被选为训练集，剩下的2万用于测试。 链接 MSRA-TD500 关于文本检测的数据集 300个训练，200个测试图像 链接 Microsoft 7-Scenes Dataset 室内人体运动的数据集 有7种不同室内环境，每包含500-1000张图像视频序列。 链接 Oxford RobotCar 户外自动驾驶数据集 包含图像，激光扫描结果和GPS数据。 链接 top Low- &amp; Mid-Level Vision 数据集 介绍 备注 网址 Deep Video Deblurring for Hand-held Cameras video/image deblurring(图像去模糊) video num:71 video time: 3-5s blurry and sharp pair image num:6708 链接 GOPRO dataset video/image deblurring(图像去模糊) blurry and sharp pair image num:3214 train num:2103 test num:1111 链接 BSD68 image restoration(图像修复)/高斯降噪 image num:68 链接 BSD100 “image restoration(图像修复)super resolution超分辨率重建” image num:100 链接 Set5 “image restoration(图像修复)super resolution超分辨率重建” image num:5 链接 Set14 “image restoration(图像修复)super resolution超分辨率重建” image num:14 链接 Urban100 “image restoration(图像修复)super resolution超分辨率重建” image num:100 链接 NYU v2 dataset “image restoration(图像修复)depth super resolution深度超分辨率重建” image num:1449 链接 Middlebury dataset “image restoration(图像修复)depth super resolution深度超分辨率重建” image pair num: 33 链接 alpha matting benchmark Natural image matting(抠图) “train num:27,test num:8” 链接 real image benchmark Natural image matting(抠图) “train num:49300,test num:1000” 链接 MSRA10K/MSRA-B Image saliency detection(显著性区域检测) image num(MSRA10K):10000 image num(MSRA-B):5000 链接 ECSSD Image saliency detection(显著性区域检测) image num:1000 链接 DUT-OMRON Image saliency detection(显著性区域检测) image num:5168 链接 PASCAL-S Image saliency detection(显著性区域检测) image num:850 链接 HKU-IS Image saliency detection(显著性区域检测) image num:4447 链接 SOD Image saliency detection(显著性区域检测) image num:300 链接 Describable Textures Dataset texture synthesis(纹理合成) image num:5640 category num:47 split train:val:test = 1:1:1 链接 CVPPP leaf segmentation Instance segmentation(样例分割) image num: 161 train num: 128 test num: 33 链接 KITTI car segmentation Instance segmentation(样例分割) image num: 3976 train num: 3712 test num: 144 val:120 链接 Cityscapes Instance segmentation(样例分割) image num: 5000 train num: 2975 test num: 1525 val:500 链接 SYMMAX Symmetry Detection(对称性检测) image num: train:200 test:100 链接 WHSYMMAX Symmetry Detection(对称性检测) image num: train:228 test:100 object num: 1 链接 SK506 Symmetry Detection(对称性检测) image num: train:300 test:206 object num: 16 链接 Sym-PASCAL Symmetry Detection(对称性检测) image num: train:648 test:787 object num: 14 链接 Color Checker Dataset Color constancy(颜色恒定) image num: 568 链接 NUS 8-Camera Dataset Color constancy(颜色恒定) image num: 1736 链接 top Text 数据集 介绍 备注 网址 Stanford Sentiment Treebank 文本情感分析 11855个句子划分为239231个短语，每个短语有个概率值，越小越负面，越大越正面 链接 IMDB 文本情感分析 100,000句子，正面负面两类 链接 Yelp 文本情感分析 无 链接 Multi-Domain Sentiment Dataset(Amazon product) 文本情感分析 100,000+句子，正面负面2类或强正面、弱正面、中立、弱负面、强负面5类 链接 SemEval 文本情感分析 20,632句子，三类（正面、负面、中立） 链接 Sentiment140(STS) 文本情感分析 1,600,000句子,三类（正面、负面、中立） 链接 top","path":"2020/02/13/开源数据集/","date":"02-13","excerpt":"","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://castile.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"数据集","slug":"数据集","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"}]},{"title":"Java中的Pair","text":"Java 中的Pair​ Pair（配对）： 当一个函数返回两个值并且两个值都有重要意义时我们一般会用Map的key和value来表达，但是这样的话就需要两个键值对，用Map映射去做处理时，此时的key相当于value的一个描述或者引用，而具体的信息都保存在value中，我们可以通过key去获取对应的value。但是当key和value都保存具体信息时，我们就需要用到Pair对了。Pair对也是键值对的形式。 ​ 实际上Pair保存的应该说是一个信息对，两个信息都是我们需要的，没有key和value之分。 实现​ 在javax.util包下，有一个简单Pair类可以直接调用，用法是直接通过构造函数将所吸引类型的Key和value存入，这个key和value没有任何的对应关系类型。 123456789101112131415161718import javafx.util.Pair;/** * @author Hongliang Zhu * @create 2020-02-12 13:02 */public class pair &#123; public static void main(String[] args) &#123; Pair&lt;Integer, String&gt; p = new Pair&lt;&gt;(1, &quot;zhuhongliang&quot;); // 要传入对应的值 System.out.println(p.getKey()); System.out.println(p.getValue()); Pair&lt;String, String&gt; p2 = new Pair&lt;&gt;(&quot;Tony&quot;, &quot;Jane&quot;); System.out.println(p2.getKey()); System.out.println(p2.getValue()); &#125;&#125; 1zhuhongliangTonyJane 这种Pair的返回对一个函数返回两个都有意义的值有特别用处。","path":"2020/02/12/Java中的Pair/","date":"02-12","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"}]},{"title":"leetcode-50-幂函数","text":"描述leetcode-50 Pow(x, n) 实现 pow(x, n) ，即计算 x 的 n 次幂函数。 示例 1: 输入: 2.00000, 10输出: 1024.00000示例 2: 输入: 2.10000, 3输出: 9.26100示例 3: 输入: 2.00000, -2输出: 0.25000解释: 2-2 = 1/22 = 1/4 = 0.25说明: -100.0 &lt; x &lt; 100.0n 是 32 位有符号整数，其数值范围是 [−231, 231 − 1] 。 链接：https://leetcode-cn.com/problems/powx-n 分析 暴力求解： 这个会超时，这里要处理一下n小于0的情况， 当n小于0的时候，将x变成1/x， n = -n； 快速幂： https://blog.csdn.net/qq_19782019/article/details/85621386 ​ 快速幂算法能帮我们算出指数非常大的幂，传统的求幂算法之所以时间复杂度非常高（为O(指数n)），就是因为当指数n非常大的时候，需要执行的循环操作次数也非常大。所以我们快速幂算法的核心思想就是每一步都把指数分成两半，而相应的底数做平方运算。这样不仅能把非常大的指数给不断变小，所需要执行的循环次数也变小，而最后表示的结果却一直不会变。 代码 https://github.com/Castile/algorithm/blob/master/leetcode/src/RecurrenceAndDynamicProgramming/leetcode50_pow.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package RecurrenceAndDynamicProgramming;/** * @author Hongliang Zhu * @create 2020-02-12 15:39 */public class leetcode50_pow &#123; public static double pow(double x, int n) &#123; long N = n; if (n &lt; 0) &#123; N = -N; x = 1 / x; &#125; double ans = 1.0; for (int i = 0; i &lt; N; i++) &#123; ans *= x; ans %= 1000; &#125; return ans; &#125; /** * 快速幂 * @param x 底数 * @param n 指数 * @return 结果 求最后三位数 */ public static double fast_pow(double x, int n)&#123; double result = 1; while (n &gt; 0 )&#123;// if(n % 2 == 0)&#123;// // 如果指数为偶数// n /= 2;// x = x * x % 1000;// &#125;if(n % 2 != 0 )&#123;// // 指数为奇数// n--; // 指数减一为偶数// result = result * x % 1000;// n /= 2;// x = x * x % 1000;// &#125; if( (n &amp; 1) == 1) &#123; // n%2 == 1 奇数 使用位运算更加高效 result = result * x % 1000; &#125; // n /= 2; n &gt;&gt;= 2; // 右移 x = x * x % 1000; &#125; return result % 1000; &#125; public static void main(String[] args) &#123; long start = System.nanoTime();// double ans = pow(2, 1000000000); double anss = fast_pow(2, 10000000); long end = System.nanoTime(); System.out.println(anss); System.out.println(&quot;耗时：&quot; + (end - start) +&quot; ns&quot;); &#125;&#125; 附上AC的结果： 12345678910111213141516171819202122232425class Solution &#123; public double myPow(double x, int n) &#123; long N = n; if (N &lt; 0) &#123; x = 1 / x; N = -N; &#125; return fastPow(x, N); &#125; private double fastPow(double x, long n)&#123; if(n == 0) return 1.0; double ans = 1.0; while(n &gt; 0)&#123; if((n &amp; 1 ) == 1)&#123; ans = ans*x; &#125; n &gt;&gt;= 1; x = x * x; &#125; return ans; &#125;&#125;; 快速幂很巧妙！值得学习！加油！！！","path":"2020/02/12/leetcode-50-幂函数/","date":"02-12","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"数学","slug":"数学","permalink":"https://castile.github.io/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"leetcode-104-二叉树的最大深度","text":"描述leetcode-104： 二叉树的最大深度【简单】 给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 说明: 叶子节点是指没有子节点的节点。 示例：给定二叉树 [3,9,20,null,null,15,7]， ​ 3 / 9 20 / 15 7返回它的最大深度 3 。 链接：https://leetcode-cn.com/problems/maximum-depth-of-binary-tree 分析 很直观想到递归来解决，根节点的数的高度等于 1 加上 左子树的高度与右子数高度的最大值。 $$Root_h = 1 + \\max(Sub_L + Sub_R)$$ 迭代： BFS广度优先遍历，因为BFS是按层次遍历，所以二叉树有多少层，二叉树的高度就等于层数。 dfs： 其实是按照二叉树的前序遍历顺序，将每个节点的当前深度记录下来，这里使用了Pair结构 时间复杂度均为O(n)， 空间复杂度均为O(n)，如果是平衡二叉树的话，时间复杂度最好情况为O(logN)。 代码github: https://github.com/Castile/algorithm/blob/master/leetcode/src/Tree/leetcode104_MaximumDepthofBinaryTree.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697import com.sun.org.apache.xalan.internal.xsltc.util.IntegerArray;import javafx.util.Pair;import jdk.internal.org.objectweb.asm.commons.InstructionAdapter;import sun.awt.TracedEventQueue;import java.util.LinkedList;/** * @author Hongliang Zhu * @create 2020-02-06 22:38 */class TreeNode &#123; int val; TreeNode left; TreeNode right; TreeNode(int x) &#123; val = x; &#125;&#125;public class leetcode104_MaximumDepthofBinaryTree &#123; // static int i =0;// static int j = 0; // 不能在这里定义 public static int maxDepth(TreeNode root) &#123; if (root == null) return 0; int i = maxDepth(root.left); int j = maxDepth(root.right); return Math.max(i, j) + 1; &#125; /** * BFS 层次遍历， 记录层数，即为深度 * * @param root 根节点 * @return 二叉树的深度 */ public static int maxDepth_BFS(TreeNode root) &#123; if (root == null) return 0; LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); // 队列 queue.add(root); int maxDepth = 0; while (!queue.isEmpty()) &#123; maxDepth++;// 层数加1 // 将当前层出队列 int currSize = queue.size(); for (int i = 0; i &lt; currSize; i++) &#123; TreeNode node = queue.poll(); if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); &#125; &#125; return maxDepth; &#125; public static int maxDepth_DFS(TreeNode root) &#123; if (root == null) return 0; LinkedList&lt;Pair&lt;TreeNode, Integer&gt;&gt; stack = new LinkedList&lt;&gt;(); // 栈 stack.push(new Pair&lt;&gt;(root, 1)); // 根节点的深度为1 int maxDepth = 0; while (!stack.isEmpty()) &#123; Pair&lt;TreeNode, Integer&gt; currNode = stack.pop(); // 当前节点 maxDepth = Math.max(maxDepth, currNode.getValue()); // 与当前节点的深度比较 // 左右子树进栈 if (currNode.getKey().left != null) &#123; stack.push(new Pair&lt;&gt;(currNode.getKey().left, currNode.getValue() + 1)); // 深度加1 &#125; if (currNode.getKey().right != null) &#123; stack.push(new Pair&lt;&gt;(currNode.getKey().right, currNode.getValue() + 1)); &#125; &#125; return maxDepth; &#125; public static void main(String[] args) &#123; TreeNode root = new TreeNode(1); TreeNode t2 = new TreeNode(2); TreeNode t3 = new TreeNode(3); TreeNode t4 = new TreeNode(4); TreeNode t5 = new TreeNode(5); root.left = t2; root.right = t3; t2.left = t4; t2.right = t5; System.out.println(maxDepth(root)); // 3 System.out.println(maxDepth_BFS(root)); // 3 System.out.println(maxDepth_DFS(root)); // 3 &#125;&#125;","path":"2020/02/12/leetcode-104-二叉树的最大深度/","date":"02-12","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"二叉树","slug":"二叉树","permalink":"https://castile.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"}]},{"title":"leetcode-206-反转链表","text":"描述 leetcode206： 反转链表 【简单】 反转一个单链表。 示例: 输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL进阶:你可以迭代或递归地反转链表。你能否用两种方法解决这道题？ 链接：https://leetcode-cn.com/problems/reverse-linked-list 分析 迭代： 如下图： ​ 时间复杂度：O(n) 。 假设 n 是列表的长度，时间复杂度是 O(n)。 ​ 空间复杂度：O(1)。 递归 1、找到递归出口 2、确定返回值 3、分析单次递归需要做的事情 下面，我们来具体分析一下： 首先，找到递归出口，这个还是非常简单的，就是当前即将反转的节点为 null 或者是 反转链表 为 null 时（一轮递归其实就只有两个节点，后面会讲），说明已经全部反转完毕了，即递归出口；其次，确定返回值，我们只需要返回反转链表的头结点即可；最后，分析单次递归需要做的事情，递归其实每一轮做的事情都是一样的，我们不需要去重复考虑，这样反而会很乱，只需要考虑单轮递归需要做什么就可以了。在这里，我们就只有两个节点，一个是即将反转的节点元素，一个是已经反转完毕的链表头结点。 我们要做的一轮递归只是 将当前节点加入到反转链表中，仅此而已。链接：https://leetcode-cn.com/problems/reverse-linked-list/solution/bang-zhu-da-jia-li-jie-di-gui-zuo-fa-by-jeromememo/ 代码 https://github.com/Castile/algorithm/blob/master/leetcode/src/LinkedList/leetcode206_ReverseLinkedList.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package LinkedList;/** * @author Hongliang Zhu * @create 2020-02-06 17:09 *//* 反转单链表： 要求时间复杂度为O((n) ，空间复杂度为O(1)； Input: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL Output: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL */public class leetcode206_ReverseLinkedList &#123; // 迭代 public static ListNode reverseList(ListNode head) &#123; if(head == null) return head; ListNode pre = null; ListNode next = null; while (head != null) &#123; next = head.next; head.next = pre; pre = head; head = next; &#125; return pre; &#125; // 递归版本 public static ListNode reverdeList_Recur(ListNode head)&#123; return help(head, null, head.next); &#125; public static ListNode help(ListNode head, ListNode pre, ListNode next)&#123; if(head == null) return pre; next = head.next; head.next = pre; pre = head; head = next; return help(head, pre, next); &#125; // 优美递归 public static ListNode reverseListRR(ListNode head)&#123; if(head == null || head.next == null) return head; ListNode p = reverseListRR(head.next); //这里的cur就是最后一个节点 ListNode cur = reverseList(head.next); //如果链表是 1-&gt;2-&gt;3-&gt;4-&gt;5，那么此时的cur就是5 //而head是4，head的下一个是5，下下一个是空 //所以head.next.next 就是5-&gt;4 head.next.next = head; //防止链表循环，需要将head.next设置为空 head.next = null; //每层递归函数都返回cur，也就是最后一个节点 return p; &#125; public static void printLinkedList(ListNode head)&#123; if(head == null) return; ListNode p = head; while (p != null)&#123; System.out.print(p.val +&quot;\\t&quot;); p = p.next; &#125; System.out.println(); &#125; public static void main(String[] args) &#123; ListNode head = new ListNode(1); ListNode n1 = new ListNode(2); ListNode n2 = new ListNode(3); ListNode n3 = new ListNode(4); ListNode n4 = new ListNode(5); head.next = n1; n1.next = n2; n2.next = n3; n3.next = n4; printLinkedList(head); ListNode re = reverseListRR(head); printLinkedList(re); &#125;&#125;","path":"2020/02/06/leetcode-206-反转链表/","date":"02-06","excerpt":"","tags":[{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"链表","slug":"链表","permalink":"https://castile.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"leetcode-119-杨辉三角2","text":"描述 leetcode119： 杨辉三角2 【简单】 给定一个非负索引 k，其中 k ≤ 33，返回杨辉三角的第 k 行。 在杨辉三角中，每个数是它左上方和右上方的数的和。 示例: 12输入: 3输出: [1,3,3,1] 分析 这题和前一题一样，只不过返回特定层，同样的思路 123456789101112131415161718192021222324class Solution &#123; public List&lt;Integer&gt; getRow(int rowIndex) &#123; List&lt;List&lt;Integer&gt;&gt; triangle = new ArrayList&lt;&gt;(); int[][] dp = new int[rowIndex+2][rowIndex+2]; if(rowIndex+1 == 0) return null; for(int i = 1 ; i &lt;= rowIndex+1; i++)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int j = 1; j &lt;= i ; j++)&#123; list.add(calc(dp, i, j)); &#125; triangle.add(list); &#125; return triangle.get(rowIndex); // 注意返回的是指定层 &#125; public int calc(int[][] dp, int i, int j)&#123; if( j == 1 || i == j)&#123; dp[i][j] = 1; return 1; &#125; if(dp[i][j] != 0) return dp[i][j]; dp[i][j] = calc(dp, i - 1, j - 1) + calc(dp, i - 1, j); return dp[i][j]; &#125;&#125; 这题和杨辉三角1的题目差不多，118题需要保存所有的，但是这题只需要返回指定层，因为当前层的值只依赖于上一层的值，故使用一个list来保存上一层的值。 12345678910111213141516public List&lt;Integer&gt; getRow(int rowIndex) &#123; List&lt;Integer&gt; pre = new ArrayList&lt;&gt;(); List&lt;Integer&gt; cur = new ArrayList&lt;&gt;(); for (int i = 0; i &lt;= rowIndex; i++)&#123; cur = new ArrayList&lt;&gt;(); for(int j = 0; j &lt;= i ; j++)&#123; if(j == 0 || i == j)&#123; cur.add(1); &#125;else&#123; cur.add(pre.get(j - 1) + pre.get(j)); &#125; &#125; pre = cur; &#125; return cur; &#125; 基于2可以继续优化：以把 pre 的 List 省去。这样的话，cur每次不去新建 List，而是把cur当作pre。 又因为更新当前 j 的时候，就把之前j的信息覆盖掉了。而更新 j + 1 的时候又需要之前j的信息，所以在更新前，我们需要一个变量把之前j的信息保存起来。 1234567891011121314public List&lt;Integer&gt; getRow(int rowIndex) &#123; int pre = 1; List&lt;Integer&gt; cur = new ArrayList&lt;&gt;(); cur.add(1); // j == 0 for(int i = 1; i &lt;= rowIndex; i++)&#123; for(int j = 1; j &lt; i; j++)&#123; int tmp = cur.get(j); cur.set(j, pre + cur.get(j)); pre = tmp; &#125; cur.add(1); // j == i &#125; return cur; &#125; 除了上边优化的思路，还有一种想法，那就是倒着进行，这样就不会存在覆盖的情况了。因为更新完j的信息后，虽然把j之前的信息覆盖掉了。但是下一次我们更新的是j - 1，需要的是j - 1和j - 2 的信息，j信息覆盖就不会造成影响了。 代码 https://github.com/Castile/algorithm/blob/master/leetcode/src/RecurrenceAndDynamicProgramming/leetcode119_PascalTriangle2.java 相似题目：杨辉三角","path":"2020/02/06/leetcode-119-杨辉三角2/","date":"02-06","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"dp","slug":"dp","permalink":"https://castile.github.io/tags/dp/"}]},{"title":"leetcode-118-杨辉三角1","text":"描述 给定一个非负整数 numRows，生成杨辉三角的前 numRows 行。 在杨辉三角中，每个数是它左上方和右上方的数的和。 示例: 输入: 5输出:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 链接：https://leetcode-cn.com/problems/pascals-triangle 分析 暴力递归：basecase：可以看到，每行的最左边和最右边的数字是1。因此，我们可以将基本情况定义如下: f(i, j)=1 where j=1 or j==i 递推关系： ​ 首先，我们定义一个函数 f(i,j)它将会返回帕斯卡三角形第 i 行、第 j 列的数字。 我们可以用下面的公式来表示这一递推关系：f(i,j)=f(i−1,j−1)+f(i−1,j) 动态规划：因为暴力递归还有很多值会重复计算，所以使用一个数组保存已经计算过的值。 代码源码： https://github.com/Castile/algorithm/blob/master/leetcode/src/RecurrenceAndDynamicProgramming/leetcode118_PascalTriangle.java 1234567891011121314151617// 暴力递归： 但是会超时 public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; triangle = new ArrayList&lt;&gt;(); if(numRows == 0) return triangle; for(int i = 1 ; i &lt;= numRows; i++)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int j = 1; j &lt;= i ; j++)&#123; list.add(calc(i, j)); &#125; triangle.add(list); &#125; return triangle; &#125; public int calc(int i, int j)&#123; if( j == 1 || i == j) return 1; return calc(i - 1, j - 1) + calc(i - 1, j); &#125; 动态规划： 12345678910111213141516171819202122232425// 动态规划 class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; triangle = new ArrayList&lt;&gt;(); int[][] dp = new int[numRows+1][numRows+1]; if(numRows == 0) return triangle; for(int i = 1 ; i &lt;= numRows; i++)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int j = 1; j &lt;= i ; j++)&#123; list.add(calc(dp, i, j)); &#125; triangle.add(list); &#125; return triangle; &#125; public int calc(int[][] dp, int i, int j)&#123; if( j == 1 || i == j)&#123; dp[i][j] = 1; return 1; &#125; if(dp[i][j] != 0) return dp[i][j]; dp[i][j] = calc(dp, i - 1, j - 1) + calc(dp, i - 1, j); return dp[i][j]; &#125; &#125; 相似题目： leetcode-119-杨辉三角2","path":"2020/02/06/leetcode-118-杨辉三角1/","date":"02-06","excerpt":"","tags":[{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"dp","slug":"dp","permalink":"https://castile.github.io/tags/dp/"}]},{"title":"CosNet:基于协同注意孪生网络的无监督视频目标分割","text":"【CVPR2019】CosNet：See More, Know More: Unsupervised Video Object Segmentation with Co-Attention Siamese Networks基于协同注意孪生网络的无监督视频目标分割代码： https://github.com/Castile/COSNet 概述​ 以往的无监督视频目标分割基于深度学习的方法仅仅考虑短期时域信息，没有考虑整个视频的全局信息，而且并没有有效利用视频内容的内在相关信息 ，**Co-attention Siamese Network(CosNet)**提出了一个统一的端到端的无监督视频目标分割网络。 ​ CosNet将UVOS作为co-attention的过程。一个co-attention模块学习去显示编码帧与帧之间的关系，使CosNet可以获取频繁相关的区域，进而可以帮助发现前景目标来进行分割。具体的，在训练阶段，co-attention过程能够分解为同一视频中任意帧对之间的相关性学习，在测试的时候，CosNet使用全局视角推断前景目标，也就是说利用测试帧与多个相关的帧的co-attention信息来判断主要的前景目标。CosNet的网络结构如下图所示。这是无监督视频目标分割最好的模型，在Davis2016数据集上的J-means达到了80.5的分数。 ​ CosNet认为无监督视频目标分割下的主要目标拥有以下特点： 1)单帧可区分(本地显著性)； 2)在整个视频序列中频繁出现的目标(全局一致性)。 ​ 这两个特点对于区分视频序列中的主要目标的非常重要的。通过考虑视频的全局信息，可以锁定主要目标，进而进行分割。 网络结构 ​ 输入是图片对，图片对可以从视频中随机取得。两帧图片经过基网络（DeeplabV3），也称编码网络（Encoder）， 将两帧编码成嵌入特征，然后协同注意力模块会计算两帧的相似性，即两帧之间的相关注意力特征。最后输入到分割模块得到最后的分割结果。 算法Co-attention Mechanisms in COSNet作者提出了三种协同注意力机制，分别为Vanilla co-attention， Symmetric co-attention，Channel-wise co-attention。一个注意力模块这显式地编码两帧之间的相关性，这样可以使得COsNet学习到频繁相关的区域。 Vanilla co-attention S 是两帧之间的afﬁnity matrix（相似矩阵），Va和Vb的shape是$$W * H * C$$Va的每一列表示特征向量，W是一个方阵 所以S又可以写成： 通过上面公式，首先对每一帧的特征表示进行线性变换，然后计算它们之间的距离 。 Symmetric co-attention如果对权重矩阵进行约束，令权重矩阵为一个对称矩阵。则投影矩阵P就变成一个正交矩阵 I是一个C * C的单位阵。则Symmetric co-attention的计算公式为： 上述公式表明将嵌入向量Va和Vb的特征投影到正交公共空间中，并保持它们的范数。这一特性可以消除不同通道之间的相关性和提高网络的泛化能力。 Channel-wise co-attention将投影矩阵P简单地表示成单位矩阵 I （也就是没有进行空间的转换），然后权重矩阵W变成对角矩阵，在这种情况下，W（也就是D）可以分为两个对角矩阵Da和Db， 因此，公式3可以重新写成一下形式，也就是Channel-wise co-attention： 这个操作相当于在计算相似度之前对Va和Vb应用一个信道权值, 这有助于缓解通道冗余 . 协同注意力操作 协同注意力操作如上图所示，在获取了相似度矩阵S之后，对S的行向量和列向量进行SoftMax操作： 结合上图： 在网络中的协同注意力模块还有一个Gated co-attention操作， 考虑到输入对、遮挡和背景噪声之间潜在的外观变化，最好对来自不同输入帧的信息进行加权，而不是平均处理所有的共同注意信息。 $$ \\sigma是一个sigmoid激活函数， w_f和b_f表示卷积核和偏置参数。 $$ 计算完gate的置信度之后，注意力Z表示为： CosNet 整体架构 CosNet是一个孪生网络，由三个级联的部分，一个基于DeepLabV3的特征嵌入模块，一个协同注意力模块以及分割模块。 训练阶段​ 上文说到，视频中的主要对象（即要分割的对象）有两个基本属性:(i)帧内可分辨性，(ii)帧间一致性。为了区分前景目标和背景(属性(i))，我们利用现有的显著性目标分割数据集DUTS和MSRA 10K来训练我们的backbone特征嵌入模块。同时，为了确保COSNet能够捕获主要视频对象的全局帧间相干性(property (ii))，我们使用视频分割数据训练整个COSNet，其中co-attention模块在捕获视频帧之间的相关性方面起着关键作用。具体来说，我们在一个视频序列中随机选取两帧来建立训练对。值得一提的是，与以往的基于循环神经网络的UVOS模型只需要连续帧相比，这种操作自然有效地扩充了训练数据, 即数据增强。 ​ 通过这种方式，COSNet可以交替使用静态图像数据和动态视频数据进行训练。在使用图像数据时，我们只训练了特征嵌入模块，其中增加了1×1的sigmoid激活卷积层，生成中间分割的sideoutput。视频数据用于训练整个COSNet，包括特征嵌入模块、协同注意模块和分割模块。利用加权二叉熵损失训练网络: 其实训练阶段是完全监督的，因为使用到了groundtruth。 测试阶段​ 训练完成之后，使用模型在其他没有见过的视频序列中进行测试。给定一个测试视频序列，我们可以将每个要分割的帧，以及从同一视频中采样的一个参考帧，依次输入到COSNet中，通过逐帧的操作，我们可以得到所有的分割结果。 ​ 然而，在这样一个简单的策略下，分割结果仍然含有相当大的噪声，因为视频中丰富的全局相关信息并没有得到充分的挖掘。因此，在测试阶段包含更多的是推导帧常重要的： 将一组N个不同的参考帧(从同一视频中均匀采样)输入推理分支，并对所有预测进行平均。 结果DAVIS-2016数据集： FBMS数据集： YoutubeObjects 数据集： 结论 协同注意力机制基于全局的视角进行推断前景和背景的分割，效果显著。 在测试时，平均多个帧的的注意力更有效 为了研究最终预测在测试阶段的帧选择策略，我们进一步使用不同的采样方法进行了一系列的实验。具体采用全局随机抽样、全局均匀抽样和局部连续抽样。从表1中可以看出，两种全局水平的采样策略都能获得近似的性能，但都优于局部采样方法。同时，基于局部采样的结果仍然优于从骨干网获得的结果。整体比较进一步证明了合并的重要性 。 关于参考帧数的选择，如表： 当N = 0时，这意味着没有共同注意分割。当N从0变为1时，可以看到一个很大的性能改进 。N从2变化到5，定量结果显示性能有所提高。当我们进一步增加N时，最终的性能没有明显的变化。实验中使用的N=5。","path":"2020/02/05/CosNet-基于协同注意孪生网络的无监督视频目标分割/","date":"02-05","excerpt":"","tags":[{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"UVOS","slug":"UVOS","permalink":"https://castile.github.io/tags/UVOS/"}]},{"title":"leetcode-344-反转字符串","text":"描述 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 char[] 的形式给出。 不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。 你可以假设数组中的所有字符都是 ASCII 码表中的可打印字符。 示例 1： 输入：[“h”,”e”,”l”,”l”,”o”]输出：[“o”,”l”,”l”,”e”,”h”]示例 2： 输入：[“H”,”a”,”n”,”n”,”a”,”h”]输出：[“h”,”a”,”n”,”n”,”a”,”H”] 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/reverse-string 分析 就地操作，而且要是O(1)的空间，可以使用迭代方法，首尾指针解决 1234567891011class Solution &#123; public void reverseString(char[] s) &#123; int len = s.length; char tmp; for(int i = 0; i &lt; len/2 ; i++)&#123; tmp = s[i]; s[i] = s[len - i - 1]; //这是末尾的值 s[len-i-1] = tmp; &#125; &#125;&#125; 也可以用递归来做，但是使用了辅助栈，不满足O(1)的空间要求 1234567891011121314class Solution &#123; public void reverseString(char[] s) &#123; help(s, 0, s.length-1); &#125; private void help(char[] s, int i, int j) &#123; if (i &gt;= j) return; char tmp = s[i]; s[i] = s[j]; s[j] = tmp; i++; j--; help(s, i, j); &#125;&#125; 代码 https://github.com/Castile/algorithm/blob/master/leetcode/src/Str/leetcode344_ReverseStr.java","path":"2020/02/03/leetcode-344-反转字符串/","date":"02-03","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"字符串","slug":"字符串","permalink":"https://castile.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"}]},{"title":"leetcode-24-两两交换链表中的节点","text":"描述 给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。 你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 示例： 给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3链接：https://leetcode-cn.com/problems/swap-nodes-in-pairs 分析 递归： ​ 我们可以定义函数 swap(head) 以实现解决方案，其中输入的参数 head 指向链表的头节点。* 而该函数应当返回将链表中每两个相邻节点交换后得到的新列表的头节点 head 。 ​ 按照我们上面列出的步骤，我们可以按下面的流程来实现函数： ​ （1）首先，我们交换列表中的前两个节点，也就是 head 和 head.next； ​ （2）然后我们以 swap(head.next.next) 的形式调用函数自身，以交换头两个节点之后列表的其余部分。 ​ （3）最后，我们将步骤（2）中的子列表的返回头与步骤（1）中交换的两个节点相连，以形成新的链 表。 迭代 新增一个头节点 dummy node， dummy.next = head； 更好操作链表。流程图如下： 代码源码： https://github.com/Castile/algorithm/blob/master/leetcode/src/LinkedList/leetcode24_SwapNodesInPairs.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package LinkedList;/** * @author Hongliang Zhu * @create 2020-02-03 15:51 */class ListNode &#123; int val; ListNode next; ListNode(int x) &#123; val = x; &#125;&#125;public class leetcode24_SwapNodesInPairs &#123; // 递归解法 public ListNode swapPairs(ListNode head) &#123; if(head == null || head.next == null) return head; ListNode n = head.next.next; // 下一次要传递的节点 //交换这两个节点 ListNode p = head.next; p.next = head; head.next = swapPairs(n); // 递归 return p; // 返回交换之后的头结点 &#125; // 迭代 public ListNode swapPairs_it(ListNode head) &#123; ListNode dummy = new ListNode(-1); dummy.next = head; ListNode pre = dummy; while(head != null &amp;&amp; head.next != null)&#123; ListNode first = head; ListNode second = head.next; // 交换 first.next = second.next; second.next = first; pre.next = second; // 初始化头 head = first.next; pre = first; &#125; return dummy.next; &#125;&#125;","path":"2020/02/03/leetcode-24-两两交换链表中的节点/","date":"02-03","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"链表","slug":"链表","permalink":"https://castile.github.io/tags/%E9%93%BE%E8%A1%A8/"}]},{"title":"leetcode-200-岛屿数量","text":"描述 给定一个由 ‘1’（陆地）和 ‘0’（水）组成的的二维网格，计算岛屿的数量。一个岛被水包围，并且它是通过水平方向或垂直方向上相邻的陆地连接而成的。你可以假设网格的四个边均被水包围。 示例 1: 输入:11110110101100000000 输出: 1示例 2: 输入:11000110000010000011 输出: 3链接：https://leetcode-cn.com/problems/number-of-islands 分析 dfs： 深度优先搜索，很明显，这是一个连通问题，求出的连通分量的个数就是岛屿的数量 并查集： 这个是并查集的一个应用，求连通分量的个数。 bfs： 使用队列解决 这里有一个大佬的题解，非常详细： https://leetcode-cn.com/problems/number-of-islands/solution/dfs-bfs-bing-cha-ji-python-dai-ma-java-dai-ma-by-l/ 官方题解也可。主要是理解算法思想 直接看代码吧 代码并查集： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class Solution &#123; int count = 0; public int numIslands(char[][] grid) &#123; if(grid == null || grid.length == 0) return 0; int m = grid.length; int n = grid[0].length; int[] parents = new int[n*m]; int[] rank = new int [n*m]; makeSet(grid, parents, rank); // 方向数组 d 是上下左右搜索的常用手法 int[][] d = new int[][]&#123;&#123;1,0&#125;, &#123;0,1&#125;, &#123;0,-1&#125;, &#123;-1,0&#125;&#125;; for(int i =0 ; i &lt; m; i++)&#123; for( int j = 0; j &lt; n; j++)&#123; if( grid[i][j] == &#x27;1&#x27;)&#123; grid[i][j] = &#x27;0&#x27;; // 已经联合的点不需要连接了。 for(int k = 0; k &lt; 4; k++)&#123; int x = i + d[k][0]; int y = j + d[k][1]; if(x &gt;= 0 &amp;&amp; x &lt; m &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; n &amp;&amp; grid[x][y] == &#x27;1&#x27;)&#123; unoin(parents, rank, x *n +y, i *n + j); &#125; &#125; &#125; &#125; &#125; return count; &#125; // 构建并查集的结构：注意这里的技巧 public void makeSet(char[][] grid, int []parents, int []rank)&#123; for(int i = 0; i &lt; grid.length ; i++)&#123; for(int j = 0; j &lt; grid[0].length; j++)&#123; if(grid[i][j] == &#x27;1&#x27;)&#123; parents[i * grid[0].length + j] = i * grid[0].length + j; rank[i * grid[0].length + j] = 1; count++; // 连通分量 &#125;else&#123; parents[i * grid[0].length + j] = -1; rank[i * grid[0].length + j] = 0; &#125; &#125; &#125; &#125; public int find(int[] parents, int a)&#123; int root = parents[a]; while(root != parents[root])&#123; root = parents[root]; &#125; return root; &#125; public void unoin(int[] parents, int []rank, int a, int b)&#123; int ra = find(parents, a); int rb = find(parents, b); if(ra != rb)&#123; if(rank[ra] &gt; rank[rb])&#123; parents[rb] = ra; rank[ra] += rank[rb]; &#125;else&#123; parents[rb] = ra; rank[ra] += rank[rb]; &#125; count--; &#125;else &#123; return; &#125; &#125;&#125; dfs： 123456789101112131415161718192021222324252627282930313233343536class Solution &#123; public int numIslands(char[][] grid) &#123; int cnt = 0; for(int i = 0; i &lt; grid.length; i++)&#123; for(int j = 0; j &lt; grid[0].length; j++)&#123; if(grid[i][j] == &#x27;1&#x27;)&#123; cnt++; // 岛屿的个数加一 infect(grid, i, j, grid.length, grid[0].length); // 感染函数 &#125; &#125; &#125; return cnt; &#125; /** * 感染函数： 将i， j位置的上下左右位置进行检查，是否为同一个岛屿 * @param m： 岛屿矩阵 * @param i： 下标 * @param j： 下标 * @param R: 行 * @param C： 列 */ public static void infect(char[][] m, int i, int j, int R, int C)&#123; if(i &lt; 0 || i &gt;= R || j &lt; 0 || j &gt;= C || m[i][j] != &#x27;1&#x27;) return; m[i][j] = &#x27;2&#x27;; // 依次感染上下左右位置 infect(m, i+1, j, R, C); infect(m, i-1, j, R, C); infect(m, i, j-1, R, C); infect(m, i, j+1, R, C); &#125;&#125; BFS： 使用队列 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123; int m,n; int[][] d = new int[][]&#123;&#123;0,1&#125;,&#123;1,0&#125;,&#123;-1,0&#125;, &#123;0,-1&#125;&#125;; // 广度优先遍历 public int numIslands(char[][] grid) &#123; if(grid == null || grid.length == 0) return 0; m = grid.length; n = grid[0].length; LinkedList&lt;Integer&gt; q = new LinkedList&lt;&gt;(); int count = 0; for(int i = 0; i &lt; m; i++)&#123; for(int j = 0; j &lt; n ; j ++)&#123; if(grid[i][j] == &#x27;1&#x27;)&#123; q.offer(i * n + j); // 入队 while(!q.isEmpty())&#123; int cur = q.poll(); // 出队 int cx = cur / n; int cy = cur % n; grid[cx][cy] = &#x27;0&#x27;; for(int[] dd: d)&#123; int x = cx + dd[0]; int y = cy + dd[1]; if(x &gt;= 0 &amp;&amp; y &gt;= 0 &amp;&amp; x &lt; m &amp;&amp; y &lt; n &amp;&amp; grid[x][y] == &#x27;1&#x27;)&#123; q.offer(x * n + y); grid[x][y] = &#x27;0&#x27;; // 要标志已访问，不然会严重超时 &#125; &#125; &#125; count++; &#125; &#125; &#125; return count; &#125;&#125;","path":"2020/02/02/leetcode-200-岛屿数量/","date":"02-02","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-695-岛屿的最大面积","text":"描述 给定一个包含了一些 0 和 1的非空二维数组 grid , 一个 岛屿 是由四个方向 (水平或垂直) 的 1 (代表土地) 构成的组合。你可以假设二维矩阵的四个边缘都被水包围着。 找到给定的二维数组中最大的岛屿面积。(如果没有岛屿，则返回面积为0。) 示例 1: [[0,0,1,0,0,0,0,1,0,0,0,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,1,1,0,1,0,0,0,0,0,0,0,0], [0,1,0,0,1,1,0,0,1,0,1,0,0], [0,1,0,0,1,1,0,0,1,1,1,0,0], [0,0,0,0,0,0,0,0,0,0,1,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,1,1,0,0,0,0]]对于上面这个给定矩阵应返回 6。注意答案不应该是11，因为岛屿只能包含水平或垂直的四个方向的‘1’。 示例 2: [[0,0,0,0,0,0,0,0]]对于上面这个给定的矩阵, 返回 0。 注意: 给定的矩阵grid 的长度和宽度都不超过 50。 链接：https://leetcode-cn.com/problems/max-area-of-island 分析dfs： 岛屿问题，看到连通区域，想到dfs来做。 用DFS搜索每个value为1的位置，递归检查相邻的位置，如果访问过，则将value设为0（避免重复访问） 直接看代码注释 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344package search;/** * @author Hongliang Zhu * @create 2020-02-02 17:04 */public class leetcode_695_MaxAreaIsland &#123; int m; int n; int[][] d = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; public int maxAreaOfIsland(int[][] grid) &#123; if(grid == null || grid.length == 0) return 0; m = grid.length; n = grid[0].length; int result = 0; for(int i = 0; i &lt; m; i++)&#123; for(int j = 0; j &lt; n ; j++)&#123; result = Math.max(result, dfs(grid, i, j)); //求最大的面积 &#125; &#125; return result; &#125;// int[][] d = new int[][]&#123;&#123;1, 0&#125;, &#123;0, 1&#125;, &#123;-1, 0&#125;, &#123;0, -1&#125;&#125;; public int dfs(int[][] grid, int x, int y)&#123; if(x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n || grid[x][y] == 0)&#123; return 0; &#125; grid[x][y] = 0; int c = 1; // 面积加1 for(int k = 0; k &lt; 4; k++)&#123; // 注意使用不同的变量，如果使用x、y会报错 int i = x + d[k][0]; int j = y + d[k][1]; c += dfs(grid, i, j); // 搜索上下左右 &#125; // for(int[] dd: d)&#123; // c += dfs(grid, x + dd[0], y + dd[1]); // &#125; return c; &#125;&#125;","path":"2020/02/02/leetcode-695-岛屿的最大面积/","date":"02-02","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-268-缺失的数字","text":"[toc] 描述 给定一个包含 0, 1, 2, …, n 中 n 个数的序列，找出 0 .. n 中没有出现在序列中的那个数。 示例 1: 输入: [3,0,1]输出: 2示例 2: 输入: [9,6,4,2,3,5,7,0,1]输出: 8链接：https://leetcode-cn.com/problems/missing-number 分析 题目说从0n的数字，所以直接累加数组得到和为sum， 加入数组没有缺失数据，那么完整数组的元素个数为原数组大小加1，利用等差数列的性质，得到从0n的和len，然后len - sum 就是缺失的那个数字了。 时间复杂度：O(n)。求出数组中所有数的和的时间复杂度为 O(n)，等差数列公式的时间复杂度为 O(1)，因此总的时间复杂度为 O(n)。空间复杂度：O(1)。算法中只用到了O(1) 的额外空间，用来存储答案。 位操作： 异或 a b 异或结果 0 0 0 0 1 1 1 0 1 1 1 0 其他数字 与 0 异或都得到它自己。 此外异或运算满足交换律. 如： 0 1 2 3 3 4 0 1 下标与数组值异或操作： 4 ^ 0 ^ 3 ^ 1 ^ 4 ^ 2 ^ 0 ^ 3 ^ 1 ( 前面的4是为了添加最后一位数字，为原数组的长度) —-&gt; 可得到缺失的值为2。 时间复杂度：O(n)。这里假设异或运算的时间复杂度是常数的，总共会进行O(n) 次异或运算，因此总的时间复杂度为 O(n)。空间复杂度：O(1)。算法中只用到了O(1) 的额外空间，用来存储答案。 哈希表 将数组中的元素放入HashSet哈希表中， 插入哈希表的时间复杂度为O(1)， N个数时间复杂度为O(n)， 然后从0到数组放长度区间内遍历， 判断哈希表中是否存在此数字，若不存在， 则此数字就是缺失的数字。遍历时间复杂度为O(n)， 故总体时间复杂度为O(n)。空间复杂度为O(n)。 还可以先排序，再找出缺失的数字，但是排序的时间复杂度不是线性时间， 为O(logN) 代码方法一： 123456789101112class Solution &#123; public int missingNumber(int[] nums) &#123; int sum = 0; for(int i = 0 ; i &lt; nums.length; i++)&#123; //数组的和 sum += nums[i]; &#125; // 缺失一个数字： 本来的和应该是： int len = (nums.length + 1) * nums.length / 2; return len - sum; &#125;&#125; 位操作： 123456789class Solution &#123; public int missingNumber(int[] nums) &#123; int m = nums.length; for(int i = 0; i &lt; nums.length; i++)&#123; m ^= i ^ nums[i]; &#125; return m; &#125;&#125; 哈希表： 12345678910111213141516class Solution &#123; public int missingNumber(int[] nums) &#123; Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); for( int i = 0; i &lt;nums.length; i++)&#123; set.add(nums[i]); &#125; for(int i = 0 ; i &lt;= nums.length; i++)&#123; if( !set.contains(i)) return i; &#125; return -1; &#125; &#125; 排序： 12345678910111213141516171819class Solution &#123; public int missingNumber(int[] nums) &#123; Arrays.sort(nums); // 判断末尾 if(nums[nums.length - 1] != nums.length)&#123; return nums.length; &#125; // 判断0 是否在首位 if(nums[0] != 0)&#123; return 0; &#125; for( int i = 0; i &lt;nums.length ; i++)&#123; if(i != nums[i]) return i; &#125; return -1; &#125; &#125;","path":"2020/02/02/leetcode-268-缺失的数字/","date":"02-02","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"位操作","slug":"位操作","permalink":"https://castile.github.io/tags/%E4%BD%8D%E6%93%8D%E4%BD%9C/"}]},{"title":"Java-集合框架","text":"一、 概述Collection​ 集合是存储对象的容器，集合中可以存储任意类型的对象，而且长度可变。在程序中有可能无法预先知道需要多少个对象，那么用数组来装对象的话，长度不好定义，而集合解决了这样的问题。 ​ 容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对（两个对象）的映射表。 注： 带对号的是线程安全类。 集合和数组的区别数组和集合类都是容器 数组长度是固定的，集合长度是可变的。数组中可以存储基本数据类型，集合只能存储对象 数组中存储数据类型是单一的，集合中可以存储任意类型的对象。 集合类的特点：用于存储对象，长度是可变的，可以存储不同类型的对象。 从上图可以看到，Set、List、Queue都是继承Collection接口。（Map是接口，下面会详细描述） Set下面有HashSet、LinkedHashSet以及一个SortedSet接口，TreeSet继承SortedSet接口，说明TreeSet里面的元素一定是有序的。 List下面有ArrayList、Vector、 LinkedList Queue下面有LinkedList和PriorityQueue类(堆结构：优先级队列)，说明LinkedLIst可以当做队列来使用。 1. Set：唯一性TreeSet基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。红黑树的算法规则是左小右大。 红黑树是一种特定类型的二叉树， 是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质： ​ 性质1：每个节点要么是黑色，要么是红色。 ​ 性质2：根节点是黑色。 ​ 性质3：每个叶子节点（NIL）是黑色。 ​ 性质4：每个红色结点的两个子结点一定都是黑色。 ​ 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 红黑树以后会补上，详解见： 30张图带你彻底理解红黑树 TreeSet可以自然排序，那么TreeSet必定具有排序规则的 ​ ① 元素自身具有比较性，需要实现Comparable接口，重写compareTo方法。这种方式叫做元素的自然排序 ​ ② 容器具备比较性，当元素不具备比较性，或者自身具备的比较性不是所需要的，那么此时也可以让容器自身具备。需要定义一个类实现Comparator接口， 重写compare方法，并将该接口的子类实例对象作为参数传递给TreeSet集合的构造方法。（注： 当Comparable比较方式和Comparator比较方式同时存在，以Comparator为主） ​ ③ 基本数据类型具备自身比较性，比如String， int等，String内部已经继承了Comparable接口，所以具备比较性，我们自己定义的元素，想要存入TreeSet中，就必须自己实现该接口，也就是说要让对象具备就比较性，如果存入相同的元素则只会存入一个到TreeSet中。 ​ ④ TreeSet中如何保证元素的唯一性： 通过compareTo或者compare方法来保证元素的唯一性。 Person类中有name和age属性，下面是重写的compareTo方法以及hashCode和equals方法。这是使元素自身具备比较性： 1234567891011121314151617181920212223242526 @Override public int hashCode() &#123; return nama.hashCode() + age*33; &#125; @Override public boolean equals(Object obj) &#123; if(!(obj instanceof Person))&#123; return false; &#125; Person p = (Person)obj; return this.nama.equals(p.nama) &amp;&amp; this.age == p.age; &#125; @Override public int compareTo(Object o) &#123; Person p = (Person)o; if(this.age &gt; p.age)&#123; return 1; &#125; if(this.age &lt; p.age)&#123; return -1; &#125; return this.nama.compareTo(p.nama); &#125; 下面是是使容器自身具备比较性，要自定义比较器：定义一个类实现Comparator接口， 重写compare方法，并将该接口的子类实例对象作为参数传递给TreeSet集合的构造方法。 1234567891011121314151617181920212223242526272829303132333435363738394041class MyComparator implements Comparator&#123; @Override public int compare(Object o1, Object o2) &#123; Person p1 = (Person) o1; Person p2 = (Person) o2; // 首先比较年龄，年龄不一样就是不同元素，因为存在同名的人 if(p1.getAge() &gt; p2.getAge())&#123; // 按照年龄升序排列 return 1; &#125; if( p1.getAge() &lt; p2.getAge())&#123; return -1; &#125; // 如果年龄相同则比较姓名 return p1.getNama().compareTo(p2.getNama()); &#125;&#125; public static void main(String[] args) &#123; TreeSet&lt;Person&gt; set = new TreeSet&lt;&gt;(new MyComparator()); // 传入比较器 set.add(new Person(&quot;张三&quot;, 12)); set.add(new Person(&quot;李四&quot;, 5)); set.add(new Person(&quot;李四&quot;, 12)); set.add(new Person(&quot;tom&quot;, 24)); set.add(new Person(&quot;tom&quot; , 24)); for (Person p: set)&#123; out.println(p.getNama()+&quot; &quot;+p.getAge()); &#125; &#125;输出： 李四 5张三 12李四 12tom 24可以看到重名的tom是相同的元素，智慧添加一个到TreeSet中，并且输出的顺序是按照年龄大小排列的 HashSet基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。（无序） HashSet是按照哈希值来存数据的，所以取数据也是按照哈希值取得的。 Set具有元素的唯一性，所以HashSet也具有此特性。 HashSet如何检查重复呢？ ​ HashSet通过hashCode值来确定元素在内存中的位置。一个hashCode位置上可以存放对个元素。元素的哈希值是通过元素的hashCode方法来获取的， HashSet首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals方法；如果hashCode不一样就不会再调用equals方法了。如果equals方法返回true，那么HashSet认为新加入的对象重复了加入失败。如果equals方法为false那么HashSet认为新加入的对象没有重复，新元素可以加入。 LinkedHashSet具有 HashSet 的查找效率，并且内部使用双向链表维护元素的插入顺序。（有序） 由链表保证元素有序 由哈希表保证元素唯一 2. ListList特有的方法 1： 增加 ​ void add(int index, E elem) 指定位置添加元素 ​ boolean addAll(int index, COllection c) 指定位置添加集合 2： 删除 ​ E remove(int index) 删除指定位置元素 3： 查找 ​ E get(int index) 注意 IndexOutOfBoundsException ​ int indexOf(Object o) 找不到返回 -1 ​ lastIndexOf(Object o) 4： 修改 ​ E set(int index, E elem) 返回的是需要替换的集合中的元素 5： 求子集合 ​ List subList(int fromIndex, int toIndex) // 包含toIndex ArrayList基于动态数组实现，支持随机访问。 底层采用数组实现， 默认为10. 查询快，增删慢。在实际开发过程中，ArrayList 是使用频率最高的一个集合。 Vector和 ArrayList 类似，但它是线程安全的。描述的是一个线程安全的ArrayList ArrayList： 单线程效率高 Vector： 多线程安全， 所以效率低 特有的方法 ​ void addElement(E obj) 在集合末尾添加元素 ​ E elementAt(int index) 返回指定角标的元素 ​ Enumeration elements() 返回集合中的所有元素， 封装到Enumeration对象中 ​ Enumeration 接口： ​ boolean hashMoreElements() 测试此枚举的对象是否包含更多的元素 ​ E nextElement() 返回下一个元素 LinkedList基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 ​ 1. 特有方法： ​ addFirst(E e) ​ addLast(E e) ​ getFirst( ) ​ getLast( ) ​ removeFirst() ​ removeLast() 数据结构 1： 栈（1.6）：push() pop() 2: 队列 ： offer() poll() 123456789101112// 栈 LinkedList list = new LinkedList(); list.push(2); list.push(4); list.push(5); list.push(6); Iterator it = list.iterator(); while (it.hasNext())&#123; out.println(it.next()); &#125; 输出： 6542 模拟队列： 123456789101112LinkedList q = new LinkedList(); q.offer(2); q.offer(3); q.offer(5); q.poll(); Iterator it1 = q.iterator(); while (it1.hasNext())&#123; out.println(it1.next()); &#125; 返回逆序的迭代器对 ​ descendingItrerator() 返回逆序的迭代器对象 3. QueueLinkedList​ 可以用它来实现双向队列。 PriorityQueue​ 基于堆结构实现，可以用它来实现优先队列。 总结 看到Array： 想到角标 看到Link： 想到first、last 看到Hash： 想到hashCode、equals 看到Tree： 想到两个接口： Comparable、 Comparator MapMap与Collection在框架中属并两列存在。interface Map&lt;K, V&gt; Map一次存储一对元素，Collection一次存一个。Map的键不能重复，保证唯一。 TreeMap​ 基于红黑树实现。可以对键进行排序。排序方法和TreeSet中类似，对于不具备比较性的对象需要自定义比较器传入容器中。 HashMap​ 基于哈希表实现， 无序，线程不同步，要保证键的唯一性，需要重写hashCode方法和equals方法。 HashTable 和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程同时写入 HashTable 不会导致数据不一致。它是遗留类，不应该去使用它，而是使用 ConcurrentHashMap 来支持线程安全，ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 Hashtable不允许null值，HashMap允许null值（key和value都允许 ) 效率比HashMap低 LinkedHashMap​ 继承了HashMap。使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用（LRU）顺序。 遍历迭代器 迭代器： 为了方便处理集合中的元素，出现了迭代器对象。这个对象比较特殊，不能通过new来创建，它是以内部类的形式存在于每个集合的内部。 ​ 每个容器都能取出元素的功能，定义一样，只不过不同的容器使用的数据结构不同而导致取出元素的具体实现不一样，将共性抽取出来形成Iterator接口。每一个容易在其内部进行了内部类的实现。也就是将取出元素的方式的细节进行封装。 IterableJDK1.5后的新接口。Collection继承了此接口，实现了Iterable的类就是可以进行迭代的，并且支持增强for循环。 IteratorIterable 接口只有一个返回迭代器的方法Iterator(). Iterator是迭代器对象。 Iteartor Iterator() 返回该集合的迭代器对象 while循环进行迭代器遍历： 1234567891011 LinkedList list = new LinkedList(); list.push(2); list.push(4); list.push(5); list.push(6);// 迭代器遍历 Iterator it = list.iterator(); while (it.hasNext()) &#123; out.println(it.next()); &#125; for循环： 123for (Iterator it = list.iterator(); it.hasNext();)&#123; out.println(it.next()); &#125; 推荐使用for循环，因为可以进行内存上的优化。 如果迭代器的指针已经指向了集合的末尾， 那么如果再调用next() 会返NoSuchElementException 异常。 如果调用move方法之前没用调用next是不合法的。会抛出IllegaStateException 迭代器原理ArrayList： 看源码 123public Iterator&lt;E&gt; iterator() &#123; return new Itr(); &#125; 看看Itr() 方法 1234567891011121314151617181920212223242526272829303132333435363738private class Itr implements Iterator&lt;E&gt; &#123; int cursor; // index of next element to return 下一个元素的下标 int lastRet = -1; // index of last element returned; -1 if no such int expectedModCount = modCount; // 如果当前的下标大小不等于容器个元素个数 就 说明还有下一个元素 public boolean hasNext() &#123; return cursor != size; &#125; // 返回下一个元素 @SuppressWarnings(&quot;unchecked&quot;) public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) // 没有下一个元素了 throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; // 当前的cursor要指向下一个 return (E) elementData[lastRet = i]; // 返回元素 &#125; public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; 来看看上面代码的checkForComodification(); 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; ​ 在对集合进行迭代过程中，不允许出现迭代器以外的对元素的操作， 因为这样会产生安全隐患，java会抛出异常并发修改异常ConcurrentModificationException， 普通迭代器只支持在迭代过程中的删除操作。 12345678910111213141516public static void main(String[] args) &#123; ArrayList list = new ArrayList(); list.add(&quot;aaa&quot;); list.add(&quot;bbb&quot;); list.add(&quot;ccc&quot;); list.add(&quot;ddd&quot;); list.add(&quot;eee&quot;); System.out.println(list); Iterator it = list.iterator(); while (it.hasNext())&#123; it.next(); it.remove(); list.add(&quot;aaaaa&quot;); // 出现了迭代器以外的对元素的操作 &#125; &#125; ​ 报错： List 特有的迭代器ListIterator如果想在迭代元素的过程中操作集合的元素，那么可以使用LIst特有的迭代器对象ListIterator，该迭代器可支持在迭代的过程中添加元素和修改元素。 implements ListIterator 接口 123public ListIterator&lt;E&gt; listIterator() &#123; return new ListItr(0); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private class ListItr extends Itr implements ListIterator&lt;E&gt; &#123; ListItr(int index) &#123; super(); cursor = index; &#125; // 是否有前一个元素 public boolean hasPrevious() &#123; return cursor != 0; &#125; // 返回下一个元素的下标 public int nextIndex() &#123; return cursor; &#125; // 返回前一个元素的下标 public int previousIndex() &#123; return cursor - 1; &#125; // 返回前一个元素： 可以逆序访问 @SuppressWarnings(&quot;unchecked&quot;) public E previous() &#123; checkForComodification(); int i = cursor - 1; if (i &lt; 0) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i; return (E) elementData[lastRet = i]; &#125; // 用指定元素替换next或者 previous返回的最后一个元素 public void set(E e) &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.set(lastRet, e); &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; // 将指定的元素加入列表，钙元素直接插入到next元素的后面 public void add(E e) &#123; checkForComodification(); try &#123; int i = cursor; ArrayList.this.add(i, e); cursor = i + 1; lastRet = -1; expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; &#125; 测试 set方法： 1234567891011121314public static void main(String[] args) &#123; ArrayList list = new ArrayList(); list.add(&quot;aaa&quot;); list.add(&quot;bbb&quot;); list.add(&quot;ccc&quot;); list.add(&quot;ddd&quot;); list.add(&quot;eee&quot;); System.out.println(list); ListIterator it = list.listIterator(); System.out.println(it.next()); it.set(&quot;zhu&quot;); System.out.println(list); &#125; 输出： [aaa, bbb, ccc, ddd, eee]aaa[zhu, bbb, ccc, ddd, eee] 测试 add方法 12345678910111213public static void main(String[] args) &#123; ArrayList list = new ArrayList(); list.add(&quot;aaa&quot;); list.add(&quot;bbb&quot;); list.add(&quot;ccc&quot;); list.add(&quot;ddd&quot;); list.add(&quot;eee&quot;); System.out.println(list); ListIterator it = list.listIterator(); System.out.println(it.next()); it.add(&quot;zhu&quot;); // 在aaa之后添加zhu System.out.println(list); &#125; 输出： [aaa, bbb, ccc, ddd, eee]aaa[aaa, zhu, bbb, ccc, ddd, eee] 遍历Map有三种方式： keySet() 获取Map中的所有键，转换成Set集合，然后遍历该Set，通过get方法获取键对应的值 values() 方法来获取所有值 ：Collection values() 不能获取到key对象 Map.Entry对象：重点！！！！推荐使用： Interface Map.Entry&lt;K,V&gt; Map.Entrypublic static interface Map.Entry&lt;K,V&gt; 将map集合中的键值对关系打包成一个Map.Entry对象，将该对象存入Set结合中，使用getKey() 和 getValue()来获取键和值 1234567891011121314public static void main(String[] args) &#123; HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); map.put(&quot;aaa&quot;, 123); map.put(&quot;bbb&quot;, 345); map.put(&quot;ccc&quot;, 121); map.put(&quot;ddd&quot;, 675); Set&lt;Map.Entry&lt;String, Integer&gt;&gt; s = map.entrySet(); Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; iterator = s.iterator(); while (iterator.hasNext())&#123; Map.Entry&lt;String, Integer&gt; en = iterator.next(); System.out.println(&quot;键： &quot;+ en.getKey()+&quot; 值：&quot;+ en.getValue()); &#125; &#125; 键： aaa 值：123键： ccc 值：121键： bbb 值：345键： ddd 值：675 源码分析 如果没有特别说明，以下源码分析基于 JDK 1.8。 一、 ArrayList1. 概览 因为 ArrayList 是基于数组实现的，所以支持快速随机访问。RandomAccess 接口标识着该类支持快速随机访问。 12public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 1234/** * Default initial capacity. 数组的默认大小为10 */ private static final int DEFAULT_CAPACITY = 10; 2. 扩容​ 添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1) ，也就是旧容量的 1.5 倍。 ​ 扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 1234567891011121314151617181920212223242526272829303132public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;// private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; 3. 删除元素 需要调用 `System.arraycopy()` 将 `index+1 ` 后面的元素都复制到 `index` 位置上，该操作的时间复杂度为 `O(N)`，可以看到 ArrayList 删除元素的代价是非常高的。 1234567891011121314public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; &#125; 4. 序列化​ ArrayList 基于数组实现，并且具有动态扩容特性，因此保存元素的数组不一定都会被使用，那么就没必要全部进行序列化。 ​ 保存元素的数组 elementData 使用 transient 修饰，该关键字声明数组默认不会被序列化。 1transient Object[] elementData; // non-private to simplify nested class access ​ ArrayList 实现了 writeObject() 和 readObject() 来控制只序列化数组中有元素填充那部分内容。 123456789101112131415161718192021222324252627/** * Reconstitute the &lt;tt&gt;ArrayList&lt;/tt&gt; instance from a stream (that is, * deserialize it). 反序列化 */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125; &#125; 123456789101112131415161718192021222324252627/** * Save the state of the &lt;tt&gt;ArrayList&lt;/tt&gt; instance to a stream (that * is, serialize it). 序列化 * * @serialData The length of the array backing the &lt;tt&gt;ArrayList&lt;/tt&gt; * instance is emitted (int), followed by all of its elements * (each an &lt;tt&gt;Object&lt;/tt&gt;) in the proper order. 只序列化数组中有元素填充那部分内容 */ private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125; &#125; ​ 序列化时需要使用 ObjectOutputStream 的 writeObject() 将对象转换为字节流并输出。而 writeObject() 方法在传入的对象存在 writeObject() 的时候会去反射调用该对象的 writeObject() 来实现序列化。反序列化使用的是 ObjectInputStream 的 readObject() 方法，原理类似。 5. Fail-Fast​ modCount 用来记录 ArrayList 结构发生变化的次数。 ​ 结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 ​ 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 ConcurrentModificationException。代码参考上节序列化中的 writeObject() 方法。 ​ fail-fast 机制是Java集合(Collection)中的一种错误机制。当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。 ​ ConcurrentModificationException 异常 ： 当方法检测到对象的并发修改，但不允许这种修改时就抛出该异常。同时需要注意的是，该异常不会始终指出对象已经由不同线程并发修改，如果单线程违反了规则，同样也有可能会抛出该异常。 ​ 诚然，迭代器的快速失败行为无法得到保证，它不能保证一定会出现该错误，但是快速失败操作会尽最大努力抛出ConcurrentModificationException异常，所以因此，为提高此类操作的正确性而编写一个依赖于此异常的程序是错误的做法，正确做法是：ConcurrentModificationException 应该仅用于检测 bug。 ​ 线程环境下产生该异常的原因是在迭代器遍历集合时，使用了集合本身的remove方法而不是迭代器的； 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; ​ 在ArrayList进行add，remove，clear等涉及到修改集合中的元素个数的操作时，modCount就会发生改变(modCount ++),所以当另一个线程(并发修改)或者同一个线程遍历过程中，调用相关方法使集合的个数发生改变，就会使modCount发生变化，这样在checkForComodification方法中就会抛出ConcurrentModificationException异常。 fail-fast会在以下两种情况下抛出ConcurrentModificationException ： （1）单线程环境 集合被创建后，在遍历它的过程中修改了结构。 注意 remove()方法会让expectModcount和modcount 相等，所以是不会抛出这个异常。 （2）多线程环境 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。 问题： fail-fast机制是如何检测的？ ​ 迭代器在遍历过程中是直接访问内部数据的，因此内部的数据在遍历的过程中无法被修改。为了保证不被修改，迭代器内部维护了一个标记 “modCount” ，当集合结构改变（添加删除或者修改），标记”modCount“会被修改，而迭代器每次的hasNext()和next()方法都会检查该”modCount“是否被改变，当检测到被修改时，抛出ConcurrentModificationException 单线程情况123456789101112131415public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0 ; i &lt; 10 ; i++ ) &#123; list.add(i + &quot;&quot;); &#125; Iterator&lt;String&gt; iterator = list.iterator(); int i = 0 ; while(iterator.hasNext()) &#123; if (i == 3) &#123; list.remove(3); &#125; System.out.println(iterator.next()); i ++; &#125;&#125; 上述代码是ArrayList单线程环境下的fail-fast ， 该段代码定义了一个Arraylist集合，并使用迭代器遍历，在遍历过程中，刻意在某一步迭代中remove一个元素，这个时候，就会发生fail-fast。 如果将以上代码修改成在next之后进行迭代器的remove操作，就不会报错。 1234567891011121314151617public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (int i = 0 ; i &lt; 10 ; i++ ) &#123; list.add(i + &quot;&quot;); &#125; Iterator&lt;String&gt; iterator = list.iterator(); int i = 0 ; while(iterator.hasNext()) &#123; System.out.println(iterator.next()); if (i == 3) &#123; iterator.remove(); // 在next之后进行迭代器的remove操作 &#125; i ++; &#125; System.out.println(list); &#125; 输出： 0123456789[0, 1, 2, 4, 5, 6, 7, 8, 9] ​ 所以，在对集合进行迭代过程中，不允许出现迭代器以外的对元素的操作， 因为这样会产生安全隐患，java会抛出异常并发修改异常ConcurrentModificationException， 普通迭代器只支持在迭代过程中的删除操作。 类似的，hashMap中发生的原理也是一样的。 HashMap发生fail-fast ： 12345678910111213141516public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); for (int i = 0 ; i &lt; 10 ; i ++ ) &#123; map.put(i+&quot;&quot;, i+&quot;&quot;); &#125; Iterator&lt;Entry&lt;String, String&gt;&gt; it = map.entrySet().iterator(); int i = 0; while (it.hasNext()) &#123; if (i == 3) &#123; map.remove(3+&quot;&quot;); &#125; Entry&lt;String, String&gt; entry = it.next(); System.out.println(&quot;key= &quot; + entry.getKey() + &quot; and value= &quot; + entry.getValue()); i++; &#125;&#125; 该段代码定义了一个hashmap对象并存放了10个键值对，在迭代遍历过程中，使用map的remove方法移除了一个元素，导致抛出了ConcurrentModificationException异常： ​ 类似，next之后调用迭代器的remove就可以成功删除。 多线程情况1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.ArrayList;import java.util.Iterator;import java.util.List;/** * @author Hongliang Zhu * @create 2020-02-10 12:53 */public class FailFastTest &#123; public static List&lt;String&gt; list = new ArrayList&lt;&gt;(); private static class MyThread1 extends Thread &#123; @Override public void run() &#123; Iterator&lt;String&gt; iterator = list.iterator(); while(iterator.hasNext()) &#123; String s = iterator.next(); System.out.println(this.getName() + &quot;:&quot; + s); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; super.run(); &#125; &#125; private static class MyThread2 extends Thread &#123; int i = 0; @Override public void run() &#123; while (i &lt; 10) &#123; System.out.println(&quot;thread2:&quot; + i); if (i == 2) &#123; list.remove(i); &#125; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; i ++; &#125; &#125; &#125; public static void main(String[] args) &#123; for(int i = 0 ; i &lt; 10;i++)&#123; list.add(i+&quot;&quot;); &#125; MyThread1 thread1 = new MyThread1(); MyThread2 thread2 = new MyThread2(); thread1.setName(&quot;thread1&quot;); thread2.setName(&quot;thread2&quot;); thread1.start(); thread2.start(); &#125;&#125; 启动两个线程，分别对其中一个对list进行迭代，另一个在线程1的迭代过程中去remove一个元素，结果也是抛出了java.util.ConcurrentModificationException 避免fail-fast方法一: 在单线程的遍历过程中，如果要进行`remove`操作，可以调用迭代器的`remove`方法而不是集合类的`remove`方法。看看ArrayList中迭代器的remove方法的源码: 1234567891011121314public void remove() &#123; if (lastRet &lt; 0) throw new IllegalStateException(); checkForComodification(); try &#123; ArrayList.this.remove(lastRet); cursor = lastRet; lastRet = -1; expectedModCount = modCount; /// 不会修改modCount，而是令其余expectedModCount相等 &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125;&#125; ​ 可以看到，该remove方法并不会修改modCount的值，并且不会对后面的遍历造成影响，因为该方法remove不能指定元素，只能remove当前遍历过的那个元素，所以调用该方法并不会发生fail-fast现象。该方法有局限性，就是上面说的，只能代用next方法之后再调用迭代器的remove方法。 方法二：安全失败 ​ 使用java并发包(java.util.concurrent)中的类来代替ArrayList 和hashMap。​ 比如使用 CopyOnWriterArrayList代替ArrayList，CopyOnWriterArrayList在是使用上跟ArrayList几乎一样，CopyOnWriter是写时复制的容器(COW)，在读写时是线程安全的。该容器在对add和remove等操作时，并不是在原数组上进行修改，而是将原数组拷贝一份，在新数组上进行修改，待完成后，才将指向旧数组的引用指向新数组，所以对于CopyOnWriterArrayList在迭代过程并不会发生fail-fast现象。但 CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。​ 对于HashMap，可以使用ConcurrentHashMap，ConcurrentHashMap采用了锁机制，是线程安全的。在迭代方面，ConcurrentHashMap使用了一种不同的迭代方式。在这种迭代方式中，当iterator被创建后集合再发生改变就不再是抛出ConcurrentModificationException，取而代之的是：在改变时new新的数据从而不影响原有的数据 ，iterator完成后再将头指针替换为新的数据 ，这样iterator线程可以使用原来老的数据，而写线程也可以并发的完成改变。即迭代不会发生fail-fast，但不保证获取的是最新的数据。 6. 安全失败（fail—safe） 快速失败（Fail-Fast）的场景： `java.util`包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改）。 ​ 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。比如上面说的COW **原理：**由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。 **缺点：**基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 ​ 场景：java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。 并发修改 ： 当一个或多个线程正在遍历一个集合Collection，此时另一个线程修改了这个集合的内容（添加，删除或者修改）。这就是并发修改 。 fail-safe机制有两个问题 （1）需要复制集合，产生大量的无效对象，开销大。 （2）无法保证读取的数据是目前原始数据结构中的数据。 7. fail-fast和 fail-safe 的区别 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModification Exception Yes No Clone object No Yes Memory Overhead No Yes Examples HashMap,Vector,ArrayList,HashSet CopyOnWriteArrayList, ConcurrentHashMap 二、 Vector123public class Vector&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable 也继承了RandomAccess接口， 可以随机访问。 1. 同步 **它的实现与 ArrayList 类似，但是使用了 `synchronized` 进行同步。** 12345678910111213public synchronized boolean add(E e) &#123; modCount++; ensureCapacityHelper(elementCount + 1); elementData[elementCount++] = e; return true;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 2 . 扩容​ Vector 的构造函数可以传入 capacityIncrement 参数，它的作用是在扩容时使容量 capacity 增长 capacityIncrement。如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。 1234567891011121314151617/** * Constructs an empty vector with the specified initial capacity and * capacity increment. 构造函数 * * @param initialCapacity 数组的初始容量 * @param capacityIncrement 扩容时使容量 `capacity` 增长 `capacityIncrement` * @throws IllegalArgumentException if the specified initial capacity * is negative */ public Vector(int initialCapacity, int capacityIncrement) &#123; super(); if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); this.elementData = new Object[initialCapacity]; this.capacityIncrement = capacityIncrement; &#125; 123456789101112private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // 如果这个参数的值小于等于 0，扩容时每次都令 capacity 为原来的两倍。 int newCapacity = oldCapacity + ((capacityIncrement &gt; 0) ? capacityIncrement : oldCapacity); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); elementData = Arrays.copyOf(elementData, newCapacity); &#125; ​ 调用没有 capacityIncrement 的构造函数时，capacityIncrement 值被设置为 0，也就是说默认情况下 Vector 每次扩容时容量都会翻倍。 1234567public Vector(int initialCapacity) &#123; this(initialCapacity, 0);&#125;public Vector() &#123; this(10);&#125; 3. 与ArrayList的比较 Vector 是同步的，因此开销就比 ArrayList 要大，访问速度更慢。最好使用 ArrayList 而不是 Vector，因为同步操作完全可以由程序员自己来控制； Vector 每次扩容请求其大小的 2 倍（也可以通过构造函数设置增长的容量），而 ArrayList 是 1.5 倍。 4. 替代方案 可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。 12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); 1234567891011public static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list) &#123; return (list instanceof RandomAccess ? new SynchronizedRandomAccessList&lt;&gt;(list) : new SynchronizedList&lt;&gt;(list)); &#125; static &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list, Object mutex) &#123; return (list instanceof RandomAccess ? new SynchronizedRandomAccessList&lt;&gt;(list, mutex) : new SynchronizedList&lt;&gt;(list, mutex)); &#125; 也可以使用 concurrent 并发包下的 CopyOnWriteArrayList 类。 1List&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); 三、 CopyOnWriteArrayList1. 读写分离写操作在一个复制的数组上进行，读操作还是在原始数组中进行，读写分离，互不影响。 写操作需要加锁，防止并发写入时导致写入数据丢失。 写操作结束之后需要把原始数组指向新的复制数组。 123456789101112131415161718192021222324252627282930/** * Appends the specified element to the end of this list. * 添加一个元素： 写操作 * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */ public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); // 加锁 try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); // 复制数组 newElements[len] = e; setArray(newElements); // 写操作结束之后需要把原始数组指向新的复制数组。 return true; &#125; finally &#123; lock.unlock(); // 去锁操作 &#125; &#125;final void setArray(Object[] a) &#123; array = a;&#125;@SuppressWarnings(&quot;unchecked&quot;)private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 2. 适用场景​ CopyOnWriteArrayList 在写操作的同时允许读操作，大大提高了读操作的性能，因此很适合读多写少的应用场景。 ​ 但是 CopyOnWriteArrayList 有其缺陷： 内存占用：在写操作时需要复制一个新的数组，使得内存占用为原来的两倍左右； 数据不一致：读操作不能读取实时性的数据，因为部分写操作的数据还未同步到读数组中。 所以 CopyOnWriteArrayList 不适合内存敏感以及对实时性要求很高的场景。 四、 Collections 与 Arrays集合框架中的工具类中的方法都是静态的 Collection中的常见方法： 对List进行二分查找： int binarySearch(list, key) ​ int binarySearch(list, key, Comparator) ​ 二分查找需要列表有序 对list集合进行排序 sort(list): 其实是使用list容器中对象的CompareTo方法 sort(list, comparator) //按照指定比较器进行排序 对集合取最大值或者最小值 ​ max（collection） min（collection） 对集合进行反转 ​ reverse(list) 对比较方式强行逆转 ​ Comparator reverseOrder(); ​ Comparator reverseOrder(Comparator); 对list中的元素的位置进行替换 ​ swap(list, x, y); 对集合中的元素进行替换， 如果被替换的元素不存在， 那么原来的集合不变 ​ replaceAll(list, old, new); 将集合变成数组 ​ Collection.toArray() 【collection不是Collections工具类】 Arrays： 用于对数组操作的工具类: Arrays.方法() 二分查找， 需要数组有序 binarySearch(int []) 数组排序 sort(int []) 将数组变成字符串 toString(int []) 复制数组 ​ copyOf() 复制部分数组 copyOfRange() 比较两个数组是否相同 equals(int [], int []) 将数组变成集合：List asList(T []) 这样可以通过结合的操作来操作数组中的元素，但是不可以死使用增删方法， add， remove，因为数组的长度固定，会出现UnsupportOperationException. 五、 LinkedList1. 概览​ 基于双向链表实现，使用 Node 存储链表节点信息。 123456789101112131415161718192021222324252627public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable&#123; transient int size = 0; /** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */ transient Node&lt;E&gt; first; /** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */ transient Node&lt;E&gt; last; /** * Constructs an empty list. */ public LinkedList() &#123; &#125; ...&#125; 每个链表存储了first和last指针，用Node来保存链表节点信息 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125; 2.与ArrayList的比较​ ArrayList 基于动态数组实现，LinkedList 基于双向链表实现。ArrayList 和 LinkedList 的区别可以归结为数组和链表的区别： 数组支持随机访问，但插入删除的代价很高，需要移动大量元素； 链表不支持随机访问，但插入删除只需要改变指针。 六、 HashMap为了便于理解，以下源码分析以 JDK 1.7 为主。 1. 存储结构内部包含了一个 Entry 类型的数组 table。Entry 存储着键值对。它包含了四个字段，从 next 字段我们可以看出 Entry 是一个链表。即数组中的每个位置被当成一个桶，一个桶存放一个链表。HashMap 使用拉链法来解决冲突，同一个链表中存放哈希值和散列桶取模运算结果相同的 Entry。 以下源码基于JDK1.7 1transient Entry[] table; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash; Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + &quot;=&quot; + getValue(); &#125;&#125; ​ HashMap中两个参数会影响他的性能：初始容量和装载因子。初始容量是指哈希表中桶的个数，即哈希表的大小； 装载因子是表示hash表中元素的填满的程度，装 载因子越大，填满的元素越多，好处是，空间利用率高了，但冲突的机会加大了；反之，加载因子越小，填满的元素越少，好处是冲突的机会减小了，但空间浪费多了。 ​ 冲突的机会越大，则查找的成本越高。反之，查找的成本越小，查找时间就越小。 因此，必须在 “冲突的机会”与”空间利用率”之间寻找一种平衡与折衷，这种平衡与折衷本质上是数据结构中有名的**”时-空”矛盾**的平衡与折衷。 ​ HashMap默认的装载因子是0.75，最大容量是16，因此可以得出HashMap的默认容量是：0.75*16=12。 用户可以自定义最大容量和装载因子。 ​ HashMap 包含如下几个构造器： HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。 HashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。 HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。 2. 拉链法工作原理1234HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();map.put(&quot;K1&quot;, &quot;V1&quot;);map.put(&quot;K2&quot;, &quot;V2&quot;);map.put(&quot;K3&quot;, &quot;V3&quot;); 新建一个 HashMap，默认大小为 16； 插入 &lt;K1,V1&gt; 键值对，先计算 K1 的 hashCode 为 115，使用除留余数法得到所在的桶下标 115%16=3。 插入 &lt;K2,V2&gt; 键值对，先计算 K2 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6。 插入 &lt;K3,V3&gt; 键值对，先计算 K3 的 hashCode 为 118，使用除留余数法得到所在的桶下标 118%16=6，插在 &lt;K2,V2&gt; 前面。 ​ 应该注意到链表的插入是以头插法方式进行的，例如上面的 &lt;K3,V3&gt; 不是插在 &lt;K2,V2&gt; 后面，而是插入在链表头部。查找需要分成两步进行： 计算键值对所在的桶； 在链表上顺序查找，时间复杂度显然和链表的长度成正比。 ​ 3. put操作1234567891011121314151617181920212223242526public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 键为 null 单独处理 if (key == null) return putForNullKey(value); int hash = hash(key); // 确定桶下标 int i = indexFor(hash, table.length); // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 插入新键值对 addEntry(hash, key, value, i); return null;&#125; HashMap 允许插入键为 null 的键值对。但是因为无法调用 null 的 hashCode() 方法，也就无法确定该键值对的桶下标，只能通过强制指定一个桶下标来存放。HashMap 使用第 0 个桶存放键为 null 的键值对。 1234567891011121314private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; ​ 使用链表的头插法，也就是新的键值对插在链表的头部，而不是链表的尾部。 12345678910111213141516void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; // 头插法，链表头部指向新的键值对 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 123456Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h;&#125; 在JDK1.8中的put操作： 思路如下： 1.table[]是否为空 2.判断table[i]处是否插入过值 3.判断链表长度是否大于8，如果大于就转换为红黑二叉树，并插入树中 4.判断key是否和原有key相同，如果相同就覆盖原有key的value，并返回原有value 5.如果key不相同，就插入一个key，记录结构变化一次 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Implements Map.put and related methods * * @param hash hash for key * @param key the key * @param value the value to put * @param onlyIfAbsent if true, don&#x27;t change existing value * @param evict if false, the table is in creation mode. * @return previous value, or null if none */ final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //判断table是否为空，如果是空的就创建一个table，并获取他的长度 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果计算出来的索引位置之前没有放过数据，就直接放入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; //进入这里说明索引位置已经放入过数据了 Node&lt;K,V&gt; e; K k; //判断put的数据和之前的数据是否重复 //key的地址或key的equals()只要有一个相等就认为key重复了，就直接覆盖原来key的value if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) //判断是否是红黑树，如果是红黑树就直接插入树中 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //如果不是红黑树，就遍历每个节点，判断链表长度是否大于8，如果大于就转换为红黑树 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 转换为红黑树 break; &#125; // 判断索引每个元素的key是否可要插入的key相同，如果相同就直接覆盖 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果e不是null，说明没有迭代到最后就跳出了循环，说明链表中有相同的key，因此只需要将value覆盖，并将oldValue返回即可 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //说明没有key相同，因此要插入一个key-value，并记录内部结构变化次数 ++modCount; if (++size &gt; threshold) // 扩容 resize(); afterNodeInsertion(evict); // 这个是给LinkedHashMap用的，HashMap里也是个空实现 return null; // 添加成功返回null &#125; get方法1234567891011121314151617181920212223242526272829303132public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; /** * Implements Map.get and related methods * * @param hash hash for key * @param key the key * @return the node, or null if none */ final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 4. 确定桶下标 很多操作都需要先确定一个键值对所在的桶下标。 12int hash = hash(key);int i = indexFor(hash, table.length); 4.1 计算 hash 值（1.7）1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 123public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value);&#125; 4.2 取模 令 x = 1&lt;&lt;4，即 x 为 2 的 4 次方，它具有以下性质： 12x : 00010000x-1 : 00001111 令一个数 y 与 x-1 做与运算，可以去除 y 位级表示的第 4 位以上数： 123y : 10110010x-1 : 00001111y&amp;(x-1) : 00000010 这个性质和 y 对 x 取模效果是一样的： 123y : 10110010x : 00010000y%x : 00000010 我们知道，位运算的代价比求模运算小的多，因此在进行这种计算时用位运算的话能带来更高的性能。 确定桶下标的最后一步是将 key 的 hash 值对桶个数取模：hash%capacity，如果能保证 capacity 为 2 的 n 次方，那么就可以将这个操作转换为位运算。 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 4.4 在JDK1.8中的hash方法 hash()方法其实顾名思义就是用来获取key的hash的一个hash值的,但是HashMap里的hash()方法似乎与一般的直接key.hashCode()不太一样，我们先看看它到底是什么样的神奇操作。 其源码如下: 12345static final int hash(Object key) &#123; int h; // key是null就返回0，key不是null就先取hashCode（）然后与这个hashCode（）无符号右移进行亦或运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // 将hashCode的值异或他的高16位获取到hash值&#125; ​ 这是因为找key的位置时，(n - 1) &amp; hash是table的索引，n的长度不够大时，只和hashCode()的低16位有关，这样发生冲突的概率就变高 ​ 为减少这种影响，设计者权衡了speed, utility, and quality，将高16位与低16位异或来减少这种影响。设计者考虑到现在的hashCode分布的已经很不错了，而且当发生较大碰撞时也用树形存储降低了冲突。仅仅异或一下，既减少了系统的开销，也不会造成的因为高16位没有参与下标的计算(table长度比较小时)而引起的碰撞。 ​ 我们知道hashCode本身是一个32位的int类型，进行这样的操作就等于将hashCode的高16位异或它的低16位得到一个新的hash值。 但是拿到这样一个hash值的作用是什么呢？我们可以先想一下如何利用key的hash值确定每个key的哈希桶索引位置而且还需要尽量均衡。第一个想到的当然是用hash值对哈希桶的长度(length)进行取模的操作。即: index = hash % length 这种方式可以用随机的hash值算出随机的索引并且分配也尽量均匀。没错！!HashMap也是这么想的。但是这种取模运算本身是对CPU运算开销比较大的，为了优化速度，HashMap采取了更优雅的方式，在putVal的核心代码可以看到HashMap采用了hash值”与”length-1的方式来确定索引位置。即： ​ index = hash &amp; length-1 hash()方法中的高16位异或16位的计算方式，是在JDK1.8之后才加上的，在JDK1.7及之前的版本里是indexFor()方法，直接用hashCode&amp;length-1计算出索引位置。这个是jdk1.7和jdk1.8中的区别。 5. 扩容-基本原理设 HashMap 的 table 长度为 M，需要存储的键值对数量为 N，如果哈希函数满足均匀性的要求，那么每条链表的长度大约为 N/M，因此查找的复杂度为 O(N/M)。 为了让查找的成本降低，应该使 N/M 尽可能小，因此需要保证 M 尽可能大，也就是说 table 要尽可能大。HashMap 采用动态扩容来根据当前的 N 值来调整 M 值，使得空间效率和时间效率都能得到保证。 和扩容相关的参数主要有：capacity、size、threshold 和 load_factor。 参数 含义 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size 键值对数量。 threshold size 的临界值，当 size 大于等于 threshold 就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = (int)(capacity* loadFactor)。 12345678910111213141516static final int DEFAULT_INITIAL_CAPACITY = 16; // 默认的初始容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; // 最大容量 2 的 30次方static final float DEFAULT_LOAD_FACTOR = 0.75f; // 默认的装载因子为0.75transient Entry[] table;transient int size; // size就是HashMap中键值对的总个数。int threshold; // size 的临界值final float loadFactor;transient int modCount; // 记录是发生内部结构变化的次数， fail-fast需要用 // 如果put值，但是put的值是覆盖原有的值，这样是不算内部结构变化的。 ​ threshold=装载因子 * capacity ，也就是说数组长度固定以后， 如果负载因子越大，所能容纳的元素个数越多，如果超过这个值就会进行扩容(默认是扩容为原来的2倍)，0.75这个值是权衡过空间和时间得出的，建议大家不要随意修改，如果在一些特殊情况下，比如空间比较多，但要求速度比较快，这时候就可以把扩容因子调小以较少hash冲突的概率。相反就增大扩容因子(这个值可以大于1)。 ​ 因为HashMap扩容每次都是扩容为原来的2倍，所以capacity 总是2的次方，这是非常规的设置，常规设置是把桶的大小设置为素数，因为素数发生hash冲突的概率要小于合数，比如HashTable的默认值设置为11，就是桶的大小为素数的应用(HashTable扩容后不能保证是素数)。HashMap采用这种设置是为了在取模和扩容的时候做出优化。 从下面的添加元素代码中可以看出，当需要扩容时，令 capacity 为原来的两倍。 123456void addEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); if (size++ &gt;= threshold) resize(2 * table.length); // 两倍扩容&#125; 扩容使用 resize() 实现，需要注意的是，扩容操作同样需要把 oldTable 的所有键值对重新插入 newTable 中，因此这一步是很费时的。 1234567891011121314151617181920212223242526272829303132void resize(int newCapacity) &#123;// 传入新的容量 Entry[] oldTable = table; // 引用扩容前的Entry数组 int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; //扩容前的数组大小如果已经达到最大(2^30)了 threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了 return; &#125; Entry[] newTable = new Entry[newCapacity]; //初始化一个新的Entry数组 transfer(newTable); //！！将数据转移到新的Entry数组里 table = newTable; //HashMap的table属性引用新的Entry数组 threshold = (int)(newCapacity * loadFactor); //修改阈值&#125;/* 这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。 */void transfer(Entry[] newTable) &#123; Entry[] src = table; //src引用了旧的Entry数组 int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组 Entry&lt;K,V&gt; e = src[j]; //取得旧Entry数组的每个元素 if (e != null) &#123; src[j] = null; //释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象） do &#123; Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置 e.next = newTable[i]; //标记[1] newTable[i] = e; //将元素放在数组上 e = next; //访问下一个Entry链上的元素 &#125; while (e != null); &#125; &#125;&#125; ​ newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。 ​ 下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。 ​ 下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。 ​ 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化： ​ 因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图： ​ 这个设计确实非常的巧妙，既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了。这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 6. 扩容-重新计算桶下标​ 在进行扩容时，需要把键值对重新计算桶下标，从而放到对应的桶上。在前面提到，HashMap 使用 hash%capacity 来确定桶下标。HashMap capacity 为 2 的 n 次方这一特点能够极大降低重新计算桶下标操作的复杂度。 ​ 假设原数组长度 capacity 为 16，扩容之后 new capacity 为 32： 12capacity : 00010000new capacity : 00100000 对于一个 Key，它的哈希值 hash 在第 5 位： 为 0，那么 hash%00010000 = hash%00100000，桶位置和原来一致； 为 1，hash%00010000 = hash%00100000 + 16，桶位置是原位置 + 16。 7. 计算数组容量​ 这里先了解一下基本的位运算 运算符 计算方式 与 &amp; 只有两个数同一位都是1才会返回1 或 l 两个数同一位只要存在一个1就是1 异或 ^ 两个数同一位不能相同才为1 左移 &lt;&lt; 所有位置左移，低位补0 右移 &gt;&gt; 正数：所有位置右移，高位补0 负数：写出补码（符号位不变，其余位置取反，然后加1），所有位置右移高位补1，然后再获取原码（符号位不变，其余位置取反，然后加1） 无符号右移 &gt;&gt; 无论正负高位补0 ​ HashMap 构造函数允许用户传入的容量不是 2 的 n 次方，因为它可以自动地将传入的容量转换为 2 的 n 次方。先考虑如何求一个数的掩码，对于 10010000，它的掩码为 11111111，可以使用以下方法得到： 用num与num左移的数字做或运算赋给num 。 123mask |= mask &gt;&gt; 1 11011000mask |= mask &gt;&gt; 2 11111110mask |= mask &gt;&gt; 4 11111111 mask+1 是大于原始数字的最小的 2 的 n 次方。 12num 10010000mask+1 100000000 以下是 HashMap 中计算数组容量的代码： 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 8. 链表转红黑树从 JDK 1.8 开始，一个桶存储的链表长度大于等于 8 时会将链表转换为红黑树。 参考 https://cyc2018.github.io/CS-Notes 超详细的HashMap解析(jdk1.8) HashMap JDK1.8实现原理 java中的fail-fast(快速失败)机制 面试题思考：java中快速失败(fail-fast)和安全失败(fail-safe)的区别是什么？ Java 8系列之重新认识HashMap","path":"2020/02/01/Java-集合框架/","date":"02-01","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"https://castile.github.io/tags/Java%E5%9F%BA%E7%A1%80/"}]},{"title":"leetcode-399-除法求值","text":"描述 给出方程式 A / B = k, 其中 A 和 B 均为代表字符串的变量， k 是一个浮点型数字。根据已知方程式求解问题，并返回计算结果。如果结果不存在，则返回 -1.0。 示例 :给定 a / b = 2.0, b / c = 3.0问题: a / c = ?, b / a = ?, a / e = ?, a / a = ?, x / x = ?返回 [6.0, 0.5, -1.0, 1.0, -1.0 ] 输入为: vector&lt;pair&lt;string, string&gt;&gt; equations, vector&amp; values, vector&lt;pair&lt;string, string&gt;&gt; queries(方程式，方程式结果，问题方程式)， 其中 equations.size() == values.size()，即方程式的长度与方程式结果长度相等（程式与结果一一对应），并且结果值均为正数。以上为方程式的描述。 返回vector类型。 基于上述例子，输入如下： equations(方程式) = [ [“a”, “b”], [“b”, “c”] ],values(方程式结果) = [2.0, 3.0],queries(问题方程式) = [ [“a”, “c”], [“b”, “a”], [“a”, “e”], [“a”, “a”], [“x”, “x”] ].输入总是有效的。你可以假设除法运算中不会出现除数为0的情况，且不存在任何矛盾的结果。链接：https://leetcode-cn.com/problems/evaluate-division 此题难度为中等，但是我做了一天….， 太菜了。。。对于我来说还是比较复杂的题目了。 分析 dfs：使用深度优先搜索就比较直观。每个字母相当于一个节点，在给定的equations中建立合适的数据结构，建图，要求方程式的结果相当于求两个节点之间是否可以到达，可以到达则求出其代价，不能到达就设为-1.0. 我觉得此题的关键就是建图。 a/c = (a/b) * (b/c)，所以我们可以用图来解决 。 并查集： 比较特殊，在路径压缩那块比较复杂。。。以后补上吧 代码Leetcode AC 代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123; public double[] calcEquation(List&lt;List&lt;String&gt;&gt; equations, double[] values, List&lt;List&lt;String&gt;&gt; queries) &#123; // 使用map的数据结构更好 // 表示 a-&gt;b 的权重 即 a / b 的值 Map&lt;String, Map&lt;String, Double&gt;&gt; g = new HashMap&lt;&gt;(); buildGraph(g, equations, values); double[] res = new double[queries.size()]; Arrays.fill(res, -1.0); int index= 0 ; for(List&lt;String&gt; q: queries)&#123; String a = q.get(0); String b = q.get(1); if(!g.containsKey(a) || !g.containsKey(b))&#123; index++; &#125;else&#123; dfs(g, a, b, res, new HashSet&lt;&gt;(), index, 1.0); index++; &#125; &#125; return res; &#125; // 建图 private void buildGraph(Map&lt;String, Map&lt;String, Double&gt;&gt; g, List&lt;List&lt;String&gt;&gt; equations, double[] values)&#123; int index = 0; for(List&lt;String&gt; e: equations)&#123; String a = e.get(0); String b = e.get(1); g.putIfAbsent(a, new HashMap&lt;&gt;()); g.putIfAbsent(b, new HashMap&lt;&gt;()); g.get(a).put(b, values[index]); // a / b g.get(b).put(a, 1.0 / values[index]); // b / a index++; g.get(a).put(a, 1.0); g.get(b).put(b, 1.0); &#125; &#125; private void dfs(Map&lt;String, Map&lt;String, Double&gt;&gt; g, String a, String b, double[] res, Set&lt;String&gt; visited, int index, double tmp) &#123; visited.add(a); if(g.get(a) == null || g.get(a).size() == 0)&#123; // 说明a没有与其他点相连 return; &#125; if(g.get(a).containsKey(b))&#123; // 刚好有a-&gt;b的路径 res[index] = g.get(a).get(b) * tmp; return; &#125; for(String next: g.get(a).keySet())&#123; if(visited.contains(next)) continue; dfs(g, next, b, res, visited, index, g.get(a).get(next)*tmp); &#125; &#125;&#125; 还有一些问题未解决，比如下面是自己写的代码，在idea上运行没毛病，但是在leetcode上就出错了。具体原因不详，欢迎大家提出问题进行交流，不胜感激！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101class Solution_DFS&#123; public double[] calcEquation(List&lt;List&lt;String&gt;&gt; equations, double[] values, List&lt;List&lt;String&gt;&gt; queries) &#123; Map&lt;String, Map&lt;String, Double&gt;&gt; g = new HashMap&lt;&gt;(); // 图 bulidGraph(g, equations, values); double[] res = new double[queries.size()]; // 结果集合 Arrays.fill(res, -1.0); // 全部设置成-1.0； int index = 0; // 遍历问题式子 for(List&lt;String&gt; q: queries)&#123; String a = q.get(0); String b = q.get(1); if(!g.containsKey(a) || !g.containsKey(b))&#123; index++; &#125;else &#123; dfs(g, a, b, res, index, new HashSet&lt;&gt;(), 1.0); index++; &#125; &#125; return res; &#125; // 下面这个方法在leetcode行不通 public double[] calcEquation_dfs(List&lt;List&lt;String&gt;&gt; equations, double[] values, List&lt;List&lt;String&gt;&gt; queries) &#123; Map&lt;String, Map&lt;String, Double&gt;&gt; g = new HashMap&lt;&gt;(); bulidGraph(g, equations, values); int index = 0; double[] ans = new double[queries.size()]; for (List&lt;String&gt; q: queries)&#123; String x = q.get(0); String y = q.get(1); if(!g.containsKey(x) || !g.containsKey(y))&#123; ans[index] = -1.0; index++; continue; &#125; HashSet&lt;String&gt; visited = new HashSet&lt;&gt;(); ans[index] = divide(x, y, g, visited); index++; &#125; return ans; &#125; // get a / b private double divide(String a, String b, Map&lt;String, Map&lt;String, Double&gt;&gt; g, Set&lt;String&gt; visitied)&#123; if( a == b)&#123; return 1.0; &#125; visitied.add(a); for(String next: g.get(a).keySet())&#123; if(visitied.contains(next)) continue; double d = divide(next, b, g, visitied); // d = next / b // a /b = next /b * a / next if(d &gt; 0) return d * g.get(a).get(next); &#125; return -1.0; &#125; private void dfs(Map&lt;String, Map&lt;String, Double&gt;&gt; g, String a, String b, double[] res, int index, Set&lt;String&gt; visited, double tmp)&#123; visited.add(a); if(g.get(a) == null || g.get(a).size() == 0)&#123; return; &#125; if(g.get(a).containsKey(b)) &#123; // 刚好存在 a-&gt;b res[index] = g.get(a).get(b) * tmp; return; &#125; for(String next: g.get(a).keySet())&#123; if(visited.contains(next)) continue; dfs(g, next, b, res, index, visited, g.get(a).get(next) * tmp); &#125; &#125; private void bulidGraph(Map&lt;String, Map&lt;String, Double&gt;&gt; g , List&lt;List&lt;String&gt;&gt; equations, double[] values)&#123; int index = 0; for(List&lt;String&gt; e: equations)&#123; String a = e.get(0); String b = e.get(1); g.putIfAbsent(a, new HashMap&lt;&gt;()); g.putIfAbsent(b, new HashMap&lt;&gt;()); g.get(a).put(b, values[index]); // a -&gt; b : a / b g.get(b).put(a, 1.0 / values[index]); // b -&gt; a : b / a; index++; g.get(a).put(a, 1.0); g.get(b).put(b, 1.0); // 自己到自己的权重为1 &#125; &#125;&#125;","path":"2020/01/31/leetcode-399-除法求值/","date":"01-31","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-547-朋友圈","text":"描述 Leetcode547：Friend_Circles 朋友圈 班上有 N 名学生。其中有些人是朋友，有些则不是。他们的友谊具有是传递性。如果已知 A 是 B 的朋友，B 是 C 的朋友，那么我们可以认为 A 也是 C 的朋友。所谓的朋友圈，是指所有朋友的集合。 给定一个 N * N 的矩阵 M，表示班级中学生之间的朋友关系。如果M[i][j] = 1，表示已知第 i 个和 j 个学生互为朋友关系，否则为不知道。你必须输出所有学生中的已知的朋友圈总数。 示例 1: 输入:[[1,1,0], [1,1,0], [0,0,1]]输出: 2说明：已知学生0和学生1互为朋友，他们在一个朋友圈。第2个学生自己在一个朋友圈。所以返回2。示例 2: 输入:[[1,1,0], [1,1,1], [0,1,1]]输出: 1说明：已知学生0和学生1互为朋友，学生1和学生2互为朋友，所以学生0和学生2也是朋友，所以他们三个在一个朋友圈，返回1。注意： N 在[1,200]的范围内。对于所有学生，有M[i][i] = 1。如果有M[i][j] = 1，则有M[j][i] = 1。 链接：https://leetcode-cn.com/problems/friend-circles 并查集、dfs、bfs 分析 并查集：转化为求连通个数。 好友关系可以看成是一个无向图，例如第 0 个人与第 1 个人是好友， 那么 M[0][1]和 M[1][0]的值都为 1。 很简单直观。 并查集： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 并查集 UFpublic class UF &#123; private int count = 0; // 连通分量 private int[] parent; // 新增一个数组记录树的“重量” private int[] size; // 构造 public UF(int n)&#123; // n个元素 this.count = n; size = new int[n]; parent = new int[n]; // 一开始每一个节点自成一个集合，都不连通 for (int i = 0; i &lt; n; i++)&#123; parent[i] = i; // 自己的父节点指向自己 size[i] = 1; // 每隔几何只有自身一个元素 &#125; &#125; public int find(int x)&#123; int root = parent[x]; while (parent[x] != x)&#123; // 路径压缩 x = parent[x]; &#125; return x; &#125; public boolean isSameSet(int a, int b)&#123; return find(a) == find(b); &#125; public int count()&#123; return count; &#125; public void union(int a, int b)&#123; int rootA = find(a); int rootB = find(b); if(rootA == rootB)&#123; return; // 同一个集合不能合并 &#125;else&#123; if(size[rootA] &gt; size[rootB])&#123; parent[rootB] = rootA; size[rootA] += size[rootB]; &#125;else &#123; parent[rootA] = rootB; size[rootB] += size[rootA]; &#125; &#125; count--; // 连通分量个数减一 &#125;&#125; dfs： 给定的矩阵可以看成图的邻接矩阵。这样我们的问题可以变成无向图连通块的个数。 M= [1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1] ​ 如果我们把 M 看成图的邻接矩阵，则图为： ​ 在这个图中，点的编号表示矩阵 M 的下标，i 和 j之间有一条边当且仅当M[i][j]为 1。 ​ 为了找到连通块的个数，一个简单的方法就是使用深度优先搜索，从每个节点开始，我们使用一个大 小为 N 的 visited数组（M大小为 N×N ），这样 visited[i] 表示第 i 个元素是否被深度优先搜索访问过。每使 用一次深度优先搜索，即重新选择了一个点进行dfs，连通分量的个数就加一。 bfs: 方法与dfs类似，只是遍历方式是层次遍历， 使用的数据结构是队列。在广度优先搜索中，我们从一个特定点开始，访问所有邻接的节点。然后对于这些邻接节点，我们依然通过访问邻接节点的方式，知道访问所有可以到达的节点。因此，我们按照一层一层的方式访问节点。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126package search;import java.util.LinkedList;import java.util.Queue;/** * @author Hongliang Zhu * @create 2020-01-29 20:57 */public class leetcode547_FriendCircles &#123; // 深度优先 public static void dfs(int[][] M, int[] visited, int i) &#123; for (int j = 0; j &lt; M.length; j++) &#123; if (M[i][j] == 1 &amp;&amp; visited[j] == 0) &#123; // 是连通的并且还未访问 visited[j] = 1; dfs(M, visited, j); &#125; &#125; &#125; public static int findCircleNum_DFS(int[][] M) &#123; int count = 0; int n = M.length; int[] visited = new int[n]; for (int i = 0; i &lt; n; i++) &#123; if (visited[i] == 0) &#123; dfs(M, visited, i); count++; // 执行一次dfs表示增加了一个连通块 &#125; &#125; return count; &#125; /* 下面使用并查集 */ static int []parents; static int []size; static int count1 = 0; // 连通分量 public static void makeSet(int n)&#123; parents = new int[n]; size = new int[n]; count1 = n; for(int i = 0; i &lt; n; i++)&#123; size[i] = 1; parents[i] = i; &#125; &#125; public static int find(int a)&#123; int root = parents[a]; while(root!= parents[root])&#123; root = parents[root]; &#125; return root; &#125; public static void union(int a, int b)&#123; int roota = find(a); int rootb = find(b); if(roota != rootb)&#123; if(size[roota] &gt; size[rootb])&#123; parents[rootb] = roota; size[roota] = size[roota]+size[rootb]; &#125;else&#123; parents[roota] = rootb; size[rootb] = size[roota]+size[rootb]; &#125; count1--; &#125; &#125; public static int findCircleNum(int[][] M) &#123; int n = M.length; makeSet(n); for(int i = 0; i&lt; n; i++)&#123; for( int j = i+1; j &lt; n; j++)&#123; if(M[i][j] == 1)// 朋友 &#123; union(i, j); &#125; &#125; &#125; return count1; // 返回连通分量的个数 &#125; // 广度优先遍历 public static int findCircleNum_BFS(int[][] M) &#123; int n = M.length; int count = 0; int[] visited = new int[n]; Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); for(int i = 0; i &lt; n; i++)&#123; if(visited[i] == 0)&#123; queue.add(i); while (!queue.isEmpty())&#123; int k = queue.remove(); visited[k] = 1; for(int j = 0; j &lt; n; j++)&#123; if(M[k][j] == 1 &amp;&amp; visited[j] == 0) queue.add(j); &#125; &#125; count++; &#125; &#125; return count; &#125; public static void main(String[] args) &#123; int[][] M = &#123;&#123;1, 1, 0&#125;, &#123;1, 1, 0&#125;, &#123;0, 0, 1&#125;&#125;; System.out.println(findCircleNum_DFS(M)); // 2 System.out.println(findCircleNum_BFS(M));// 2 System.out.println(findCircleNum(M));// 2 &#125;&#125; 注： 使用并查集速度最快。","path":"2020/01/30/leetcode-547-朋友圈/","date":"01-30","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"bfs","slug":"bfs","permalink":"https://castile.github.io/tags/bfs/"}]},{"title":"Java关键字","text":"final1. 数据声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 1234final int x = 1;// x = 2; // cannot assign value to final variable &#x27;x&#x27;final A y = new A();y.a = 1; 2. 方法声明方法不能被子类重写。 private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。 3. 类声明类不允许被继承。 static1. 静态变量 静态变量：又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它。静态变量在内存中只存在一份。 实例变量：每创建一个实例就会产生一个实例变量，它与该实例同生共死。 123456789101112public class A &#123; private int x; // 实例变量 private static int y; // 静态变量 public static void main(String[] args) &#123; // int x = A.x; // Non-static field &#x27;x&#x27; cannot be referenced from a static context A a = new A(); int x = a.x; int y = A.y; &#125;&#125; 2. 静态方法静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // Illegal combination of modifiers: &#x27;abstract&#x27; and &#x27;static&#x27;&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字，因此这两个关键字与具体对象关联。 即静态域中不能访问非静态的，因为静态的变量是先于对象（或者非静态）出现。 1234567891011public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // Non-static field &#x27;y&#x27; cannot be referenced from a static context // int b = this.y; // &#x27;A.this&#x27; cannot be referenced from a static context &#125;&#125; 3. 静态语句块静态语句块在类初始化时运行一次。 123456789101112public class A &#123; static &#123; System.out.println(&quot;123&quot;); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125;// 结果只输出一次“123” 4. 静态内部类内部类 大部分时候，类被定义成一个独立的程序单元。在某些情况下，也会把一个类放在另一个类的内部定义，这个定义在其他类内部的类就被称为内部类（有些地方也叫做嵌套类），包含内部类的类也被称为外部类（有些地方也叫做宿主类） 内部类的作用 更好的封装性 内部类成员可以直接访问外部类的私有数据，因为内部类被当成其外部类成员，但外部类不能访问内部类的实现细节，例如内部类的成员变量 匿名内部类适合用于创建那些仅需要一次使用的类 使用static来修饰一个内部类，则这个内部类就属于外部类本身，而不属于外部类的某个对象。称为静态内部类（也可称为类内部类），这样的内部类是类级别的，static关键字的作用是把类的成员变成类相关，而不是实例相关 。 注意： 非静态内部类中不允许定义静态成员 外部类的静态成员不可以直接使用非静态内部类 静态内部类，不能访问外部类的实例成员，只能访问外部类的类成员 在建造者模式中有使用，具体可以参考链接 非静态内部类依赖于外部类的实例，也就是说需要先创建外部类实例，才能用这个实例去创建非静态内部类。而静态内部类不需要。 123456789101112131415public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // &#x27;OuterClass.this&#x27; cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125;Copy to clipboardErrorCopied 静态内部类不能访问外部类的非静态的变量和方法。 5. 静态导包在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 一般我们导入一个类都用 import com…..ClassName; 而静态导入是这样：import static com…..ClassName.*; 这里的多了个static，还有就是类名ClassName后面多了个.* ，意思是导入这个类里的静态方法。当然，也可以只导入某个静态方法，只要把 .* 换成静态方法名就行了。然后在这个类中，就可以直接用方法名调用静态方法，而不必用ClassName.方法名 的方式来调用。 好处： 这种方法的好处就是可以简化一些操作，例如打印操作System.out.println(…); 就可以将其写入一个静态方 法print(…)，在使用时直接print(…)就可以了。但是这种方法建议在有很多重复调用的时候使用，如果仅有一到两次调用，不如直接写来的方便。 1234567891011121314151617import static java.lang.System.out;/** * @author Hongliang Zhu * @create 2020-01-29 10:40 */public class keywords &#123; static &#123; out.println(&quot;hello&quot;); &#125; public static void main(String[] args) &#123; &#125;&#125; 6. 初始化顺序静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 1public static String staticField = &quot;静态变量&quot;; 123static &#123; System.out.println(&quot;静态语句块&quot;);&#125; 1public String field = &quot;实例变量&quot;; 123&#123; System.out.println(&quot;普通语句块&quot;);&#125; 最后才是构造函数的初始化 123public InitialOrderTest() &#123; System.out.println(&quot;构造函数&quot;);&#125; 存在继承的情况下，初始化顺序为： 父类（静态变量、静态语句块） 子类（静态变量、静态语句块） 父类（实例变量、普通语句块） 父类（构造函数） 子类（实例变量、普通语句块） 子类（构造函数） 参考 https://cyc2018.github.io/CS-Notes https://blog.csdn.net/cd18333612683/article/details/79129503 https://blog.csdn.net/u012338954/article/details/51010337","path":"2020/01/29/Java关键字/","date":"01-29","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"Java基础","slug":"Java基础","permalink":"https://castile.github.io/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"关键字","slug":"关键字","permalink":"https://castile.github.io/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"}]},{"title":"leetcode-990-等式方程的可满足性","text":"描述 给定一个由表示变量之间关系的字符串方程组成的数组，每个字符串方程 equations[i] 的长度为 4，并采用两种不同的形式之一：”a==b” 或 “a!=b”。在这里，a 和 b 是小写字母（不一定不同），表示单字母变量名。只有当可以将整数分配给变量名，以便满足所有给定的方程时才返回 true，否则返回 false。 示例 1： 输入：[“a==b”,”b!=a”]输出：false解释：如果我们指定，a = 1 且 b = 1，那么可以满足第一个方程，但无法满足第二个方程。没有办法分配变量同时满足这两个方程。示例 2： 输出：[“b==a”， “a==b”]输入：true解释：我们可以指定 a = 1 且 b = 1 以满足满足这两个方程。示例 3： 输入：[“a==b”,”b==c”,”a==c”]输出：true示例 4： 输入：[“a==b”, “b!=c”,”c==a”]输出：false示例 5： 输入：[“c==c”, “b==d”, “x!=z”]输出：true 链接：https://leetcode-cn.com/problems/satisfiability-of-equality-equations 分析 根据等式的传递性，可以想到使用并查集非常快速可以解决此题。动态连通性其实就是一种等价关系，具有「自反性」「传递性」和「对称性」，其实 == 关系也是一种等价关系，具有这些性质。所以这个问题用 Union-Find 算法就很自然。 核心思想是，将 equations 中的算式根据 == 和 != 分成两部分，先处理 == 算式，使得他们通过相等关系各自勾结成门派；然后处理 != 算式，检查不等关系是否破坏了相等关系的连通性。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.ArrayList;import java.util.Stack;/** * @author Hongliang Zhu * @create 2020-01-28 21:28 */public class leetcode990_SatisfiabilityOfEqualityEquations &#123; // 并查集 public static boolean equationsPossible(String[] equations) &#123; UF uf = new UF(26); // 26个字母 // 所有等式连通 for (String eq : equations) &#123; if (eq.charAt(1) == &#x27;=&#x27;) &#123; // 判断为等式 char x = eq.charAt(0); char y = eq.charAt(3); uf.union(x - &#x27;a&#x27;, y - &#x27;a&#x27;); &#125; &#125; // 判断不等式会不会破坏连通性 for (String eq : equations) &#123; if (eq.charAt(1) == &#x27;!&#x27;) &#123; // 判断为不等式 char x = eq.charAt(0); char y = eq.charAt(3); if (uf.isSameSet(x - &#x27;a&#x27;, y - &#x27;a&#x27;)) &#123; return false; &#125; &#125; &#125; return true; &#125; public static void main(String[] args) &#123; String[] equations1 = &#123;&quot;c==c&quot;, &quot;b==d&quot;, &quot;x!=z&quot;&#125;; System.out.println(equationsPossible(equations1)); // true String[] equations2 = &#123;&quot;a==b&quot;, &quot;b==c&quot;, &quot;a==c&quot;&#125;; System.out.println(equationsPossible(equations2)); // true String[] equations3 = &#123;&quot;b==a&quot;, &quot;a!=b&quot;&#125;; System.out.println(equationsPossible(equations3)); // fasle &#125;&#125; dfs，图的联通性，染色问题，这是leetcode官方题解： ​ 思路： 所有相互等于的变量能组成一个联通分量。举一个例子，如果 a=b, b=c, c=d，那么 a, b, c, d 就在同一个联通分量中，因为它们必须相等。 ​ 第一步，我们基于给定的等式，用深度优先遍历将每一个变量按照联通分量染色。 ​ 将联通分量染色之后，我们分析形如 a != b 的不等式。如果两个分量有相同的颜色，那么它们一定相等，因此 如果说它们不相等的话，就一定无法满足给定的方程组。返回false。 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import java.util.ArrayList;import java.util.Stack;/** * @author Hongliang Zhu * @create 2020-01-28 21:28 */public class leetcode990_SatisfiabilityOfEqualityEquations &#123; //连通 染色 public static boolean equationsPossible_DFS(String[] equations) &#123; ArrayList&lt;Integer&gt;[] graph = new ArrayList[26]; // 26个字母 // 初始化 for (int i = 0; i &lt; 26; i++) &#123; graph[i] = new ArrayList&lt;Integer&gt;(); &#125; // 等式进行连通 for (String eq : equations) &#123; if (eq.charAt(1) == &#x27;=&#x27;) &#123; char x = eq.charAt(0); char y = eq.charAt(3); graph[x - &#x27;a&#x27;].add(y - &#x27;a&#x27;); graph[y - &#x27;a&#x27;].add(x - &#x27;a&#x27;); &#125; &#125; int[] color = new int[26]; // 准备26种颜色 int t = 0; for (int i = 0; i &lt; 26; i++) &#123; if (color[i] == 0) &#123; // 第i个字母还没染色 t++; // 增加一种颜色 Stack&lt;Integer&gt; s = new Stack&lt;Integer&gt;(); s.push(i); while (!s.isEmpty()) &#123; int node = s.pop(); for (int nn : graph[node]) &#123;// 取出与node连通的所有点， 即取出等式两边的字母 if (color[nn] == 0) &#123; color[nn] = t; // 连通的节点设置成相同的颜色 s.push(nn); // 将与之连通的节点进栈，实现等式传递性的功能 &#125; &#125; &#125; &#125; &#125; // 检查不等式的合法性 for (String eq : equations) &#123; if (eq.charAt(1) == &#x27;!&#x27;) &#123; int x = eq.charAt(0) - &#x27;a&#x27;; int y = eq.charAt(3) - &#x27;a&#x27;; if (x == y || color[x] != 0 &amp;&amp; color[x] == color[y]) &#123; // 字母相等，颜色相同的一定不满足不等关系 return false; &#125; &#125; &#125; return true; &#125; public static void main(String[] args) &#123; String[] equations1 = &#123;&quot;c==c&quot;, &quot;b==d&quot;, &quot;x!=z&quot;&#125;; String[] equations2 = &#123;&quot;a==b&quot;, &quot;b==c&quot;, &quot;a==c&quot;&#125;; String[] equations3 = &#123;&quot;b==a&quot;, &quot;a!=b&quot;&#125;; System.out.println(equationsPossible_DFS(equations1)); // true System.out.println(equationsPossible_DFS(equations2)); // true System.out.println(equationsPossible_DFS(equations3)); // false &#125;&#125; 复杂度分析 时间复杂度： O(N)，其中 N是方程组 equations 的数量。 空间复杂度： O(1），认为字母表的大小是 O(1) 的。","path":"2020/01/28/leetcode-990-等式方程的可满足性/","date":"01-28","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"Java的自动装箱和拆箱","text":"自动装箱/拆箱 自动装箱：指开发人员可以把一个基本数据类型直接赋给对应的包装类。 自动拆箱：指开发人员可以把一个包装类对象直接赋给对应的基本数据类型。 基本数据类型包装类 包装类 基本数据类型 Byte byte Integer int Long long Boolean boolean Float float Double double Character char 对象变基本数据类型:拆箱 基本数据类型包装为对象:装箱 在使用这些基本类型对应的包装类型时，如果该数值范围在缓冲池范围内，就可以直接使用缓冲池中的对象。 Example： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Demo5 &#123; public static void main(String[] args) &#123; String str = &quot;12&quot;; //字符串转换成int类型数据。 可以把字符串转换成对应的数字 int i = Integer.parseInt(str); System.out.println(i+1); //把数字转换成字符串 System.out.println(&quot;把整数转换成对应 的字符串：&quot;+Integer.toString(i)); //把整数转换成对应的进制形式 System.out.println(&quot;10的二进制：&quot;+ Integer.toBinaryString(10)); System.out.println(&quot;10的二进制：&quot;+ Integer.toBinaryString(10)); System.out.println(&quot;10的十六进制：&quot;+ Integer.toHexString(10)); //可以把字符串当成对应的进行数据帮你转换 String data = &quot;10&quot;; int a = Integer.parseInt(data, 2); System.out.println(&quot;a=&quot;+a); //集合： 集合是可以存储任意对象类型数据的容器。 ArrayList list = new ArrayList(); list.add(1); list.add(2); list.add(3); //自动装箱： 自动把java的基本数据类型数据转换成对象类型数据。 int temp = 10; //基本数据类型 Integer b =temp; //把a存储的值赋予给b变量。 //自动拆箱： 把引用类型的数据转换成基本类型的数据 Integer c = new Integer(13); int d = c; // System.out.println(d); //引用的数据类型 Integer e = 127; Integer f = 127; System.out.println(&quot;同一个对象吗？&quot;+(e==f)); // ture &#125; &#125; 注意： Integer类内部维护 了缓冲数组，该缓冲数组存储的-128~127这些数据在一个数组中。如果你获取的数据是落入到这个范围之内的，那么就直接从该缓冲区中获取对应的数据。【Java8】 编译器会在自动装箱过程调用 valueOf() 方法，因此多个值相同且值在缓存池范围内的 Integer 实例使用自动装箱来创建，那么就会引用相同的对象。 123456789101112131415public class integer &#123; public static void main(String[] args) &#123; Integer a = new Integer(111); Integer b = new Integer(111); Integer c = Integer.valueOf(111); Integer d = Integer.valueOf(111); System.out.println(a == b); System.out.println(c == d); &#125;&#125; 结果： false true new Integer(123) 与 Integer.valueOf(123) 的区别在于： new Integer(123) 每次都会新建一个对象； Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 看下面的例子： 123456789101112131415161718192021/** * @author Hongliang Zhu * @create 2020-01-28 11:38 */public class integer &#123; public static void main(String[] args) &#123; Integer a = new Integer(160); Integer b = new Integer(160); Integer c = Integer.valueOf(160); Integer d = Integer.valueOf(160); System.out.println(a == b); System.out.println(c == d); &#125;&#125; 结果为： false false 因为160超过了缓存的范围（-128-127），所以都是不同的对象， valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。 如果不在缓存池中，则会new一个Integer对象。 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); &#125; 看源码： 123456789101112131415161718192021222324252627282930313233 private static class IntegerCache &#123; static final int low = -128; static final int high; static final Integer cache[]; static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127; &#125; private IntegerCache() &#123;&#125;&#125; ​ 在 jdk 1.8 所有的数值类缓冲池中，Integer 的缓冲池 IntegerCache 很特殊，这个缓冲池的下界是 - 128，上界默认是 127，但是这个上界是可调的，在启动 jvm 的时候，通过 -XX:AutoBoxCacheMax= 来指定这个缓冲池的大小，该选项在 JVM 初始化的时候会设定一个名为 java.lang.IntegerCache.high 系统属性，然后 IntegerCache 初始化的时候就会读取该系统属性来决定上界。 参考 [https://cyc2018.github.io/CS-Notes/#/notes/Java%20%E5%9F%BA%E7%A1%80](https://cyc2018.github.io/CS-Notes/#/notes/Java 基础) https://blog.csdn.net/Castile_zhu/article/details/78822267","path":"2020/01/28/Java的自动装箱和拆箱/","date":"01-28","excerpt":"","tags":[{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"java基础","slug":"java基础","permalink":"https://castile.github.io/tags/java%E5%9F%BA%E7%A1%80/"}]},{"title":"leetcode-684-冗余连接","text":"描述 Leetcode684:RedundantConnection 冗余连接①： 在本问题中, 树指的是一个连通且无环的无向图。 输入一个图，该图由一个有着N个节点 (节点值不重复1, 2, …, N) 的树及一条附加的边构成。附加的边的两个顶点包含在1到N中间，这条附加的边不属于树中已存在的边。 结果图是一个以边组成的二维数组。每一个边的元素是一对[u, v] ，满足 u &lt; v，表示连接顶点u 和v的无向图的边。 返回一条可以删去的边，使得结果图是一个有着N个节点的树。如果有多个答案，则返回二维数组中最后出现的边。答案边 [u, v] 应满足相同的格式 u &lt; v。 示例 1： 输入: [[1,2], [1,3], [2,3]]输出: [2,3]解释: 给定的无向图为: 1 / 2 - 3示例 2： 输入: [[1,2], [2,3], [3,4], [1,4], [1,5]]输出: [1,4]解释: 给定的无向图为:5 - 1 - 2 | | 4 - 3注意: 输入的二维数组大小在 3 到 1000。二维数组中的整数在1到N之间，其中N是输入数组的大小。链接：https://leetcode-cn.com/problems/redundant-connection 分析并查集的应用： 直接看代码，一次AC 代码12345678910111213141516171819202122232425262728293031323334353637383940import java.util.Arrays;/** * @author Hongliang Zhu * @create 2020-01-27 10:17 *//*Leetcode684:RedundantConnection 冗余连接① */public class leetcode684_RedundantConnection &#123; public static int[] findRedundantConnection(int[][] edges) &#123; if(edges == null || edges.length == 0) return null; int n = edges.length; System.out.println(n); UF uf = new UF(n+1); for(int[] edge: edges)&#123; if(!uf.isSameSet(edge[0], edge[1]))&#123; uf.union(edge[0], edge[1]); &#125;else&#123; return edge; &#125; &#125; return null; &#125; public static void main(String[] args) &#123; int [][]edges = &#123;&#123; 1,2 &#125;,&#123;1,3&#125;,&#123; 2,3&#125;&#125;; int []res = findRedundantConnection(edges); System.out.println(Arrays.toString(res)); &#125;&#125;","path":"2020/01/27/leetcode-684-冗余连接/","date":"01-27","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-130-被围绕的区域","text":"描述 Leetcode-130： 被围绕的区域 给定一个二维的矩阵，包含 ‘X’ 和 ‘O’（字母 O）。 找到所有被 ‘X’ 围绕的区域，并将这些区域里所有的 ‘O’ 用 ‘X’ 填充。 示例: X X X XX O O XX X O XX O X X运行你的函数后，矩阵变为： X X X XX X X XX X X XX O X X解释: 被围绕的区间不会存在于边界上，换句话说，任何边界上的 ‘O’ 都不会被填充为 ‘X’。 任何不在边界上，或不与边界上的 ‘O’ 相连的 ‘O’ 最终都会被填充为 ‘X’。如果两个元素在水平或垂直方向相邻，则称它们是“相连”的。 链接：https://leetcode-cn.com/problems/surrounded-regions 分析 dfs搜索：将边界上的‘O’及其连通的先设置成‘#’标识，这些是不会被填充的，等搜索完毕之后再将这些标志换回‘O’。而在里面的‘O’就是被包围的区域，通过双层循环将里面的’O‘替换成’X‘即可。 并查集：并查集的思想就是，同一个连通区域内的所有点的根节点是同一个。将每个点映射成一个数字。先假设每个点的根节点就是他们自己，然后我们以此输入连通的点对，然后将其中一个点的根节点赋成另一个节点的根节点，这样这两个点所在连通区域又相互连通了。 并查集代码：UF 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @author Hongliang Zhu * @create 2020-01-25 21:25 */// 并查集 UFpublic class UF &#123; private int count = 0; // 连通分量 private int[] parent; // 新增一个数组记录树的“重量” private int[] size; // 构造 public UF(int n)&#123; // n个元素 this.count = n; size = new int[n]; parent = new int[n]; // 一开始每一个节点自成一个集合，都不连通 for (int i = 0; i &lt; n; i++)&#123; parent[i] = i; // 自己的父节点指向自己 size[i] = 1; // 每隔几何只有自身一个元素 &#125; &#125; public int find(int x)&#123; int root = parent[x]; while (parent[x] != x)&#123; // 路径压缩 x = parent[x]; &#125; return x; &#125; public boolean isSameSet(int a, int b)&#123; return find(a) == find(b); &#125; public int count()&#123; return count; &#125; public void union(int a, int b)&#123; int rootA = find(a); int rootB = find(b); if(rootA == rootB)&#123; return; // 同一个集合不能合并 &#125;else&#123; if(size[rootA] &gt; size[rootB])&#123; parent[rootB] = rootA; size[rootA] += size[rootB]; &#125;else &#123; parent[rootA] = rootB; size[rootB] += size[rootA]; &#125; &#125; count--; // 连通分量个数减一 &#125;&#125; 可以把那些不需要被替换的 O 看成一个拥有独门绝技的门派，它们有一个共同祖师爷叫 **dummy**，这些 O 和 dummy 互相连通，而那些需要被替换的 O 与 dummy 不连通。 如下图: ​ 首先要解决的是，根据我们的实现，Union-Find 底层用的是一维数组，构造函数需要传入这个数组的大小，而题目给的是一个二维棋盘。 ​ 这个很简单，二维坐标 (x,y) 可以转换成 x * n + y 这个数（m 是棋盘的行数，n 是棋盘的列数）。敲黑板，这是将二维坐标映射到一维的常用技巧。 ​ 其次，我们之前描述的「祖师爷」是虚构的，需要给他老人家留个位置。索引 [0.. m*n-1] 都是棋盘内坐标的一维映射，那就让这个虚拟的 dummy 节点占据索引 m * n 好了。 ​ 我们的思路是把所有边界上的 O看做一个连通区域。遇到 O 就执行并查集合并操作，这样所有的 O 就会被分成两类 和边界上的 O在一个连通区域内的。这些 O 我们保留。 不和边界上的O 在一个连通区域内的。这些 O 就是被包围的，替换。 代码 dfs版本 123456789101112131415161718192021222324252627282930313233343536373839404142class Solution &#123; int[][] directions = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; public void solve(char[][] board) &#123; if(board == null || board.length == 0) return; int m = board.length; int n = board[0].length; // 边缘搜索 for(int i = 0; i &lt; m; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; if((i == 0 || j == 0 || i == m-1 || j == n-1) &amp;&amp; (board[i][j] == &#x27;O&#x27;))&#123; dfs(board, i, j); &#125; &#125; &#125; // for(int i = 0; i &lt; m; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; if(board[i][j] == &#x27;O&#x27;)&#123; board[i][j] = &#x27;X&#x27;; &#125; if(board[i][j] == &#x27;#&#x27;)&#123; board[i][j] = &#x27;O&#x27;; &#125; &#125; &#125; &#125; public void dfs(char[][] board, int i, int j)&#123; if(i &lt; 0 || j &lt; 0 || i &gt;= board.length || j &gt;= board[0].length || board[i][j] != &#x27;O&#x27;) return; board[i][j] = &#x27;#&#x27;; for(int[] d: directions)&#123; dfs(board, i+d[0], d[1]+j); &#125; &#125;&#125; 并查集 1234567891011121314151617181920212223242526272829303132333435363738394041// 使用并查集解决public static void solveUF(char[][] board) &#123; if(board==null || board.length == 0) return; int m = board.length; int n = board[0].length; // 边界上的‘O’的根节点都是dummy UF uf = new UF(n * m + 1);// 增加一个存储dummy节点 int dummy = m * n; for(int i = 0; i &lt; m; i++)&#123; for(int j = 0; j &lt; n; j++)&#123; if(board[i][j] == &#x27;O&#x27;)&#123; // 目标 if(i == 0 || j == 0 || i == m -1 || j == n -1) &#123; // 如果是边界上的&#x27;O&#x27;， 与dummy合并 uf.union(i*n+j, dummy); &#125;else&#123; // 里面的 // 方向数组 d 是上下左右搜索的常用手法 int[][] d = new int[][]&#123;&#123;1,0&#125;, &#123;0,1&#125;, &#123;0,-1&#125;, &#123;-1,0&#125;&#125;; // 将此 O 与上下左右的 O 连通 for (int k = 0; k &lt; 4; k++) &#123; int x = i + d[k][0]; int y = j + d[k][1]; if (board[x][y] == &#x27;O&#x27;) uf.union(x * n + y, i * n + j); &#125; &#125; &#125; &#125; &#125; for (int i = 1; i &lt; m-1; i++)&#123; for( int j = 1; j &lt; n-1; j++)&#123; if(!uf.isSameSet(i*n+j, dummy))&#123; board[i][j] = &#x27;X&#x27;; &#125; &#125; &#125; &#125; 参考： https://cyc2018.github.io/CS-Notes https://labuladong.gitbook.io/algo/gao-pin-mian-shi-xi-lie/unionfind-suan-fa-ying-yong#yi-dfs-de-ti-dai-fang-an","path":"2020/01/26/leetcode-130-被围绕的区域/","date":"01-26","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"}]},{"title":"leetcode-1-两数之和","text":"描述 给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9所以返回 [0, 1]链接：https://leetcode-cn.com/problems/two-sum 分析 暴力方法： 直接两层循环，时间复杂度较高：O(n^2^) 哈希方法：使用哈希表可以实现O(1)级别的存取。存储每个数对应的下标，复杂度 O(n) 参考： HashMap的时间复杂度O(1)的思考： ​ 原文链接：https://blog.csdn.net/donggua3694857/article/details/64127131 Java代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package Arrays;import java.util.HashMap;/** * @author Hongliang Zhu * @create 2020-01-23 21:39 */public class leetcode_1_twoSum &#123; // 暴力法 public static int[] twoSum(int[] nums, int target) &#123; int[] a = new int[2]; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = i + 1; j &lt; nums.length; j++) &#123; if (nums[i] + nums[j] == target) &#123; a[0] = i; a[1] = j; break; &#125; &#125; &#125; return a; &#125; // 哈希 public static int[] twoSum1(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; mymap = new HashMap&lt;&gt;(); for(int i = 0; i &lt; nums.length; i++)&#123; mymap.put(nums[i], i); &#125; for(int i = 0; i &lt; nums.length; i++)&#123; int t = target - nums[i]; if(mymap.containsKey(t) &amp;&amp; mymap.get(t) != i )&#123;// 注意后面这个条件，题目要求 return new int[] &#123;i,mymap.get(t)&#125;; &#125; &#125; return null; &#125; public static void main(String[] args) &#123; int[] nums = &#123; 2,11,15, 7&#125;; int target = 9; int []result = twoSum1(nums, target); for (int i = 0; i &lt; result.length; i++) &#123; System.out.println(result[i]); &#125; &#125;&#125; 参考HashMap： https://mp.weixin.qq.com/s?__biz=MzI4Njg5MDA5NA==&amp;mid=2247486169&amp;idx=2&amp;sn=9818c995d51a19cd4a40c2605bdcfa5d&amp;chksm=ebd74bd8dca0c2cefe86f54bcdd7f799ceda0a14deb72a4fcec7efa29fc3deffbc6e80d8a90f&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1575479594341&amp;sharer_shareid=2d7d0e474d11d42bad66b1f70e2c85ff&amp;key=688085f24308deb8e963b43a687ea8ed3be23533e2ae4e751f02a336bb46979d39e6c74e731daa5fc22d9e719338c7f0f98152a12a38beef1d0023e2939dd0eda93264a9d032b8cc555448c332453c25&amp;ascene=1&amp;uin=MjA3NDA5MzU4MQ==&amp;devicetype=Windows%2010&amp;version=62070158&amp;lang=zh_CN&amp;exportkey=A5ZIZKTn0EuksyOXwEiV%2bEk=&amp;pass_ticket=Nb/JBXAYTcQup5FBKcfsQy6kFv5X2eJwQ333U4h1UYJmrnawwezuSj8nX18XzQ8s","path":"2020/01/23/leetcode-1-两数之和/","date":"01-23","excerpt":"","tags":[{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"}]},{"title":"leetcode-128-最长连续序列","text":"描述 LeetCode128: 最长连续序列longest-consecutive-sequence 给定一个未排序的整数数组，找出最长连续序列的长度。 要求算法的时间复杂度为 ==O(n)==。 【困难】 示例: 输入: [100, 4, 200, 1, 3, 2]输出: 4解释: 最长连续序列是 [1, 2, 3, 4]。它的长度为 4。 链接：https://leetcode-cn.com/problems/longest-consecutive-sequence 分析​ 如果允许O(nlogn)的复杂度，那么可以先排序，可是本题要求 O(n) 。由于序列里的元素是无序的，又要求 O(n) ，首先要想到用哈希表。用一个哈希表存储所有出现过的元素，对每个元素，以该元素为中心，往左右扩张，直到不连续为止，记 录下最长的长度。 Java代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445package Arrays;import java.util.HashSet;/** * @author Hongliang Zhu * @create 2020-01-22 18:15 *//*给定一个未排序的整数数组，找出最长连续序列的长度。要求算法的时间复杂度为 O(n)。 */public class leetcode128_LongestConsecutiveSequence &#123; public static int longestConsecutive(int[] nums) &#123; HashSet&lt;Integer&gt; myset = new HashSet&lt;&gt;(); for(int i: nums)&#123; myset.add(i); &#125; int longest = 0; for(int i: nums) &#123; int len = 1; for(int j = i+1; myset.contains(j); j++)&#123; myset.remove(j); len++; &#125; for (int j = i - 1; myset.contains(j); j--)&#123; myset.remove(j); len++; &#125; longest = Math.max(longest, len); &#125; return longest; &#125; public static void main(String[] args) &#123; int []nums = &#123;100, 4, 200, 1, 3, 2&#125;; int len = longestConsecutive(nums); System.out.println(len); &#125;&#125; 输出4 时间复杂度为O(n) ， 空间复杂度O(n) Leetcode官方： 12345678910111213141516171819202122232425262728293031class Solution &#123; public int longestConsecutive(int[] nums) &#123; if (nums.length == 0) &#123; return 0; &#125; Arrays.sort(nums); int longestStreak = 1; int currentStreak = 1; for (int i = 1; i &lt; nums.length; i++) &#123; if (nums[i] != nums[i-1]) &#123; if (nums[i] == nums[i-1]+1) &#123; currentStreak += 1; &#125; else &#123; longestStreak = Math.max(longestStreak, currentStreak); currentStreak = 1; &#125; &#125; &#125; return Math.max(longestStreak, currentStreak); &#125;&#125;作者：LeetCode链接：https://leetcode-cn.com/problems/longest-consecutive-sequence/solution/zui-chang-lian-xu-xu-lie-by-leetcode/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","path":"2020/01/22/leetcode-128-LongestConsecutiveSequence/","date":"01-22","excerpt":"","tags":[{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"哈希","slug":"哈希","permalink":"https://castile.github.io/tags/%E5%93%88%E5%B8%8C/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"}]},{"title":"leetcode-80-删除排序数组的重复项2","text":"描述leetcode-80-删除排序数组的重复项2： 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素最多出现两次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。链接：https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array-ii相似题目： https:/Castile.github.io/2020/01/21/leetcode26-删除排序数组的重复项/ ==tag：双指针思想== 示例 1: 给定 nums = [1,1,1,2,2,3], 函数应返回新长度 length = 5, 并且原数组的前五个元素被修改为 1, 1, 2, 2, 3 。 你不需要考虑数组中超出新长度后面的元素。示例 2: 给定 nums = [0,0,1,1,1,1,2,3,3], 函数应返回新长度 length = 7, 并且原数组的前五个元素被修改为 0, 0, 1, 1, 2, 3, 3 。 你不需要考虑数组中超出新长度后面的元素。 分析​ 覆盖多余的重复项。由于题目要求原地操作，设置两个指针，一个为快指针，用来遍历整个数组，一个慢指针，用来记录数组的长度以及覆盖数组的位置下标。题目要求每个元素最多出现两次，则应该引入一个计数变量，记录元素出现的次数。 ​ 特别地，题目给的数组为已经排好序的数组，如果未排序，则需要引入一个hashmap来记录出现次数。 ​ 从下标1开始遍历，nums[i-1] ?= nums[i] ：如果相等，则更新 时间复杂度O(n)， 空间复杂度O(1) Java代码实现1234567891011121314151617181920212223242526272829303132333435363738394041/** * @author Hongliang Zhu * @create 2020-01-22 10:07 */public class leetcode_80_remove_duplicates_from_sorted_array_ii &#123; public static int removeDuplicates(int[] nums) &#123; if(nums.length == 0) return 0; int p = 1; int c = 1; // 计数 for(int i = 1; i &lt; nums.length; i++)&#123; if(nums[i] == nums[i-1])&#123; c++; &#125;else &#123; c = 1; //复位 &#125; if( c &lt;= 2) &#123; nums[p] = nums[i]; p++; &#125; &#125; return p; &#125; public static void main(String[] args) &#123; int []nums = &#123;0,0,1,1,1,1,2,3,3&#125;; int len = removeDuplicates(nums); System.out.println(len); for (int i = 0; i &lt; len; i++) &#123; System.out.println(nums[i]); &#125; &#125;&#125; 输出： 1270,0,1,1,2,3,3, 另外： 1234567891011121314public static int removeDuplicates2(int[] nums) &#123; if (nums.length &lt;= 2)&#123; return nums.length; &#125; int index = 2; for(int i = 2; i &lt; nums.length; i++)&#123; if(nums[index-2] != nums[i])&#123; nums[index++] = nums[i]; &#125; &#125; return index;&#125; 扩展性，例如将上面的数字2 改为 3 ， 就变成了允许重复最多3次。 **相似题目： https:/Castile.github.io/2020/01/21/leetcode26-删除排序数组的重复项/","path":"2020/01/22/leetcode-80-删除排序数组的重复项2/","date":"01-22","excerpt":"","tags":[{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"双指针","slug":"双指针","permalink":"https://castile.github.io/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]},{"title":"leetcode26-删除排序数组的重复项","text":"描述 给定一个排序数组，你需要在原地删除重复出现的元素，使得每个元素只出现一次，返回移除后数组的新长度。不要使用额外的数组空间，你必须在原地修改输入数组并在使用 O(1) 额外空间的条件下完成。链接：https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array 示例 1: 给定数组 nums = [1,1,2], 函数应该返回新的长度 2, 并且原数组 nums 的前两个元素被修改为 1, 2。 你不需要考虑数组中超出新长度后面的元素。 示例 2: 给定 nums = [0,0,1,1,1,2,2,3,3,4], 函数应该返回新的长度 5, 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 思路可以采用快慢指针，即双指针思路，这种方法在线性表查重，判断环上用的比较多。 ​ 数组完成排序后，我们可以放置两个指针 p 和q，其中p是慢指针，而 q 是快指针。只要 nums[p] = nums[q]，我们就增加 q以跳过重复项。当我们遇到 nums[p] ≠ nums[q] 时，跳过重复项的运行已经结束，因此我们必须把它（nums[q]）的值复制到 nums[p+1]。然后递增 p，接着我们将再次重复相同的过程，直到q到达数组的末尾为止。 ​ 时间复杂度O(n), 空间复杂度O(1)： 123456789101112131415161718192021class Solution &#123; public int removeDuplicates(int[] nums) &#123; if(nums.length == 0)&#123; return 0; &#125; int p = 0; int q = 1; while(q &lt; nums.length)&#123; if(nums[p] == nums[q])&#123; q++; &#125;else&#123; nums[p+1] = nums[q]; p++; &#125; &#125; return p + 1 ; &#125;&#125; 相关： https:/Castile.github.io/2020/01/22/leetcode-80-删除排序数组的重复项2/","path":"2020/01/21/leetcode26-删除排序数组的重复项/","date":"01-21","excerpt":"","tags":[{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"最长公共子序列问题","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#include&lt;bits/stdc++.h&gt;using namespace std;/* 最长公共子序列问题 2019-12-15 12:48:14*/char x[100];char y[100];int dp[100][100];int b[100][100];int LCS(char x[], char y[],int m, int n)&#123; // 初始化 for (int i = 0; i &lt;= m; i++) // 初始化第一列 &#123; dp[i][0] = 0; &#125; for (int i = 0; i &lt;= n; i++) &#123; dp[0][i] = 0; // 初始化第一行 &#125; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; if (x[i] == y[j]) &#123; dp[i][j] = dp[i - 1][j - 1] + 1; b[i][j] = 1; &#125; else if (dp[i - 1][j] &gt;= dp[i][j - 1]) &#123; dp[i][j] = dp[i - 1][j]; b[i][j] = 2; &#125; else &#123; dp[i][j] = dp[i][j - 1]; b[i][j] = 3; &#125; &#125; &#125; return dp[m][n];&#125;// 根据b矩阵得出最长公共子序列stack&lt;char&gt; s;void getLCS(int i, int j)&#123; // basecase if (i &gt; 0 &amp;&amp; j &gt; 0) &#123; if (b[i][j] == 1) &#123; s.push(x[i]); getLCS(i - 1, j - 1); &#125; if (b[i][j] == 2) &#123; getLCS(i - 1, j); &#125; if (b[i][j] == 3) &#123; getLCS(i, j - 1); &#125; &#125; &#125;int main()&#123; int m, n = 0; cin &gt;&gt; m &gt;&gt; n; for (int i = 1; i &lt;= m; i++) &#123; cin &gt;&gt; x[i]; &#125; for (int i = 1; i &lt;= n; i++) &#123; cin &gt;&gt; y[i]; &#125; cout &lt;&lt; LCS(x, y, m, n) &lt;&lt; endl; //dp矩阵 for (int i = 0; i &lt;= m; i++) &#123; for (int j = 0; j &lt;= n; j++) &#123; cout &lt;&lt; dp[i][j] &lt;&lt; &quot;\\t&quot;; &#125; cout &lt;&lt; endl; &#125; cout &lt;&lt; endl; getLCS(m, n); //打印最长公共子序列 while (!s.empty()) &#123; cout &lt;&lt; s.top() &lt;&lt; endl; s.pop(); &#125; system(&quot;pause&quot;); return 0;&#125;","path":"2020/01/20/最长公共子序列问题/","date":"01-20","excerpt":"","tags":[{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"}]}],"categories":[],"tags":[{"name":"DDD","slug":"DDD","permalink":"https://castile.github.io/tags/DDD/"},{"name":"领域驱动设计","slug":"领域驱动设计","permalink":"https://castile.github.io/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1/"},{"name":"限界上下文","slug":"限界上下文","permalink":"https://castile.github.io/tags/%E9%99%90%E7%95%8C%E4%B8%8A%E4%B8%8B%E6%96%87/"},{"name":"nebula","slug":"nebula","permalink":"https://castile.github.io/tags/nebula/"},{"name":"图数据库","slug":"图数据库","permalink":"https://castile.github.io/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Thread","slug":"Thread","permalink":"https://castile.github.io/tags/Thread/"},{"name":"多线程","slug":"多线程","permalink":"https://castile.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"Java","slug":"Java","permalink":"https://castile.github.io/tags/Java/"},{"name":"设计模式","slug":"设计模式","permalink":"https://castile.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"锁","slug":"锁","permalink":"https://castile.github.io/tags/%E9%94%81/"},{"name":"io","slug":"io","permalink":"https://castile.github.io/tags/io/"},{"name":"mysql","slug":"mysql","permalink":"https://castile.github.io/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://castile.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"},{"name":"Lambda","slug":"Lambda","permalink":"https://castile.github.io/tags/Lambda/"},{"name":"纯函数","slug":"纯函数","permalink":"https://castile.github.io/tags/%E7%BA%AF%E5%87%BD%E6%95%B0/"},{"name":"NiFi","slug":"NiFi","permalink":"https://castile.github.io/tags/NiFi/"},{"name":"文档","slug":"文档","permalink":"https://castile.github.io/tags/%E6%96%87%E6%A1%A3/"},{"name":"Stateless","slug":"Stateless","permalink":"https://castile.github.io/tags/Stateless/"},{"name":"SSL","slug":"SSL","permalink":"https://castile.github.io/tags/SSL/"},{"name":"ssl","slug":"ssl","permalink":"https://castile.github.io/tags/ssl/"},{"name":"nifi","slug":"nifi","permalink":"https://castile.github.io/tags/nifi/"},{"name":"身份验证","slug":"身份验证","permalink":"https://castile.github.io/tags/%E8%BA%AB%E4%BB%BD%E9%AA%8C%E8%AF%81/"},{"name":"RPC","slug":"RPC","permalink":"https://castile.github.io/tags/RPC/"},{"name":"rpc","slug":"rpc","permalink":"https://castile.github.io/tags/rpc/"},{"name":"Netty","slug":"Netty","permalink":"https://castile.github.io/tags/Netty/"},{"name":"Flink","slug":"Flink","permalink":"https://castile.github.io/tags/Flink/"},{"name":"Operator Chain","slug":"Operator-Chain","permalink":"https://castile.github.io/tags/Operator-Chain/"},{"name":"Slots","slug":"Slots","permalink":"https://castile.github.io/tags/Slots/"},{"name":"软件复杂性","slug":"软件复杂性","permalink":"https://castile.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%A4%8D%E6%9D%82%E6%80%A7/"},{"name":"战略设计","slug":"战略设计","permalink":"https://castile.github.io/tags/%E6%88%98%E7%95%A5%E8%AE%BE%E8%AE%A1/"},{"name":"战术设计","slug":"战术设计","permalink":"https://castile.github.io/tags/%E6%88%98%E6%9C%AF%E8%AE%BE%E8%AE%A1/"},{"name":"聚合","slug":"聚合","permalink":"https://castile.github.io/tags/%E8%81%9A%E5%90%88/"},{"name":"聚合算子","slug":"聚合算子","permalink":"https://castile.github.io/tags/%E8%81%9A%E5%90%88%E7%AE%97%E5%AD%90/"},{"name":"算子","slug":"算子","permalink":"https://castile.github.io/tags/%E7%AE%97%E5%AD%90/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://castile.github.io/tags/SpringBoot/"},{"name":"秒杀项目","slug":"秒杀项目","permalink":"https://castile.github.io/tags/%E7%A7%92%E6%9D%80%E9%A1%B9%E7%9B%AE/"},{"name":"spring-batch","slug":"spring-batch","permalink":"https://castile.github.io/tags/spring-batch/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://castile.github.io/tags/RabbitMQ/"},{"name":"mq","slug":"mq","permalink":"https://castile.github.io/tags/mq/"},{"name":"消息中间件","slug":"消息中间件","permalink":"https://castile.github.io/tags/%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"flink","slug":"flink","permalink":"https://castile.github.io/tags/flink/"},{"name":"linux","slug":"linux","permalink":"https://castile.github.io/tags/linux/"},{"name":"blog","slug":"blog","permalink":"https://castile.github.io/tags/blog/"},{"name":"网络","slug":"网络","permalink":"https://castile.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"https","slug":"https","permalink":"https://castile.github.io/tags/https/"},{"name":"refactory","slug":"refactory","permalink":"https://castile.github.io/tags/refactory/"},{"name":"NIO","slug":"NIO","permalink":"https://castile.github.io/tags/NIO/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://castile.github.io/tags/ZooKeeper/"},{"name":"hosts","slug":"hosts","permalink":"https://castile.github.io/tags/hosts/"},{"name":"ssh免密","slug":"ssh免密","permalink":"https://castile.github.io/tags/ssh%E5%85%8D%E5%AF%86/"},{"name":"centos","slug":"centos","permalink":"https://castile.github.io/tags/centos/"},{"name":"papers","slug":"papers","permalink":"https://castile.github.io/tags/papers/"},{"name":"中等","slug":"中等","permalink":"https://castile.github.io/tags/%E4%B8%AD%E7%AD%89/"},{"name":"贪心","slug":"贪心","permalink":"https://castile.github.io/tags/%E8%B4%AA%E5%BF%83/"},{"name":"算法","slug":"算法","permalink":"https://castile.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"困难","slug":"困难","permalink":"https://castile.github.io/tags/%E5%9B%B0%E9%9A%BE/"},{"name":"redis","slug":"redis","permalink":"https://castile.github.io/tags/redis/"},{"name":"gc","slug":"gc","permalink":"https://castile.github.io/tags/gc/"},{"name":"JVM","slug":"JVM","permalink":"https://castile.github.io/tags/JVM/"},{"name":"模板","slug":"模板","permalink":"https://castile.github.io/tags/%E6%A8%A1%E6%9D%BF/"},{"name":"topK","slug":"topK","permalink":"https://castile.github.io/tags/topK/"},{"name":"字符串","slug":"字符串","permalink":"https://castile.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/"},{"name":"腾讯","slug":"腾讯","permalink":"https://castile.github.io/tags/%E8%85%BE%E8%AE%AF/"},{"name":"笔试","slug":"笔试","permalink":"https://castile.github.io/tags/%E7%AC%94%E8%AF%95/"},{"name":"校招","slug":"校招","permalink":"https://castile.github.io/tags/%E6%A0%A1%E6%8B%9B/"},{"name":"excel","slug":"excel","permalink":"https://castile.github.io/tags/excel/"},{"name":"tools","slug":"tools","permalink":"https://castile.github.io/tags/tools/"},{"name":"plugin","slug":"plugin","permalink":"https://castile.github.io/tags/plugin/"},{"name":"插件","slug":"插件","permalink":"https://castile.github.io/tags/%E6%8F%92%E4%BB%B6/"},{"name":"spring","slug":"spring","permalink":"https://castile.github.io/tags/spring/"},{"name":"aop","slug":"aop","permalink":"https://castile.github.io/tags/aop/"},{"name":"mybatis","slug":"mybatis","permalink":"https://castile.github.io/tags/mybatis/"},{"name":"juc","slug":"juc","permalink":"https://castile.github.io/tags/juc/"},{"name":"synchronized","slug":"synchronized","permalink":"https://castile.github.io/tags/synchronized/"},{"name":"volatile","slug":"volatile","permalink":"https://castile.github.io/tags/volatile/"},{"name":"并发","slug":"并发","permalink":"https://castile.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"jvm","slug":"jvm","permalink":"https://castile.github.io/tags/jvm/"},{"name":"dp","slug":"dp","permalink":"https://castile.github.io/tags/dp/"},{"name":"简单","slug":"简单","permalink":"https://castile.github.io/tags/%E7%AE%80%E5%8D%95/"},{"name":"数学","slug":"数学","permalink":"https://castile.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"数据结构","slug":"数据结构","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"web","slug":"web","permalink":"https://castile.github.io/tags/web/"},{"name":"人工智能","slug":"人工智能","permalink":"https://castile.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"},{"name":"latex","slug":"latex","permalink":"https://castile.github.io/tags/latex/"},{"name":"UVOS","slug":"UVOS","permalink":"https://castile.github.io/tags/UVOS/"},{"name":"errors","slug":"errors","permalink":"https://castile.github.io/tags/errors/"},{"name":"maven","slug":"maven","permalink":"https://castile.github.io/tags/maven/"},{"name":"JavaWeb","slug":"JavaWeb","permalink":"https://castile.github.io/tags/JavaWeb/"},{"name":"Attention","slug":"Attention","permalink":"https://castile.github.io/tags/Attention/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://castile.github.io/tags/Pytorch/"},{"name":"Mysql","slug":"Mysql","permalink":"https://castile.github.io/tags/Mysql/"},{"name":"davis","slug":"davis","permalink":"https://castile.github.io/tags/davis/"},{"name":"matlab","slug":"matlab","permalink":"https://castile.github.io/tags/matlab/"},{"name":"Http","slug":"Http","permalink":"https://castile.github.io/tags/Http/"},{"name":"Servlet","slug":"Servlet","permalink":"https://castile.github.io/tags/Servlet/"},{"name":"快速排序","slug":"快速排序","permalink":"https://castile.github.io/tags/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/"},{"name":"排序","slug":"排序","permalink":"https://castile.github.io/tags/%E6%8E%92%E5%BA%8F/"},{"name":"递归","slug":"递归","permalink":"https://castile.github.io/tags/%E9%80%92%E5%BD%92/"},{"name":"归并排序","slug":"归并排序","permalink":"https://castile.github.io/tags/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/"},{"name":"反射","slug":"反射","permalink":"https://castile.github.io/tags/%E5%8F%8D%E5%B0%84/"},{"name":"数组","slug":"数组","permalink":"https://castile.github.io/tags/%E6%95%B0%E7%BB%84/"},{"name":"二分","slug":"二分","permalink":"https://castile.github.io/tags/%E4%BA%8C%E5%88%86/"},{"name":"VOS","slug":"VOS","permalink":"https://castile.github.io/tags/VOS/"},{"name":"IO","slug":"IO","permalink":"https://castile.github.io/tags/IO/"},{"name":"线程","slug":"线程","permalink":"https://castile.github.io/tags/%E7%BA%BF%E7%A8%8B/"},{"name":"链表","slug":"链表","permalink":"https://castile.github.io/tags/%E9%93%BE%E8%A1%A8/"},{"name":"数据集","slug":"数据集","permalink":"https://castile.github.io/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/"},{"name":"二叉树","slug":"二叉树","permalink":"https://castile.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"dfs","slug":"dfs","permalink":"https://castile.github.io/tags/dfs/"},{"name":"并查集","slug":"并查集","permalink":"https://castile.github.io/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/"},{"name":"搜索","slug":"搜索","permalink":"https://castile.github.io/tags/%E6%90%9C%E7%B4%A2/"},{"name":"位操作","slug":"位操作","permalink":"https://castile.github.io/tags/%E4%BD%8D%E6%93%8D%E4%BD%9C/"},{"name":"Java基础","slug":"Java基础","permalink":"https://castile.github.io/tags/Java%E5%9F%BA%E7%A1%80/"},{"name":"bfs","slug":"bfs","permalink":"https://castile.github.io/tags/bfs/"},{"name":"关键字","slug":"关键字","permalink":"https://castile.github.io/tags/%E5%85%B3%E9%94%AE%E5%AD%97/"},{"name":"java基础","slug":"java基础","permalink":"https://castile.github.io/tags/java%E5%9F%BA%E7%A1%80/"},{"name":"哈希","slug":"哈希","permalink":"https://castile.github.io/tags/%E5%93%88%E5%B8%8C/"},{"name":"双指针","slug":"双指针","permalink":"https://castile.github.io/tags/%E5%8F%8C%E6%8C%87%E9%92%88/"}]}